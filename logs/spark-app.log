23/12/01 14:03:17 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:03:17 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:03:17 INFO xnio: XNIO version 3.8.7.Final
23/12/01 14:03:17 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/01 14:03:17 INFO threads: JBoss Threads version 3.1.0.Final
23/12/01 14:03:17 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:03:17 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:03:17 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:03:17 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:03:17 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:03:17 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:03:17 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:03:17 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:03:17 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:03:17 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO xnio: XNIO version 3.8.7.Final
23/12/01 14:06:03 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/01 14:06:03 INFO threads: JBoss Threads version 3.1.0.Final
23/12/01 14:06:03 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:03 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:15 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/01 14:06:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/01 14:06:15 INFO SparkContext: Running Spark version 3.5.0
23/12/01 14:06:15 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 14:06:15 INFO SparkContext: Java version 11.0.20
23/12/01 14:06:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/01 14:06:15 INFO ResourceUtils: ==============================================================
23/12/01 14:06:15 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/01 14:06:15 INFO ResourceUtils: ==============================================================
23/12/01 14:06:15 INFO SparkContext: Submitted application: sparkApp
23/12/01 14:06:15 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/01 14:06:15 INFO ResourceProfile: Limiting resource is cpu
23/12/01 14:06:15 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/01 14:06:15 INFO SecurityManager: Changing view acls to: bsoleille
23/12/01 14:06:15 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/01 14:06:15 INFO SecurityManager: Changing view acls groups to: 
23/12/01 14:06:15 INFO SecurityManager: Changing modify acls groups to: 
23/12/01 14:06:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/01 14:06:16 INFO Utils: Successfully started service 'sparkDriver' on port 46553.
23/12/01 14:06:16 INFO SparkEnv: Registering MapOutputTracker
23/12/01 14:06:16 INFO SparkEnv: Registering BlockManagerMaster
23/12/01 14:06:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/01 14:06:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/01 14:06:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/01 14:06:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dd78f5f2-a984-4124-8d67-bdb3735edc5f
23/12/01 14:06:16 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/01 14:06:16 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/01 14:06:16 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/01 14:06:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/01 14:06:16 INFO Utils: Successfully started service 'SparkUI' on port 4041.
23/12/01 14:06:16 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/01 14:06:16 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 14:06:16 INFO Executor: Java version 11.0.20
23/12/01 14:06:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/01 14:06:16 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@98ac0fe for default.
23/12/01 14:06:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42381.
23/12/01 14:06:16 INFO NettyBlockTransferService: Server created on 10.25.86.80:42381
23/12/01 14:06:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/01 14:06:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 42381, None)
23/12/01 14:06:16 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:42381 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 42381, None)
23/12/01 14:06:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 42381, None)
23/12/01 14:06:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 42381, None)
23/12/01 14:06:16 WARN SharedState: URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
23/12/01 14:06:16 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/01 14:06:16 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/01 14:06:17 INFO CodeGenerator: Code generated in 95.170813 ms
23/12/01 14:06:18 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 14:06:18 INFO DAGScheduler: Got job 0 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 14:06:18 INFO DAGScheduler: Final stage: ResultStage 0 (show at ApiTest.worksheet.sc:166)
23/12/01 14:06:18 INFO DAGScheduler: Parents of final stage: List()
23/12/01 14:06:18 INFO DAGScheduler: Missing parents: List()
23/12/01 14:06:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 14:06:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 14:06:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 14:06:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:42381 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 14:06:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/01 14:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 14:06:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/01 14:06:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 14:06:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/01 14:06:18 INFO CodeGenerator: Code generated in 9.855458 ms
23/12/01 14:06:18 INFO CodeGenerator: Code generated in 27.07453 ms
23/12/01 14:06:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1677 bytes result sent to driver
23/12/01 14:06:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 149 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 14:06:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/01 14:06:18 INFO DAGScheduler: ResultStage 0 (show at ApiTest.worksheet.sc:166) finished in 0.249 s
23/12/01 14:06:18 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 14:06:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/01 14:06:18 INFO DAGScheduler: Job 0 finished: show at ApiTest.worksheet.sc:166, took 0.269522 s
23/12/01 14:06:18 INFO CodeGenerator: Code generated in 11.845163 ms
23/12/01 14:06:18 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.25.86.80:42381 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 14:06:18 INFO CodeGenerator: Code generated in 7.796168 ms
23/12/01 14:06:18 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 14:06:18 INFO DAGScheduler: Got job 1 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 14:06:18 INFO DAGScheduler: Final stage: ResultStage 1 (show at ApiTest.worksheet.sc:166)
23/12/01 14:06:18 INFO DAGScheduler: Parents of final stage: List()
23/12/01 14:06:18 INFO DAGScheduler: Missing parents: List()
23/12/01 14:06:18 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 14:06:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 14:06:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 14:06:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.25.86.80:42381 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 14:06:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
23/12/01 14:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 14:06:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/12/01 14:06:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 14:06:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/12/01 14:06:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1634 bytes result sent to driver
23/12/01 14:06:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 14:06:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/12/01 14:06:18 INFO DAGScheduler: ResultStage 1 (show at ApiTest.worksheet.sc:166) finished in 0.018 s
23/12/01 14:06:18 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 14:06:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/12/01 14:06:18 INFO DAGScheduler: Job 1 finished: show at ApiTest.worksheet.sc:166, took 0.019744 s
23/12/01 14:06:18 INFO CodeGenerator: Code generated in 7.586941 ms
23/12/01 14:06:18 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.25.86.80:42381 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 14:06:57 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:57 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:57 INFO xnio: XNIO version 3.8.7.Final
23/12/01 14:06:57 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/01 14:06:57 INFO threads: JBoss Threads version 3.1.0.Final
23/12/01 14:06:57 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:57 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:57 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:57 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:57 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:57 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:57 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:57 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:06:57 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 14:06:57 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 14:47:04 INFO CodeGenerator: Code generated in 8.44424 ms
23/12/01 14:47:04 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 14:47:04 INFO DAGScheduler: Got job 2 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 14:47:04 INFO DAGScheduler: Final stage: ResultStage 2 (show at ApiTest.worksheet.sc:166)
23/12/01 14:47:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 14:47:04 INFO DAGScheduler: Missing parents: List()
23/12/01 14:47:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 14:47:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 14:47:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 14:47:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 14:47:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
23/12/01 14:47:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 14:47:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
23/12/01 14:47:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 14:47:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/12/01 14:47:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1677 bytes result sent to driver
23/12/01 14:47:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 17 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 14:47:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/12/01 14:47:05 INFO DAGScheduler: ResultStage 2 (show at ApiTest.worksheet.sc:166) finished in 0.059 s
23/12/01 14:47:05 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 14:47:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/12/01 14:47:05 INFO DAGScheduler: Job 2 finished: show at ApiTest.worksheet.sc:166, took 0.061582 s
23/12/01 14:47:05 INFO CodeGenerator: Code generated in 7.660221 ms
23/12/01 14:47:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 15:37:12 INFO CodeGenerator: Code generated in 8.801434 ms
23/12/01 15:37:12 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 15:37:12 INFO DAGScheduler: Got job 3 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 15:37:12 INFO DAGScheduler: Final stage: ResultStage 3 (show at ApiTest.worksheet.sc:166)
23/12/01 15:37:12 INFO DAGScheduler: Parents of final stage: List()
23/12/01 15:37:12 INFO DAGScheduler: Missing parents: List()
23/12/01 15:37:12 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 15:37:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 15:37:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 15:37:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 15:37:12 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
23/12/01 15:37:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 15:37:12 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
23/12/01 15:37:12 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 15:37:12 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/12/01 15:37:12 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1677 bytes result sent to driver
23/12/01 15:37:12 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 15:37:12 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/12/01 15:37:12 INFO DAGScheduler: ResultStage 3 (show at ApiTest.worksheet.sc:166) finished in 0.073 s
23/12/01 15:37:12 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 15:37:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
23/12/01 15:37:12 INFO DAGScheduler: Job 3 finished: show at ApiTest.worksheet.sc:166, took 0.076059 s
23/12/01 15:37:12 INFO CodeGenerator: Code generated in 7.669022 ms
23/12/01 15:37:12 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:07:58 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/01 16:07:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/01 16:07:58 INFO SparkContext: Running Spark version 3.5.0
23/12/01 16:07:58 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:07:58 INFO SparkContext: Java version 11.0.20
23/12/01 16:07:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/01 16:07:59 INFO ResourceUtils: ==============================================================
23/12/01 16:07:59 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/01 16:07:59 INFO ResourceUtils: ==============================================================
23/12/01 16:07:59 INFO SparkContext: Submitted application: Spark Parquet Example
23/12/01 16:07:59 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/01 16:07:59 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
23/12/01 16:07:59 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/01 16:07:59 INFO SecurityManager: Changing view acls to: bsoleille
23/12/01 16:07:59 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/01 16:07:59 INFO SecurityManager: Changing view acls groups to: 
23/12/01 16:07:59 INFO SecurityManager: Changing modify acls groups to: 
23/12/01 16:07:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/01 16:07:59 INFO Utils: Successfully started service 'sparkDriver' on port 40271.
23/12/01 16:07:59 INFO SparkEnv: Registering MapOutputTracker
23/12/01 16:07:59 INFO SparkEnv: Registering BlockManagerMaster
23/12/01 16:07:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/01 16:07:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/01 16:07:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/01 16:07:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-82212edc-6bea-4532-94f2-9ee9645b988b
23/12/01 16:07:59 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/01 16:07:59 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/01 16:07:59 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/01 16:07:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/01 16:07:59 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/01 16:07:59 INFO Utils: Successfully started service 'SparkUI' on port 4042.
23/12/01 16:07:59 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/01 16:07:59 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:07:59 INFO Executor: Java version 11.0.20
23/12/01 16:07:59 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/01 16:07:59 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5d46bed7 for default.
23/12/01 16:07:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34297.
23/12/01 16:07:59 INFO NettyBlockTransferService: Server created on 10.25.86.80:34297
23/12/01 16:07:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/01 16:07:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 34297, None)
23/12/01 16:07:59 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:34297 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 34297, None)
23/12/01 16:07:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 34297, None)
23/12/01 16:07:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 34297, None)
23/12/01 16:07:59 WARN SharedState: URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
23/12/01 16:07:59 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/01 16:07:59 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/01 16:08:01 INFO CodeGenerator: Code generated in 119.825005 ms
23/12/01 16:08:01 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:62
23/12/01 16:08:01 INFO DAGScheduler: Got job 0 (show at SparkTest.worksheet.sc:62) with 1 output partitions
23/12/01 16:08:01 INFO DAGScheduler: Final stage: ResultStage 0 (show at SparkTest.worksheet.sc:62)
23/12/01 16:08:01 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:01 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:01 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:62), which has no missing parents
23/12/01 16:08:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:08:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 16:08:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:34297 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:01 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:62) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/01 16:08:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:01 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/01 16:08:01 INFO CodeGenerator: Code generated in 9.331211 ms
23/12/01 16:08:01 INFO CodeGenerator: Code generated in 27.657261 ms
23/12/01 16:08:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1677 bytes result sent to driver
23/12/01 16:08:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 143 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/01 16:08:01 INFO DAGScheduler: ResultStage 0 (show at SparkTest.worksheet.sc:62) finished in 0.302 s
23/12/01 16:08:01 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/01 16:08:01 INFO DAGScheduler: Job 0 finished: show at SparkTest.worksheet.sc:62, took 0.329990 s
23/12/01 16:08:01 INFO CodeGenerator: Code generated in 7.616697 ms
23/12/01 16:08:01 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/12/01 16:08:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/12/01 16:08:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/12/01 16:08:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/12/01 16:08:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/12/01 16:08:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/12/01 16:08:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/12/01 16:08:01 INFO CodeGenerator: Code generated in 6.182013 ms
23/12/01 16:08:01 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:72
23/12/01 16:08:01 INFO DAGScheduler: Got job 1 (parquet at SparkTest.worksheet.sc:72) with 1 output partitions
23/12/01 16:08:01 INFO DAGScheduler: Final stage: ResultStage 1 (parquet at SparkTest.worksheet.sc:72)
23/12/01 16:08:01 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:01 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:01 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:72), which has no missing parents
23/12/01 16:08:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 215.6 KiB, free 434.2 MiB)
23/12/01 16:08:01 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.25.86.80:34297 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 76.7 KiB, free 434.1 MiB)
23/12/01 16:08:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.25.86.80:34297 (size: 76.7 KiB, free: 434.3 MiB)
23/12/01 16:08:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:72) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/12/01 16:08:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 16:08:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/12/01 16:08:02 INFO CodeGenerator: Code generated in 6.376131 ms
23/12/01 16:08:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/12/01 16:08:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/12/01 16:08:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/12/01 16:08:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/12/01 16:08:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/12/01 16:08:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/12/01 16:08:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "index",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 index;
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/12/01 16:08:02 INFO CodecPool: Got brand-new compressor [.snappy]
23/12/01 16:08:02 INFO FileOutputCommitter: Saved output of task 'attempt_202312011608014166816365865289635_0001_m_000000_1' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202312011608014166816365865289635_0001_m_000000
23/12/01 16:08:02 INFO SparkHadoopMapRedUtil: attempt_202312011608014166816365865289635_0001_m_000000_1: Committed. Elapsed time: 0 ms.
23/12/01 16:08:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2785 bytes result sent to driver
23/12/01 16:08:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 549 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/12/01 16:08:02 INFO DAGScheduler: ResultStage 1 (parquet at SparkTest.worksheet.sc:72) finished in 0.591 s
23/12/01 16:08:02 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/12/01 16:08:02 INFO DAGScheduler: Job 1 finished: parquet at SparkTest.worksheet.sc:72, took 0.594133 s
23/12/01 16:08:02 INFO FileFormatWriter: Start to commit write Job aecacddf-8b99-4682-8172-557c073396a7.
23/12/01 16:08:02 INFO FileFormatWriter: Write Job aecacddf-8b99-4682-8172-557c073396a7 committed. Elapsed time: 10 ms.
23/12/01 16:08:02 INFO FileFormatWriter: Finished processing stats for write job aecacddf-8b99-4682-8172-557c073396a7.
23/12/01 16:08:02 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
23/12/01 16:08:02 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:76
23/12/01 16:08:02 INFO DAGScheduler: Got job 2 (parquet at SparkTest.worksheet.sc:76) with 1 output partitions
23/12/01 16:08:02 INFO DAGScheduler: Final stage: ResultStage 2 (parquet at SparkTest.worksheet.sc:76)
23/12/01 16:08:02 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:02 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:76), which has no missing parents
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/12/01 16:08:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.25.86.80:34297 (size: 36.9 KiB, free: 434.3 MiB)
23/12/01 16:08:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:76) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
23/12/01 16:08:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/12/01 16:08:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/12/01 16:08:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2128 bytes result sent to driver
23/12/01 16:08:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 57 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/12/01 16:08:02 INFO DAGScheduler: ResultStage 2 (parquet at SparkTest.worksheet.sc:76) finished in 0.069 s
23/12/01 16:08:02 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/12/01 16:08:02 INFO DAGScheduler: Job 2 finished: parquet at SparkTest.worksheet.sc:76, took 0.071356 s
23/12/01 16:08:02 INFO FileSourceStrategy: Pushed Filters: 
23/12/01 16:08:02 INFO FileSourceStrategy: Post-Scan Filters: 
23/12/01 16:08:02 INFO CodeGenerator: Code generated in 19.697954 ms
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 200.8 KiB, free 433.8 MiB)
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
23/12/01 16:08:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.25.86.80:34297 (size: 34.9 KiB, free: 434.3 MiB)
23/12/01 16:08:02 INFO SparkContext: Created broadcast 3 from show at SparkTest.worksheet.sc:81
23/12/01 16:08:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/12/01 16:08:02 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.25.86.80:34297 in memory (size: 76.7 KiB, free: 434.3 MiB)
23/12/01 16:08:02 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:81
23/12/01 16:08:02 INFO DAGScheduler: Got job 3 (show at SparkTest.worksheet.sc:81) with 1 output partitions
23/12/01 16:08:02 INFO DAGScheduler: Final stage: ResultStage 3 (show at SparkTest.worksheet.sc:81)
23/12/01 16:08:02 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:02 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:02 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:81), which has no missing parents
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.6 KiB, free 434.0 MiB)
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.0 MiB)
23/12/01 16:08:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.25.86.80:34297 (size: 6.8 KiB, free: 434.3 MiB)
23/12/01 16:08:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:81) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
23/12/01 16:08:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/12/01 16:08:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/12/01 16:08:02 INFO CodeGenerator: Code generated in 15.732603 ms
23/12/01 16:08:02 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-f284260d-afb0-4820-980b-c93c8a88bce7-c000.snappy.parquet, range: 0-1246, partition values: [empty row]
23/12/01 16:08:02 INFO CodecPool: Got brand-new decompressor [.snappy]
23/12/01 16:08:02 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.25.86.80:34297 in memory (size: 36.9 KiB, free: 434.4 MiB)
23/12/01 16:08:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1971 bytes result sent to driver
23/12/01 16:08:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 115 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/12/01 16:08:02 INFO DAGScheduler: ResultStage 3 (show at SparkTest.worksheet.sc:81) finished in 0.137 s
23/12/01 16:08:02 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
23/12/01 16:08:02 INFO DAGScheduler: Job 3 finished: show at SparkTest.worksheet.sc:81, took 0.142872 s
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 7.974989 ms
23/12/01 16:08:03 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:94
23/12/01 16:08:03 INFO DAGScheduler: Got job 4 (show at SparkTest.worksheet.sc:94) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ResultStage 4 (show at SparkTest.worksheet.sc:94)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:94), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.7 KiB, free 434.1 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.25.86.80:34297 (size: 6.5 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:94) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 7.397198 ms
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1640 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 17 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ResultStage 4 (show at SparkTest.worksheet.sc:94) finished in 0.023 s
23/12/01 16:08:03 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
23/12/01 16:08:03 INFO DAGScheduler: Job 4 finished: show at SparkTest.worksheet.sc:94, took 0.025370 s
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 5.995176 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 11.596649 ms
23/12/01 16:08:03 INFO DAGScheduler: Registering RDD 15 (collect at SparkTest.worksheet.sc:102) as input to shuffle 0
23/12/01 16:08:03 INFO DAGScheduler: Got map stage job 5 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (collect at SparkTest.worksheet.sc:102)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[15] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 19.2 KiB, free 434.1 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.1 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.25.86.80:34297 (size: 8.2 KiB, free: 434.3 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.25.86.80:34297 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[15] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.25.86.80:34297 in memory (size: 34.9 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.25.86.80:34297 in memory (size: 6.8 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8138 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 10.114158 ms
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1930 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 57 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ShuffleMapStage 5 (collect at SparkTest.worksheet.sc:102) finished in 0.110 s
23/12/01 16:08:03 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:03 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:03 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:03 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 9.612574 ms
23/12/01 16:08:03 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:102
23/12/01 16:08:03 INFO DAGScheduler: Got job 6 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ResultStage 7 (collect at SparkTest.worksheet.sc:102)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[18] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.3 KiB, free 434.4 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.25.86.80:34297 (size: 6.6 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[18] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 6) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 7.0 (TID 6)
23/12/01 16:08:03 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 6.711882 ms
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 7.0 (TID 6). 4084 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 6) in 52 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ResultStage 7 (collect at SparkTest.worksheet.sc:102) finished in 0.060 s
23/12/01 16:08:03 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
23/12/01 16:08:03 INFO DAGScheduler: Job 6 finished: collect at SparkTest.worksheet.sc:102, took 0.069896 s
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 4.618758 ms
23/12/01 16:08:03 INFO SparkContext: Starting job: show at Ast.scala:95
23/12/01 16:08:03 INFO DAGScheduler: Got job 7 (show at Ast.scala:95) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ResultStage 8 (show at Ast.scala:95)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[20] at show at Ast.scala:95), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.5 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.25.86.80:34297 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[20] at show at Ast.scala:95) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 1634 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ResultStage 8 (show at Ast.scala:95) finished in 0.014 s
23/12/01 16:08:03 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
23/12/01 16:08:03 INFO DAGScheduler: Job 7 finished: show at Ast.scala:95, took 0.017157 s
23/12/01 16:08:03 INFO SparkContext: Starting job: show at Ast.scala:96
23/12/01 16:08:03 INFO DAGScheduler: Got job 8 (show at Ast.scala:96) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ResultStage 9 (show at Ast.scala:96)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[22] at show at Ast.scala:96), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 15.5 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.25.86.80:34297 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[22] at show at Ast.scala:96) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 1634 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ResultStage 9 (show at Ast.scala:96) finished in 0.014 s
23/12/01 16:08:03 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/12/01 16:08:03 INFO DAGScheduler: Job 8 finished: show at Ast.scala:96, took 0.016066 s
23/12/01 16:08:03 INFO DAGScheduler: Registering RDD 24 (show at Ast.scala:108) as input to shuffle 1
23/12/01 16:08:03 INFO DAGScheduler: Got map stage job 9 (show at Ast.scala:108) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (show at Ast.scala:108)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[24] at show at Ast.scala:108), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 17.7 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.25.86.80:34297 (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.25.86.80:34297 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[24] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.25.86.80:34297 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.25.86.80:34297 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.25.86.80:34297 in memory (size: 6.6 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 6.584303 ms
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1991 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 25 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ShuffleMapStage 10 (show at Ast.scala:108) finished in 0.044 s
23/12/01 16:08:03 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:03 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:03 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:03 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:03 INFO ShufflePartitionsUtil: For shuffle(1, 1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 19.930057 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 6.776074 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 5.711414 ms
23/12/01 16:08:03 INFO SparkContext: Starting job: show at Ast.scala:108
23/12/01 16:08:03 INFO DAGScheduler: Got job 10 (show at Ast.scala:108) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ResultStage 12 (show at Ast.scala:108)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[31] at show at Ast.scala:108), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 40.1 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.25.86.80:34297 (size: 16.3 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[31] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 10) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 12.0 (TID 10)
23/12/01 16:08:03 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 6.275348 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 14.634942 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 3.977138 ms
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 6.754925 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 11.223649 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 12.0 (TID 10). 4898 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 10) in 99 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 12 (show at Ast.scala:108) finished in 0.110 s
23/12/01 16:08:04 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 10 finished: show at Ast.scala:108, took 0.113726 s
23/12/01 16:08:04 INFO DAGScheduler: Registering RDD 33 (show at Ast.scala:112) as input to shuffle 2
23/12/01 16:08:04 INFO DAGScheduler: Got map stage job 11 (show at Ast.scala:112) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (show at Ast.scala:112)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[33] at show at Ast.scala:112), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 17.7 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.25.86.80:34297 (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[33] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 11) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 13.0 (TID 11)
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 13.0 (TID 11). 1991 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 11) in 12 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ShuffleMapStage 13 (show at Ast.scala:112) finished in 0.018 s
23/12/01 16:08:04 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:04 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(2, 2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO SparkContext: Starting job: show at Ast.scala:112
23/12/01 16:08:04 INFO DAGScheduler: Got job 12 (show at Ast.scala:112) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 15 (show at Ast.scala:112)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[40] at show at Ast.scala:112), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 40.1 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.25.86.80:34297 (size: 16.3 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[40] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 15.0 (TID 12)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 15.0 (TID 12). 4898 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 12 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 15 (show at Ast.scala:112) finished in 0.021 s
23/12/01 16:08:04 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 12 finished: show at Ast.scala:112, took 0.024646 s
23/12/01 16:08:04 INFO SparkContext: Starting job: show at Ast.scala:113
23/12/01 16:08:04 INFO DAGScheduler: Got job 13 (show at Ast.scala:113) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 16 (show at Ast.scala:113)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[42] at show at Ast.scala:113), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 15.5 KiB, free 434.2 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.25.86.80:34297 (size: 6.4 KiB, free: 434.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.25.86.80:34297 in memory (size: 16.3 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[42] at show at Ast.scala:113) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 13) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 16.0 (TID 13)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.25.86.80:34297 in memory (size: 16.3 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.25.86.80:34297 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.25.86.80:34297 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 16.0 (TID 13). 1634 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 13) in 10 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 16 (show at Ast.scala:113) finished in 0.026 s
23/12/01 16:08:04 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 13 finished: show at Ast.scala:113, took 0.028865 s
23/12/01 16:08:04 INFO DAGScheduler: Registering RDD 44 (show at Ast.scala:126) as input to shuffle 3
23/12/01 16:08:04 INFO DAGScheduler: Got map stage job 14 (show at Ast.scala:126) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ShuffleMapStage 17 (show at Ast.scala:126)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[44] at show at Ast.scala:126), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 17.7 KiB, free 434.4 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.25.86.80:34297 (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[44] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 14) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 17.0 (TID 14)
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 17.0 (TID 14). 1991 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 14) in 14 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ShuffleMapStage 17 (show at Ast.scala:126) finished in 0.023 s
23/12/01 16:08:04 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:04 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(3, 3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 11.220167 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 9.983091 ms
23/12/01 16:08:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 38.7 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.25.86.80:34297 (size: 15.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 19.0 (TID 15)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 7.920069 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 10.494762 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 19.0 (TID 15). 4897 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 34 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.040 s
23/12/01 16:08:04 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.060623 s
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 4.251137 ms
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.25.86.80:34297 (size: 337.0 B, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 8.084337 ms
23/12/01 16:08:04 INFO SparkContext: Starting job: show at Ast.scala:126
23/12/01 16:08:04 INFO DAGScheduler: Got job 16 (show at Ast.scala:126) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 21 (show at Ast.scala:126)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[54] at show at Ast.scala:126), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 15.1 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.25.86.80:34297 (size: 6.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[54] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 16) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 21.0 (TID 16)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 7.452804 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 21.0 (TID 16). 4165 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 16) in 14 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 21 (show at Ast.scala:126) finished in 0.020 s
23/12/01 16:08:04 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 16 finished: show at Ast.scala:126, took 0.022829 s
23/12/01 16:08:04 INFO DAGScheduler: Registering RDD 56 (show at SparkTest.worksheet.sc:115) as input to shuffle 4
23/12/01 16:08:04 INFO DAGScheduler: Got map stage job 17 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (show at SparkTest.worksheet.sc:115)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[56] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 17.7 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.25.86.80:34297 (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.25.86.80:34297 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[56] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 22.0 (TID 17)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 10.25.86.80:34297 in memory (size: 337.0 B, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 10.25.86.80:34297 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 10.25.86.80:34297 in memory (size: 15.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.25.86.80:34297 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 22.0 (TID 17). 1991 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 12 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ShuffleMapStage 22 (show at SparkTest.worksheet.sc:115) finished in 0.029 s
23/12/01 16:08:04 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:04 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(4, 4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO DAGScheduler: Got job 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 24 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[63] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 38.7 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.25.86.80:34297 (size: 15.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[63] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 18) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 24.0 (TID 18)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 24.0 (TID 18). 4897 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 18) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 24 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.016 s
23/12/01 16:08:04 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 18 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.018536 s
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.25.86.80:34297 (size: 337.0 B, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 21 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:115
23/12/01 16:08:04 INFO DAGScheduler: Got job 19 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 26 (show at SparkTest.worksheet.sc:115)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[66] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 15.1 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.25.86.80:34297 (size: 6.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[66] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 19) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 26.0 (TID 19)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 26.0 (TID 19). 4165 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 19) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 26 (show at SparkTest.worksheet.sc:115) finished in 0.014 s
23/12/01 16:08:04 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 19 finished: show at SparkTest.worksheet.sc:115, took 0.015829 s
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 3.884453 ms
23/12/01 16:08:04 INFO DAGScheduler: Registering RDD 68 (isEmpty at SparkTest.worksheet.sc:120) as input to shuffle 5
23/12/01 16:08:04 INFO DAGScheduler: Got map stage job 20 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (isEmpty at SparkTest.worksheet.sc:120)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[68] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 17.3 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.25.86.80:34297 (size: 7.5 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[68] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 20) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 27.0 (TID 20)
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 3.777078 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 27.0 (TID 20). 1991 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 20) in 17 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ShuffleMapStage 27 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.021 s
23/12/01 16:08:04 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:04 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(5, 5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 23.968396 ms
23/12/01 16:08:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO DAGScheduler: Got job 21 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[75] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 35.3 KiB, free 433.2 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 433.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.25.86.80:34297 (size: 14.5 KiB, free: 434.3 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[75] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 21) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 29.0 (TID 21)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 7.013913 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 29.0 (TID 21). 4817 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 21) in 17 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.022 s
23/12/01 16:08:04 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 21 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.025596 s
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 1024.1 KiB, free 432.2 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 251.0 B, free 432.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.25.86.80:34297 (size: 251.0 B, free: 434.3 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 25 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 4.138849 ms
23/12/01 16:08:04 INFO SparkContext: Starting job: isEmpty at SparkTest.worksheet.sc:120
23/12/01 16:08:04 INFO DAGScheduler: Got job 22 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 31 (isEmpty at SparkTest.worksheet.sc:120)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[78] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 13.3 KiB, free 432.2 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 432.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.25.86.80:34297 (size: 6.4 KiB, free: 434.3 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[78] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 22) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 31.0 (TID 22)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 4.760254 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 31.0 (TID 22). 3262 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 22) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 31 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.015 s
23/12/01 16:08:04 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 22 finished: isEmpty at SparkTest.worksheet.sc:120, took 0.017356 s
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 4.147157 ms
23/12/01 16:08:04 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:04 INFO DAGScheduler: Got job 23 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 32 (collect at Ast.scala:253)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[82] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 17.5 KiB, free 432.2 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 432.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 10.25.86.80:34297 in memory (size: 15.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.25.86.80:34297 (size: 7.4 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[82] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 10.25.86.80:34297 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 23) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 32.0 (TID 23)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 10.25.86.80:34297 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 10.25.86.80:34297 in memory (size: 337.0 B, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 10.25.86.80:34297 in memory (size: 251.0 B, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 10.25.86.80:34297 in memory (size: 7.5 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 10.25.86.80:34297 in memory (size: 14.5 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 10.25.86.80:34297 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 4.797122 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 32.0 (TID 23). 1826 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 23) in 20 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 32 (collect at Ast.scala:253) finished in 0.037 s
23/12/01 16:08:04 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 23 finished: collect at Ast.scala:253, took 0.039498 s
23/12/01 16:08:05 INFO DAGScheduler: Registering RDD 83 (collect at Ast.scala:253) as input to shuffle 6
23/12/01 16:08:05 INFO DAGScheduler: Got map stage job 24 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[83] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 19.0 KiB, free 434.4 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.25.86.80:34297 (size: 8.2 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[83] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 24) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 33.0 (TID 24)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 33.0 (TID 24). 1793 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 24) in 12 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ShuffleMapStage 33 (collect at Ast.scala:253) finished in 0.019 s
23/12/01 16:08:05 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:05 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:05 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 6.031625 ms
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:05 INFO DAGScheduler: Got job 25 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 35 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[86] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 24.9 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.25.86.80:34297 (size: 10.8 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[86] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 25) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 35.0 (TID 25)
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 5.46639 ms
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 35.0 (TID 25). 4494 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 25) in 14 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 35 (collect at Ast.scala:253) finished in 0.018 s
23/12/01 16:08:05 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 25 finished: collect at Ast.scala:253, took 0.020155 s
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 5.815795 ms
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:05 INFO DAGScheduler: Got job 26 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 36 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[90] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 17.5 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.25.86.80:34297 (size: 7.4 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[90] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 26) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 36.0 (TID 26)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 36.0 (TID 26). 1826 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 26) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 36 (collect at Ast.scala:253) finished in 0.015 s
23/12/01 16:08:05 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 26 finished: collect at Ast.scala:253, took 0.016196 s
23/12/01 16:08:05 INFO DAGScheduler: Registering RDD 91 (collect at Ast.scala:253) as input to shuffle 7
23/12/01 16:08:05 INFO DAGScheduler: Got map stage job 27 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[91] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 19.0 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.25.86.80:34297 (size: 8.2 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[91] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 27) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 37.0 (TID 27)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 37.0 (TID 27). 1793 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 27) in 23 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ShuffleMapStage 37 (collect at Ast.scala:253) finished in 0.027 s
23/12/01 16:08:05 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:05 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:05 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:05 INFO DAGScheduler: Got job 28 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 39 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[94] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 24.9 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.25.86.80:34297 (size: 10.7 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[94] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 28) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 39.0 (TID 28)
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 39.0 (TID 28). 4494 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 28) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 39 (collect at Ast.scala:253) finished in 0.009 s
23/12/01 16:08:05 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 28 finished: collect at Ast.scala:253, took 0.011702 s
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:05 INFO DAGScheduler: Got job 29 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 40 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[98] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 17.5 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.25.86.80:34297 (size: 7.4 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[98] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 29) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 40.0 (TID 29)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 40.0 (TID 29). 1826 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 29) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 40 (collect at Ast.scala:253) finished in 0.012 s
23/12/01 16:08:05 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 29 finished: collect at Ast.scala:253, took 0.013996 s
23/12/01 16:08:05 INFO DAGScheduler: Registering RDD 99 (collect at Ast.scala:253) as input to shuffle 8
23/12/01 16:08:05 INFO DAGScheduler: Got map stage job 30 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[99] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 19.0 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.25.86.80:34297 (size: 8.2 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[99] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 30) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 41.0 (TID 30)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 41.0 (TID 30). 1793 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 30) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ShuffleMapStage 41 (collect at Ast.scala:253) finished in 0.015 s
23/12/01 16:08:05 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:05 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:05 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:05 INFO DAGScheduler: Got job 31 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 43 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[102] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 24.9 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.1 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.25.86.80:34297 (size: 10.8 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[102] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 31) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 43.0 (TID 31)
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 43.0 (TID 31). 4494 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 31) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 43 (collect at Ast.scala:253) finished in 0.011 s
23/12/01 16:08:05 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 31 finished: collect at Ast.scala:253, took 0.013565 s
23/12/01 16:08:05 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:150
23/12/01 16:08:05 INFO DAGScheduler: Got job 32 (show at SparkTest.worksheet.sc:150) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 44 (show at SparkTest.worksheet.sc:150)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[104] at show at SparkTest.worksheet.sc:150), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 15.7 KiB, free 434.1 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.25.86.80:34297 (size: 6.5 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[104] at show at SparkTest.worksheet.sc:150) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 32) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 44.0 (TID 32)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 44.0 (TID 32). 1683 bytes result sent to driver
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 10.25.86.80:34297 in memory (size: 7.4 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 32) in 18 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 44 (show at SparkTest.worksheet.sc:150) finished in 0.021 s
23/12/01 16:08:05 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 10.25.86.80:34297 in memory (size: 7.4 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 10.25.86.80:34297 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO DAGScheduler: Job 32 finished: show at SparkTest.worksheet.sc:150, took 0.024068 s
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 10.25.86.80:34297 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 10.25.86.80:34297 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 10.25.86.80:34297 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 10.25.86.80:34297 in memory (size: 10.7 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 10.25.86.80:34297 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 10.25.86.80:34297 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 7.442277 ms
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:159
23/12/01 16:08:05 INFO DAGScheduler: Got job 33 (collect at SparkTest.worksheet.sc:159) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 45 (collect at SparkTest.worksheet.sc:159)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[112] at collect at SparkTest.worksheet.sc:159), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 15.4 KiB, free 434.4 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.25.86.80:34297 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[112] at collect at SparkTest.worksheet.sc:159) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 33) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 45.0 (TID 33)
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 6.143042 ms
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 45.0 (TID 33). 1650 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 33) in 13 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 45 (collect at SparkTest.worksheet.sc:159) finished in 0.016 s
23/12/01 16:08:05 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 33 finished: collect at SparkTest.worksheet.sc:159, took 0.018172 s
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 5.201567 ms
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 10.25.86.80:34297 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 10.25.86.80:34297 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/12/01 16:08:06 INFO CodeGenerator: Code generated in 14.492557 ms
23/12/01 16:08:06 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 16:08:06 INFO DAGScheduler: Got job 4 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 16:08:06 INFO DAGScheduler: Final stage: ResultStage 4 (show at ApiTest.worksheet.sc:166)
23/12/01 16:08:06 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:06 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:06 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 16:08:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:08:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:08:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:06 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:06 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
23/12/01 16:08:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 16:08:06 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
23/12/01 16:08:06 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1634 bytes result sent to driver
23/12/01 16:08:06 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:06 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/12/01 16:08:06 INFO DAGScheduler: ResultStage 4 (show at ApiTest.worksheet.sc:166) finished in 0.044 s
23/12/01 16:08:06 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
23/12/01 16:08:06 INFO DAGScheduler: Job 4 finished: show at ApiTest.worksheet.sc:166, took 0.045205 s
23/12/01 16:08:06 INFO CodeGenerator: Code generated in 6.628521 ms
23/12/01 16:08:06 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:27 INFO CodeGenerator: Code generated in 6.548793 ms
23/12/01 16:08:27 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 16:08:27 INFO DAGScheduler: Got job 5 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 16:08:27 INFO DAGScheduler: Final stage: ResultStage 5 (show at ApiTest.worksheet.sc:166)
23/12/01 16:08:27 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:27 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:27 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 16:08:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:08:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:08:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:27 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
23/12/01 16:08:27 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 16:08:27 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
23/12/01 16:08:27 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1634 bytes result sent to driver
23/12/01 16:08:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
23/12/01 16:08:27 INFO DAGScheduler: ResultStage 5 (show at ApiTest.worksheet.sc:166) finished in 0.019 s
23/12/01 16:08:27 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
23/12/01 16:08:27 INFO DAGScheduler: Job 5 finished: show at ApiTest.worksheet.sc:166, took 0.020319 s
23/12/01 16:08:27 INFO CodeGenerator: Code generated in 6.346334 ms
23/12/01 16:08:27 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:18 INFO CodeGenerator: Code generated in 6.466909 ms
23/12/01 16:09:18 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:09:18 INFO DAGScheduler: Got job 6 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:09:18 INFO DAGScheduler: Final stage: ResultStage 6 (show at ApiTest.worksheet.sc:170)
23/12/01 16:09:18 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:09:18 INFO DAGScheduler: Missing parents: List()
23/12/01 16:09:18 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:09:18 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:09:18 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:09:18 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:18 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
23/12/01 16:09:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:09:18 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
23/12/01 16:09:18 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:09:18 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
23/12/01 16:09:18 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1634 bytes result sent to driver
23/12/01 16:09:18 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:09:18 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
23/12/01 16:09:18 INFO DAGScheduler: ResultStage 6 (show at ApiTest.worksheet.sc:170) finished in 0.015 s
23/12/01 16:09:18 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:09:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
23/12/01 16:09:18 INFO DAGScheduler: Job 6 finished: show at ApiTest.worksheet.sc:170, took 0.016153 s
23/12/01 16:09:18 INFO CodeGenerator: Code generated in 6.224049 ms
23/12/01 16:09:18 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:25 INFO CodeGenerator: Code generated in 6.951902 ms
23/12/01 16:09:25 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:09:25 INFO DAGScheduler: Got job 7 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:09:25 INFO DAGScheduler: Final stage: ResultStage 7 (show at ApiTest.worksheet.sc:170)
23/12/01 16:09:25 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:09:25 INFO DAGScheduler: Missing parents: List()
23/12/01 16:09:25 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[31] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:09:25 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:09:25 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:09:25 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:25 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
23/12/01 16:09:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[31] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:09:25 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/12/01 16:09:25 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:09:25 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
23/12/01 16:09:25 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1634 bytes result sent to driver
23/12/01 16:09:25 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:09:25 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/12/01 16:09:25 INFO DAGScheduler: ResultStage 7 (show at ApiTest.worksheet.sc:170) finished in 0.019 s
23/12/01 16:09:25 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:09:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
23/12/01 16:09:25 INFO DAGScheduler: Job 7 finished: show at ApiTest.worksheet.sc:170, took 0.021162 s
23/12/01 16:09:25 INFO CodeGenerator: Code generated in 5.702782 ms
23/12/01 16:09:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:47 INFO CodeGenerator: Code generated in 5.729062 ms
23/12/01 16:09:47 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:09:47 INFO DAGScheduler: Got job 8 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:09:47 INFO DAGScheduler: Final stage: ResultStage 8 (show at ApiTest.worksheet.sc:170)
23/12/01 16:09:47 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:09:47 INFO DAGScheduler: Missing parents: List()
23/12/01 16:09:47 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:09:47 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:09:47 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:09:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:47 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
23/12/01 16:09:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:09:47 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
23/12/01 16:09:47 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:09:47 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
23/12/01 16:09:47 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1634 bytes result sent to driver
23/12/01 16:09:47 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:09:47 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/12/01 16:09:47 INFO DAGScheduler: ResultStage 8 (show at ApiTest.worksheet.sc:170) finished in 0.031 s
23/12/01 16:09:47 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:09:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
23/12/01 16:09:47 INFO DAGScheduler: Job 8 finished: show at ApiTest.worksheet.sc:170, took 0.032614 s
23/12/01 16:09:47 INFO CodeGenerator: Code generated in 6.048962 ms
23/12/01 16:09:47 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:56 INFO CodeGenerator: Code generated in 5.580613 ms
23/12/01 16:09:56 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:09:56 INFO DAGScheduler: Got job 9 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:09:56 INFO DAGScheduler: Final stage: ResultStage 9 (show at ApiTest.worksheet.sc:170)
23/12/01 16:09:56 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:09:56 INFO DAGScheduler: Missing parents: List()
23/12/01 16:09:56 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[39] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:09:56 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:09:56 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:09:56 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:56 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
23/12/01 16:09:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[39] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:09:56 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
23/12/01 16:09:56 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:09:56 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
23/12/01 16:09:56 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1634 bytes result sent to driver
23/12/01 16:09:56 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:09:56 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/12/01 16:09:56 INFO DAGScheduler: ResultStage 9 (show at ApiTest.worksheet.sc:170) finished in 0.013 s
23/12/01 16:09:56 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:09:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/12/01 16:09:56 INFO DAGScheduler: Job 9 finished: show at ApiTest.worksheet.sc:170, took 0.014806 s
23/12/01 16:09:56 INFO CodeGenerator: Code generated in 5.397501 ms
23/12/01 16:09:56 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:12:30 INFO CodeGenerator: Code generated in 6.060437 ms
23/12/01 16:12:30 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:12:30 INFO DAGScheduler: Got job 10 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:12:30 INFO DAGScheduler: Final stage: ResultStage 10 (show at ApiTest.worksheet.sc:170)
23/12/01 16:12:30 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:12:30 INFO DAGScheduler: Missing parents: List()
23/12/01 16:12:30 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[45] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:12:30 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:12:30 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 16:12:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.25.86.80:42381 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:12:30 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
23/12/01 16:12:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:12:30 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
23/12/01 16:12:30 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:12:30 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
23/12/01 16:12:30 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1634 bytes result sent to driver
23/12/01 16:12:30 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:12:30 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/12/01 16:12:30 INFO DAGScheduler: ResultStage 10 (show at ApiTest.worksheet.sc:170) finished in 0.019 s
23/12/01 16:12:30 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:12:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
23/12/01 16:12:30 INFO DAGScheduler: Job 10 finished: show at ApiTest.worksheet.sc:170, took 0.020348 s
23/12/01 16:12:30 INFO CodeGenerator: Code generated in 5.422827 ms
23/12/01 16:12:30 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.25.86.80:42381 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:12:42 INFO CodeGenerator: Code generated in 5.537141 ms
23/12/01 16:12:42 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:12:42 INFO DAGScheduler: Got job 11 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:12:42 INFO DAGScheduler: Final stage: ResultStage 11 (show at ApiTest.worksheet.sc:170)
23/12/01 16:12:42 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:12:42 INFO DAGScheduler: Missing parents: List()
23/12/01 16:12:42 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[51] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:12:42 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:12:42 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 16:12:42 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.25.86.80:42381 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:12:42 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
23/12/01 16:12:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[51] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:12:42 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
23/12/01 16:12:42 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:12:42 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
23/12/01 16:12:43 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1677 bytes result sent to driver
23/12/01 16:12:43 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 17 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:12:43 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
23/12/01 16:12:43 INFO DAGScheduler: ResultStage 11 (show at ApiTest.worksheet.sc:170) finished in 0.024 s
23/12/01 16:12:43 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:12:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
23/12/01 16:12:43 INFO DAGScheduler: Job 11 finished: show at ApiTest.worksheet.sc:170, took 0.026085 s
23/12/01 16:12:43 INFO CodeGenerator: Code generated in 5.34749 ms
23/12/01 16:12:43 INFO CodeGenerator: Code generated in 4.077823 ms
23/12/01 16:12:43 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/01 16:12:43 INFO DAGScheduler: Got job 12 (collect at SparkJob.scala:13) with 1 output partitions
23/12/01 16:12:43 INFO DAGScheduler: Final stage: ResultStage 12 (collect at SparkJob.scala:13)
23/12/01 16:12:43 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:12:43 INFO DAGScheduler: Missing parents: List()
23/12/01 16:12:43 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[57] at collect at SparkJob.scala:13), which has no missing parents
23/12/01 16:12:43 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/01 16:12:43 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 434.4 MiB)
23/12/01 16:12:43 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.25.86.80:42381 (size: 6.1 KiB, free: 434.4 MiB)
23/12/01 16:12:43 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
23/12/01 16:12:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[57] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/01 16:12:43 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
23/12/01 16:12:43 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:12:43 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
23/12/01 16:12:43 INFO CodeGenerator: Code generated in 5.477899 ms
23/12/01 16:12:43 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1657 bytes result sent to driver
23/12/01 16:12:43 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 14 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:12:43 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
23/12/01 16:12:43 INFO DAGScheduler: ResultStage 12 (collect at SparkJob.scala:13) finished in 0.030 s
23/12/01 16:12:43 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:12:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
23/12/01 16:12:43 INFO DAGScheduler: Job 12 finished: collect at SparkJob.scala:13, took 0.032039 s
23/12/01 16:12:43 INFO CodeGenerator: Code generated in 5.389266 ms
23/12/01 16:12:43 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.25.86.80:42381 in memory (size: 6.1 KiB, free: 434.4 MiB)
23/12/01 16:12:43 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.25.86.80:42381 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:15:07 INFO CodeGenerator: Code generated in 5.65055 ms
23/12/01 16:15:07 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:15:07 INFO DAGScheduler: Got job 13 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:15:07 INFO DAGScheduler: Final stage: ResultStage 13 (show at ApiTest.worksheet.sc:170)
23/12/01 16:15:07 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:15:07 INFO DAGScheduler: Missing parents: List()
23/12/01 16:15:07 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[61] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:15:07 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:15:07 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 16:15:07 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.25.86.80:42381 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:15:07 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
23/12/01 16:15:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[61] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:15:07 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
23/12/01 16:15:07 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:15:07 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
23/12/01 16:15:07 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1634 bytes result sent to driver
23/12/01 16:15:07 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:15:07 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/12/01 16:15:07 INFO DAGScheduler: ResultStage 13 (show at ApiTest.worksheet.sc:170) finished in 0.013 s
23/12/01 16:15:07 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:15:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
23/12/01 16:15:07 INFO DAGScheduler: Job 13 finished: show at ApiTest.worksheet.sc:170, took 0.015201 s
23/12/01 16:15:07 INFO CodeGenerator: Code generated in 5.882555 ms
23/12/01 16:15:07 INFO CodeGenerator: Code generated in 4.215756 ms
23/12/01 16:15:07 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/01 16:15:07 INFO DAGScheduler: Got job 14 (collect at SparkJob.scala:13) with 1 output partitions
23/12/01 16:15:07 INFO DAGScheduler: Final stage: ResultStage 14 (collect at SparkJob.scala:13)
23/12/01 16:15:07 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:15:07 INFO DAGScheduler: Missing parents: List()
23/12/01 16:15:07 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[67] at collect at SparkJob.scala:13), which has no missing parents
23/12/01 16:15:07 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.25.86.80:42381 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:15:07 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/01 16:15:07 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/12/01 16:15:07 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.25.86.80:42381 (size: 6.2 KiB, free: 434.4 MiB)
23/12/01 16:15:07 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580
23/12/01 16:15:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[67] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/01 16:15:07 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
23/12/01 16:15:07 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:15:07 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
23/12/01 16:15:07 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1657 bytes result sent to driver
23/12/01 16:15:07 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:15:07 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
23/12/01 16:15:07 INFO DAGScheduler: ResultStage 14 (collect at SparkJob.scala:13) finished in 0.009 s
23/12/01 16:15:07 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:15:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
23/12/01 16:15:07 INFO DAGScheduler: Job 14 finished: collect at SparkJob.scala:13, took 0.019402 s
23/12/01 16:15:07 INFO CodeGenerator: Code generated in 5.433901 ms
23/12/01 16:15:07 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.25.86.80:42381 in memory (size: 6.2 KiB, free: 434.4 MiB)
23/12/01 16:17:43 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:17:43 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:17:43 INFO xnio: XNIO version 3.8.7.Final
23/12/01 16:17:43 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/01 16:17:43 INFO threads: JBoss Threads version 3.1.0.Final
23/12/01 16:17:43 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:17:43 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:17:43 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:17:43 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:17:43 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:17:43 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:17:43 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:17:43 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:17:43 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:17:43 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:20:21 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/01 16:20:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/01 16:20:21 INFO SparkContext: Running Spark version 3.5.0
23/12/01 16:20:21 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:20:21 INFO SparkContext: Java version 11.0.20
23/12/01 16:20:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/01 16:20:22 INFO ResourceUtils: ==============================================================
23/12/01 16:20:22 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/01 16:20:22 INFO ResourceUtils: ==============================================================
23/12/01 16:20:22 INFO SparkContext: Submitted application: sparkApp
23/12/01 16:20:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/01 16:20:22 INFO ResourceProfile: Limiting resource is cpu
23/12/01 16:20:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/01 16:20:22 INFO SecurityManager: Changing view acls to: bsoleille
23/12/01 16:20:22 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/01 16:20:22 INFO SecurityManager: Changing view acls groups to: 
23/12/01 16:20:22 INFO SecurityManager: Changing modify acls groups to: 
23/12/01 16:20:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/01 16:20:22 INFO Utils: Successfully started service 'sparkDriver' on port 39933.
23/12/01 16:20:22 INFO SparkEnv: Registering MapOutputTracker
23/12/01 16:20:22 INFO SparkEnv: Registering BlockManagerMaster
23/12/01 16:20:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/01 16:20:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/01 16:20:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/01 16:20:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-be9188a4-7bff-4d06-a0b4-e354a89f54ce
23/12/01 16:20:22 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/01 16:20:22 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/01 16:20:22 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/01 16:20:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/01 16:20:22 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/01 16:20:22 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/01 16:20:22 INFO Utils: Successfully started service 'SparkUI' on port 4043.
23/12/01 16:20:22 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/01 16:20:22 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:20:22 INFO Executor: Java version 11.0.20
23/12/01 16:20:22 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/01 16:20:22 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@186989dc for default.
23/12/01 16:20:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41709.
23/12/01 16:20:22 INFO NettyBlockTransferService: Server created on 10.25.86.80:41709
23/12/01 16:20:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/01 16:20:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 41709, None)
23/12/01 16:20:22 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:41709 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 41709, None)
23/12/01 16:20:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 41709, None)
23/12/01 16:20:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 41709, None)
23/12/01 16:20:22 WARN SharedState: URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
23/12/01 16:20:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/01 16:20:22 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 129.907236 ms
23/12/01 16:20:24 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:20:24 INFO DAGScheduler: Got job 0 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:20:24 INFO DAGScheduler: Final stage: ResultStage 0 (show at ApiTest.worksheet.sc:170)
23/12/01 16:20:24 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:20:24 INFO DAGScheduler: Missing parents: List()
23/12/01 16:20:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:20:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:20:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 16:20:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:41709 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:20:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/01 16:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:20:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/01 16:20:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:20:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 13.511278 ms
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 31.665589 ms
23/12/01 16:20:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1677 bytes result sent to driver
23/12/01 16:20:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 196 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:20:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/01 16:20:24 INFO DAGScheduler: ResultStage 0 (show at ApiTest.worksheet.sc:170) finished in 0.341 s
23/12/01 16:20:24 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:20:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/01 16:20:24 INFO DAGScheduler: Job 0 finished: show at ApiTest.worksheet.sc:170, took 0.385060 s
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 7.978941 ms
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 7.084814 ms
23/12/01 16:20:24 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/01 16:20:24 INFO DAGScheduler: Got job 1 (collect at SparkJob.scala:13) with 1 output partitions
23/12/01 16:20:24 INFO DAGScheduler: Final stage: ResultStage 1 (collect at SparkJob.scala:13)
23/12/01 16:20:24 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:20:24 INFO DAGScheduler: Missing parents: List()
23/12/01 16:20:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at SparkJob.scala:13), which has no missing parents
23/12/01 16:20:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/01 16:20:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 434.4 MiB)
23/12/01 16:20:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.25.86.80:41709 (size: 6.1 KiB, free: 434.4 MiB)
23/12/01 16:20:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
23/12/01 16:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/01 16:20:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/12/01 16:20:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 16:20:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 6.463147 ms
23/12/01 16:20:24 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.25.86.80:41709 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:20:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1700 bytes result sent to driver
23/12/01 16:20:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:20:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/12/01 16:20:24 INFO DAGScheduler: ResultStage 1 (collect at SparkJob.scala:13) finished in 0.046 s
23/12/01 16:20:24 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:20:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/12/01 16:20:24 INFO DAGScheduler: Job 1 finished: collect at SparkJob.scala:13, took 0.048438 s
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 10.889675 ms
23/12/01 16:21:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.25.86.80:41709 in memory (size: 6.1 KiB, free: 434.4 MiB)
23/12/01 16:32:49 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:32:49 INFO xnio: XNIO version 3.8.7.Final
23/12/01 16:32:49 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/01 16:32:49 INFO threads: JBoss Threads version 3.1.0.Final
23/12/01 16:32:49 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:32:49 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:32:59 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:33:26 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/01 16:33:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/01 16:33:55 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:34:14 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:34:14 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:34:14 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:34:14 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:34:14 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:34:14 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:34:34 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:38:35 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:38:35 INFO xnio: XNIO version 3.8.7.Final
23/12/01 16:38:35 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/01 16:38:35 INFO threads: JBoss Threads version 3.1.0.Final
23/12/01 16:38:55 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:38:55 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:39:05 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:39:08 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/01 16:39:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/01 16:39:35 INFO SparkContext: Running Spark version 3.5.0
23/12/01 16:39:35 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:39:35 INFO SparkContext: Java version 11.0.20
23/12/01 16:39:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/01 16:39:35 INFO ResourceUtils: ==============================================================
23/12/01 16:39:35 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/01 16:39:35 INFO ResourceUtils: ==============================================================
23/12/01 16:39:35 INFO SparkContext: Submitted application: sparkApp
23/12/01 16:39:35 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/01 16:39:35 INFO ResourceProfile: Limiting resource is cpu
23/12/01 16:39:35 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/01 16:39:35 INFO SecurityManager: Changing view acls to: bsoleille
23/12/01 16:39:35 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/01 16:39:35 INFO SecurityManager: Changing view acls groups to: 
23/12/01 16:39:35 INFO SecurityManager: Changing modify acls groups to: 
23/12/01 16:39:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/01 16:39:35 INFO Utils: Successfully started service 'sparkDriver' on port 34317.
23/12/01 16:39:35 INFO SparkEnv: Registering MapOutputTracker
23/12/01 16:39:35 INFO SparkEnv: Registering BlockManagerMaster
23/12/01 16:39:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/01 16:39:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/01 16:39:35 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/01 16:39:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-327c3112-38c8-4e4f-976e-da4f58bafbcb
23/12/01 16:39:35 INFO MemoryStore: MemoryStore started with capacity 9.1 GiB
23/12/01 16:39:35 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/01 16:39:35 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/01 16:39:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/01 16:39:35 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/01 16:39:35 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/01 16:39:35 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/12/01 16:39:35 INFO Utils: Successfully started service 'SparkUI' on port 4044.
23/12/01 16:39:35 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/01 16:39:35 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:39:35 INFO Executor: Java version 11.0.20
23/12/01 16:39:35 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/01 16:39:35 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@10c6d899 for default.
23/12/01 16:39:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45783.
23/12/01 16:39:35 INFO NettyBlockTransferService: Server created on 10.25.86.80:45783
23/12/01 16:39:35 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/01 16:39:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 45783, None)
23/12/01 16:39:35 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:45783 with 9.1 GiB RAM, BlockManagerId(driver, 10.25.86.80, 45783, None)
23/12/01 16:39:35 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 45783, None)
23/12/01 16:39:35 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 45783, None)
23/12/01 16:39:36 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/01 16:39:36 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/01 16:39:51 INFO CodeGenerator: Code generated in 135.796806 ms
23/12/01 16:39:52 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/01 16:39:52 INFO DAGScheduler: Got job 0 (collect at SparkJob.scala:13) with 1 output partitions
23/12/01 16:39:52 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkJob.scala:13)
23/12/01 16:39:52 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:39:52 INFO DAGScheduler: Missing parents: List()
23/12/01 16:39:52 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13), which has no missing parents
23/12/01 16:39:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 9.1 GiB)
23/12/01 16:39:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 9.1 GiB)
23/12/01 16:39:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:45783 (size: 6.1 KiB, free: 9.1 GiB)
23/12/01 16:39:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/01 16:39:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/01 16:39:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/01 16:39:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:39:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/01 16:39:52 INFO CodeGenerator: Code generated in 7.747346 ms
23/12/01 16:39:52 INFO CodeGenerator: Code generated in 32.980556 ms
23/12/01 16:39:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1700 bytes result sent to driver
23/12/01 16:39:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 666 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:39:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/01 16:39:52 INFO DAGScheduler: ResultStage 0 (collect at SparkJob.scala:13) finished in 0.768 s
23/12/01 16:39:52 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:39:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/01 16:39:52 INFO DAGScheduler: Job 0 finished: collect at SparkJob.scala:13, took 0.795147 s
23/12/01 16:39:52 INFO CodeGenerator: Code generated in 7.55883 ms
23/12/01 16:39:59 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:40:07 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:40:07 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:40:07 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:40:07 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:40:07 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:40:07 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:40:11 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:40:11 INFO SparkContext: Invoking stop() from shutdown hook
23/12/01 16:40:11 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/01 16:40:11 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4044
23/12/01 16:40:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/12/01 16:40:11 INFO MemoryStore: MemoryStore cleared
23/12/01 16:40:11 INFO BlockManager: BlockManager stopped
23/12/01 16:40:11 INFO BlockManagerMaster: BlockManagerMaster stopped
23/12/01 16:40:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/12/01 16:40:11 INFO SparkContext: Successfully stopped SparkContext
23/12/01 16:40:11 INFO ShutdownHookManager: Shutdown hook called
23/12/01 16:40:11 INFO ShutdownHookManager: Deleting directory /tmp/spark-57b6d772-01d6-4a25-89d9-7c5b3d7037d0
23/12/01 16:42:17 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:42:17 INFO xnio: XNIO version 3.8.7.Final
23/12/01 16:42:17 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/01 16:42:17 INFO threads: JBoss Threads version 3.1.0.Final
23/12/01 16:42:23 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:42:23 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:42:26 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/01 16:42:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/01 16:42:33 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:42:52 INFO SparkContext: Running Spark version 3.5.0
23/12/01 16:42:52 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:42:52 INFO SparkContext: Java version 11.0.20
23/12/01 16:42:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/01 16:42:52 INFO ResourceUtils: ==============================================================
23/12/01 16:42:52 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/01 16:42:52 INFO ResourceUtils: ==============================================================
23/12/01 16:42:52 INFO SparkContext: Submitted application: sparkApp
23/12/01 16:42:52 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/01 16:42:52 INFO ResourceProfile: Limiting resource is cpu
23/12/01 16:42:52 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/01 16:42:52 INFO SecurityManager: Changing view acls to: bsoleille
23/12/01 16:42:52 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/01 16:42:52 INFO SecurityManager: Changing view acls groups to: 
23/12/01 16:42:52 INFO SecurityManager: Changing modify acls groups to: 
23/12/01 16:42:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/01 16:42:52 INFO Utils: Successfully started service 'sparkDriver' on port 35303.
23/12/01 16:42:52 INFO SparkEnv: Registering MapOutputTracker
23/12/01 16:42:52 INFO SparkEnv: Registering BlockManagerMaster
23/12/01 16:42:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/01 16:42:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/01 16:42:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/01 16:42:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-07526d0e-5cb3-4aad-be10-1bb8f3863cec
23/12/01 16:42:52 INFO MemoryStore: MemoryStore started with capacity 9.1 GiB
23/12/01 16:42:52 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/01 16:42:53 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/01 16:42:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/01 16:42:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/01 16:42:53 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/01 16:42:53 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/12/01 16:42:53 INFO Utils: Successfully started service 'SparkUI' on port 4044.
23/12/01 16:42:53 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/01 16:42:53 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:42:53 INFO Executor: Java version 11.0.20
23/12/01 16:42:53 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/01 16:42:53 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@71dc044c for default.
23/12/01 16:42:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40739.
23/12/01 16:42:53 INFO NettyBlockTransferService: Server created on 10.25.86.80:40739
23/12/01 16:42:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/01 16:42:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 40739, None)
23/12/01 16:42:53 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:40739 with 9.1 GiB RAM, BlockManagerId(driver, 10.25.86.80, 40739, None)
23/12/01 16:42:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 40739, None)
23/12/01 16:42:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 40739, None)
23/12/01 16:42:53 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/01 16:42:53 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/01 16:43:05 INFO CodeGenerator: Code generated in 139.313405 ms
23/12/01 16:43:05 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/01 16:43:05 INFO DAGScheduler: Got job 0 (collect at SparkJob.scala:13) with 1 output partitions
23/12/01 16:43:05 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkJob.scala:13)
23/12/01 16:43:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:43:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:43:05 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13), which has no missing parents
23/12/01 16:43:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 9.1 GiB)
23/12/01 16:43:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 9.1 GiB)
23/12/01 16:43:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:40739 (size: 6.1 KiB, free: 9.1 GiB)
23/12/01 16:43:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/01 16:43:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/01 16:43:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/01 16:43:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:43:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/01 16:43:05 INFO CodeGenerator: Code generated in 7.410289 ms
23/12/01 16:43:06 INFO CodeGenerator: Code generated in 28.07724 ms
23/12/01 16:43:06 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1700 bytes result sent to driver
23/12/01 16:43:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 688 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:43:06 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/01 16:43:06 INFO DAGScheduler: ResultStage 0 (collect at SparkJob.scala:13) finished in 0.783 s
23/12/01 16:43:06 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:43:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/01 16:43:06 INFO DAGScheduler: Job 0 finished: collect at SparkJob.scala:13, took 0.807342 s
23/12/01 16:43:06 INFO CodeGenerator: Code generated in 9.653941 ms
23/12/01 16:44:33 INFO SparkContext: Invoking stop() from shutdown hook
23/12/01 16:44:33 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/01 16:44:33 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4044
23/12/01 16:44:33 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:44:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/12/01 16:44:33 INFO MemoryStore: MemoryStore cleared
23/12/01 16:44:33 INFO BlockManager: BlockManager stopped
23/12/01 16:44:33 INFO BlockManagerMaster: BlockManagerMaster stopped
23/12/01 16:44:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/12/01 16:44:33 INFO SparkContext: Successfully stopped SparkContext
23/12/01 16:44:33 INFO ShutdownHookManager: Shutdown hook called
23/12/01 16:44:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-dce47a7d-e974-4afc-90fa-58fa8cee69cd
23/12/01 16:44:55 WARN RemoteEndpoint: Unmatched cancel notification for request id 3357
23/12/01 16:45:25 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:45:25 INFO xnio: XNIO version 3.8.7.Final
23/12/01 16:45:25 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/01 16:45:25 INFO threads: JBoss Threads version 3.1.0.Final
23/12/01 16:45:37 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:45:37 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:45:47 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:46:00 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/01 16:46:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/01 16:46:27 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:47:04 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:47:04 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:47:04 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:47:04 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:47:04 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 16:47:04 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/01 16:47:24 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/01 17:24:09 ERROR CompilerAccess: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085)_17-24-09-833.md
23/12/01 23:24:38 WARN RemoteEndpoint: Unmatched cancel notification for request id 6192
23/12/01 23:47:21 WARN RemoteEndpoint: Unmatched cancel notification for request id 6988
23/12/01 23:51:56 WARN RemoteEndpoint: Unmatched cancel notification for request id 7260
23/12/02 13:50:46 WARN RemoteEndpoint: Unmatched cancel notification for request id 9527
23/12/02 13:52:11 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:12 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:15 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:17 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:33 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:36 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:40 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:44 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:47 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 22:34:17 WARN RemoteEndpoint: Unmatched cancel notification for request id 10108
23/12/02 22:43:36 WARN RemoteEndpoint: Unmatched cancel notification for request id 10932
23/12/02 22:45:17 WARN RemoteEndpoint: Unmatched cancel notification for request id 11042
23/12/02 22:46:25 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/02 22:46:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/02 22:46:26 INFO SparkContext: Running Spark version 3.5.0
23/12/02 22:46:26 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/02 22:46:26 INFO SparkContext: Java version 11.0.20
23/12/02 22:46:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/02 22:46:26 INFO ResourceUtils: ==============================================================
23/12/02 22:46:26 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/02 22:46:26 INFO ResourceUtils: ==============================================================
23/12/02 22:46:26 INFO SparkContext: Submitted application: sparkApp
23/12/02 22:46:26 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/02 22:46:26 INFO ResourceProfile: Limiting resource is cpu
23/12/02 22:46:26 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/02 22:46:26 INFO SecurityManager: Changing view acls to: bsoleille
23/12/02 22:46:26 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/02 22:46:26 INFO SecurityManager: Changing view acls groups to: 
23/12/02 22:46:26 INFO SecurityManager: Changing modify acls groups to: 
23/12/02 22:46:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/02 22:46:26 INFO Utils: Successfully started service 'sparkDriver' on port 42417.
23/12/02 22:46:26 INFO SparkEnv: Registering MapOutputTracker
23/12/02 22:46:26 INFO SparkEnv: Registering BlockManagerMaster
23/12/02 22:46:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/02 22:46:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/02 22:46:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/02 22:46:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c5bc54e6-41d1-433d-a884-a2d1a6394b6c
23/12/02 22:46:26 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/02 22:46:26 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/02 22:46:26 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/02 22:46:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/02 22:46:26 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/02 22:46:26 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/02 22:46:26 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/12/02 22:46:26 INFO Utils: Successfully started service 'SparkUI' on port 4044.
23/12/02 22:46:26 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/02 22:46:26 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/02 22:46:26 INFO Executor: Java version 11.0.20
23/12/02 22:46:26 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/02 22:46:26 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@108052f0 for default.
23/12/02 22:46:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40183.
23/12/02 22:46:26 INFO NettyBlockTransferService: Server created on 10.25.86.80:40183
23/12/02 22:46:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/02 22:46:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 40183, None)
23/12/02 22:46:26 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:40183 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 40183, None)
23/12/02 22:46:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 40183, None)
23/12/02 22:46:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 40183, None)
23/12/02 22:46:27 INFO threads: JBoss Threads version 3.1.0.Final
23/12/02 22:46:27 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/02 22:46:27 INFO xnio: XNIO version 3.8.7.Final
23/12/02 22:46:27 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/02 22:46:33 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/02 22:46:33 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/02 22:46:34 INFO CodeGenerator: Code generated in 127.394045 ms
23/12/02 22:46:34 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/02 22:46:34 INFO DAGScheduler: Got job 0 (collect at SparkJob.scala:13) with 1 output partitions
23/12/02 22:46:34 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkJob.scala:13)
23/12/02 22:46:34 INFO DAGScheduler: Parents of final stage: List()
23/12/02 22:46:34 INFO DAGScheduler: Missing parents: List()
23/12/02 22:46:34 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13), which has no missing parents
23/12/02 22:46:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/02 22:46:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 434.4 MiB)
23/12/02 22:46:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:40183 (size: 6.1 KiB, free: 434.4 MiB)
23/12/02 22:46:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/02 22:46:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/02 22:46:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/02 22:46:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/02 22:46:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/02 22:46:34 INFO CodeGenerator: Code generated in 6.755156 ms
23/12/02 22:46:35 INFO CodeGenerator: Code generated in 26.507991 ms
23/12/02 22:46:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1700 bytes result sent to driver
23/12/02 22:46:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 758 ms on 10.25.86.80 (executor driver) (1/1)
23/12/02 22:46:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/02 22:46:35 INFO DAGScheduler: ResultStage 0 (collect at SparkJob.scala:13) finished in 0.878 s
23/12/02 22:46:35 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/02 22:46:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/02 22:46:35 INFO DAGScheduler: Job 0 finished: collect at SparkJob.scala:13, took 0.907479 s
23/12/02 22:46:35 INFO CodeGenerator: Code generated in 8.693206 ms
23/12/02 22:46:35 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/02 22:46:35 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4044
23/12/02 22:46:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/12/02 22:46:35 INFO MemoryStore: MemoryStore cleared
23/12/02 22:46:35 INFO BlockManager: BlockManager stopped
23/12/02 22:46:35 INFO BlockManagerMaster: BlockManagerMaster stopped
23/12/02 22:46:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/12/02 22:46:35 INFO SparkContext: Successfully stopped SparkContext
23/12/03 07:36:12 WARN RemoteEndpoint: Unmatched cancel notification for request id 12545
23/12/03 07:38:07 ERROR RemoteEndpoint: Internal error: java.lang.UnsupportedOperationException: tail of empty list
java.util.concurrent.CompletionException: java.lang.UnsupportedOperationException: tail of empty list
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.UnsupportedOperationException: tail of empty list
	at scala.collection.immutable.Nil$.tail(List.scala:664)
	at scala.collection.immutable.Nil$.tail(List.scala:661)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.$anonfun$endPosOfTree$1(CreateCompanionObjectCodeAction.scala:77)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.endPosOfTree(CreateCompanionObjectCodeAction.scala:75)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.$anonfun$contribute$5(CreateCompanionObjectCodeAction.scala:61)
	at scala.Option.map(Option.scala:242)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.$anonfun$contribute$4(CreateCompanionObjectCodeAction.scala:58)
	at scala.Option$WithFilter.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.$anonfun$contribute$2(CreateCompanionObjectCodeAction.scala:56)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.$anonfun$contribute$1(CreateCompanionObjectCodeAction.scala:55)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	... 3 more
23/12/03 07:39:42 INFO ShutdownHookManager: Shutdown hook called
23/12/03 07:39:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-7bf99f39-956d-4c83-bcfd-5d6f051e0bbb
23/12/03 07:39:42 ERROR Configuration: error parsing conf core-default.xml
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/target/bg-jobs/sbt_c67fdfa2/target/a96afb48/359669fc/hadoop-client-api-3.3.4.jar
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)
	at java.base/sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:149)
	at java.base/sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
	at java.base/java.nio.file.Files.readAttributes(Files.java:1764)
	at java.base/java.util.zip.ZipFile$Source.get(ZipFile.java:1381)
	at java.base/java.util.zip.ZipFile$CleanableResource.<init>(ZipFile.java:840)
	at java.base/java.util.zip.ZipFile$CleanableResource$FinalizableResource.<init>(ZipFile.java:866)
	at java.base/java.util.zip.ZipFile$CleanableResource.get(ZipFile.java:855)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:257)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:186)
	at java.base/java.util.jar.JarFile.<init>(JarFile.java:348)
	at java.base/sun.net.www.protocol.jar.URLJarFile.<init>(URLJarFile.java:103)
	at java.base/sun.net.www.protocol.jar.URLJarFile.getJarFile(URLJarFile.java:72)
	at java.base/sun.net.www.protocol.jar.JarFileFactory.get(JarFileFactory.java:99)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.connect(JarURLConnection.java:125)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.getInputStream(JarURLConnection.java:155)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:3009)
	at org.apache.hadoop.conf.Configuration.getStreamReader(Configuration.java:3105)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3063)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:3036)
	at org.apache.hadoop.conf.Configuration.loadProps(Configuration.java:2914)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2896)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:1246)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1863)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)
	at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)
	at org.apache.hadoop.util.ShutdownHookManager.shutdownExecutor(ShutdownHookManager.java:145)
	at org.apache.hadoop.util.ShutdownHookManager.access$300(ShutdownHookManager.java:65)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:102)
23/12/03 07:39:59 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/03 07:39:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/03 07:39:59 INFO SparkContext: Running Spark version 3.5.0
23/12/03 07:39:59 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 07:39:59 INFO SparkContext: Java version 11.0.20
23/12/03 07:39:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/03 07:39:59 INFO ResourceUtils: ==============================================================
23/12/03 07:39:59 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/03 07:39:59 INFO ResourceUtils: ==============================================================
23/12/03 07:39:59 INFO SparkContext: Submitted application: sparkApp
23/12/03 07:39:59 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/03 07:39:59 INFO ResourceProfile: Limiting resource is cpu
23/12/03 07:39:59 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/03 07:39:59 INFO SecurityManager: Changing view acls to: bsoleille
23/12/03 07:39:59 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/03 07:39:59 INFO SecurityManager: Changing view acls groups to: 
23/12/03 07:39:59 INFO SecurityManager: Changing modify acls groups to: 
23/12/03 07:39:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/03 07:39:59 INFO Utils: Successfully started service 'sparkDriver' on port 39179.
23/12/03 07:39:59 INFO SparkEnv: Registering MapOutputTracker
23/12/03 07:39:59 INFO SparkEnv: Registering BlockManagerMaster
23/12/03 07:39:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/03 07:39:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/03 07:39:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/03 07:39:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5e74cc00-e084-48e5-9177-53a6edbb5a73
23/12/03 07:39:59 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/03 07:40:00 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/03 07:40:00 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/03 07:40:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/03 07:40:00 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/03 07:40:00 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/03 07:40:00 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/12/03 07:40:00 INFO Utils: Successfully started service 'SparkUI' on port 4044.
23/12/03 07:40:00 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/03 07:40:00 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 07:40:00 INFO Executor: Java version 11.0.20
23/12/03 07:40:00 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/03 07:40:00 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1dfc6201 for default.
23/12/03 07:40:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36213.
23/12/03 07:40:00 INFO NettyBlockTransferService: Server created on 10.25.86.80:36213
23/12/03 07:40:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/03 07:40:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 36213, None)
23/12/03 07:40:00 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:36213 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 36213, None)
23/12/03 07:40:00 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 36213, None)
23/12/03 07:40:00 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 36213, None)
23/12/03 07:40:00 INFO threads: JBoss Threads version 3.1.0.Final
23/12/03 07:40:00 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 07:40:00 INFO xnio: XNIO version 3.8.7.Final
23/12/03 07:40:00 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/03 07:40:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/03 07:40:08 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/03 07:40:09 INFO CodeGenerator: Code generated in 120.614594 ms
23/12/03 07:40:09 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/03 07:40:09 INFO DAGScheduler: Got job 0 (collect at SparkJob.scala:13) with 1 output partitions
23/12/03 07:40:09 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkJob.scala:13)
23/12/03 07:40:09 INFO DAGScheduler: Parents of final stage: List()
23/12/03 07:40:09 INFO DAGScheduler: Missing parents: List()
23/12/03 07:40:09 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13), which has no missing parents
23/12/03 07:40:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/03 07:40:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 434.4 MiB)
23/12/03 07:40:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:36213 (size: 6.1 KiB, free: 434.4 MiB)
23/12/03 07:40:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/03 07:40:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/03 07:40:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/03 07:40:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/03 07:40:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/03 07:40:09 INFO CodeGenerator: Code generated in 10.973462 ms
23/12/03 07:40:10 INFO CodeGenerator: Code generated in 25.735866 ms
23/12/03 07:40:10 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1700 bytes result sent to driver
23/12/03 07:40:10 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 779 ms on 10.25.86.80 (executor driver) (1/1)
23/12/03 07:40:10 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/03 07:40:10 INFO DAGScheduler: ResultStage 0 (collect at SparkJob.scala:13) finished in 0.877 s
23/12/03 07:40:10 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/03 07:40:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/03 07:40:10 INFO DAGScheduler: Job 0 finished: collect at SparkJob.scala:13, took 0.906075 s
23/12/03 07:40:10 INFO CodeGenerator: Code generated in 8.29866 ms
23/12/03 07:40:10 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/03 07:40:10 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4044
23/12/03 07:40:10 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/12/03 07:40:10 INFO MemoryStore: MemoryStore cleared
23/12/03 07:40:10 INFO BlockManager: BlockManager stopped
23/12/03 07:40:10 INFO BlockManagerMaster: BlockManagerMaster stopped
23/12/03 07:40:10 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/12/03 07:40:10 INFO SparkContext: Successfully stopped SparkContext
23/12/03 07:40:25 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/03 07:40:25 INFO SparkContext: SparkContext already stopped.
23/12/03 07:40:25 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/03 07:40:25 INFO SparkContext: SparkContext already stopped.
23/12/03 07:49:23 WARN RemoteEndpoint: Unmatched cancel notification for request id 13444
23/12/03 07:50:57 INFO ShutdownHookManager: Shutdown hook called
23/12/03 07:50:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-be278748-b70b-44c8-873a-ad8fd05687f5
23/12/03 07:50:57 ERROR Configuration: error parsing conf core-default.xml
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/target/bg-jobs/sbt_5a7d4dd9/target/a96afb48/359669fc/hadoop-client-api-3.3.4.jar
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)
	at java.base/sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:149)
	at java.base/sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
	at java.base/java.nio.file.Files.readAttributes(Files.java:1764)
	at java.base/java.util.zip.ZipFile$Source.get(ZipFile.java:1381)
	at java.base/java.util.zip.ZipFile$CleanableResource.<init>(ZipFile.java:840)
	at java.base/java.util.zip.ZipFile$CleanableResource$FinalizableResource.<init>(ZipFile.java:866)
	at java.base/java.util.zip.ZipFile$CleanableResource.get(ZipFile.java:855)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:257)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:186)
	at java.base/java.util.jar.JarFile.<init>(JarFile.java:348)
	at java.base/sun.net.www.protocol.jar.URLJarFile.<init>(URLJarFile.java:103)
	at java.base/sun.net.www.protocol.jar.URLJarFile.getJarFile(URLJarFile.java:72)
	at java.base/sun.net.www.protocol.jar.JarFileFactory.get(JarFileFactory.java:99)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.connect(JarURLConnection.java:125)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.getInputStream(JarURLConnection.java:155)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:3009)
	at org.apache.hadoop.conf.Configuration.getStreamReader(Configuration.java:3105)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3063)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:3036)
	at org.apache.hadoop.conf.Configuration.loadProps(Configuration.java:2914)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2896)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:1246)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1863)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)
	at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)
	at org.apache.hadoop.util.ShutdownHookManager.shutdownExecutor(ShutdownHookManager.java:145)
	at org.apache.hadoop.util.ShutdownHookManager.access$300(ShutdownHookManager.java:65)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:102)
23/12/03 08:21:36 WARN RemoteEndpoint: Unmatched cancel notification for request id 15111
23/12/03 08:23:05 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/03 08:23:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/03 08:23:05 INFO SparkContext: Running Spark version 3.5.0
23/12/03 08:23:05 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 08:23:05 INFO SparkContext: Java version 11.0.20
23/12/03 08:23:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/03 08:23:06 INFO ResourceUtils: ==============================================================
23/12/03 08:23:06 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/03 08:23:06 INFO ResourceUtils: ==============================================================
23/12/03 08:23:06 INFO SparkContext: Submitted application: sparkApp
23/12/03 08:23:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/03 08:23:06 INFO ResourceProfile: Limiting resource is cpu
23/12/03 08:23:06 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/03 08:23:06 INFO SecurityManager: Changing view acls to: bsoleille
23/12/03 08:23:06 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/03 08:23:06 INFO SecurityManager: Changing view acls groups to: 
23/12/03 08:23:06 INFO SecurityManager: Changing modify acls groups to: 
23/12/03 08:23:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/03 08:23:06 INFO Utils: Successfully started service 'sparkDriver' on port 44889.
23/12/03 08:23:06 INFO SparkEnv: Registering MapOutputTracker
23/12/03 08:23:06 INFO SparkEnv: Registering BlockManagerMaster
23/12/03 08:23:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/03 08:23:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/03 08:23:06 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/03 08:23:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-38926cc7-5dc5-4ed4-ba4e-b2b14a0a6b33
23/12/03 08:23:06 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/03 08:23:06 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/03 08:23:06 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/03 08:23:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/03 08:23:06 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/03 08:23:06 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/03 08:23:06 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/12/03 08:23:06 INFO Utils: Successfully started service 'SparkUI' on port 4044.
23/12/03 08:23:06 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/03 08:23:06 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 08:23:06 INFO Executor: Java version 11.0.20
23/12/03 08:23:06 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/03 08:23:06 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7240ab59 for default.
23/12/03 08:23:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39529.
23/12/03 08:23:06 INFO NettyBlockTransferService: Server created on 10.25.86.80:39529
23/12/03 08:23:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/03 08:23:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 39529, None)
23/12/03 08:23:06 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:39529 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 39529, None)
23/12/03 08:23:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 39529, None)
23/12/03 08:23:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 39529, None)
23/12/03 08:23:06 INFO threads: JBoss Threads version 3.1.0.Final
23/12/03 08:23:06 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 08:23:06 INFO xnio: XNIO version 3.8.7.Final
23/12/03 08:23:06 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/03 08:23:14 INFO SparkContext: Invoking stop() from shutdown hook
23/12/03 08:23:14 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/03 08:23:14 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4044
23/12/03 08:23:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/12/03 08:23:14 INFO MemoryStore: MemoryStore cleared
23/12/03 08:23:14 INFO BlockManager: BlockManager stopped
23/12/03 08:23:14 INFO BlockManagerMaster: BlockManagerMaster stopped
23/12/03 08:23:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/12/03 08:23:14 INFO SparkContext: Successfully stopped SparkContext
23/12/03 08:23:14 INFO ShutdownHookManager: Shutdown hook called
23/12/03 08:23:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-6b3c96a5-2822-41a4-aea0-8778b5185c25
23/12/03 08:23:14 ERROR Configuration: error parsing conf core-default.xml
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/target/bg-jobs/sbt_3dd4ae13/target/a96afb48/359669fc/hadoop-client-api-3.3.4.jar
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)
	at java.base/sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:149)
	at java.base/sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
	at java.base/java.nio.file.Files.readAttributes(Files.java:1764)
	at java.base/java.util.zip.ZipFile$Source.get(ZipFile.java:1381)
	at java.base/java.util.zip.ZipFile$CleanableResource.<init>(ZipFile.java:840)
	at java.base/java.util.zip.ZipFile$CleanableResource$FinalizableResource.<init>(ZipFile.java:866)
	at java.base/java.util.zip.ZipFile$CleanableResource.get(ZipFile.java:855)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:257)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:186)
	at java.base/java.util.jar.JarFile.<init>(JarFile.java:348)
	at java.base/sun.net.www.protocol.jar.URLJarFile.<init>(URLJarFile.java:103)
	at java.base/sun.net.www.protocol.jar.URLJarFile.getJarFile(URLJarFile.java:72)
	at java.base/sun.net.www.protocol.jar.JarFileFactory.get(JarFileFactory.java:99)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.connect(JarURLConnection.java:125)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.getInputStream(JarURLConnection.java:155)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:3009)
	at org.apache.hadoop.conf.Configuration.getStreamReader(Configuration.java:3105)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3063)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:3036)
	at org.apache.hadoop.conf.Configuration.loadProps(Configuration.java:2914)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2896)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:1246)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1863)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)
	at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)
	at org.apache.hadoop.util.ShutdownHookManager.shutdownExecutor(ShutdownHookManager.java:145)
	at org.apache.hadoop.util.ShutdownHookManager.access$300(ShutdownHookManager.java:65)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:102)
23/12/03 08:23:23 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/03 08:23:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/03 08:23:23 INFO SparkContext: Running Spark version 3.5.0
23/12/03 08:23:23 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 08:23:23 INFO SparkContext: Java version 11.0.20
23/12/03 08:23:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/03 08:23:23 INFO ResourceUtils: ==============================================================
23/12/03 08:23:23 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/03 08:23:23 INFO ResourceUtils: ==============================================================
23/12/03 08:23:23 INFO SparkContext: Submitted application: sparkApp
23/12/03 08:23:23 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/03 08:23:23 INFO ResourceProfile: Limiting resource is cpu
23/12/03 08:23:23 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/03 08:23:23 INFO SecurityManager: Changing view acls to: bsoleille
23/12/03 08:23:23 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/03 08:23:23 INFO SecurityManager: Changing view acls groups to: 
23/12/03 08:23:23 INFO SecurityManager: Changing modify acls groups to: 
23/12/03 08:23:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/03 08:23:23 INFO Utils: Successfully started service 'sparkDriver' on port 41851.
23/12/03 08:23:23 INFO SparkEnv: Registering MapOutputTracker
23/12/03 08:23:23 INFO SparkEnv: Registering BlockManagerMaster
23/12/03 08:23:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/03 08:23:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/03 08:23:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/03 08:23:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-442956b1-1610-477e-a193-c79ce04fb55e
23/12/03 08:23:23 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/03 08:23:23 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/03 08:23:23 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/03 08:23:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/03 08:23:23 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/03 08:23:23 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/03 08:23:23 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/12/03 08:23:23 INFO Utils: Successfully started service 'SparkUI' on port 4044.
23/12/03 08:23:23 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/03 08:23:23 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 08:23:23 INFO Executor: Java version 11.0.20
23/12/03 08:23:23 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/03 08:23:23 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@14d277a4 for default.
23/12/03 08:23:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38801.
23/12/03 08:23:23 INFO NettyBlockTransferService: Server created on 10.25.86.80:38801
23/12/03 08:23:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/03 08:23:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 38801, None)
23/12/03 08:23:23 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:38801 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 38801, None)
23/12/03 08:23:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 38801, None)
23/12/03 08:23:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 38801, None)
23/12/03 08:23:24 INFO threads: JBoss Threads version 3.1.0.Final
23/12/03 08:23:24 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 08:23:24 INFO xnio: XNIO version 3.8.7.Final
23/12/03 08:23:24 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/03 08:23:37 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/03 08:23:37 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/03 08:23:38 INFO CodeGenerator: Code generated in 136.395477 ms
23/12/03 08:23:39 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/03 08:23:39 INFO DAGScheduler: Got job 0 (collect at SparkJob.scala:13) with 1 output partitions
23/12/03 08:23:39 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkJob.scala:13)
23/12/03 08:23:39 INFO DAGScheduler: Parents of final stage: List()
23/12/03 08:23:39 INFO DAGScheduler: Missing parents: List()
23/12/03 08:23:39 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13), which has no missing parents
23/12/03 08:23:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/03 08:23:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 434.4 MiB)
23/12/03 08:23:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:38801 (size: 6.1 KiB, free: 434.4 MiB)
23/12/03 08:23:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/03 08:23:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/03 08:23:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/03 08:23:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/03 08:23:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/03 08:23:39 INFO CodeGenerator: Code generated in 10.751369 ms
23/12/03 08:23:39 INFO CodeGenerator: Code generated in 26.120237 ms
23/12/03 08:23:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1700 bytes result sent to driver
23/12/03 08:23:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 752 ms on 10.25.86.80 (executor driver) (1/1)
23/12/03 08:23:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/03 08:23:39 INFO DAGScheduler: ResultStage 0 (collect at SparkJob.scala:13) finished in 0.864 s
23/12/03 08:23:39 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/03 08:23:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/03 08:23:39 INFO DAGScheduler: Job 0 finished: collect at SparkJob.scala:13, took 0.890316 s
23/12/03 08:23:39 INFO CodeGenerator: Code generated in 9.17196 ms
23/12/03 08:23:39 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/03 08:23:39 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4044
23/12/03 08:23:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/12/03 08:23:39 INFO MemoryStore: MemoryStore cleared
23/12/03 08:23:39 INFO BlockManager: BlockManager stopped
23/12/03 08:23:39 INFO BlockManagerMaster: BlockManagerMaster stopped
23/12/03 08:23:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/12/03 08:23:39 INFO SparkContext: Successfully stopped SparkContext
23/12/03 22:02:36 INFO ShutdownHookManager: Shutdown hook called
23/12/03 22:02:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-00ef0fa1-d3c7-4d59-aadf-f6acbb2ec2af
23/12/03 22:02:36 ERROR Configuration: error parsing conf core-default.xml
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/target/bg-jobs/sbt_8b99e99e/target/a96afb48/359669fc/hadoop-client-api-3.3.4.jar
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)
	at java.base/sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:149)
	at java.base/sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
	at java.base/java.nio.file.Files.readAttributes(Files.java:1764)
	at java.base/java.util.zip.ZipFile$Source.get(ZipFile.java:1381)
	at java.base/java.util.zip.ZipFile$CleanableResource.<init>(ZipFile.java:840)
	at java.base/java.util.zip.ZipFile$CleanableResource$FinalizableResource.<init>(ZipFile.java:866)
	at java.base/java.util.zip.ZipFile$CleanableResource.get(ZipFile.java:855)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:257)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:186)
	at java.base/java.util.jar.JarFile.<init>(JarFile.java:348)
	at java.base/sun.net.www.protocol.jar.URLJarFile.<init>(URLJarFile.java:103)
	at java.base/sun.net.www.protocol.jar.URLJarFile.getJarFile(URLJarFile.java:72)
	at java.base/sun.net.www.protocol.jar.JarFileFactory.get(JarFileFactory.java:99)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.connect(JarURLConnection.java:125)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.getInputStream(JarURLConnection.java:155)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:3009)
	at org.apache.hadoop.conf.Configuration.getStreamReader(Configuration.java:3105)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3063)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:3036)
	at org.apache.hadoop.conf.Configuration.loadProps(Configuration.java:2914)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2896)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:1246)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1863)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)
	at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)
	at org.apache.hadoop.util.ShutdownHookManager.shutdownExecutor(ShutdownHookManager.java:145)
	at org.apache.hadoop.util.ShutdownHookManager.access$300(ShutdownHookManager.java:65)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:102)
23/12/03 22:03:54 ERROR CompilerAccess: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-03/r_compiler-error_(project-effective-scala-c1-s14-3039-4085)_22-03-54-764.md
23/12/03 22:04:31 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/03 22:04:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/03 22:04:31 INFO SparkContext: Running Spark version 3.5.0
23/12/03 22:04:31 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 22:04:31 INFO SparkContext: Java version 11.0.20
23/12/03 22:04:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/03 22:04:31 INFO ResourceUtils: ==============================================================
23/12/03 22:04:31 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/03 22:04:31 INFO ResourceUtils: ==============================================================
23/12/03 22:04:31 INFO SparkContext: Submitted application: sparkApp
23/12/03 22:04:31 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/03 22:04:31 INFO ResourceProfile: Limiting resource is cpu
23/12/03 22:04:31 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/03 22:04:31 INFO SecurityManager: Changing view acls to: bsoleille
23/12/03 22:04:31 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/03 22:04:31 INFO SecurityManager: Changing view acls groups to: 
23/12/03 22:04:31 INFO SecurityManager: Changing modify acls groups to: 
23/12/03 22:04:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/03 22:04:31 INFO Utils: Successfully started service 'sparkDriver' on port 45341.
23/12/03 22:04:31 INFO SparkEnv: Registering MapOutputTracker
23/12/03 22:04:31 INFO SparkEnv: Registering BlockManagerMaster
23/12/03 22:04:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/03 22:04:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/03 22:04:31 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/03 22:04:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5e72a832-cdf4-41fa-a4fb-57ca3b85ddc2
23/12/03 22:04:31 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/03 22:04:31 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/03 22:04:31 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/03 22:04:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/03 22:04:31 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/03 22:04:31 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/03 22:04:31 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/12/03 22:04:31 INFO Utils: Successfully started service 'SparkUI' on port 4044.
23/12/03 22:04:32 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/03 22:04:32 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 22:04:32 INFO Executor: Java version 11.0.20
23/12/03 22:04:32 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/03 22:04:32 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4a6ada35 for default.
23/12/03 22:04:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33149.
23/12/03 22:04:32 INFO NettyBlockTransferService: Server created on 10.25.86.80:33149
23/12/03 22:04:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/03 22:04:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 33149, None)
23/12/03 22:04:32 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:33149 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 33149, None)
23/12/03 22:04:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 33149, None)
23/12/03 22:04:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 33149, None)
23/12/03 22:04:32 INFO threads: JBoss Threads version 3.1.0.Final
23/12/03 22:04:32 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 22:04:32 INFO xnio: XNIO version 3.8.7.Final
23/12/03 22:04:32 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/03 22:04:40 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/03 22:04:40 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/03 22:04:41 INFO CodeGenerator: Code generated in 118.178224 ms
23/12/03 22:04:42 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/03 22:04:42 INFO DAGScheduler: Got job 0 (collect at SparkJob.scala:13) with 1 output partitions
23/12/03 22:04:42 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkJob.scala:13)
23/12/03 22:04:42 INFO DAGScheduler: Parents of final stage: List()
23/12/03 22:04:42 INFO DAGScheduler: Missing parents: List()
23/12/03 22:04:42 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13), which has no missing parents
23/12/03 22:04:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/03 22:04:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 434.4 MiB)
23/12/03 22:04:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:33149 (size: 6.1 KiB, free: 434.4 MiB)
23/12/03 22:04:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/03 22:04:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/03 22:04:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/03 22:04:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/03 22:04:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/03 22:04:42 INFO CodeGenerator: Code generated in 9.680034 ms
23/12/03 22:04:42 INFO CodeGenerator: Code generated in 26.375605 ms
23/12/03 22:04:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1700 bytes result sent to driver
23/12/03 22:04:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 741 ms on 10.25.86.80 (executor driver) (1/1)
23/12/03 22:04:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/03 22:04:42 INFO DAGScheduler: ResultStage 0 (collect at SparkJob.scala:13) finished in 0.862 s
23/12/03 22:04:42 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/03 22:04:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/03 22:04:42 INFO DAGScheduler: Job 0 finished: collect at SparkJob.scala:13, took 0.886712 s
23/12/03 22:04:42 INFO CodeGenerator: Code generated in 8.623222 ms
23/12/03 22:04:42 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/03 22:04:43 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4044
23/12/03 22:04:43 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/12/03 22:04:43 INFO MemoryStore: MemoryStore cleared
23/12/03 22:04:43 INFO BlockManager: BlockManager stopped
23/12/03 22:04:43 INFO BlockManagerMaster: BlockManagerMaster stopped
23/12/03 22:04:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/12/03 22:04:43 INFO SparkContext: Successfully stopped SparkContext
23/12/03 22:05:55 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/03 22:05:55 INFO SparkContext: SparkContext already stopped.
23/12/03 22:06:14 INFO ShutdownHookManager: Shutdown hook called
23/12/03 22:06:14 INFO ShutdownHookManager: Deleting directory /tmp/spark-c3b195e9-dc97-429c-8427-de3184bb3620
23/12/03 22:06:14 ERROR Configuration: error parsing conf core-default.xml
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/target/bg-jobs/sbt_bbde6e35/target/a96afb48/359669fc/hadoop-client-api-3.3.4.jar
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)
	at java.base/sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:149)
	at java.base/sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
	at java.base/java.nio.file.Files.readAttributes(Files.java:1764)
	at java.base/java.util.zip.ZipFile$Source.get(ZipFile.java:1381)
	at java.base/java.util.zip.ZipFile$CleanableResource.<init>(ZipFile.java:840)
	at java.base/java.util.zip.ZipFile$CleanableResource$FinalizableResource.<init>(ZipFile.java:866)
	at java.base/java.util.zip.ZipFile$CleanableResource.get(ZipFile.java:855)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:257)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:186)
	at java.base/java.util.jar.JarFile.<init>(JarFile.java:348)
	at java.base/sun.net.www.protocol.jar.URLJarFile.<init>(URLJarFile.java:103)
	at java.base/sun.net.www.protocol.jar.URLJarFile.getJarFile(URLJarFile.java:72)
	at java.base/sun.net.www.protocol.jar.JarFileFactory.get(JarFileFactory.java:99)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.connect(JarURLConnection.java:125)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.getInputStream(JarURLConnection.java:155)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:3009)
	at org.apache.hadoop.conf.Configuration.getStreamReader(Configuration.java:3105)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3063)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:3036)
	at org.apache.hadoop.conf.Configuration.loadProps(Configuration.java:2914)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2896)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:1246)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1863)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)
	at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)
	at org.apache.hadoop.util.ShutdownHookManager.shutdownExecutor(ShutdownHookManager.java:145)
	at org.apache.hadoop.util.ShutdownHookManager.access$300(ShutdownHookManager.java:65)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:102)
23/12/03 22:06:23 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/03 22:06:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/03 22:06:23 INFO SparkContext: Running Spark version 3.5.0
23/12/03 22:06:23 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 22:06:23 INFO SparkContext: Java version 11.0.20
23/12/03 22:06:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/03 22:06:23 INFO ResourceUtils: ==============================================================
23/12/03 22:06:23 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/03 22:06:23 INFO ResourceUtils: ==============================================================
23/12/03 22:06:23 INFO SparkContext: Submitted application: sparkApp
23/12/03 22:06:23 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/03 22:06:23 INFO ResourceProfile: Limiting resource is cpu
23/12/03 22:06:23 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/03 22:06:23 INFO SecurityManager: Changing view acls to: bsoleille
23/12/03 22:06:23 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/03 22:06:23 INFO SecurityManager: Changing view acls groups to: 
23/12/03 22:06:23 INFO SecurityManager: Changing modify acls groups to: 
23/12/03 22:06:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/03 22:06:23 INFO Utils: Successfully started service 'sparkDriver' on port 41459.
23/12/03 22:06:23 INFO SparkEnv: Registering MapOutputTracker
23/12/03 22:06:23 INFO SparkEnv: Registering BlockManagerMaster
23/12/03 22:06:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/03 22:06:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/03 22:06:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/03 22:06:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d47df259-78d5-4774-8ce0-58e8ad8cf47d
23/12/03 22:06:23 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/03 22:06:23 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/03 22:06:23 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/03 22:06:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/03 22:06:23 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/03 22:06:23 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/03 22:06:23 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/12/03 22:06:23 INFO Utils: Successfully started service 'SparkUI' on port 4044.
23/12/03 22:06:24 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/03 22:06:24 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 22:06:24 INFO Executor: Java version 11.0.20
23/12/03 22:06:24 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/03 22:06:24 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3d5a2315 for default.
23/12/03 22:06:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39843.
23/12/03 22:06:24 INFO NettyBlockTransferService: Server created on 10.25.86.80:39843
23/12/03 22:06:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/03 22:06:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 39843, None)
23/12/03 22:06:24 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:39843 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 39843, None)
23/12/03 22:06:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 39843, None)
23/12/03 22:06:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 39843, None)
23/12/03 22:06:24 INFO threads: JBoss Threads version 3.1.0.Final
23/12/03 22:06:24 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 22:06:24 INFO xnio: XNIO version 3.8.7.Final
23/12/03 22:06:24 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/03 22:06:30 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/03 22:06:30 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/03 22:06:31 INFO CodeGenerator: Code generated in 129.304295 ms
23/12/03 22:06:31 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/03 22:06:31 INFO DAGScheduler: Got job 0 (collect at SparkJob.scala:13) with 1 output partitions
23/12/03 22:06:31 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkJob.scala:13)
23/12/03 22:06:31 INFO DAGScheduler: Parents of final stage: List()
23/12/03 22:06:31 INFO DAGScheduler: Missing parents: List()
23/12/03 22:06:31 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13), which has no missing parents
23/12/03 22:06:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/03 22:06:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 434.4 MiB)
23/12/03 22:06:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:39843 (size: 6.1 KiB, free: 434.4 MiB)
23/12/03 22:06:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/03 22:06:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/03 22:06:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/03 22:06:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/03 22:06:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/03 22:06:31 INFO CodeGenerator: Code generated in 6.516206 ms
23/12/03 22:06:32 INFO CodeGenerator: Code generated in 25.903299 ms
23/12/03 22:06:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1700 bytes result sent to driver
23/12/03 22:06:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 694 ms on 10.25.86.80 (executor driver) (1/1)
23/12/03 22:06:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/03 22:06:32 INFO DAGScheduler: ResultStage 0 (collect at SparkJob.scala:13) finished in 0.792 s
23/12/03 22:06:32 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/03 22:06:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/03 22:06:32 INFO DAGScheduler: Job 0 finished: collect at SparkJob.scala:13, took 0.815907 s
23/12/03 22:06:32 INFO CodeGenerator: Code generated in 10.747463 ms
23/12/03 22:06:32 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/03 22:06:32 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4044
23/12/03 22:06:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/12/03 22:06:32 INFO MemoryStore: MemoryStore cleared
23/12/03 22:06:32 INFO BlockManager: BlockManager stopped
23/12/03 22:06:32 INFO BlockManagerMaster: BlockManagerMaster stopped
23/12/03 22:06:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/12/03 22:06:32 INFO SparkContext: Successfully stopped SparkContext
23/12/03 22:08:10 INFO ShutdownHookManager: Shutdown hook called
23/12/03 22:08:10 INFO ShutdownHookManager: Deleting directory /tmp/spark-72c756ea-9c7a-4918-9a4a-3cd093454b81
23/12/03 22:08:10 ERROR Configuration: error parsing conf core-default.xml
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/target/bg-jobs/sbt_cf2a513a/target/a96afb48/359669fc/hadoop-client-api-3.3.4.jar
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)
	at java.base/sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:149)
	at java.base/sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
	at java.base/java.nio.file.Files.readAttributes(Files.java:1764)
	at java.base/java.util.zip.ZipFile$Source.get(ZipFile.java:1381)
	at java.base/java.util.zip.ZipFile$CleanableResource.<init>(ZipFile.java:840)
	at java.base/java.util.zip.ZipFile$CleanableResource$FinalizableResource.<init>(ZipFile.java:866)
	at java.base/java.util.zip.ZipFile$CleanableResource.get(ZipFile.java:855)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:257)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:186)
	at java.base/java.util.jar.JarFile.<init>(JarFile.java:348)
	at java.base/sun.net.www.protocol.jar.URLJarFile.<init>(URLJarFile.java:103)
	at java.base/sun.net.www.protocol.jar.URLJarFile.getJarFile(URLJarFile.java:72)
	at java.base/sun.net.www.protocol.jar.JarFileFactory.get(JarFileFactory.java:99)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.connect(JarURLConnection.java:125)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.getInputStream(JarURLConnection.java:155)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:3009)
	at org.apache.hadoop.conf.Configuration.getStreamReader(Configuration.java:3105)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3063)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:3036)
	at org.apache.hadoop.conf.Configuration.loadProps(Configuration.java:2914)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2896)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:1246)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1863)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)
	at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)
	at org.apache.hadoop.util.ShutdownHookManager.shutdownExecutor(ShutdownHookManager.java:145)
	at org.apache.hadoop.util.ShutdownHookManager.access$300(ShutdownHookManager.java:65)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:102)
23/12/03 22:08:25 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/03 22:08:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/03 22:08:25 INFO SparkContext: Running Spark version 3.5.0
23/12/03 22:08:25 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 22:08:25 INFO SparkContext: Java version 11.0.20
23/12/03 22:08:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/03 22:08:25 INFO ResourceUtils: ==============================================================
23/12/03 22:08:25 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/03 22:08:25 INFO ResourceUtils: ==============================================================
23/12/03 22:08:25 INFO SparkContext: Submitted application: sparkApp
23/12/03 22:08:25 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/03 22:08:25 INFO ResourceProfile: Limiting resource is cpu
23/12/03 22:08:25 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/03 22:08:25 INFO SecurityManager: Changing view acls to: bsoleille
23/12/03 22:08:25 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/03 22:08:25 INFO SecurityManager: Changing view acls groups to: 
23/12/03 22:08:25 INFO SecurityManager: Changing modify acls groups to: 
23/12/03 22:08:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/03 22:08:26 INFO Utils: Successfully started service 'sparkDriver' on port 34719.
23/12/03 22:08:26 INFO SparkEnv: Registering MapOutputTracker
23/12/03 22:08:26 INFO SparkEnv: Registering BlockManagerMaster
23/12/03 22:08:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/03 22:08:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/03 22:08:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/03 22:08:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9a0c6f7a-2be8-4155-a082-204e3ee86b52
23/12/03 22:08:26 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/03 22:08:26 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/03 22:08:26 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/03 22:08:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/03 22:08:26 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/03 22:08:26 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/03 22:08:26 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/12/03 22:08:26 INFO Utils: Successfully started service 'SparkUI' on port 4044.
23/12/03 22:08:26 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/03 22:08:26 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/03 22:08:26 INFO Executor: Java version 11.0.20
23/12/03 22:08:26 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/03 22:08:26 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@15517ade for default.
23/12/03 22:08:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46547.
23/12/03 22:08:26 INFO NettyBlockTransferService: Server created on 10.25.86.80:46547
23/12/03 22:08:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/03 22:08:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 46547, None)
23/12/03 22:08:26 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:46547 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 46547, None)
23/12/03 22:08:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 46547, None)
23/12/03 22:08:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 46547, None)
23/12/03 22:08:26 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 22:08:26 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 22:08:26 INFO xnio: XNIO version 3.8.7.Final
23/12/03 22:08:26 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/03 22:08:26 INFO threads: JBoss Threads version 3.1.0.Final
23/12/03 22:08:26 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/03 22:08:26 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 22:08:26 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/03 22:08:26 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/03 22:08:26 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 22:08:26 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/03 22:08:26 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 22:08:26 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/03 22:08:26 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 22:08:27 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/03 22:08:27 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/03 22:08:27 INFO undertow: stopping server: Undertow - 2.2.20.Final
23/12/03 22:12:53 WARN WadlFeature: JAX-B API not found . WADL feature is disabled.
23/12/04 09:51:30 WARN RemoteEndpoint: Unmatched cancel notification for request id 17436
23/12/04 09:51:32 WARN RemoteEndpoint: Unmatched cancel notification for request id 17441
23/12/04 09:55:41 WARN RemoteEndpoint: Unmatched cancel notification for request id 18017
23/12/04 10:12:45 WARN RemoteEndpoint: Unmatched cancel notification for request id 19290
23/12/04 10:22:10 WARN RemoteEndpoint: Unmatched cancel notification for request id 20675
23/12/04 10:35:22 WARN RemoteEndpoint: Unmatched cancel notification for request id 21146
23/12/04 10:38:45 WARN RemoteEndpoint: Unmatched cancel notification for request id 21575
23/12/04 10:41:46 WARN RemoteEndpoint: Unmatched cancel notification for request id 21910
23/12/04 10:41:46 WARN RemoteEndpoint: Unmatched cancel notification for request id 21911
23/12/04 10:42:05 ERROR RemoteEndpoint: Internal error: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
java.util.concurrent.CompletionException: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:159)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
23/12/04 10:42:05 ERROR RemoteEndpoint: Internal error: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
java.util.concurrent.CompletionException: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:159)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
23/12/04 10:47:31 INFO SparkContext: Invoking stop() from shutdown hook
23/12/04 10:47:31 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/04 10:47:31 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4044
23/12/04 10:47:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/12/04 10:47:31 INFO MemoryStore: MemoryStore cleared
23/12/04 10:47:31 INFO BlockManager: BlockManager stopped
23/12/04 10:47:31 INFO BlockManagerMaster: BlockManagerMaster stopped
23/12/04 10:47:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/12/04 10:47:31 INFO SparkContext: Successfully stopped SparkContext
23/12/04 10:47:31 INFO ShutdownHookManager: Shutdown hook called
23/12/04 10:47:31 INFO ShutdownHookManager: Deleting directory /tmp/spark-411257ab-f6e1-4e07-85a4-4f156204e3c9
23/12/04 10:51:12 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/04 10:51:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/04 10:51:12 INFO SparkContext: Running Spark version 3.5.0
23/12/04 10:51:12 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/04 10:51:12 INFO SparkContext: Java version 11.0.20
23/12/04 10:51:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/04 10:51:12 INFO ResourceUtils: ==============================================================
23/12/04 10:51:12 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/04 10:51:12 INFO ResourceUtils: ==============================================================
23/12/04 10:51:12 INFO SparkContext: Submitted application: Spark dataframes for processing in startup.ast
23/12/04 10:51:12 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/04 10:51:12 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor
23/12/04 10:51:12 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/04 10:51:12 INFO SecurityManager: Changing view acls to: bsoleille
23/12/04 10:51:12 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/04 10:51:12 INFO SecurityManager: Changing view acls groups to: 
23/12/04 10:51:12 INFO SecurityManager: Changing modify acls groups to: 
23/12/04 10:51:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/04 10:51:12 INFO Utils: Successfully started service 'sparkDriver' on port 43943.
23/12/04 10:51:12 INFO SparkEnv: Registering MapOutputTracker
23/12/04 10:51:12 INFO SparkEnv: Registering BlockManagerMaster
23/12/04 10:51:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/04 10:51:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/04 10:51:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/04 10:51:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0d458197-1d07-4a74-91cd-131d0719563e
23/12/04 10:51:12 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/04 10:51:12 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/04 10:51:12 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/04 10:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/04 10:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/04 10:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/04 10:51:13 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
23/12/04 10:51:13 INFO Utils: Successfully started service 'SparkUI' on port 4044.
23/12/04 10:51:13 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/04 10:51:13 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/04 10:51:13 INFO Executor: Java version 11.0.20
23/12/04 10:51:13 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/04 10:51:13 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@118775d for default.
23/12/04 10:51:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45157.
23/12/04 10:51:13 INFO NettyBlockTransferService: Server created on 10.25.86.80:45157
23/12/04 10:51:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/04 10:51:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 45157, None)
23/12/04 10:51:13 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:45157 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 45157, None)
23/12/04 10:51:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 45157, None)
23/12/04 10:51:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 45157, None)
23/12/04 10:51:13 INFO threads: JBoss Threads version 3.1.0.Final
23/12/04 10:51:13 INFO undertow: starting server: Undertow - 2.2.20.Final
23/12/04 10:51:13 INFO xnio: XNIO version 3.8.7.Final
23/12/04 10:51:13 INFO nio: XNIO NIO Implementation Version 3.8.7.Final
23/12/04 10:51:23 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/04 10:51:23 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/04 10:51:24 INFO CodeGenerator: Code generated in 123.356817 ms
23/12/04 10:51:24 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/04 10:51:24 INFO DAGScheduler: Got job 0 (collect at SparkJob.scala:13) with 1 output partitions
23/12/04 10:51:24 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkJob.scala:13)
23/12/04 10:51:24 INFO DAGScheduler: Parents of final stage: List()
23/12/04 10:51:24 INFO DAGScheduler: Missing parents: List()
23/12/04 10:51:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13), which has no missing parents
23/12/04 10:51:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/04 10:51:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 434.4 MiB)
23/12/04 10:51:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:45157 (size: 6.1 KiB, free: 434.4 MiB)
23/12/04 10:51:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/04 10:51:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/04 10:51:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/04 10:51:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/04 10:51:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/04 10:51:25 INFO CodeGenerator: Code generated in 8.657464 ms
23/12/04 10:51:25 INFO CodeGenerator: Code generated in 26.585459 ms
23/12/04 10:51:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1700 bytes result sent to driver
23/12/04 10:51:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 813 ms on 10.25.86.80 (executor driver) (1/1)
23/12/04 10:51:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/04 10:51:25 INFO DAGScheduler: ResultStage 0 (collect at SparkJob.scala:13) finished in 0.913 s
23/12/04 10:51:25 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/04 10:51:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/04 10:51:25 INFO DAGScheduler: Job 0 finished: collect at SparkJob.scala:13, took 0.938364 s
23/12/04 10:51:25 INFO CodeGenerator: Code generated in 10.339321 ms
23/12/04 10:51:52 INFO SparkContext: Invoking stop() from shutdown hook
23/12/04 10:51:52 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/12/04 10:51:52 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4044
23/12/04 10:51:52 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/12/04 10:51:52 INFO MemoryStore: MemoryStore cleared
23/12/04 10:51:52 INFO BlockManager: BlockManager stopped
23/12/04 10:51:52 INFO BlockManagerMaster: BlockManagerMaster stopped
23/12/04 10:51:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/12/04 10:51:52 INFO SparkContext: Successfully stopped SparkContext
23/12/04 10:51:52 INFO ShutdownHookManager: Shutdown hook called
23/12/04 10:51:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-16bd182d-8f4c-4dce-9e4e-0dbf5f8b5d19
23/12/04 10:51:52 ERROR Configuration: error parsing conf core-default.xml
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/target/bg-jobs/sbt_7f15e44d/target/a96afb48/359669fc/hadoop-client-api-3.3.4.jar
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55)
	at java.base/sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:149)
	at java.base/sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99)
	at java.base/java.nio.file.Files.readAttributes(Files.java:1764)
	at java.base/java.util.zip.ZipFile$Source.get(ZipFile.java:1381)
	at java.base/java.util.zip.ZipFile$CleanableResource.<init>(ZipFile.java:840)
	at java.base/java.util.zip.ZipFile$CleanableResource$FinalizableResource.<init>(ZipFile.java:866)
	at java.base/java.util.zip.ZipFile$CleanableResource.get(ZipFile.java:855)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:257)
	at java.base/java.util.zip.ZipFile.<init>(ZipFile.java:186)
	at java.base/java.util.jar.JarFile.<init>(JarFile.java:348)
	at java.base/sun.net.www.protocol.jar.URLJarFile.<init>(URLJarFile.java:103)
	at java.base/sun.net.www.protocol.jar.URLJarFile.getJarFile(URLJarFile.java:72)
	at java.base/sun.net.www.protocol.jar.JarFileFactory.get(JarFileFactory.java:99)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.connect(JarURLConnection.java:125)
	at java.base/sun.net.www.protocol.jar.JarURLConnection.getInputStream(JarURLConnection.java:155)
	at org.apache.hadoop.conf.Configuration.parse(Configuration.java:3009)
	at org.apache.hadoop.conf.Configuration.getStreamReader(Configuration.java:3105)
	at org.apache.hadoop.conf.Configuration.loadResource(Configuration.java:3063)
	at org.apache.hadoop.conf.Configuration.loadResources(Configuration.java:3036)
	at org.apache.hadoop.conf.Configuration.loadProps(Configuration.java:2914)
	at org.apache.hadoop.conf.Configuration.getProps(Configuration.java:2896)
	at org.apache.hadoop.conf.Configuration.get(Configuration.java:1246)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1863)
	at org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)
	at org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)
	at org.apache.hadoop.util.ShutdownHookManager.shutdownExecutor(ShutdownHookManager.java:145)
	at org.apache.hadoop.util.ShutdownHookManager.access$300(ShutdownHookManager.java:65)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:102)
