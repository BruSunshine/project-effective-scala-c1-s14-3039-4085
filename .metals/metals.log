2023.11.30 10:27:59 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.30 10:28:00 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:28:00 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:28:00 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:28:00 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:28:00 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:28:00 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:28:00 INFO  time: Connected to build server in 0.44s[0m
2023.11.30 10:28:01 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 10:28:02 INFO  running '/home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals5086891921994303325/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'[0m
2023.11.30 10:28:02 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.11.30 10:28:03 INFO  [info] welcome to sbt 1.9.6 (Eclipse Adoptium Java 11.0.20)[0m
2023.11.30 10:28:03 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build-build from metals.sbt ...[0m
2023.11.30 10:28:04 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/project[0m
2023.11.30 10:28:04 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build from metals.sbt ...[0m
2023.11.30 10:28:04 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project[0m
2023.11.30 10:28:07 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-build.json[0m
2023.11.30 10:28:07 INFO  [success] Total time: 1 s, completed Nov 30, 2023, 10:28:07 AM[0m
2023.11.30 10:28:07 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085 from build.sbt ...[0m
2023.11.30 10:28:07 INFO  [info] set current project to myScala3Project (in build file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/)[0m
2023.11.30 10:28:07 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-test.json[0m
2023.11.30 10:28:07 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085.json[0m
2023.11.30 10:28:07 INFO  [success] Total time: 0 s, completed Nov 30, 2023, 10:28:08 AM[0m
2023.11.30 10:28:08 INFO  time: indexed workspace in 5.33s[0m
2023.11.30 10:28:08 INFO  time: ran 'sbt bloopInstall' in 6.02s[0m
2023.11.30 10:28:08 INFO  Disconnecting from Bloop session...[0m
2023.11.30 10:28:08 INFO  Cancelling compilation on Bloop server[0m
2023.11.30 10:28:08 INFO  Shut down connection with build server.[0m
2023.11.30 10:28:09 INFO  Shut down connection with build server.[0m
2023.11.30 10:28:09 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:28:09 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:28:09 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:28:09 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:28:09 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:28:09 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:28:09 INFO  time: Connected to build server in 0.16s[0m
2023.11.30 10:28:09 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 10:28:11 INFO  time: indexed workspace in 2.05s[0m
error: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/.metals/.tmp/Main3056551971867302975.scala is not a file
2023.11.30 10:28:23 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.11.30 10:28:23 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.11.30 10:28:23 INFO  Starting debug proxy for [startup.integration_testing.httpServerSuite(test7: Serialize and deserialize expression with dataframe processed through http server)][0m
2023.11.30 10:28:23 INFO  Loaded expression compiler in 1 millisecond[0m
2023.11.30 10:28:23 INFO  Loaded step filter in 0 milliseconds[0m
2023.11.30 10:28:23 INFO  Loaded all sources and classes in 869 milliseconds[0m
2023.11.30 10:28:26 INFO  Trying to attach to remote debuggee VM localhost:54429 .[0m
2023.11.30 10:28:26 INFO  Attaching to debuggee VM succeeded.[0m
2023.11.30 10:28:29 INFO  Closing debug server tcp://0.0.0.0:37279[0m
2023.11.30 10:28:29 INFO  Canceling debug proxy for [startup.integration_testing.httpServerSuite(test7: Serialize and deserialize expression with dataframe processed through http server)][0m
2023.11.30 10:28:51 INFO  Shutting down server[0m
2023.11.30 10:28:51 INFO  shutting down Metals[0m
2023.11.30 10:28:51 INFO  Shut down connection with build server.[0m
2023.11.30 10:28:51 INFO  Shut down connection with build server.[0m
2023.11.30 10:28:51 INFO  Exiting server[0m
2023.11.30 10:29:18 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.30 10:29:19 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:29:19 INFO  skipping build import with status 'Installed'[0m
2023.11.30 10:29:19 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:29:19 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:29:19 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:29:19 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:29:19 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:29:19 INFO  time: Connected to build server in 0.49s[0m
2023.11.30 10:29:19 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 10:29:21 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.11.30 10:29:23 INFO  time: indexed workspace in 1.64s[0m
2023.11.30 10:30:01 INFO  Disconnecting from Bloop session...[0m
2023.11.30 10:30:01 INFO  Shut down connection with build server.[0m
2023.11.30 10:30:01 INFO  Shut down connection with build server.[0m
2023.11.30 10:30:01 INFO  Deleted directories inside .bloop[0m
2023.11.30 10:30:01 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:30:01 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:30:01 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:30:02 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:30:02 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:30:02 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:30:02 INFO  time: Connected to build server in 1.15s[0m
2023.11.30 10:30:02 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 10:30:03 INFO  time: indexed workspace in 1.35s[0m
2023.11.30 10:30:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 10:30:09 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (6 scala sources)[0m
2023.11.30 10:30:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 5.63s[0m
2023.11.30 10:30:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.94s[0m
2023.11.30 10:30:20 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.11.30 10:30:20 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.11.30 10:30:21 INFO  Starting debug proxy for [startup.integration_testing.httpServerSuite(test7: Serialize and deserialize expression with dataframe processed through http server)][0m
2023.11.30 10:30:21 INFO  Loaded expression compiler in 370 milliseconds[0m
2023.11.30 10:30:21 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/ch/epfl/scala/scala-debug-step-filter_3/3.1.4/scala-debug-step-filter_3-3.1.4.jar[0m
2023.11.30 10:30:21 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/tasty-core_3/3.3.1/tasty-core_3-3.3.1.jar[0m
2023.11.30 10:30:21 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala3-library_3/3.3.1/scala3-library_3-3.3.1.jar[0m
2023.11.30 10:30:21 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/ch/epfl/scala/tasty-query_3/0.8.4/tasty-query_3-0.8.4.jar[0m
2023.11.30 10:30:21 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.13.10/scala-library-2.13.10.jar[0m
2023.11.30 10:30:21 INFO  Loaded step filter in 23 milliseconds[0m
2023.11.30 10:30:22 INFO  Loaded all sources and classes in 1 second[0m
2023.11.30 10:30:25 INFO  Trying to attach to remote debuggee VM localhost:52237 .[0m
2023.11.30 10:30:25 INFO  Attaching to debuggee VM succeeded.[0m
2023.11.30 10:30:28 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:28 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SparkContext: Running Spark version 3.5.0[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SparkContext: OS info Linux, 6.2.0-36-generic, amd64[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SparkContext: Java version 11.0.20[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO ResourceUtils: ==============================================================[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO ResourceUtils: No custom resources configured for spark.driver.[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO ResourceUtils: ==============================================================[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SparkContext: Submitted application: Spark Parquet Example[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO ResourceProfile: Limiting resource is cpus at 1 tasks per executor[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO ResourceProfileManager: Added ResourceProfile id: 0[0m
2023.11.30 10:30:29 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SecurityManager: Changing view acls to: bsoleille[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SecurityManager: Changing modify acls to: bsoleille[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SecurityManager: Changing view acls groups to: [0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SecurityManager: Changing modify acls groups to: [0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO Utils: Successfully started service 'sparkDriver' on port 39559.[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SparkEnv: Registering MapOutputTracker[0m
2023.11.30 10:30:28 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.11.30 10:30:28 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.5.0/spark-unsafe_2.13-3.5.0.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.11.30 10:30:28 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.11.30 10:30:28 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.11.30 10:30:28 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SparkEnv: Registering BlockManagerMaster[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-65219f58-0ab3-4f56-a741-019906dc28e4[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO MemoryStore: MemoryStore started with capacity 9.1 GiB[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO SparkEnv: Registering OutputCommitCoordinator[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO Executor: Starting executor ID driver on host 10.25.86.80[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO Executor: OS info Linux, 6.2.0-36-generic, amd64[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO Executor: Java version 11.0.20[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3ac51c9c for default.[0m
2023.11.30 10:30:29 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38989.[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO NettyBlockTransferService: Server created on 10.25.86.80:38989[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 38989, None)[0m
2023.11.30 10:30:29 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:38989 with 9.1 GiB RAM, BlockManagerId(driver, 10.25.86.80, 38989, None)[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 38989, None)[0m
2023.11.30 10:30:28 ERROR 23/11/30 10:30:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 38989, None)[0m
2023.11.30 10:30:29 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:29 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:30 ERROR 23/11/30 10:30:30 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.[0m
2023.11.30 10:30:30 ERROR 23/11/30 10:30:30 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:34 INFO CodeGenerator: Code generated in 135.870634 ms[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO CodeGenerator: Code generated in 12.174846 ms[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO SparkContext: Starting job: collect at Ast.scala:272[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Got job 0 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Final stage: ResultStage 0 (collect at Ast.scala:272)[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 17.4 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:38989 (size: 7.3 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) [0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO CodeGenerator: Code generated in 8.889342 ms[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO CodeGenerator: Code generated in 7.056471 ms[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO CodeGenerator: Code generated in 24.417411 ms[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1869 bytes result sent to driver[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 651 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool [0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: ResultStage 0 (collect at Ast.scala:272) finished in 0.771 s[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Job 0 finished: collect at Ast.scala:272, took 0.800188 s[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Registering RDD 8 (collect at Ast.scala:272) as input to shuffle 0[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Got map stage job 1 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (collect at Ast.scala:272)[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 18.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.25.86.80:38989 (size: 8.1 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8138 bytes) [0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)[0m
2023.11.30 10:30:34 ERROR 23/11/30 10:30:35 INFO CodeGenerator: Code generated in 5.09019 ms[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1793 bytes result sent to driver[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 48 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool [0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:35 INFO DAGScheduler: ShuffleMapStage 1 (collect at Ast.scala:272) finished in 0.064 s[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:35 INFO DAGScheduler: looking for newly runnable stages[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:35 INFO DAGScheduler: running: HashSet()[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:35 INFO DAGScheduler: waiting: HashSet()[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:35 INFO DAGScheduler: failed: HashSet()[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO CodeGenerator: Code generated in 9.203665 ms[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO SparkContext: Starting job: collect at Ast.scala:272[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO DAGScheduler: Got job 2 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO DAGScheduler: Final stage: ResultStage 3 (collect at Ast.scala:272)[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 24.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.25.86.80:38989 (size: 10.7 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:30:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) [0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO CodeGenerator: Code generated in 6.794411 ms[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO CodeGenerator: Code generated in 4.62991 ms[0m
2023.11.30 10:30:36 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 4537 bytes result sent to driver[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 89 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool [0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO DAGScheduler: ResultStage 3 (collect at Ast.scala:272) finished in 0.099 s[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO DAGScheduler: Job 2 finished: collect at Ast.scala:272, took 0.105849 s[0m
2023.11.30 10:30:35 ERROR 23/11/30 10:30:36 INFO CodeGenerator: Code generated in 6.52455 ms[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:38 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:38 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:38 INFO FileOutputCommitter: File Output Committer Algorithm version is 1[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:38 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:38 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO SparkContext: Starting job: parquet at Ast.scala:283[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO DAGScheduler: Got job 3 (parquet at Ast.scala:283) with 1 output partitions[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO DAGScheduler: Final stage: ResultStage 4 (parquet at Ast.scala:283)[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[14] at parquet at Ast.scala:283), which has no missing parents[0m
2023.11.30 10:30:39 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:39 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 216.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:39 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 77.0 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.25.86.80:38989 (size: 77.0 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:39 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[14] at parquet at Ast.scala:283) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8328 bytes) [0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO CodecConfig: Compression: SNAPPY[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO CodecConfig: Compression: SNAPPY[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false][0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:[0m
2023.11.30 10:30:38 ERROR {[0m
2023.11.30 10:30:38 ERROR   "type" : "struct",[0m
2023.11.30 10:30:38 ERROR   "fields" : [ {[0m
2023.11.30 10:30:38 ERROR     "name" : "index",[0m
2023.11.30 10:30:38 ERROR     "type" : "integer",[0m
2023.11.30 10:30:38 ERROR     "nullable" : false,[0m
2023.11.30 10:30:38 ERROR     "metadata" : { }[0m
2023.11.30 10:30:38 ERROR   }, {[0m
2023.11.30 10:30:38 ERROR     "name" : "doubleField",[0m
2023.11.30 10:30:38 ERROR     "type" : "double",[0m
2023.11.30 10:30:38 ERROR     "nullable" : false,[0m
2023.11.30 10:30:38 ERROR     "metadata" : { }[0m
2023.11.30 10:30:38 ERROR   }, {[0m
2023.11.30 10:30:38 ERROR     "name" : "stringField",[0m
2023.11.30 10:30:38 ERROR     "type" : "string",[0m
2023.11.30 10:30:38 ERROR     "nullable" : false,[0m
2023.11.30 10:30:38 ERROR     "metadata" : { }[0m
2023.11.30 10:30:38 ERROR   }, {[0m
2023.11.30 10:30:38 ERROR     "name" : "intField",[0m
2023.11.30 10:30:38 ERROR     "type" : "integer",[0m
2023.11.30 10:30:38 ERROR     "nullable" : false,[0m
2023.11.30 10:30:38 ERROR     "metadata" : { }[0m
2023.11.30 10:30:38 ERROR   } ][0m
2023.11.30 10:30:38 ERROR }[0m
2023.11.30 10:30:38 ERROR and corresponding Parquet message type:[0m
2023.11.30 10:30:38 ERROR message spark_schema {[0m
2023.11.30 10:30:38 ERROR   required int32 index;[0m
2023.11.30 10:30:38 ERROR   required double doubleField;[0m
2023.11.30 10:30:38 ERROR   required binary stringField (STRING);[0m
2023.11.30 10:30:38 ERROR   required int32 intField;[0m
2023.11.30 10:30:38 ERROR }[0m
2023.11.30 10:30:38 ERROR [0m
2023.11.30 10:30:38 ERROR        [0m
2023.11.30 10:30:39 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO CodecPool: Got brand-new compressor [.snappy][0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO FileOutputCommitter: Saved output of task 'attempt_20231130103039578801784945685593_0004_m_000000_3' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/_temporary/0/task_20231130103039578801784945685593_0004_m_000000[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO SparkHadoopMapRedUtil: attempt_20231130103039578801784945685593_0004_m_000000_3: Committed. Elapsed time: 1 ms.[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 2742 bytes result sent to driver[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 448 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool [0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO DAGScheduler: ResultStage 4 (parquet at Ast.scala:283) finished in 0.486 s[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO DAGScheduler: Job 3 finished: parquet at Ast.scala:283, took 0.489966 s[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO FileFormatWriter: Start to commit write Job 1c9d1617-75f2-400c-bef0-e3172f893d53.[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO FileFormatWriter: Write Job 1c9d1617-75f2-400c-bef0-e3172f893d53 committed. Elapsed time: 9 ms.[0m
2023.11.30 10:30:38 ERROR 23/11/30 10:30:39 INFO FileFormatWriter: Finished processing stats for write job 1c9d1617-75f2-400c-bef0-e3172f893d53.[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO SparkContext: Starting job: collect at Ast.scala:272[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Got job 4 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Final stage: ResultStage 5 (collect at Ast.scala:272)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[18] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 17.4 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.25.86.80:38989 (size: 7.3 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[18] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) [0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO Executor: Running task 0.0 in stage 5.0 (TID 4)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.25.86.80:38989 in memory (size: 7.3 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.25.86.80:38989 in memory (size: 10.7 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 1826 bytes result sent to driver[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 12 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool [0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: ResultStage 5 (collect at Ast.scala:272) finished in 0.020 s[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.25.86.80:38989 in memory (size: 77.0 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Job 4 finished: collect at Ast.scala:272, took 0.024025 s[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.25.86.80:38989 in memory (size: 8.1 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Registering RDD 19 (collect at Ast.scala:272) as input to shuffle 1[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Got map stage job 5 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Final stage: ShuffleMapStage 6 (collect at Ast.scala:272)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[19] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.25.86.80:38989 (size: 8.1 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[19] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8138 bytes) [0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO Executor: Running task 0.0 in stage 6.0 (TID 5)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO Executor: Finished task 0.0 in stage 6.0 (TID 5). 1793 bytes result sent to driver[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 13 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool [0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: ShuffleMapStage 6 (collect at Ast.scala:272) finished in 0.020 s[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: looking for newly runnable stages[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: running: HashSet()[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: waiting: HashSet()[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: failed: HashSet()[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO SparkContext: Starting job: collect at Ast.scala:272[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Got job 6 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Final stage: ResultStage 8 (collect at Ast.scala:272)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[22] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 24.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.25.86.80:38989 (size: 10.7 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[22] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 6) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) [0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO Executor: Running task 0.0 in stage 8.0 (TID 6)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms[0m
2023.11.30 10:30:41 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO Executor: Finished task 0.0 in stage 8.0 (TID 6). 4494 bytes result sent to driver[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 6) in 11 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool [0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: ResultStage 8 (collect at Ast.scala:272) finished in 0.016 s[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished[0m
2023.11.30 10:30:41 ERROR 23/11/30 10:30:41 INFO DAGScheduler: Job 6 finished: collect at Ast.scala:272, took 0.019212 s[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO SparkContext: Starting job: collect at Ast.scala:272[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Got job 7 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Final stage: ResultStage 9 (collect at Ast.scala:272)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[26] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 17.4 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.3 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.25.86.80:38989 (size: 7.3 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[26] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 7) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) [0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO Executor: Running task 0.0 in stage 9.0 (TID 7)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO Executor: Finished task 0.0 in stage 9.0 (TID 7). 1826 bytes result sent to driver[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 7) in 8 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool [0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: ResultStage 9 (collect at Ast.scala:272) finished in 0.012 s[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Job 7 finished: collect at Ast.scala:272, took 0.014495 s[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Registering RDD 27 (collect at Ast.scala:272) as input to shuffle 2[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Got map stage job 8 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (collect at Ast.scala:272)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[27] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 18.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.25.86.80:38989 (size: 8.1 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[27] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 8) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) [0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO Executor: Running task 0.0 in stage 10.0 (TID 8)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO Executor: Finished task 0.0 in stage 10.0 (TID 8). 1793 bytes result sent to driver[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 8) in 12 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool [0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: ShuffleMapStage 10 (collect at Ast.scala:272) finished in 0.017 s[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: looking for newly runnable stages[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: running: HashSet()[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: waiting: HashSet()[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: failed: HashSet()[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO SparkContext: Starting job: collect at Ast.scala:272[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Got job 9 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Final stage: ResultStage 12 (collect at Ast.scala:272)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[30] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 24.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.25.86.80:38989 (size: 10.7 KiB, free: 9.1 GiB)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[30] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 9) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) [0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO Executor: Running task 0.0 in stage 12.0 (TID 9)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms[0m
2023.11.30 10:30:44 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO Executor: Finished task 0.0 in stage 12.0 (TID 9). 4494 bytes result sent to driver[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 9) in 12 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool [0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: ResultStage 12 (collect at Ast.scala:272) finished in 0.018 s[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished[0m
2023.11.30 10:30:44 ERROR 23/11/30 10:30:44 INFO DAGScheduler: Job 9 finished: collect at Ast.scala:272, took 0.021466 s[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO SparkContext: Starting job: parquet at Ast.scala:299[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO DAGScheduler: Got job 10 (parquet at Ast.scala:299) with 1 output partitions[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO DAGScheduler: Final stage: ResultStage 13 (parquet at Ast.scala:299)[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[32] at parquet at Ast.scala:299), which has no missing parents[0m
2023.11.30 10:31:01 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:01 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 102.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:01 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.25.86.80:38989 (size: 36.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:31:01 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[32] at parquet at Ast.scala:299) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 10) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8073 bytes) [0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO Executor: Running task 0.0 in stage 13.0 (TID 10)[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO Executor: Finished task 0.0 in stage 13.0 (TID 10). 2042 bytes result sent to driver[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 10) in 41 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool [0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO DAGScheduler: ResultStage 13 (parquet at Ast.scala:299) finished in 0.052 s[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished[0m
2023.11.30 10:31:01 ERROR 23/11/30 10:31:01 INFO DAGScheduler: Job 10 finished: parquet at Ast.scala:299, took 0.053217 s[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO SparkContext: Starting job: parquet at Ast.scala:299[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO DAGScheduler: Got job 11 (parquet at Ast.scala:299) with 1 output partitions[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO DAGScheduler: Final stage: ResultStage 14 (parquet at Ast.scala:299)[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[34] at parquet at Ast.scala:299), which has no missing parents[0m
2023.11.30 10:31:03 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:03 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 102.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:03 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.25.86.80:38989 (size: 36.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:31:03 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[34] at parquet at Ast.scala:299) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 11) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8073 bytes) [0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO Executor: Running task 0.0 in stage 14.0 (TID 11)[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO Executor: Finished task 0.0 in stage 14.0 (TID 11). 2042 bytes result sent to driver[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 11) in 11 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool [0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO DAGScheduler: ResultStage 14 (parquet at Ast.scala:299) finished in 0.023 s[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished[0m
2023.11.30 10:31:03 ERROR 23/11/30 10:31:03 INFO DAGScheduler: Job 11 finished: parquet at Ast.scala:299, took 0.024954 s[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO SparkContext: Starting job: parquet at Ast.scala:299[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO DAGScheduler: Got job 12 (parquet at Ast.scala:299) with 1 output partitions[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO DAGScheduler: Final stage: ResultStage 15 (parquet at Ast.scala:299)[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[36] at parquet at Ast.scala:299), which has no missing parents[0m
2023.11.30 10:31:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 102.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.25.86.80:38989 (size: 36.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:31:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[36] at parquet at Ast.scala:299) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8073 bytes) [0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO Executor: Running task 0.0 in stage 15.0 (TID 12)[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO Executor: Finished task 0.0 in stage 15.0 (TID 12). 2042 bytes result sent to driver[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 7 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool [0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO DAGScheduler: ResultStage 15 (parquet at Ast.scala:299) finished in 0.018 s[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished[0m
2023.11.30 10:31:05 ERROR 23/11/30 10:31:05 INFO DAGScheduler: Job 12 finished: parquet at Ast.scala:299, took 0.019836 s[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO FileSourceStrategy: Pushed Filters: [0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO FileSourceStrategy: Post-Scan Filters: [0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO CodeGenerator: Code generated in 12.982388 ms[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:20 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO SparkContext: Created broadcast 13 from show at Ast.scala:97[0m
2023.11.30 10:31:20 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO SparkContext: Starting job: show at Ast.scala:97[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO DAGScheduler: Got job 13 (show at Ast.scala:97) with 1 output partitions[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO DAGScheduler: Final stage: ResultStage 16 (show at Ast.scala:97)[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[40] at show at Ast.scala:97), which has no missing parents[0m
2023.11.30 10:31:20 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:20 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 16.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:20 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.25.86.80:38989 (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:31:20 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[40] at show at Ast.scala:97) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 13) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO Executor: Running task 0.0 in stage 16.0 (TID 13)[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO CodeGenerator: Code generated in 14.653056 ms[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO CodecPool: Got brand-new decompressor [.snappy][0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO Executor: Finished task 0.0 in stage 16.0 (TID 13). 1928 bytes result sent to driver[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 13) in 99 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool [0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO DAGScheduler: ResultStage 16 (show at Ast.scala:97) finished in 0.113 s[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO DAGScheduler: Job 13 finished: show at Ast.scala:97, took 0.115527 s[0m
2023.11.30 10:31:20 ERROR 23/11/30 10:31:20 INFO CodeGenerator: Code generated in 8.181961 ms[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileSourceStrategy: Pushed Filters: [0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileSourceStrategy: Post-Scan Filters: [0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO SparkContext: Created broadcast 15 from show at Ast.scala:98[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO SparkContext: Starting job: show at Ast.scala:98[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Got job 14 (show at Ast.scala:98) with 1 output partitions[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Final stage: ResultStage 17 (show at Ast.scala:98)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[44] at show at Ast.scala:98), which has no missing parents[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 16.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.25.86.80:38989 (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[44] at show at Ast.scala:98) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 14) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO Executor: Running task 0.0 in stage 17.0 (TID 14)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO Executor: Finished task 0.0 in stage 17.0 (TID 14). 1928 bytes result sent to driver[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 14) in 10 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool [0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: ResultStage 17 (show at Ast.scala:98) finished in 0.017 s[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Job 14 finished: show at Ast.scala:98, took 0.018765 s[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#43)[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#51)[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO CodeGenerator: Code generated in 7.033646 ms[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO SparkContext: Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Final stage: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[48] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 16.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.25.86.80:38989 (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[48] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 15) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO Executor: Running task 0.0 in stage 18.0 (TID 15)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO CodeGenerator: Code generated in 9.696684 ms[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FilterCompat: Filtering using predicate: noteq(index, null)[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO Executor: Finished task 0.0 in stage 18.0 (TID 15). 2007 bytes result sent to driver[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 15) in 47 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool [0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: ResultStage 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.055 s[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.057378 s[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO CodeGenerator: Code generated in 4.412417 ms[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 1024.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 318.0 B, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.25.86.80:38989 (size: 318.0 B, free: 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO SparkContext: Created broadcast 19 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#43)[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO CodeGenerator: Code generated in 9.702045 ms[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO SparkContext: Created broadcast 20 from show at Ast.scala:110[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO SparkContext: Starting job: show at Ast.scala:110[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Got job 16 (show at Ast.scala:110) with 1 output partitions[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Final stage: ResultStage 19 (show at Ast.scala:110)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[52] at show at Ast.scala:110), which has no missing parents[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 19.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.25.86.80:38989 (size: 8.0 KiB, free: 9.1 GiB)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[52] at show at Ast.scala:110) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 16) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO Executor: Running task 0.0 in stage 19.0 (TID 16)[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO CodeGenerator: Code generated in 12.201284 ms[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO FilterCompat: Filtering using predicate: noteq(index, null)[0m
2023.11.30 10:31:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO Executor: Finished task 0.0 in stage 19.0 (TID 16). 2118 bytes result sent to driver[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 16) in 24 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool [0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: ResultStage 19 (show at Ast.scala:110) finished in 0.031 s[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished[0m
2023.11.30 10:31:24 ERROR 23/11/30 10:31:24 INFO DAGScheduler: Job 16 finished: show at Ast.scala:110, took 0.032902 s[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#43)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#51)[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO SparkContext: Created broadcast 22 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Got job 17 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Final stage: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[56] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 16.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.25.86.80:38989 (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[56] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 17) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO Executor: Running task 0.0 in stage 20.0 (TID 17)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FilterCompat: Filtering using predicate: noteq(index, null)[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO Executor: Finished task 0.0 in stage 20.0 (TID 17). 2007 bytes result sent to driver[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 17) in 13 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: ResultStage 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.018 s[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Job 17 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.019945 s[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 1024.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 318.0 B, free 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.25.86.80:38989 (size: 318.0 B, free: 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO SparkContext: Created broadcast 24 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#43)[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO SparkContext: Created broadcast 25 from show at Ast.scala:114[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO SparkContext: Starting job: show at Ast.scala:114[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Got job 18 (show at Ast.scala:114) with 1 output partitions[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Final stage: ResultStage 21 (show at Ast.scala:114)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[60] at show at Ast.scala:114), which has no missing parents[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 19.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.25.86.80:38989 (size: 8.0 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[60] at show at Ast.scala:114) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 18) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO Executor: Running task 0.0 in stage 21.0 (TID 18)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO FilterCompat: Filtering using predicate: noteq(index, null)[0m
2023.11.30 10:32:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO Executor: Finished task 0.0 in stage 21.0 (TID 18). 2118 bytes result sent to driver[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 18) in 10 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: ResultStage 21 (show at Ast.scala:114) finished in 0.017 s[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished[0m
2023.11.30 10:32:05 ERROR 23/11/30 10:32:05 INFO DAGScheduler: Job 18 finished: show at Ast.scala:114, took 0.019346 s[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO FileSourceStrategy: Pushed Filters: [0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO FileSourceStrategy: Post-Scan Filters: [0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:07 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO SparkContext: Created broadcast 27 from show at Ast.scala:115[0m
2023.11.30 10:32:07 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO SparkContext: Starting job: show at Ast.scala:115[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO DAGScheduler: Got job 19 (show at Ast.scala:115) with 1 output partitions[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO DAGScheduler: Final stage: ResultStage 22 (show at Ast.scala:115)[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[64] at show at Ast.scala:115), which has no missing parents[0m
2023.11.30 10:32:07 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:07 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 16.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:07 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.25.86.80:38989 (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:07 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[64] at show at Ast.scala:115) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 19) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO Executor: Running task 0.0 in stage 22.0 (TID 19)[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO Executor: Finished task 0.0 in stage 22.0 (TID 19). 1928 bytes result sent to driver[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 19) in 14 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO DAGScheduler: ResultStage 22 (show at Ast.scala:115) finished in 0.019 s[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished[0m
2023.11.30 10:32:07 ERROR 23/11/30 10:32:07 INFO DAGScheduler: Job 19 finished: show at Ast.scala:115, took 0.021696 s[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#43)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#51)[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#59)[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO SparkContext: Created broadcast 29 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Got job 20 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Final stage: ResultStage 23 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[68] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 16.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.25.86.80:38989 (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[68] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 20) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO Executor: Running task 0.0 in stage 23.0 (TID 20)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FilterCompat: Filtering using predicate: noteq(index, null)[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO Executor: Finished task 0.0 in stage 23.0 (TID 20). 2007 bytes result sent to driver[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 20) in 11 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: ResultStage 23 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.016 s[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Job 20 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.017099 s[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 1024.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 318.0 B, free 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.25.86.80:38989 (size: 318.0 B, free: 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO SparkContext: Created broadcast 31 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#43)[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO CodeGenerator: Code generated in 10.839746 ms[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO SparkContext: Created broadcast 32 from show at Ast.scala:128[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO SparkContext: Starting job: show at Ast.scala:128[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Got job 21 (show at Ast.scala:128) with 1 output partitions[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Final stage: ResultStage 24 (show at Ast.scala:128)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[72] at show at Ast.scala:128), which has no missing parents[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 22.4 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.25.86.80:38989 (size: 8.6 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[72] at show at Ast.scala:128) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 21) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO Executor: Running task 0.0 in stage 24.0 (TID 21)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO CodeGenerator: Code generated in 14.360977 ms[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO FilterCompat: Filtering using predicate: noteq(index, null)[0m
2023.11.30 10:32:24 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO Executor: Finished task 0.0 in stage 24.0 (TID 21). 2172 bytes result sent to driver[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 21) in 28 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: ResultStage 24 (show at Ast.scala:128) finished in 0.033 s[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished[0m
2023.11.30 10:32:24 ERROR 23/11/30 10:32:24 INFO DAGScheduler: Job 21 finished: show at Ast.scala:128, took 0.034659 s[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#43)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#51)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#59)[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO SparkContext: Created broadcast 34 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Got job 22 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Final stage: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[76] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 16.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.25.86.80:38989 (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[76] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 22) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO Executor: Running task 0.0 in stage 25.0 (TID 22)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FilterCompat: Filtering using predicate: noteq(index, null)[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO Executor: Finished task 0.0 in stage 25.0 (TID 22). 2007 bytes result sent to driver[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 22) in 7 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: ResultStage 25 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.013 s[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Job 22 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.013926 s[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 1024.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 318.0 B, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.25.86.80:38989 (size: 318.0 B, free: 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO SparkContext: Created broadcast 36 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#43)[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO CodeGenerator: Code generated in 9.436739 ms[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO SparkContext: Created broadcast 37 from collect at Ast.scala:272[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO CodeGenerator: Code generated in 6.085035 ms[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO SparkContext: Starting job: collect at Ast.scala:272[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Got job 23 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Final stage: ResultStage 26 (collect at Ast.scala:272)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[82] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 25.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 9.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.25.86.80:38989 (size: 9.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[82] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 23) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO Executor: Running task 0.0 in stage 26.0 (TID 23)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO CodeGenerator: Code generated in 10.512063 ms[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO CodeGenerator: Code generated in 5.50453 ms[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FilterCompat: Filtering using predicate: noteq(index, null)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO Executor: Finished task 0.0 in stage 26.0 (TID 23). 2331 bytes result sent to driver[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 23) in 30 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: ResultStage 26 (collect at Ast.scala:272) finished in 0.035 s[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Job 23 finished: collect at Ast.scala:272, took 0.037116 s[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Registering RDD 83 (collect at Ast.scala:272) as input to shuffle 3[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Got map stage job 24 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (collect at Ast.scala:272)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[83] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 27.2 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 10.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.25.86.80:38989 (size: 10.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[83] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 24) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8468 bytes) [0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO Executor: Running task 0.0 in stage 27.0 (TID 24)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO CodeGenerator: Code generated in 5.516137 ms[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO FilterCompat: Filtering using predicate: noteq(index, null)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO Executor: Finished task 0.0 in stage 27.0 (TID 24). 2298 bytes result sent to driver[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 24) in 20 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: ShuffleMapStage 27 (collect at Ast.scala:272) finished in 0.026 s[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: looking for newly runnable stages[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: running: HashSet()[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: waiting: HashSet()[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: failed: HashSet()[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO CodeGenerator: Code generated in 5.487562 ms[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO SparkContext: Starting job: collect at Ast.scala:272[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Got job 25 (collect at Ast.scala:272) with 1 output partitions[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Final stage: ResultStage 29 (collect at Ast.scala:272)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[86] at collect at Ast.scala:272), which has no missing parents[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 38.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.25.86.80:38989 (size: 16.4 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[86] at collect at Ast.scala:272) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 25) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) [0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO Executor: Running task 0.0 in stage 29.0 (TID 25)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO ShuffleBlockFetcherIterator: Getting 1 (432.0 B) non-empty blocks including 1 (432.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms[0m
2023.11.30 10:32:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO CodeGenerator: Code generated in 7.998325 ms[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO CodeGenerator: Code generated in 4.619285 ms[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO Executor: Finished task 0.0 in stage 29.0 (TID 25). 5956 bytes result sent to driver[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 25) in 26 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: ResultStage 29 (collect at Ast.scala:272) finished in 0.031 s[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO DAGScheduler: Job 25 finished: collect at Ast.scala:272, took 0.034806 s[0m
2023.11.30 10:32:35 ERROR 23/11/30 10:32:35 INFO CodeGenerator: Code generated in 5.398782 ms[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#43)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#51)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#59)[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SparkContext: Created broadcast 41 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Got job 26 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Final stage: ResultStage 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[90] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 16.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.25.86.80:38989 (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[90] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 26) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO Executor: Running task 0.0 in stage 30.0 (TID 26)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FilterCompat: Filtering using predicate: noteq(index, null)[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 10.25.86.80:38989 in memory (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO Executor: Finished task 0.0 in stage 30.0 (TID 26). 2050 bytes result sent to driver[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.25.86.80:38989 in memory (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 26) in 32 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: ResultStage 30 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.038 s[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Job 26 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.038836 s[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 10.25.86.80:38989 in memory (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 10.25.86.80:38989 in memory (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 1024.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 318.0 B, free 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.25.86.80:38989 (size: 318.0 B, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SparkContext: Created broadcast 43 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 10.25.86.80:38989 in memory (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 10.25.86.80:38989 in memory (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileSourceStrategy: Pushed Filters: IsNotNull(index)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(index#43)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.25.86.80:38989 in memory (size: 7.3 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.25.86.80:38989 in memory (size: 36.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 10.25.86.80:38989 in memory (size: 8.0 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.25.86.80:38989 in memory (size: 36.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 10.25.86.80:38989 in memory (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 10.25.86.80:38989 in memory (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 10.25.86.80:38989 in memory (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.25.86.80:38989 in memory (size: 36.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 10.25.86.80:38989 in memory (size: 318.0 B, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 10.25.86.80:38989 in memory (size: 10.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 10.25.86.80:38989 in memory (size: 8.6 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 10.25.86.80:38989 in memory (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 10.25.86.80:38989 in memory (size: 8.0 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 10.25.86.80:38989 in memory (size: 318.0 B, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 10.25.86.80:38989 in memory (size: 318.0 B, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.25.86.80:38989 in memory (size: 8.1 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.25.86.80:38989 in memory (size: 10.7 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.25.86.80:38989 in memory (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 10.25.86.80:38989 in memory (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SparkContext: Created broadcast 44 from parquet at Ast.scala:283[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.25.86.80:38989 in memory (size: 10.7 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.25.86.80:38989 in memory (size: 7.3 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.25.86.80:38989 in memory (size: 8.1 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SparkContext: Starting job: parquet at Ast.scala:283[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 10.25.86.80:38989 in memory (size: 9.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Got job 27 (parquet at Ast.scala:283) with 1 output partitions[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Final stage: ResultStage 31 (parquet at Ast.scala:283)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 10.25.86.80:38989 in memory (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[95] at parquet at Ast.scala:283), which has no missing parents[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 10.25.86.80:38989 in memory (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.25.86.80:38989 in memory (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 10.25.86.80:38989 in memory (size: 318.0 B, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 10.25.86.80:38989 in memory (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 10.25.86.80:38989 in memory (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 10.25.86.80:38989 in memory (size: 16.4 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 10.25.86.80:38989 in memory (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 223.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 79.4 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.25.86.80:38989 (size: 79.4 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[95] at parquet at Ast.scala:283) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 27) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8809 bytes) [0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO Executor: Running task 0.0 in stage 31.0 (TID 27)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO CodecConfig: Compression: SNAPPY[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO CodecConfig: Compression: SNAPPY[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false][0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:[0m
2023.11.30 10:32:37 ERROR {[0m
2023.11.30 10:32:37 ERROR   "type" : "struct",[0m
2023.11.30 10:32:37 ERROR   "fields" : [ {[0m
2023.11.30 10:32:37 ERROR     "name" : "index",[0m
2023.11.30 10:32:37 ERROR     "type" : "integer",[0m
2023.11.30 10:32:37 ERROR     "nullable" : true,[0m
2023.11.30 10:32:37 ERROR     "metadata" : { }[0m
2023.11.30 10:32:37 ERROR   }, {[0m
2023.11.30 10:32:37 ERROR     "name" : "doubleField",[0m
2023.11.30 10:32:37 ERROR     "type" : "double",[0m
2023.11.30 10:32:37 ERROR     "nullable" : true,[0m
2023.11.30 10:32:37 ERROR     "metadata" : { }[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:37 ERROR   }, {[0m
2023.11.30 10:32:37 ERROR     "name" : "stringField",[0m
2023.11.30 10:32:37 ERROR     "type" : "string",[0m
2023.11.30 10:32:37 ERROR     "nullable" : true,[0m
2023.11.30 10:32:37 ERROR     "metadata" : { }[0m
2023.11.30 10:32:37 ERROR   }, {[0m
2023.11.30 10:32:37 ERROR     "name" : "intField",[0m
2023.11.30 10:32:37 ERROR     "type" : "integer",[0m
2023.11.30 10:32:37 ERROR     "nullable" : true,[0m
2023.11.30 10:32:37 ERROR     "metadata" : { }[0m
2023.11.30 10:32:37 ERROR   } ][0m
2023.11.30 10:32:37 ERROR }[0m
2023.11.30 10:32:37 ERROR and corresponding Parquet message type:[0m
2023.11.30 10:32:37 ERROR message spark_schema {[0m
2023.11.30 10:32:37 ERROR   optional int32 index;[0m
2023.11.30 10:32:37 ERROR   optional double doubleField;[0m
2023.11.30 10:32:37 ERROR   optional binary stringField (STRING);[0m
2023.11.30 10:32:37 ERROR   optional int32 intField;[0m
2023.11.30 10:32:37 ERROR }[0m
2023.11.30 10:32:37 ERROR [0m
2023.11.30 10:32:37 ERROR        [0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/fea0b5c8d657767c37269b0871dc034e4e03a3284577d3c205a95465b7c24df8.parquet/part-00000-1ff881f8-c14e-4018-8b9f-b9437100b7c6-c000.snappy.parquet, range: 0-1246, partition values: [empty row][0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FilterCompat: Filtering using predicate: noteq(index, null)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileOutputCommitter: Saved output of task 'attempt_202311301032377530123777194305096_0031_m_000000_27' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/6ed6590ed5b0d3977c42a362e765ef102e2b3acec91e0482e0ab60862c44369d.parquet/_temporary/0/task_202311301032377530123777194305096_0031_m_000000[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO SparkHadoopMapRedUtil: attempt_202311301032377530123777194305096_0031_m_000000_27: Committed. Elapsed time: 2 ms.[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO Executor: Finished task 0.0 in stage 31.0 (TID 27). 3204 bytes result sent to driver[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 27) in 42 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: ResultStage 31 (parquet at Ast.scala:283) finished in 0.057 s[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO DAGScheduler: Job 27 finished: parquet at Ast.scala:283, took 0.060629 s[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileFormatWriter: Start to commit write Job f9225221-fc68-4f7d-a5e6-ac93d4a01a9c.[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileFormatWriter: Write Job f9225221-fc68-4f7d-a5e6-ac93d4a01a9c committed. Elapsed time: 9 ms.[0m
2023.11.30 10:32:37 ERROR 23/11/30 10:32:37 INFO FileFormatWriter: Finished processing stats for write job f9225221-fc68-4f7d-a5e6-ac93d4a01a9c.[0m
2023.11.30 10:32:37 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:41 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO SparkContext: Starting job: parquet at Ast.scala:299[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO DAGScheduler: Got job 28 (parquet at Ast.scala:299) with 1 output partitions[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO DAGScheduler: Final stage: ResultStage 32 (parquet at Ast.scala:299)[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[97] at parquet at Ast.scala:299), which has no missing parents[0m
2023.11.30 10:32:42 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:42 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 102.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:42 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.25.86.80:38989 (size: 36.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:42 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[97] at parquet at Ast.scala:299) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 28) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8073 bytes) [0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO Executor: Running task 0.0 in stage 32.0 (TID 28)[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO Executor: Finished task 0.0 in stage 32.0 (TID 28). 2042 bytes result sent to driver[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 28) in 7 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO DAGScheduler: ResultStage 32 (parquet at Ast.scala:299) finished in 0.014 s[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished[0m
2023.11.30 10:32:41 ERROR 23/11/30 10:32:42 INFO DAGScheduler: Job 28 finished: parquet at Ast.scala:299, took 0.015230 s[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO FileSourceStrategy: Pushed Filters: [0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO FileSourceStrategy: Post-Scan Filters: [0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 200.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:45 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.25.86.80:38989 (size: 34.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO SparkContext: Created broadcast 47 from show at IntegrationSuite.scala:158[0m
2023.11.30 10:32:45 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO SparkContext: Starting job: show at IntegrationSuite.scala:158[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO DAGScheduler: Got job 29 (show at IntegrationSuite.scala:158) with 1 output partitions[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO DAGScheduler: Final stage: ResultStage 33 (show at IntegrationSuite.scala:158)[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[101] at show at IntegrationSuite.scala:158), which has no missing parents[0m
2023.11.30 10:32:45 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:45 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 16.6 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:45 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.25.86.80:38989 (size: 6.8 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:45 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[101] at show at IntegrationSuite.scala:158) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 29) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8479 bytes) [0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO Executor: Running task 0.0 in stage 33.0 (TID 29)[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/6ed6590ed5b0d3977c42a362e765ef102e2b3acec91e0482e0ab60862c44369d.parquet/part-00000-96775d32-497a-4e73-8c67-a812f575dfd1-c000.snappy.parquet, range: 0-1302, partition values: [empty row][0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO Executor: Finished task 0.0 in stage 33.0 (TID 29). 1961 bytes result sent to driver[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 29) in 7 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO DAGScheduler: ResultStage 33 (show at IntegrationSuite.scala:158) finished in 0.010 s[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 33: Stage finished[0m
2023.11.30 10:32:45 ERROR 23/11/30 10:32:45 INFO DAGScheduler: Job 29 finished: show at IntegrationSuite.scala:158, took 0.011691 s[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO FileSourceStrategy: Pushed Filters: [0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO FileSourceStrategy: Post-Scan Filters: [0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO CodeGenerator: Code generated in 4.944252 ms[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 200.2 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 34.7 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.25.86.80:38989 (size: 34.7 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO SparkContext: Created broadcast 49 from count at IntegrationSuite.scala:160[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Registering RDD 105 (count at IntegrationSuite.scala:160) as input to shuffle 4[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Got map stage job 30 (count at IntegrationSuite.scala:160) with 1 output partitions[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Final stage: ShuffleMapStage 34 (count at IntegrationSuite.scala:160)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Parents of final stage: List()[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[105] at count at IntegrationSuite.scala:160), which has no missing parents[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 17.5 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.25.86.80:38989 (size: 7.9 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[105] at count at IntegrationSuite.scala:160) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 30) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8468 bytes) [0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO Executor: Running task 0.0 in stage 34.0 (TID 30)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO CodeGenerator: Code generated in 5.553671 ms[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/6ed6590ed5b0d3977c42a362e765ef102e2b3acec91e0482e0ab60862c44369d.parquet/part-00000-96775d32-497a-4e73-8c67-a812f575dfd1-c000.snappy.parquet, range: 0-1302, partition values: [empty row][0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO Executor: Finished task 0.0 in stage 34.0 (TID 30). 2224 bytes result sent to driver[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 30) in 14 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: ShuffleMapStage 34 (count at IntegrationSuite.scala:160) finished in 0.019 s[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: looking for newly runnable stages[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: running: HashSet()[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: waiting: HashSet()[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: failed: HashSet()[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO CodeGenerator: Code generated in 5.65963 ms[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO SparkContext: Starting job: count at IntegrationSuite.scala:160[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Got job 31 (count at IntegrationSuite.scala:160) with 1 output partitions[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Final stage: ResultStage 36 (count at IntegrationSuite.scala:160)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Missing parents: List()[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[108] at count at IntegrationSuite.scala:160), which has no missing parents[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 13.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 9.1 GiB)[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.25.86.80:38989 (size: 6.1 KiB, free: 9.1 GiB)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1580[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[108] at count at IntegrationSuite.scala:160) (first 15 tasks are for partitions Vector(0))[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 31) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) [0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO Executor: Running task 0.0 in stage 36.0 (TID 31)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO CodeGenerator: Code generated in 5.766213 ms[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO Executor: Finished task 0.0 in stage 36.0 (TID 31). 4084 bytes result sent to driver[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 31) in 15 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool [0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: ResultStage 36 (count at IntegrationSuite.scala:160) finished in 0.019 s[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO DAGScheduler: Job 31 finished: count at IntegrationSuite.scala:160, took 0.020774 s[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO SparkContext: Invoking stop() from shutdown hook[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO SparkContext: SparkContext is stopping with exitCode 0.[0m
2023.11.30 10:32:55 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4040[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped![0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO MemoryStore: MemoryStore cleared[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO BlockManager: BlockManager stopped[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO BlockManagerMaster: BlockManagerMaster stopped[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped![0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO SparkContext: Successfully stopped SparkContext[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO ShutdownHookManager: Shutdown hook called[0m
2023.11.30 10:32:55 ERROR 23/11/30 10:32:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-ceea4f87-061a-4f75-8e5c-2f02e2a766f3[0m
2023.11.30 10:32:55 INFO  Closing debug server tcp://0.0.0.0:38739[0m
2023.11.30 10:32:55 INFO  Canceling debug proxy for [startup.integration_testing.httpServerSuite(test7: Serialize and deserialize expression with dataframe processed through http server)][0m
2023.11.30 10:34:16 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:102: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:34:17 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:34:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 79ms[0m
2023.11.30 10:34:18 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:102: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:34:20 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:34:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.47s[0m
2023.11.30 10:34:24 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:90: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:34:25 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:34:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 58ms[0m
2023.11.30 10:34:25 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:90: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:34:26 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala[0m
2023.11.30 10:34:27 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:34:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.35s[0m
2023.11.30 10:34:34 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:67: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:34:34 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:34:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 68ms[0m
2023.11.30 10:34:35 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:67: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:34:36 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:34:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.34s[0m
2023.11.30 10:34:42 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:34:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.15s[0m
2023.11.30 10:34:43 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:34:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.36s[0m
Nov 30, 2023 10:34:46 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 209
2023.11.30 10:34:47 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:35: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:34:48 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:34:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 56ms[0m
2023.11.30 10:34:48 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:35: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 10:34:49 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:34:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.33s[0m
2023.11.30 10:35:25 INFO  Shutting down server[0m
2023.11.30 10:35:25 INFO  shutting down Metals[0m
2023.11.30 10:35:25 INFO  Shut down connection with build server.[0m
2023.11.30 10:35:25 INFO  Shut down connection with build server.[0m
2023.11.30 10:35:25 INFO  Exiting server[0m
2023.11.30 10:35:32 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.30 10:35:33 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:35:33 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:35:33 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:35:33 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:35:33 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:35:33 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:35:33 INFO  time: Connected to build server in 0.54s[0m
2023.11.30 10:35:33 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 10:35:35 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.11.30 10:35:36 INFO  running '/home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals9265003706357939618/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'[0m
2023.11.30 10:35:37 INFO  [info] welcome to sbt 1.9.6 (Eclipse Adoptium Java 11.0.20)[0m
2023.11.30 10:35:37 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build-build from metals.sbt ...[0m
2023.11.30 10:35:38 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/project[0m
2023.11.30 10:35:38 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build from metals.sbt ...[0m
2023.11.30 10:35:38 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project[0m
2023.11.30 10:35:39 INFO  time: indexed workspace in 4.18s[0m
2023.11.30 10:35:40 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-build.json[0m
2023.11.30 10:35:40 INFO  [success] Total time: 1 s, completed Nov 30, 2023, 10:35:40 AM[0m
2023.11.30 10:35:40 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085 from build.sbt ...[0m
2023.11.30 10:35:40 INFO  [info] set current project to myScala3Project (in build file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/)[0m
2023.11.30 10:35:40 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-test.json[0m
2023.11.30 10:35:40 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085.json[0m
2023.11.30 10:35:41 INFO  [success] Total time: 1 s, completed Nov 30, 2023, 10:35:41 AM[0m
2023.11.30 10:35:42 INFO  time: ran 'sbt bloopInstall' in 5.64s[0m
2023.11.30 10:35:42 INFO  Disconnecting from Bloop session...[0m
2023.11.30 10:35:42 INFO  Shut down connection with build server.[0m
2023.11.30 10:35:42 INFO  Shut down connection with build server.[0m
2023.11.30 10:35:42 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:35:42 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:35:42 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:35:42 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:35:42 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:35:42 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:35:42 INFO  time: Connected to build server in 0.16s[0m
2023.11.30 10:35:42 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 10:35:44 INFO  time: indexed workspace in 1.93s[0m
error: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/.metals/.tmp/Main4265586051068270768.scala is not a file
2023.11.30 10:36:28 ERROR Unable to run scalafix, please check logs for more info.
java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Nov 30, 2023 10:36:28 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.util.concurrent.ExecutionException: Boxed Exception
java.util.concurrent.CompletionException: java.util.concurrent.ExecutionException: Boxed Exception
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.concurrent.ExecutionException: Boxed Exception
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)
	at scala.concurrent.impl.Promise$DefaultPromise.<init>(Promise.scala:108)
	at scala.concurrent.Promise$.failed(Promise.scala:147)
	at scala.concurrent.Future$.failed(Future.scala:651)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:141)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
Caused by: java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	... 4 more

2023.11.30 10:36:28 ERROR Unable to run scalafix, please check logs for more info.
java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Nov 30, 2023 10:36:28 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.util.concurrent.ExecutionException: Boxed Exception
java.util.concurrent.CompletionException: java.util.concurrent.ExecutionException: Boxed Exception
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.concurrent.ExecutionException: Boxed Exception
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)
	at scala.concurrent.impl.Promise$DefaultPromise.<init>(Promise.scala:108)
	at scala.concurrent.Promise$.failed(Promise.scala:147)
	at scala.concurrent.Future$.failed(Future.scala:651)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:141)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
Caused by: java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	... 4 more

2023.11.30 10:36:33 ERROR Unable to run scalafix, please check logs for more info.
java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Nov 30, 2023 10:36:33 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.util.concurrent.ExecutionException: Boxed Exception
java.util.concurrent.CompletionException: java.util.concurrent.ExecutionException: Boxed Exception
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.concurrent.ExecutionException: Boxed Exception
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)
	at scala.concurrent.impl.Promise$DefaultPromise.<init>(Promise.scala:108)
	at scala.concurrent.Promise$.failed(Promise.scala:147)
	at scala.concurrent.Future$.failed(Future.scala:651)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:141)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
Caused by: java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	... 4 more

2023.11.30 10:36:33 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:36:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.35s[0m
2023.11.30 10:36:43 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:36:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.35s[0m
2023.11.30 10:36:46 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.30 10:36:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.34s[0m
2023.11.30 10:37:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:37:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.45s[0m
2023.11.30 10:37:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:37:15 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 10:37:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.4s[0m
2023.11.30 10:37:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:37:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 10:37:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:37:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
Nov 30, 2023 10:37:46 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 171
2023.11.30 10:38:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:38:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.11.30 10:38:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:38:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.67s[0m
2023.11.30 10:38:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:38:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.61s[0m
2023.11.30 10:39:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:39:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.64s[0m
2023.11.30 10:39:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:39:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.57s[0m
2023.11.30 10:39:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:39:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.63s[0m
2023.11.30 10:39:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:39:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.66s[0m
2023.11.30 10:39:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:39:59 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala[0m
2023.11.30 10:39:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.59s[0m
2023.11.30 10:40:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:40:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.55s[0m
2023.11.30 10:40:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:40:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.54s[0m
2023.11.30 10:41:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:41:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.58s[0m
2023.11.30 10:41:39 ERROR Unable to run scalafix, please check logs for more info.
java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Nov 30, 2023 10:41:39 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.util.concurrent.ExecutionException: Boxed Exception
java.util.concurrent.CompletionException: java.util.concurrent.ExecutionException: Boxed Exception
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.concurrent.ExecutionException: Boxed Exception
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)
	at scala.concurrent.impl.Promise$DefaultPromise.<init>(Promise.scala:108)
	at scala.concurrent.Promise$.failed(Promise.scala:147)
	at scala.concurrent.Future$.failed(Future.scala:651)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:141)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
Caused by: java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	... 4 more

2023.11.30 10:41:40 ERROR Unable to run scalafix, please check logs for more info.
java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Nov 30, 2023 10:41:40 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.util.concurrent.ExecutionException: Boxed Exception
java.util.concurrent.CompletionException: java.util.concurrent.ExecutionException: Boxed Exception
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.concurrent.ExecutionException: Boxed Exception
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)
	at scala.concurrent.impl.Promise$DefaultPromise.<init>(Promise.scala:108)
	at scala.concurrent.Promise$.failed(Promise.scala:147)
	at scala.concurrent.Future$.failed(Future.scala:651)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:141)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
Caused by: java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	... 4 more

2023.11.30 10:41:49 ERROR Unable to run scalafix, please check logs for more info.
java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Nov 30, 2023 10:41:49 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.util.concurrent.ExecutionException: Boxed Exception
java.util.concurrent.CompletionException: java.util.concurrent.ExecutionException: Boxed Exception
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.concurrent.ExecutionException: Boxed Exception
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)
	at scala.concurrent.impl.Promise$DefaultPromise.<init>(Promise.scala:108)
	at scala.concurrent.Promise$.failed(Promise.scala:147)
	at scala.concurrent.Future$.failed(Future.scala:651)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:141)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
Caused by: java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	... 4 more

2023.11.30 10:41:52 ERROR Unable to run scalafix, please check logs for more info.
java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Nov 30, 2023 10:41:52 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.util.concurrent.ExecutionException: Boxed Exception
java.util.concurrent.CompletionException: java.util.concurrent.ExecutionException: Boxed Exception
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.concurrent.ExecutionException: Boxed Exception
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)
	at scala.concurrent.impl.Promise$DefaultPromise.<init>(Promise.scala:108)
	at scala.concurrent.Promise$.failed(Promise.scala:147)
	at scala.concurrent.Future$.failed(Future.scala:651)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:141)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
Caused by: java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	... 4 more

2023.11.30 10:41:53 ERROR Unable to run scalafix, please check logs for more info.
java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Nov 30, 2023 10:41:53 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.util.concurrent.ExecutionException: Boxed Exception
java.util.concurrent.CompletionException: java.util.concurrent.ExecutionException: Boxed Exception
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.concurrent.ExecutionException: Boxed Exception
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)
	at scala.concurrent.impl.Promise$DefaultPromise.<init>(Promise.scala:108)
	at scala.concurrent.Promise$.failed(Promise.scala:147)
	at scala.concurrent.Future$.failed(Future.scala:651)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:141)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
Caused by: java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	... 4 more

2023.11.30 10:41:54 ERROR Unable to run scalafix, please check logs for more info.
java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Nov 30, 2023 10:41:54 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.util.concurrent.ExecutionException: Boxed Exception
java.util.concurrent.CompletionException: java.util.concurrent.ExecutionException: Boxed Exception
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.concurrent.ExecutionException: Boxed Exception
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)
	at scala.concurrent.impl.Promise$DefaultPromise.<init>(Promise.scala:108)
	at scala.concurrent.Promise$.failed(Promise.scala:147)
	at scala.concurrent.Future$.failed(Future.scala:651)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:141)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
Caused by: java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	... 4 more

2023.11.30 10:42:37 ERROR Unable to run scalafix, please check logs for more info.
java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Nov 30, 2023 10:42:37 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.util.concurrent.ExecutionException: Boxed Exception
java.util.concurrent.CompletionException: java.util.concurrent.ExecutionException: Boxed Exception
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.concurrent.ExecutionException: Boxed Exception
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)
	at scala.concurrent.impl.Promise$DefaultPromise.<init>(Promise.scala:108)
	at scala.concurrent.Promise$.failed(Promise.scala:147)
	at scala.concurrent.Future$.failed(Future.scala:651)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:141)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
Caused by: java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	... 4 more

2023.11.30 10:42:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:42:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.47s[0m
2023.11.30 10:42:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:42:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.49s[0m
2023.11.30 10:42:58 INFO  Shutting down server[0m
2023.11.30 10:42:58 INFO  shutting down Metals[0m
2023.11.30 10:42:58 INFO  Shut down connection with build server.[0m
2023.11.30 10:42:58 INFO  Shut down connection with build server.[0m
2023.11.30 10:42:58 INFO  Exiting server[0m
2023.11.30 10:43:05 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.30 10:43:05 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:43:05 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:43:05 INFO  skipping build import with status 'Installed'[0m
2023.11.30 10:43:05 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:43:05 INFO  Attempting to connect to the build server...[0m
2023.11.30 10:43:05 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 10:43:05 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 10:43:05 INFO  time: Connected to build server in 0.36s[0m
2023.11.30 10:43:05 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 10:43:08 INFO  time: indexed workspace in 2.57s[0m
2023.11.30 10:45:41 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/sparkdata/DataframeApi.scala[0m
2023.11.30 10:45:41 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/sparkdata/DataframeApi.scala[0m
2023.11.30 10:45:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:45:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.11.30 10:45:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:45:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 57ms[0m
2023.11.30 10:45:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:45:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 76ms[0m
2023.11.30 10:46:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:46:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 56ms[0m
2023.11.30 10:46:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:46:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 54ms[0m
2023.11.30 10:46:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:46:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 10:46:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:46:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 10:48:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:48:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 10:48:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:48:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 10:48:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:48:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 10:48:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:48:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 10:48:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:48:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 10:49:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:49:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 10:49:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:49:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 10:49:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:49:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 10:49:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 10:49:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 11:57:46 INFO  Shutting down server[0m
2023.11.30 11:57:46 INFO  shutting down Metals[0m
2023.11.30 11:57:46 INFO  Shut down connection with build server.[0m
2023.11.30 11:57:46 INFO  Shut down connection with build server.[0m
2023.11.30 11:57:46 INFO  Exiting server[0m
2023.11.30 13:54:37 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.30 13:54:37 INFO  Attempting to connect to the build server...[0m
2023.11.30 13:54:37 INFO  skipping build import with status 'Installed'[0m
2023.11.30 13:54:37 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 13:54:39 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 13:54:39 INFO  Attempting to connect to the build server...[0m
2023.11.30 13:54:39 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 13:54:39 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 13:54:39 INFO  time: Connected to build server in 2.34s[0m
2023.11.30 13:54:39 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 13:54:40 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
Nov 30, 2023 1:54:43 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10
2023.11.30 13:54:43 INFO  time: indexed workspace in 2.42s[0m
2023.11.30 13:55:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:55:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 1.44s[0m
2023.11.30 13:55:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:55:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 1.4s[0m
2023.11.30 13:55:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:55:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.49s[0m
2023.11.30 13:55:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:55:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.65s[0m
2023.11.30 13:55:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:55:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 2.01s[0m
2023.11.30 13:58:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:58:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.11.30 13:58:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:58:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 13:59:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:59:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 13:59:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:59:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 13:59:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:59:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 13:59:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:59:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 13:59:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:59:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 13:59:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 13:59:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 14:00:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:00:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.11.30 14:00:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:00:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 14:03:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:03:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.11.30 14:03:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:03:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 14:03:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:03:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.11.30 14:03:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:03:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 14:03:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:03:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 14:03:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:03:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.11.30 14:03:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:03:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.11.30 14:03:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:03:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.69s[0m
2023.11.30 14:05:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:05:27 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:05:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.56s[0m
2023.11.30 14:06:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:06:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.11.30 14:07:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:07:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.11.30 14:07:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:07:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.11.30 14:07:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:07:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.47s[0m
2023.11.30 14:07:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:07:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.11.30 14:07:23 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:07:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:07:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.11.30 14:07:25 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:07:26 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:07:26 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:07:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:07:28 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:07:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.44s[0m
2023.11.30 14:07:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:07:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.42s[0m
2023.11.30 14:10:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:10:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.4s[0m
2023.11.30 14:11:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:11:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:11:06 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:11:10 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:11:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:11:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.11.30 14:11:11 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:11:13 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:11:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:11:14 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:11:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.4s[0m
2023.11.30 14:11:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:11:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.11.30 14:11:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:11:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:12:45 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.11.30 14:12:45 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.11.30 14:12:45 INFO  Starting debug proxy for [startup.integration_testing.httpServerSuite(test1)][0m
2023.11.30 14:12:46 INFO  Loaded expression compiler in 491 milliseconds[0m
2023.11.30 14:12:46 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/ch/epfl/scala/scala-debug-step-filter_3/3.1.4/scala-debug-step-filter_3-3.1.4.jar[0m
2023.11.30 14:12:46 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/tasty-core_3/3.3.1/tasty-core_3-3.3.1.jar[0m
2023.11.30 14:12:46 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala3-library_3/3.3.1/scala3-library_3-3.3.1.jar[0m
2023.11.30 14:12:46 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/ch/epfl/scala/tasty-query_3/0.8.4/tasty-query_3-0.8.4.jar[0m
2023.11.30 14:12:46 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.13.10/scala-library-2.13.10.jar[0m
2023.11.30 14:12:46 INFO  Loaded step filter in 23 milliseconds[0m
2023.11.30 14:12:47 INFO  Loaded all sources and classes in 1 second[0m
2023.11.30 14:12:50 INFO  Trying to attach to remote debuggee VM localhost:45833 .[0m
2023.11.30 14:12:50 INFO  Attaching to debuggee VM succeeded.[0m
2023.11.30 14:13:25 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.11.30 14:13:25 ERROR 23/11/30 14:13:25 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)[0m
2023.11.30 14:13:25 ERROR 23/11/30 14:13:25 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address[0m
2023.11.30 14:13:25 ERROR 23/11/30 14:13:25 INFO SparkContext: Running Spark version 3.5.0[0m
2023.11.30 14:13:25 ERROR 23/11/30 14:13:25 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64[0m
2023.11.30 14:13:25 ERROR 23/11/30 14:13:25 INFO SparkContext: Java version 11.0.20[0m
2023.11.30 14:13:25 ERROR 23/11/30 14:13:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable[0m
2023.11.30 14:13:25 ERROR Setting Spark log level to "WARN".[0m
2023.11.30 14:13:25 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.11.30 14:13:25 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.5.0/spark-unsafe_2.13-3.5.0.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.11.30 14:13:25 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.11.30 14:13:25 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.11.30 14:13:25 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.11.30 14:16:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:16:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 14:16:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:16:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.42s[0m
2023.11.30 14:16:34 INFO  Canceling debug proxy for [startup.integration_testing.httpServerSuite(test1)][0m
2023.11.30 14:16:34 ERROR Failed to initialize communication: Socket closed[0m
2023.11.30 14:16:34 INFO  Closing debug server tcp://0.0.0.0:32901[0m
2023.11.30 14:17:08 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.11.30 14:17:08 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.11.30 14:17:08 INFO  Starting debug proxy for [startup.integration_testing.httpServerSuite(test1)][0m
2023.11.30 14:17:08 INFO  Loaded expression compiler in 1 millisecond[0m
2023.11.30 14:17:08 INFO  Loaded step filter in 0 milliseconds[0m
2023.11.30 14:17:09 INFO  Loaded all sources and classes in 1 second[0m
2023.11.30 14:17:12 INFO  Trying to attach to remote debuggee VM localhost:52901 .[0m
2023.11.30 14:17:12 INFO  Attaching to debuggee VM succeeded.[0m
2023.11.30 14:17:29 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.11.30 14:17:29 ERROR 23/11/30 14:17:29 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)[0m
2023.11.30 14:17:29 ERROR 23/11/30 14:17:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address[0m
2023.11.30 14:17:29 ERROR 23/11/30 14:17:29 INFO SparkContext: Running Spark version 3.5.0[0m
2023.11.30 14:17:29 ERROR 23/11/30 14:17:29 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64[0m
2023.11.30 14:17:29 ERROR 23/11/30 14:17:29 INFO SparkContext: Java version 11.0.20[0m
2023.11.30 14:17:29 ERROR 23/11/30 14:17:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable[0m
2023.11.30 14:17:29 ERROR Setting Spark log level to "WARN".[0m
2023.11.30 14:17:29 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.11.30 14:17:29 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.5.0/spark-unsafe_2.13-3.5.0.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.11.30 14:17:29 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.11.30 14:17:29 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.11.30 14:17:29 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.11.30 14:18:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:18:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.49s[0m
2023.11.30 14:18:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:18:44 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:18:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.46s[0m
2023.11.30 14:18:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:18:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.41s[0m
2023.11.30 14:18:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:18:56 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:18:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.39s[0m
2023.11.30 14:19:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:19:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.39s[0m
2023.11.30 14:19:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:19:04 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:19:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.4s[0m
2023.11.30 14:19:13 ERROR java.lang.IllegalStateException: UT000002: The response has already been started[0m
2023.11.30 14:19:13 ERROR 	at io.undertow.server.HttpServerExchange.setStatusCode(HttpServerExchange.java:1480)[0m
2023.11.30 14:19:13 ERROR 	at cask.main.Main$.writeResponse(Main.scala:174)[0m
2023.11.30 14:19:13 ERROR 	at cask.main.Main$DefaultHandler.$anonfun$2(Main.scala:99)[0m
2023.11.30 14:19:13 ERROR 	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)[0m
2023.11.30 14:19:13 ERROR 	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)[0m
2023.11.30 14:19:13 ERROR 	at cask.main.Main$DefaultHandler.handleRequest(Main.scala:117)[0m
2023.11.30 14:19:13 ERROR 	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387)[0m
2023.11.30 14:19:13 ERROR 	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852)[0m
2023.11.30 14:19:13 ERROR 	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)[0m
2023.11.30 14:19:13 ERROR 	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019)[0m
2023.11.30 14:19:13 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558)[0m
2023.11.30 14:19:13 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1423)[0m
2023.11.30 14:19:13 ERROR 	at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1282)[0m
2023.11.30 14:19:13 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.11.30 14:19:28 INFO  Canceling debug proxy for [startup.integration_testing.httpServerSuite(test1)][0m
2023.11.30 14:19:28 INFO  Closing debug server tcp://0.0.0.0:41617[0m
2023.11.30 14:19:28 ERROR Failed to initialize communication: Socket closed[0m
2023.11.30 14:20:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:20:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
23/11/30 14:21:15 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/11/30 14:21:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/11/30 14:21:15 INFO SparkContext: Running Spark version 3.5.0
23/11/30 14:21:15 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/11/30 14:21:15 INFO SparkContext: Java version 11.0.20
23/11/30 14:21:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/11/30 14:21:16 INFO ResourceUtils: ==============================================================
23/11/30 14:21:16 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/30 14:21:16 INFO ResourceUtils: ==============================================================
23/11/30 14:21:16 INFO SparkContext: Submitted application: Spark Parquet Example
23/11/30 14:21:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/30 14:21:16 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
23/11/30 14:21:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/30 14:21:16 INFO SecurityManager: Changing view acls to: bsoleille
23/11/30 14:21:16 INFO SecurityManager: Changing modify acls to: bsoleille
23/11/30 14:21:16 INFO SecurityManager: Changing view acls groups to: 
23/11/30 14:21:16 INFO SecurityManager: Changing modify acls groups to: 
23/11/30 14:21:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/11/30 14:21:16 INFO Utils: Successfully started service 'sparkDriver' on port 44341.
23/11/30 14:21:16 INFO SparkEnv: Registering MapOutputTracker
23/11/30 14:21:16 INFO SparkEnv: Registering BlockManagerMaster
23/11/30 14:21:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/30 14:21:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/30 14:21:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/30 14:21:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-203eed34-d185-4e36-9d7e-a15f9aca6079
23/11/30 14:21:16 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/30 14:21:16 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/30 14:21:16 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/11/30 14:21:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/11/30 14:21:16 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/11/30 14:21:16 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/11/30 14:21:16 INFO Executor: Java version 11.0.20
23/11/30 14:21:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/11/30 14:21:16 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@e9679a0 for default.
23/11/30 14:21:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43823.
23/11/30 14:21:16 INFO NettyBlockTransferService: Server created on 10.25.86.80:43823
23/11/30 14:21:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/30 14:21:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 43823, None)
23/11/30 14:21:16 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:43823 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 43823, None)
23/11/30 14:21:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 43823, None)
23/11/30 14:21:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 43823, None)
23/11/30 14:21:17 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/11/30 14:21:17 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/11/30 14:21:18 INFO CodeGenerator: Code generated in 146.330926 ms
23/11/30 14:21:18 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:62
23/11/30 14:21:18 INFO DAGScheduler: Got job 0 (show at SparkTest.worksheet.sc:62) with 1 output partitions
23/11/30 14:21:18 INFO DAGScheduler: Final stage: ResultStage 0 (show at SparkTest.worksheet.sc:62)
23/11/30 14:21:18 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:18 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:62), which has no missing parents
23/11/30 14:21:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/11/30 14:21:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/11/30 14:21:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:62) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/11/30 14:21:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/11/30 14:21:18 INFO CodeGenerator: Code generated in 10.684679 ms
23/11/30 14:21:19 INFO CodeGenerator: Code generated in 31.782279 ms
23/11/30 14:21:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1720 bytes result sent to driver
23/11/30 14:21:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 794 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:19 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/11/30 14:21:19 INFO DAGScheduler: ResultStage 0 (show at SparkTest.worksheet.sc:62) finished in 0.930 s
23/11/30 14:21:19 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/11/30 14:21:19 INFO DAGScheduler: Job 0 finished: show at SparkTest.worksheet.sc:62, took 0.961141 s
23/11/30 14:21:19 INFO CodeGenerator: Code generated in 9.159319 ms
23/11/30 14:21:19 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:19 INFO CodeGenerator: Code generated in 5.82708 ms
23/11/30 14:21:19 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:72
23/11/30 14:21:19 INFO DAGScheduler: Got job 1 (parquet at SparkTest.worksheet.sc:72) with 1 output partitions
23/11/30 14:21:19 INFO DAGScheduler: Final stage: ResultStage 1 (parquet at SparkTest.worksheet.sc:72)
23/11/30 14:21:19 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:19 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:19 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:72), which has no missing parents
23/11/30 14:21:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 215.6 KiB, free 434.2 MiB)
23/11/30 14:21:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 76.7 KiB, free 434.1 MiB)
23/11/30 14:21:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.25.86.80:43823 (size: 76.7 KiB, free: 434.3 MiB)
23/11/30 14:21:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:72) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:19 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/11/30 14:21:19 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/11/30 14:21:19 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/11/30 14:21:19 INFO CodeGenerator: Code generated in 5.389712 ms
23/11/30 14:21:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:19 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:21:19 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:21:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/30 14:21:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "index",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 index;
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/30 14:21:19 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:21:20 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/30 14:21:20 INFO FileOutputCommitter: Saved output of task 'attempt_202311301421194394560642618710655_0001_m_000000_1' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311301421194394560642618710655_0001_m_000000
23/11/30 14:21:20 INFO SparkHadoopMapRedUtil: attempt_202311301421194394560642618710655_0001_m_000000_1: Committed. Elapsed time: 0 ms.
23/11/30 14:21:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2785 bytes result sent to driver
23/11/30 14:21:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 512 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/11/30 14:21:20 INFO DAGScheduler: ResultStage 1 (parquet at SparkTest.worksheet.sc:72) finished in 0.553 s
23/11/30 14:21:20 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/11/30 14:21:20 INFO DAGScheduler: Job 1 finished: parquet at SparkTest.worksheet.sc:72, took 0.555281 s
23/11/30 14:21:20 INFO FileFormatWriter: Start to commit write Job bfe915f2-3b3e-452c-806b-4ef1cdf777b4.
23/11/30 14:21:20 INFO FileFormatWriter: Write Job bfe915f2-3b3e-452c-806b-4ef1cdf777b4 committed. Elapsed time: 25 ms.
23/11/30 14:21:20 INFO FileFormatWriter: Finished processing stats for write job bfe915f2-3b3e-452c-806b-4ef1cdf777b4.
23/11/30 14:21:20 INFO InMemoryFileIndex: It took 10 ms to list leaf files for 1 paths.
23/11/30 14:21:20 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:76
23/11/30 14:21:20 INFO DAGScheduler: Got job 2 (parquet at SparkTest.worksheet.sc:76) with 1 output partitions
23/11/30 14:21:20 INFO DAGScheduler: Final stage: ResultStage 2 (parquet at SparkTest.worksheet.sc:76)
23/11/30 14:21:20 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:20 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:20 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:76), which has no missing parents
23/11/30 14:21:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/11/30 14:21:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/11/30 14:21:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.25.86.80:43823 (size: 36.9 KiB, free: 434.3 MiB)
23/11/30 14:21:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:76) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
23/11/30 14:21:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/11/30 14:21:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/11/30 14:21:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2085 bytes result sent to driver
23/11/30 14:21:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 42 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/11/30 14:21:20 INFO DAGScheduler: ResultStage 2 (parquet at SparkTest.worksheet.sc:76) finished in 0.061 s
23/11/30 14:21:20 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/11/30 14:21:20 INFO DAGScheduler: Job 2 finished: parquet at SparkTest.worksheet.sc:76, took 0.062961 s
23/11/30 14:21:20 INFO FileSourceStrategy: Pushed Filters: 
23/11/30 14:21:20 INFO FileSourceStrategy: Post-Scan Filters: 
23/11/30 14:21:20 INFO CodeGenerator: Code generated in 24.478843 ms
23/11/30 14:21:20 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 200.8 KiB, free 433.8 MiB)
23/11/30 14:21:20 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.25.86.80:43823 in memory (size: 36.9 KiB, free: 434.3 MiB)
23/11/30 14:21:20 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.9 MiB)
23/11/30 14:21:20 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.25.86.80:43823 (size: 34.9 KiB, free: 434.3 MiB)
23/11/30 14:21:20 INFO SparkContext: Created broadcast 3 from show at SparkTest.worksheet.sc:81
23/11/30 14:21:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/11/30 14:21:20 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:81
23/11/30 14:21:20 INFO DAGScheduler: Got job 3 (show at SparkTest.worksheet.sc:81) with 1 output partitions
23/11/30 14:21:20 INFO DAGScheduler: Final stage: ResultStage 3 (show at SparkTest.worksheet.sc:81)
23/11/30 14:21:20 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:20 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:20 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:81), which has no missing parents
23/11/30 14:21:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.6 KiB, free 433.9 MiB)
23/11/30 14:21:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 433.9 MiB)
23/11/30 14:21:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.25.86.80:43823 (size: 6.8 KiB, free: 434.3 MiB)
23/11/30 14:21:20 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:81) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:20 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
23/11/30 14:21:20 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/11/30 14:21:20 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/11/30 14:21:20 INFO CodeGenerator: Code generated in 16.973323 ms
23/11/30 14:21:20 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-11b6b4fe-56e4-4cc4-9e67-bc5edf6fc9a6-c000.snappy.parquet, range: 0-1246, partition values: [empty row]
23/11/30 14:21:20 INFO CodecPool: Got brand-new decompressor [.snappy]
23/11/30 14:21:20 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.25.86.80:43823 in memory (size: 76.7 KiB, free: 434.4 MiB)
23/11/30 14:21:20 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1928 bytes result sent to driver
23/11/30 14:21:20 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 131 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:20 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/11/30 14:21:20 INFO DAGScheduler: ResultStage 3 (show at SparkTest.worksheet.sc:81) finished in 0.159 s
23/11/30 14:21:20 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
23/11/30 14:21:20 INFO DAGScheduler: Job 3 finished: show at SparkTest.worksheet.sc:81, took 0.163531 s
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 7.411787 ms
23/11/30 14:21:21 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.25.86.80:43823 in memory (size: 6.8 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.25.86.80:43823 in memory (size: 34.9 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:94
23/11/30 14:21:21 INFO DAGScheduler: Got job 4 (show at SparkTest.worksheet.sc:94) with 1 output partitions
23/11/30 14:21:21 INFO DAGScheduler: Final stage: ResultStage 4 (show at SparkTest.worksheet.sc:94)
23/11/30 14:21:21 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:21 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:21 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:94), which has no missing parents
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.7 KiB, free 434.4 MiB)
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.4 MiB)
23/11/30 14:21:21 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:94) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:21 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
23/11/30 14:21:21 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/11/30 14:21:21 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 7.4049 ms
23/11/30 14:21:21 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1640 bytes result sent to driver
23/11/30 14:21:21 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 19 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:21 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/11/30 14:21:21 INFO DAGScheduler: ResultStage 4 (show at SparkTest.worksheet.sc:94) finished in 0.025 s
23/11/30 14:21:21 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
23/11/30 14:21:21 INFO DAGScheduler: Job 4 finished: show at SparkTest.worksheet.sc:94, took 0.027247 s
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 8.433918 ms
23/11/30 14:21:21 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 6.828203 ms
23/11/30 14:21:21 INFO DAGScheduler: Registering RDD 15 (collect at SparkTest.worksheet.sc:102) as input to shuffle 0
23/11/30 14:21:21 INFO DAGScheduler: Got map stage job 5 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:21:21 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:21:21 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:21 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:21 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[15] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 19.2 KiB, free 434.4 MiB)
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.4 MiB)
23/11/30 14:21:21 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[15] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:21 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
23/11/30 14:21:21 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8138 bytes) 
23/11/30 14:21:21 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 10.193904 ms
23/11/30 14:21:21 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1973 bytes result sent to driver
23/11/30 14:21:21 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 66 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:21 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
23/11/30 14:21:21 INFO DAGScheduler: ShuffleMapStage 5 (collect at SparkTest.worksheet.sc:102) finished in 0.089 s
23/11/30 14:21:21 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:21 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:21 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:21 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 7.506405 ms
23/11/30 14:21:21 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:102
23/11/30 14:21:21 INFO DAGScheduler: Got job 6 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:21:21 INFO DAGScheduler: Final stage: ResultStage 7 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:21:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
23/11/30 14:21:21 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:21 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[18] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.3 KiB, free 434.4 MiB)
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)
23/11/30 14:21:21 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.25.86.80:43823 (size: 6.6 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[18] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:21 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/11/30 14:21:21 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 6) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:21 INFO Executor: Running task 0.0 in stage 7.0 (TID 6)
23/11/30 14:21:21 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 6.116127 ms
23/11/30 14:21:21 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO Executor: Finished task 0.0 in stage 7.0 (TID 6). 4127 bytes result sent to driver
23/11/30 14:21:21 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 6) in 52 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:21 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/11/30 14:21:21 INFO DAGScheduler: ResultStage 7 (collect at SparkTest.worksheet.sc:102) finished in 0.060 s
23/11/30 14:21:21 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
23/11/30 14:21:21 INFO DAGScheduler: Job 6 finished: collect at SparkTest.worksheet.sc:102, took 0.069114 s
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 5.053569 ms
23/11/30 14:21:21 INFO SparkContext: Starting job: show at Ast.scala:95
23/11/30 14:21:21 INFO DAGScheduler: Got job 7 (show at Ast.scala:95) with 1 output partitions
23/11/30 14:21:21 INFO DAGScheduler: Final stage: ResultStage 8 (show at Ast.scala:95)
23/11/30 14:21:21 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:21 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:21 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[20] at show at Ast.scala:95), which has no missing parents
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/11/30 14:21:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[20] at show at Ast.scala:95) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:21 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
23/11/30 14:21:21 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:21 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
23/11/30 14:21:21 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 1634 bytes result sent to driver
23/11/30 14:21:21 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 10 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:21 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/11/30 14:21:21 INFO DAGScheduler: ResultStage 8 (show at Ast.scala:95) finished in 0.016 s
23/11/30 14:21:21 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
23/11/30 14:21:21 INFO DAGScheduler: Job 7 finished: show at Ast.scala:95, took 0.018265 s
23/11/30 14:21:21 INFO SparkContext: Starting job: show at Ast.scala:96
23/11/30 14:21:21 INFO DAGScheduler: Got job 8 (show at Ast.scala:96) with 1 output partitions
23/11/30 14:21:21 INFO DAGScheduler: Final stage: ResultStage 9 (show at Ast.scala:96)
23/11/30 14:21:21 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:21 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:21 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[22] at show at Ast.scala:96), which has no missing parents
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 15.5 KiB, free 434.3 MiB)
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.3 MiB)
23/11/30 14:21:21 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[22] at show at Ast.scala:96) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:21 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
23/11/30 14:21:21 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:21 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
23/11/30 14:21:21 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 1634 bytes result sent to driver
23/11/30 14:21:21 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 18 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:21 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/11/30 14:21:21 INFO DAGScheduler: ResultStage 9 (show at Ast.scala:96) finished in 0.026 s
23/11/30 14:21:21 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/11/30 14:21:21 INFO DAGScheduler: Job 8 finished: show at Ast.scala:96, took 0.028046 s
23/11/30 14:21:21 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.25.86.80:43823 in memory (size: 6.6 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO DAGScheduler: Registering RDD 24 (show at Ast.scala:108) as input to shuffle 1
23/11/30 14:21:21 INFO DAGScheduler: Got map stage job 9 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:21:21 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (show at Ast.scala:108)
23/11/30 14:21:21 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:21 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:21 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[24] at show at Ast.scala:108), which has no missing parents
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 17.7 KiB, free 434.4 MiB)
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.4 MiB)
23/11/30 14:21:21 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:21 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[24] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:21 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
23/11/30 14:21:21 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:21 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 8.306252 ms
23/11/30 14:21:21 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1991 bytes result sent to driver
23/11/30 14:21:21 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 31 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:21 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/11/30 14:21:21 INFO DAGScheduler: ShuffleMapStage 10 (show at Ast.scala:108) finished in 0.050 s
23/11/30 14:21:21 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:21 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:21 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:21 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:21 INFO ShufflePartitionsUtil: For shuffle(1, 1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 43.742148 ms
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 9.871006 ms
23/11/30 14:21:21 INFO CodeGenerator: Code generated in 8.537582 ms
23/11/30 14:21:21 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:21 INFO SparkContext: Starting job: show at Ast.scala:108
23/11/30 14:21:21 INFO DAGScheduler: Got job 10 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:21:21 INFO DAGScheduler: Final stage: ResultStage 12 (show at Ast.scala:108)
23/11/30 14:21:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
23/11/30 14:21:21 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:21 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[31] at show at Ast.scala:108), which has no missing parents
23/11/30 14:21:21 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 40.1 KiB, free 434.4 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 16.2 KiB, free 434.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.25.86.80:43823 (size: 16.2 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[31] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 10) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 12.0 (TID 10)
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 8.767198 ms
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 14.895229 ms
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 3.992827 ms
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 7.505753 ms
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 13.773954 ms
23/11/30 14:21:22 INFO Executor: Finished task 0.0 in stage 12.0 (TID 10). 4898 bytes result sent to driver
23/11/30 14:21:22 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 10) in 96 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:22 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
23/11/30 14:21:22 INFO DAGScheduler: ResultStage 12 (show at Ast.scala:108) finished in 0.115 s
23/11/30 14:21:22 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
23/11/30 14:21:22 INFO DAGScheduler: Job 10 finished: show at Ast.scala:108, took 0.123421 s
23/11/30 14:21:22 INFO DAGScheduler: Registering RDD 33 (show at Ast.scala:112) as input to shuffle 2
23/11/30 14:21:22 INFO DAGScheduler: Got map stage job 11 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:21:22 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (show at Ast.scala:112)
23/11/30 14:21:22 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:22 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:22 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[33] at show at Ast.scala:112), which has no missing parents
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 17.7 KiB, free 434.3 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[33] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 11) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 13.0 (TID 11)
23/11/30 14:21:22 INFO Executor: Finished task 0.0 in stage 13.0 (TID 11). 1991 bytes result sent to driver
23/11/30 14:21:22 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 11) in 20 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:22 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/11/30 14:21:22 INFO DAGScheduler: ShuffleMapStage 13 (show at Ast.scala:112) finished in 0.028 s
23/11/30 14:21:22 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:22 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:22 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:22 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:22 INFO ShufflePartitionsUtil: For shuffle(2, 2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.25.86.80:43823 in memory (size: 16.2 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Starting job: show at Ast.scala:112
23/11/30 14:21:22 INFO DAGScheduler: Got job 12 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:21:22 INFO DAGScheduler: Final stage: ResultStage 15 (show at Ast.scala:112)
23/11/30 14:21:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
23/11/30 14:21:22 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:22 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[40] at show at Ast.scala:112), which has no missing parents
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 40.1 KiB, free 434.4 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.25.86.80:43823 (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[40] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 15.0 (TID 12)
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:22 INFO Executor: Finished task 0.0 in stage 15.0 (TID 12). 4898 bytes result sent to driver
23/11/30 14:21:22 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 14 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:22 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
23/11/30 14:21:22 INFO DAGScheduler: ResultStage 15 (show at Ast.scala:112) finished in 0.024 s
23/11/30 14:21:22 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
23/11/30 14:21:22 INFO DAGScheduler: Job 12 finished: show at Ast.scala:112, took 0.028428 s
23/11/30 14:21:22 INFO SparkContext: Starting job: show at Ast.scala:113
23/11/30 14:21:22 INFO DAGScheduler: Got job 13 (show at Ast.scala:113) with 1 output partitions
23/11/30 14:21:22 INFO DAGScheduler: Final stage: ResultStage 16 (show at Ast.scala:113)
23/11/30 14:21:22 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:22 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:22 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[42] at show at Ast.scala:113), which has no missing parents
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 15.5 KiB, free 434.3 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[42] at show at Ast.scala:113) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 13) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 16.0 (TID 13)
23/11/30 14:21:22 INFO Executor: Finished task 0.0 in stage 16.0 (TID 13). 1634 bytes result sent to driver
23/11/30 14:21:22 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 13) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:22 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
23/11/30 14:21:22 INFO DAGScheduler: ResultStage 16 (show at Ast.scala:113) finished in 0.015 s
23/11/30 14:21:22 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
23/11/30 14:21:22 INFO DAGScheduler: Job 13 finished: show at Ast.scala:113, took 0.016762 s
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.25.86.80:43823 in memory (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO DAGScheduler: Registering RDD 44 (show at Ast.scala:126) as input to shuffle 3
23/11/30 14:21:22 INFO DAGScheduler: Got map stage job 14 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:21:22 INFO DAGScheduler: Final stage: ShuffleMapStage 17 (show at Ast.scala:126)
23/11/30 14:21:22 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:22 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:22 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[44] at show at Ast.scala:126), which has no missing parents
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 17.7 KiB, free 434.4 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.4 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[44] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 14) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 17.0 (TID 14)
23/11/30 14:21:22 INFO Executor: Finished task 0.0 in stage 17.0 (TID 14). 1991 bytes result sent to driver
23/11/30 14:21:22 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 14) in 13 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:22 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
23/11/30 14:21:22 INFO DAGScheduler: ShuffleMapStage 17 (show at Ast.scala:126) finished in 0.019 s
23/11/30 14:21:22 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:22 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:22 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:22 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:22 INFO ShufflePartitionsUtil: For shuffle(3, 3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 10.044782 ms
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 5.595777 ms
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:22 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:22 INFO DAGScheduler: Final stage: ResultStage 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
23/11/30 14:21:22 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:22 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 38.7 KiB, free 434.4 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 19.0 (TID 15)
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 7.962549 ms
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 13.573702 ms
23/11/30 14:21:22 INFO Executor: Finished task 0.0 in stage 19.0 (TID 15). 4897 bytes result sent to driver
23/11/30 14:21:22 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 40 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:22 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
23/11/30 14:21:22 INFO DAGScheduler: ResultStage 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.055 s
23/11/30 14:21:22 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
23/11/30 14:21:22 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.058597 s
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 4.344567 ms
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:22 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 7.281546 ms
23/11/30 14:21:22 INFO SparkContext: Starting job: show at Ast.scala:126
23/11/30 14:21:22 INFO DAGScheduler: Got job 16 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:21:22 INFO DAGScheduler: Final stage: ResultStage 21 (show at Ast.scala:126)
23/11/30 14:21:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
23/11/30 14:21:22 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:22 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[54] at show at Ast.scala:126), which has no missing parents
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 15.1 KiB, free 433.3 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[54] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 16) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 21.0 (TID 16)
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 8.905506 ms
23/11/30 14:21:22 INFO Executor: Finished task 0.0 in stage 21.0 (TID 16). 4165 bytes result sent to driver
23/11/30 14:21:22 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 16) in 17 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:22 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
23/11/30 14:21:22 INFO DAGScheduler: ResultStage 21 (show at Ast.scala:126) finished in 0.022 s
23/11/30 14:21:22 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
23/11/30 14:21:22 INFO DAGScheduler: Job 16 finished: show at Ast.scala:126, took 0.026087 s
23/11/30 14:21:22 INFO DAGScheduler: Registering RDD 56 (show at SparkTest.worksheet.sc:115) as input to shuffle 4
23/11/30 14:21:22 INFO DAGScheduler: Got map stage job 17 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:21:22 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (show at SparkTest.worksheet.sc:115)
23/11/30 14:21:22 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:22 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:22 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[56] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 17.7 KiB, free 433.3 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[56] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 22.0 (TID 17)
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO Executor: Finished task 0.0 in stage 22.0 (TID 17). 1991 bytes result sent to driver
23/11/30 14:21:22 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:22 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
23/11/30 14:21:22 INFO DAGScheduler: ShuffleMapStage 22 (show at SparkTest.worksheet.sc:115) finished in 0.023 s
23/11/30 14:21:22 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:22 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:22 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:22 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:22 INFO ShufflePartitionsUtil: For shuffle(4, 4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:22 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:22 INFO DAGScheduler: Got job 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:22 INFO DAGScheduler: Final stage: ResultStage 24 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
23/11/30 14:21:22 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:22 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[63] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 38.7 KiB, free 434.3 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[63] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 18) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 24.0 (TID 18)
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:22 INFO Executor: Finished task 0.0 in stage 24.0 (TID 18). 4897 bytes result sent to driver
23/11/30 14:21:22 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 18) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:22 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
23/11/30 14:21:22 INFO DAGScheduler: ResultStage 24 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.020 s
23/11/30 14:21:22 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
23/11/30 14:21:22 INFO DAGScheduler: Job 18 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.024241 s
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 21 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:22 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:22 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:115
23/11/30 14:21:22 INFO DAGScheduler: Got job 19 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:21:22 INFO DAGScheduler: Final stage: ResultStage 26 (show at SparkTest.worksheet.sc:115)
23/11/30 14:21:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
23/11/30 14:21:22 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:22 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[66] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 15.1 KiB, free 433.3 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[66] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 19) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 26.0 (TID 19)
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:22 INFO Executor: Finished task 0.0 in stage 26.0 (TID 19). 4165 bytes result sent to driver
23/11/30 14:21:22 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 19) in 19 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:22 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
23/11/30 14:21:22 INFO DAGScheduler: ResultStage 26 (show at SparkTest.worksheet.sc:115) finished in 0.025 s
23/11/30 14:21:22 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
23/11/30 14:21:22 INFO DAGScheduler: Job 19 finished: show at SparkTest.worksheet.sc:115, took 0.026604 s
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 5.226894 ms
23/11/30 14:21:22 INFO DAGScheduler: Registering RDD 68 (isEmpty at SparkTest.worksheet.sc:120) as input to shuffle 5
23/11/30 14:21:22 INFO DAGScheduler: Got map stage job 20 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:21:22 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:21:22 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:22 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:22 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:21:22 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[68] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 17.3 KiB, free 434.4 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 434.4 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.25.86.80:43823 (size: 7.5 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[68] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 20) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 27.0 (TID 20)
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 5.037691 ms
23/11/30 14:21:22 INFO Executor: Finished task 0.0 in stage 27.0 (TID 20). 1991 bytes result sent to driver
23/11/30 14:21:22 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 20) in 22 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:22 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
23/11/30 14:21:22 INFO DAGScheduler: ShuffleMapStage 27 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.028 s
23/11/30 14:21:22 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:22 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:22 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:22 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:22 INFO ShufflePartitionsUtil: For shuffle(5, 5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:22 INFO CodeGenerator: Code generated in 14.018099 ms
23/11/30 14:21:22 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:22 INFO DAGScheduler: Got job 21 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:22 INFO DAGScheduler: Final stage: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
23/11/30 14:21:22 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:22 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[75] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 35.3 KiB, free 434.3 MiB)
23/11/30 14:21:22 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 434.3 MiB)
23/11/30 14:21:22 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.25.86.80:43823 (size: 14.5 KiB, free: 434.4 MiB)
23/11/30 14:21:22 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[75] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:22 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
23/11/30 14:21:22 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 21) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:22 INFO Executor: Running task 0.0 in stage 29.0 (TID 21)
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:23 INFO CodeGenerator: Code generated in 6.962492 ms
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 29.0 (TID 21). 4817 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 21) in 18 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.032 s
23/11/30 14:21:23 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
23/11/30 14:21:23 INFO DAGScheduler: Job 21 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.034625 s
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 251.0 B, free 433.3 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.25.86.80:43823 (size: 251.0 B, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 25 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:23 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:23 INFO CodeGenerator: Code generated in 4.223434 ms
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 10.25.86.80:43823 in memory (size: 14.5 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Starting job: isEmpty at SparkTest.worksheet.sc:120
23/11/30 14:21:23 INFO DAGScheduler: Got job 22 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:21:23 INFO DAGScheduler: Final stage: ResultStage 31 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:21:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
23/11/30 14:21:23 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:23 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[78] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 13.3 KiB, free 433.4 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 433.4 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[78] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:23 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
23/11/30 14:21:23 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 22) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:23 INFO Executor: Running task 0.0 in stage 31.0 (TID 22)
23/11/30 14:21:23 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:23 INFO CodeGenerator: Code generated in 4.202791 ms
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 31.0 (TID 22). 3262 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 22) in 10 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ResultStage 31 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.014 s
23/11/30 14:21:23 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
23/11/30 14:21:23 INFO DAGScheduler: Job 22 finished: isEmpty at SparkTest.worksheet.sc:120, took 0.015669 s
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 10.25.86.80:43823 in memory (size: 7.5 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO CodeGenerator: Code generated in 6.824534 ms
23/11/30 14:21:23 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:23 INFO DAGScheduler: Got job 23 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:23 INFO DAGScheduler: Final stage: ResultStage 32 (collect at Ast.scala:253)
23/11/30 14:21:23 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:23 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:23 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[82] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 17.5 KiB, free 433.4 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 433.4 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[82] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:23 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
23/11/30 14:21:23 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 23) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:23 INFO Executor: Running task 0.0 in stage 32.0 (TID 23)
23/11/30 14:21:23 INFO CodeGenerator: Code generated in 5.360553 ms
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 32.0 (TID 23). 1826 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 23) in 22 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ResultStage 32 (collect at Ast.scala:253) finished in 0.026 s
23/11/30 14:21:23 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
23/11/30 14:21:23 INFO DAGScheduler: Job 23 finished: collect at Ast.scala:253, took 0.028785 s
23/11/30 14:21:23 INFO DAGScheduler: Registering RDD 83 (collect at Ast.scala:253) as input to shuffle 6
23/11/30 14:21:23 INFO DAGScheduler: Got map stage job 24 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:23 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (collect at Ast.scala:253)
23/11/30 14:21:23 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:23 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:23 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[83] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 19.0 KiB, free 433.4 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[83] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:23 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
23/11/30 14:21:23 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 24) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:23 INFO Executor: Running task 0.0 in stage 33.0 (TID 24)
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 33.0 (TID 24). 1793 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 24) in 13 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ShuffleMapStage 33 (collect at Ast.scala:253) finished in 0.020 s
23/11/30 14:21:23 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:23 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:23 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:23 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:23 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:23 INFO CodeGenerator: Code generated in 5.248796 ms
23/11/30 14:21:23 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:23 INFO DAGScheduler: Got job 25 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:23 INFO DAGScheduler: Final stage: ResultStage 35 (collect at Ast.scala:253)
23/11/30 14:21:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
23/11/30 14:21:23 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:23 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[86] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 24.9 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 433.4 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[86] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:23 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
23/11/30 14:21:23 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 25) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:23 INFO Executor: Running task 0.0 in stage 35.0 (TID 25)
23/11/30 14:21:23 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:23 INFO CodeGenerator: Code generated in 7.911545 ms
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 35.0 (TID 25). 4494 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 25) in 18 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ResultStage 35 (collect at Ast.scala:253) finished in 0.025 s
23/11/30 14:21:23 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
23/11/30 14:21:23 INFO DAGScheduler: Job 25 finished: collect at Ast.scala:253, took 0.028596 s
23/11/30 14:21:23 INFO CodeGenerator: Code generated in 5.117407 ms
23/11/30 14:21:23 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:23 INFO DAGScheduler: Got job 26 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:23 INFO DAGScheduler: Final stage: ResultStage 36 (collect at Ast.scala:253)
23/11/30 14:21:23 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:23 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:23 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[90] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 17.5 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[90] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:23 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
23/11/30 14:21:23 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 26) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:23 INFO Executor: Running task 0.0 in stage 36.0 (TID 26)
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 36.0 (TID 26). 1826 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 26) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ResultStage 36 (collect at Ast.scala:253) finished in 0.014 s
23/11/30 14:21:23 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
23/11/30 14:21:23 INFO DAGScheduler: Job 26 finished: collect at Ast.scala:253, took 0.017030 s
23/11/30 14:21:23 INFO DAGScheduler: Registering RDD 91 (collect at Ast.scala:253) as input to shuffle 7
23/11/30 14:21:23 INFO DAGScheduler: Got map stage job 27 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:23 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (collect at Ast.scala:253)
23/11/30 14:21:23 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:23 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:23 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[91] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 19.0 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[91] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:23 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
23/11/30 14:21:23 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 27) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:23 INFO Executor: Running task 0.0 in stage 37.0 (TID 27)
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 37.0 (TID 27). 1793 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 27) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ShuffleMapStage 37 (collect at Ast.scala:253) finished in 0.014 s
23/11/30 14:21:23 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:23 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:23 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:23 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:23 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO DAGScheduler: Got job 28 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:23 INFO DAGScheduler: Final stage: ResultStage 39 (collect at Ast.scala:253)
23/11/30 14:21:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
23/11/30 14:21:23 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[94] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 24.9 KiB, free 433.4 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 433.4 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.25.86.80:43823 (size: 10.7 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[94] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:23 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
23/11/30 14:21:23 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 28) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:23 INFO Executor: Running task 0.0 in stage 39.0 (TID 28)
23/11/30 14:21:23 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 39.0 (TID 28). 4494 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 28) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ResultStage 39 (collect at Ast.scala:253) finished in 0.019 s
23/11/30 14:21:23 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
23/11/30 14:21:23 INFO DAGScheduler: Job 28 finished: collect at Ast.scala:253, took 0.021548 s
23/11/30 14:21:23 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:23 INFO DAGScheduler: Got job 29 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:23 INFO DAGScheduler: Final stage: ResultStage 40 (collect at Ast.scala:253)
23/11/30 14:21:23 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:23 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:23 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[98] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 17.5 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[98] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:23 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
23/11/30 14:21:23 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 29) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:23 INFO Executor: Running task 0.0 in stage 40.0 (TID 29)
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 40.0 (TID 29). 1826 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 29) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ResultStage 40 (collect at Ast.scala:253) finished in 0.012 s
23/11/30 14:21:23 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
23/11/30 14:21:23 INFO DAGScheduler: Job 29 finished: collect at Ast.scala:253, took 0.014460 s
23/11/30 14:21:23 INFO DAGScheduler: Registering RDD 99 (collect at Ast.scala:253) as input to shuffle 8
23/11/30 14:21:23 INFO DAGScheduler: Got map stage job 30 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:23 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (collect at Ast.scala:253)
23/11/30 14:21:23 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:23 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:23 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[99] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 19.0 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[99] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:23 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
23/11/30 14:21:23 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 30) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:23 INFO Executor: Running task 0.0 in stage 41.0 (TID 30)
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 41.0 (TID 30). 1793 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 30) in 10 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ShuffleMapStage 41 (collect at Ast.scala:253) finished in 0.014 s
23/11/30 14:21:23 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:23 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:23 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:23 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:23 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:23 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:23 INFO DAGScheduler: Got job 31 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:23 INFO DAGScheduler: Final stage: ResultStage 43 (collect at Ast.scala:253)
23/11/30 14:21:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
23/11/30 14:21:23 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:23 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[102] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 24.9 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[102] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:23 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
23/11/30 14:21:23 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 31) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:23 INFO Executor: Running task 0.0 in stage 43.0 (TID 31)
23/11/30 14:21:23 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 43.0 (TID 31). 4494 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 31) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ResultStage 43 (collect at Ast.scala:253) finished in 0.011 s
23/11/30 14:21:23 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
23/11/30 14:21:23 INFO DAGScheduler: Job 31 finished: collect at Ast.scala:253, took 0.012619 s
23/11/30 14:21:23 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:150
23/11/30 14:21:23 INFO DAGScheduler: Got job 32 (show at SparkTest.worksheet.sc:150) with 1 output partitions
23/11/30 14:21:23 INFO DAGScheduler: Final stage: ResultStage 44 (show at SparkTest.worksheet.sc:150)
23/11/30 14:21:23 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:23 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:23 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[104] at show at SparkTest.worksheet.sc:150), which has no missing parents
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 15.7 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 433.3 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[104] at show at SparkTest.worksheet.sc:150) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:23 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
23/11/30 14:21:23 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 32) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:23 INFO Executor: Running task 0.0 in stage 44.0 (TID 32)
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 10.25.86.80:43823 in memory (size: 251.0 B, free: 434.4 MiB)
23/11/30 14:21:23 INFO Executor: Finished task 0.0 in stage 44.0 (TID 32). 1640 bytes result sent to driver
23/11/30 14:21:23 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 32) in 19 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:23 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
23/11/30 14:21:23 INFO DAGScheduler: ResultStage 44 (show at SparkTest.worksheet.sc:150) finished in 0.021 s
23/11/30 14:21:23 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
23/11/30 14:21:23 INFO DAGScheduler: Job 32 finished: show at SparkTest.worksheet.sc:150, took 0.023430 s
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO CodeGenerator: Code generated in 10.229099 ms
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 10.25.86.80:43823 in memory (size: 10.7 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:23 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
2023.11.30 14:21:23 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 12s[0m
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 6.657692 ms
23/11/30 14:21:25 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:62
23/11/30 14:21:25 INFO DAGScheduler: Got job 33 (show at SparkTest.worksheet.sc:62) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ResultStage 45 (show at SparkTest.worksheet.sc:62)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[114] at show at SparkTest.worksheet.sc:62), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[114] at show at SparkTest.worksheet.sc:62) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 33) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 45.0 (TID 33)
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 45.0 (TID 33). 1634 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 33) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ResultStage 45 (show at SparkTest.worksheet.sc:62) finished in 0.030 s
23/11/30 14:21:25 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
23/11/30 14:21:25 INFO DAGScheduler: Job 33 finished: show at SparkTest.worksheet.sc:62, took 0.031741 s
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 6.955484 ms
23/11/30 14:21:25 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 4.400847 ms
23/11/30 14:21:25 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:72
23/11/30 14:21:25 INFO DAGScheduler: Got job 34 (parquet at SparkTest.worksheet.sc:72) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ResultStage 46 (parquet at SparkTest.worksheet.sc:72)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ResultStage 46 (MapPartitionsRDD[116] at parquet at SparkTest.worksheet.sc:72), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 215.6 KiB, free 434.2 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 76.7 KiB, free 434.1 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.25.86.80:43823 (size: 76.7 KiB, free: 434.3 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 46 (MapPartitionsRDD[116] at parquet at SparkTest.worksheet.sc:72) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 34) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 46.0 (TID 34)
23/11/30 14:21:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:25 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:25 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:25 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:25 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:25 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:21:25 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:21:25 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/30 14:21:25 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "index",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 index;
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/30 14:21:25 INFO FileOutputCommitter: Saved output of task 'attempt_202311301421253200279179052939672_0046_m_000000_34' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311301421253200279179052939672_0046_m_000000
23/11/30 14:21:25 INFO SparkHadoopMapRedUtil: attempt_202311301421253200279179052939672_0046_m_000000_34: Committed. Elapsed time: 0 ms.
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 46.0 (TID 34). 2699 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 34) in 39 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ResultStage 46 (parquet at SparkTest.worksheet.sc:72) finished in 0.054 s
23/11/30 14:21:25 INFO DAGScheduler: Job 34 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 46: Stage finished
23/11/30 14:21:25 INFO DAGScheduler: Job 34 finished: parquet at SparkTest.worksheet.sc:72, took 0.056991 s
23/11/30 14:21:25 INFO FileFormatWriter: Start to commit write Job a61827f3-9932-4348-b8eb-b062ff99c6a5.
23/11/30 14:21:25 INFO FileFormatWriter: Write Job a61827f3-9932-4348-b8eb-b062ff99c6a5 committed. Elapsed time: 10 ms.
23/11/30 14:21:25 INFO FileFormatWriter: Finished processing stats for write job a61827f3-9932-4348-b8eb-b062ff99c6a5.
23/11/30 14:21:25 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
23/11/30 14:21:25 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 10.25.86.80:43823 in memory (size: 76.7 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:76
23/11/30 14:21:25 INFO DAGScheduler: Got job 35 (parquet at SparkTest.worksheet.sc:76) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ResultStage 47 (parquet at SparkTest.worksheet.sc:76)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[118] at parquet at SparkTest.worksheet.sc:76), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 102.9 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.25.86.80:43823 (size: 36.9 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[118] at parquet at SparkTest.worksheet.sc:76) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 35) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 47.0 (TID 35)
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 47.0 (TID 35). 2042 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 35) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ResultStage 47 (parquet at SparkTest.worksheet.sc:76) finished in 0.014 s
23/11/30 14:21:25 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 47: Stage finished
23/11/30 14:21:25 INFO DAGScheduler: Job 35 finished: parquet at SparkTest.worksheet.sc:76, took 0.015777 s
23/11/30 14:21:25 INFO FileSourceStrategy: Pushed Filters: 
23/11/30 14:21:25 INFO FileSourceStrategy: Post-Scan Filters: 
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 6.670463 ms
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 200.8 KiB, free 434.1 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 434.0 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.25.86.80:43823 (size: 34.9 KiB, free: 434.3 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 40 from show at SparkTest.worksheet.sc:81
23/11/30 14:21:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/11/30 14:21:25 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:81
23/11/30 14:21:25 INFO DAGScheduler: Got job 36 (show at SparkTest.worksheet.sc:81) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ResultStage 48 (show at SparkTest.worksheet.sc:81)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[122] at show at SparkTest.worksheet.sc:81), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 16.6 KiB, free 434.0 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.0 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.25.86.80:43823 (size: 6.8 KiB, free: 434.3 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[122] at show at SparkTest.worksheet.sc:81) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 36) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 48.0 (TID 36)
23/11/30 14:21:25 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-9b84a311-c1d3-4eff-aae3-7f0bdbc1b00b-c000.snappy.parquet, range: 0-1246, partition values: [empty row]
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 48.0 (TID 36). 1928 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 36) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ResultStage 48 (show at SparkTest.worksheet.sc:81) finished in 0.016 s
23/11/30 14:21:25 INFO DAGScheduler: Job 36 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
23/11/30 14:21:25 INFO DAGScheduler: Job 36 finished: show at SparkTest.worksheet.sc:81, took 0.017776 s
23/11/30 14:21:25 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 10.25.86.80:43823 in memory (size: 6.8 KiB, free: 434.3 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 10.25.86.80:43823 in memory (size: 34.9 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 10.25.86.80:43823 in memory (size: 36.9 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 11.525669 ms
23/11/30 14:21:25 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:94
23/11/30 14:21:25 INFO DAGScheduler: Got job 37 (show at SparkTest.worksheet.sc:94) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ResultStage 49 (show at SparkTest.worksheet.sc:94)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[124] at show at SparkTest.worksheet.sc:94), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 15.7 KiB, free 434.4 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.4 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[124] at show at SparkTest.worksheet.sc:94) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 37) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 49.0 (TID 37)
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 49.0 (TID 37). 1640 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 37) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ResultStage 49 (show at SparkTest.worksheet.sc:94) finished in 0.020 s
23/11/30 14:21:25 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 49: Stage finished
23/11/30 14:21:25 INFO DAGScheduler: Job 37 finished: show at SparkTest.worksheet.sc:94, took 0.022828 s
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 7.238583 ms
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 6.722163 ms
23/11/30 14:21:25 INFO DAGScheduler: Registering RDD 126 (collect at SparkTest.worksheet.sc:102) as input to shuffle 9
23/11/30 14:21:25 INFO DAGScheduler: Got map stage job 38 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ShuffleMapStage 50 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[126] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 19.2 KiB, free 434.4 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.4 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[126] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 50.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 38) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 50.0 (TID 38)
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 50.0 (TID 38). 1930 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 38) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ShuffleMapStage 50 (collect at SparkTest.worksheet.sc:102) finished in 0.011 s
23/11/30 14:21:25 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:25 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:25 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:25 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 7.530631 ms
23/11/30 14:21:25 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:102
23/11/30 14:21:25 INFO DAGScheduler: Got job 39 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ResultStage 52 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 51)
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[129] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 14.3 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.25.86.80:43823 (size: 6.6 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[129] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 39) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 52.0 (TID 39)
23/11/30 14:21:25 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 52.0 (TID 39). 4084 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 39) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ResultStage 52 (collect at SparkTest.worksheet.sc:102) finished in 0.015 s
23/11/30 14:21:25 INFO DAGScheduler: Job 39 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 52: Stage finished
23/11/30 14:21:25 INFO DAGScheduler: Job 39 finished: collect at SparkTest.worksheet.sc:102, took 0.016558 s
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 5.879193 ms
23/11/30 14:21:25 INFO SparkContext: Starting job: show at Ast.scala:95
23/11/30 14:21:25 INFO DAGScheduler: Got job 40 (show at Ast.scala:95) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ResultStage 53 (show at Ast.scala:95)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[131] at show at Ast.scala:95), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 15.5 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 53 (MapPartitionsRDD[131] at show at Ast.scala:95) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 53.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 40) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 53.0 (TID 40)
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 53.0 (TID 40). 1634 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 40) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ResultStage 53 (show at Ast.scala:95) finished in 0.011 s
23/11/30 14:21:25 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 53: Stage finished
23/11/30 14:21:25 INFO DAGScheduler: Job 40 finished: show at Ast.scala:95, took 0.012785 s
23/11/30 14:21:25 INFO SparkContext: Starting job: show at Ast.scala:96
23/11/30 14:21:25 INFO DAGScheduler: Got job 41 (show at Ast.scala:96) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ResultStage 54 (show at Ast.scala:96)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[133] at show at Ast.scala:96), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 15.5 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[133] at show at Ast.scala:96) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 41) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 54.0 (TID 41)
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 54.0 (TID 41). 1634 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 41) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ResultStage 54 (show at Ast.scala:96) finished in 0.011 s
23/11/30 14:21:25 INFO DAGScheduler: Job 41 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
23/11/30 14:21:25 INFO DAGScheduler: Job 41 finished: show at Ast.scala:96, took 0.013238 s
23/11/30 14:21:25 INFO DAGScheduler: Registering RDD 135 (show at Ast.scala:108) as input to shuffle 10
23/11/30 14:21:25 INFO DAGScheduler: Got map stage job 42 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ShuffleMapStage 55 (show at Ast.scala:108)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[135] at show at Ast.scala:108), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 17.7 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Removed broadcast_45_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[135] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 42) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 55.0 (TID 42)
23/11/30 14:21:25 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 10.25.86.80:43823 in memory (size: 6.6 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 55.0 (TID 42). 1991 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 42) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ShuffleMapStage 55 (show at Ast.scala:108) finished in 0.051 s
23/11/30 14:21:25 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:25 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:25 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:25 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:25 INFO ShufflePartitionsUtil: For shuffle(10, 10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 12.044709 ms
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 7.115647 ms
23/11/30 14:21:25 INFO CodeGenerator: Code generated in 5.342987 ms
23/11/30 14:21:25 INFO SparkContext: Starting job: show at Ast.scala:108
23/11/30 14:21:25 INFO DAGScheduler: Got job 43 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ResultStage 57 (show at Ast.scala:108)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[142] at show at Ast.scala:108), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 40.1 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.25.86.80:43823 (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[142] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 43) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 57.0 (TID 43)
23/11/30 14:21:25 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:25 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 57.0 (TID 43). 4898 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 43) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ResultStage 57 (show at Ast.scala:108) finished in 0.013 s
23/11/30 14:21:25 INFO DAGScheduler: Job 43 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
23/11/30 14:21:25 INFO DAGScheduler: Job 43 finished: show at Ast.scala:108, took 0.015656 s
23/11/30 14:21:25 INFO DAGScheduler: Registering RDD 144 (show at Ast.scala:112) as input to shuffle 11
23/11/30 14:21:25 INFO DAGScheduler: Got map stage job 44 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ShuffleMapStage 58 (show at Ast.scala:112)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[144] at show at Ast.scala:112), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 17.7 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[144] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 44) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 58.0 (TID 44)
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 58.0 (TID 44). 1991 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 44) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ShuffleMapStage 58 (show at Ast.scala:112) finished in 0.014 s
23/11/30 14:21:25 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:25 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:25 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:25 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:25 INFO ShufflePartitionsUtil: For shuffle(11, 11), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:25 INFO SparkContext: Starting job: show at Ast.scala:112
23/11/30 14:21:25 INFO DAGScheduler: Got job 45 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ResultStage 60 (show at Ast.scala:112)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ResultStage 60 (MapPartitionsRDD[151] at show at Ast.scala:112), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 40.1 KiB, free 434.3 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.2 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.25.86.80:43823 (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 60 (MapPartitionsRDD[151] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 45) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 60.0 (TID 45)
23/11/30 14:21:25 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:25 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 60.0 (TID 45). 4898 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 45) in 10 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ResultStage 60 (show at Ast.scala:112) finished in 0.014 s
23/11/30 14:21:25 INFO DAGScheduler: Job 45 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 60: Stage finished
23/11/30 14:21:25 INFO DAGScheduler: Job 45 finished: show at Ast.scala:112, took 0.016822 s
23/11/30 14:21:25 INFO SparkContext: Starting job: show at Ast.scala:113
23/11/30 14:21:25 INFO DAGScheduler: Got job 46 (show at Ast.scala:113) with 1 output partitions
23/11/30 14:21:25 INFO DAGScheduler: Final stage: ResultStage 61 (show at Ast.scala:113)
23/11/30 14:21:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:25 INFO DAGScheduler: Submitting ResultStage 61 (MapPartitionsRDD[153] at show at Ast.scala:113), which has no missing parents
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 15.5 KiB, free 434.2 MiB)
23/11/30 14:21:25 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.2 MiB)
23/11/30 14:21:25 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:21:25 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 61 (MapPartitionsRDD[153] at show at Ast.scala:113) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:25 INFO TaskSchedulerImpl: Adding task set 61.0 with 1 tasks resource profile 0
23/11/30 14:21:25 INFO TaskSetManager: Starting task 0.0 in stage 61.0 (TID 46) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:25 INFO Executor: Running task 0.0 in stage 61.0 (TID 46)
23/11/30 14:21:25 INFO Executor: Finished task 0.0 in stage 61.0 (TID 46). 1634 bytes result sent to driver
23/11/30 14:21:25 INFO TaskSetManager: Finished task 0.0 in stage 61.0 (TID 46) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:25 INFO TaskSchedulerImpl: Removed TaskSet 61.0, whose tasks have all completed, from pool 
23/11/30 14:21:25 INFO DAGScheduler: ResultStage 61 (show at Ast.scala:113) finished in 0.008 s
23/11/30 14:21:25 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 61: Stage finished
23/11/30 14:21:25 INFO DAGScheduler: Job 46 finished: show at Ast.scala:113, took 0.010484 s
23/11/30 14:21:26 INFO DAGScheduler: Registering RDD 155 (show at Ast.scala:126) as input to shuffle 12
23/11/30 14:21:26 INFO DAGScheduler: Got map stage job 47 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ShuffleMapStage 62 (show at Ast.scala:126)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ShuffleMapStage 62 (MapPartitionsRDD[155] at show at Ast.scala:126), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 17.7 KiB, free 434.2 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.2 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_47_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 62 (MapPartitionsRDD[155] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 62.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_49_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_51_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 62.0 (TID 47) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 10.25.86.80:43823 in memory (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 62.0 (TID 47)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 10.25.86.80:43823 in memory (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 62.0 (TID 47). 1991 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 62.0 (TID 47) in 12 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 62.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ShuffleMapStage 62 (show at Ast.scala:126) finished in 0.027 s
23/11/30 14:21:26 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:26 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:26 INFO ShufflePartitionsUtil: For shuffle(12, 12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:26 INFO CodeGenerator: Code generated in 7.382603 ms
23/11/30 14:21:26 INFO CodeGenerator: Code generated in 4.570694 ms
23/11/30 14:21:26 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:26 INFO DAGScheduler: Got job 48 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 64 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 63)
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 64 (MapPartitionsRDD[162] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 38.7 KiB, free 434.3 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 64 (MapPartitionsRDD[162] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 48) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 64.0 (TID 48)
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 64.0 (TID 48). 4897 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 48) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 64 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.013 s
23/11/30 14:21:26 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 64: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 48 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.015485 s
23/11/30 14:21:26 INFO CodeGenerator: Code generated in 4.073345 ms
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 54 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:26 INFO ShufflePartitionsUtil: For shuffle(12), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:26 INFO CodeGenerator: Code generated in 9.88632 ms
23/11/30 14:21:26 INFO SparkContext: Starting job: show at Ast.scala:126
23/11/30 14:21:26 INFO DAGScheduler: Got job 49 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 66 (show at Ast.scala:126)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[165] at show at Ast.scala:126), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 15.1 KiB, free 433.3 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[165] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 49) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 66.0 (TID 49)
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 66.0 (TID 49). 4165 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 49) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 66 (show at Ast.scala:126) finished in 0.007 s
23/11/30 14:21:26 INFO DAGScheduler: Job 49 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 49 finished: show at Ast.scala:126, took 0.009041 s
23/11/30 14:21:26 INFO DAGScheduler: Registering RDD 167 (show at SparkTest.worksheet.sc:115) as input to shuffle 13
23/11/30 14:21:26 INFO DAGScheduler: Got map stage job 50 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ShuffleMapStage 67 (show at SparkTest.worksheet.sc:115)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[167] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 17.7 KiB, free 433.3 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[167] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 50) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 67.0 (TID 50)
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 67.0 (TID 50). 1991 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 50) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ShuffleMapStage 67 (show at SparkTest.worksheet.sc:115) finished in 0.011 s
23/11/30 14:21:26 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:26 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:26 INFO ShufflePartitionsUtil: For shuffle(13, 13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:26 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:26 INFO DAGScheduler: Got job 51 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 69 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[174] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 38.7 KiB, free 433.2 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 433.2 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[174] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 51) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 69.0 (TID 51)
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 69.0 (TID 51). 4897 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 51) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 69 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.010 s
23/11/30 14:21:26 INFO DAGScheduler: Job 51 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 51 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.011749 s
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 1024.1 KiB, free 432.2 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 337.0 B, free 432.2 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 58 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:26 INFO ShufflePartitionsUtil: For shuffle(13), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:26 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:115
23/11/30 14:21:26 INFO DAGScheduler: Got job 52 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 71 (show at SparkTest.worksheet.sc:115)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 70)
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 71 (MapPartitionsRDD[177] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 15.1 KiB, free 432.2 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 432.2 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 71 (MapPartitionsRDD[177] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 71.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 71.0 (TID 52) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 71.0 (TID 52)
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 71.0 (TID 52). 4165 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 71.0 (TID 52) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 71.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 71 (show at SparkTest.worksheet.sc:115) finished in 0.006 s
23/11/30 14:21:26 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 71: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 52 finished: show at SparkTest.worksheet.sc:115, took 0.007706 s
23/11/30 14:21:26 INFO CodeGenerator: Code generated in 2.993051 ms
23/11/30 14:21:26 INFO DAGScheduler: Registering RDD 179 (isEmpty at SparkTest.worksheet.sc:120) as input to shuffle 14
23/11/30 14:21:26 INFO DAGScheduler: Got map stage job 53 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ShuffleMapStage 72 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ShuffleMapStage 72 (MapPartitionsRDD[179] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 17.3 KiB, free 432.2 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 432.2 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 10.25.86.80:43823 (size: 7.5 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 72 (MapPartitionsRDD[179] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 53) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 72.0 (TID 53)
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 72.0 (TID 53). 1991 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 53) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ShuffleMapStage 72 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.009 s
23/11/30 14:21:26 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:26 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:26 INFO ShufflePartitionsUtil: For shuffle(14, 14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:26 INFO CodeGenerator: Code generated in 5.605037 ms
23/11/30 14:21:26 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:26 INFO DAGScheduler: Got job 54 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 74 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 73)
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 74 (MapPartitionsRDD[186] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 35.3 KiB, free 432.1 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 432.1 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 10.25.86.80:43823 (size: 14.5 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 74 (MapPartitionsRDD[186] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 74.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 74.0 (TID 54) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 74.0 (TID 54)
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 74.0 (TID 54). 4817 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 74.0 (TID 54) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 74.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 74 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.009 s
23/11/30 14:21:26 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 74: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 54 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.010847 s
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 1024.1 KiB, free 431.1 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 251.0 B, free 431.1 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 10.25.86.80:43823 (size: 251.0 B, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 62 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:26 INFO ShufflePartitionsUtil: For shuffle(14), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:26 INFO CodeGenerator: Code generated in 3.737086 ms
23/11/30 14:21:26 INFO SparkContext: Starting job: isEmpty at SparkTest.worksheet.sc:120
23/11/30 14:21:26 INFO DAGScheduler: Got job 55 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 76 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 75)
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 76 (MapPartitionsRDD[189] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 13.3 KiB, free 431.1 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 431.1 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 76 (MapPartitionsRDD[189] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 55) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 76.0 (TID 55)
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 76.0 (TID 55). 3262 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 55) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 76 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.006 s
23/11/30 14:21:26 INFO DAGScheduler: Job 55 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 76: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 55 finished: isEmpty at SparkTest.worksheet.sc:120, took 0.007242 s
23/11/30 14:21:26 INFO CodeGenerator: Code generated in 3.779404 ms
23/11/30 14:21:26 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:26 INFO DAGScheduler: Got job 56 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 77 (collect at Ast.scala:253)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 77 (MapPartitionsRDD[193] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 17.5 KiB, free 431.1 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 431.1 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 77 (MapPartitionsRDD[193] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 77.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 77.0 (TID 56) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 77.0 (TID 56)
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 77.0 (TID 56). 1826 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 77.0 (TID 56) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 77.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 77 (collect at Ast.scala:253) finished in 0.008 s
23/11/30 14:21:26 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 77: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 56 finished: collect at Ast.scala:253, took 0.008825 s
23/11/30 14:21:26 INFO DAGScheduler: Registering RDD 194 (collect at Ast.scala:253) as input to shuffle 15
23/11/30 14:21:26 INFO DAGScheduler: Got map stage job 57 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ShuffleMapStage 78 (collect at Ast.scala:253)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ShuffleMapStage 78 (MapPartitionsRDD[194] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 19.0 KiB, free 431.1 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 431.1 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 78 (MapPartitionsRDD[194] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 57) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 78.0 (TID 57)
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 78.0 (TID 57). 1793 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 57) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ShuffleMapStage 78 (collect at Ast.scala:253) finished in 0.010 s
23/11/30 14:21:26 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:26 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:26 INFO ShufflePartitionsUtil: For shuffle(15), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:26 INFO CodeGenerator: Code generated in 4.651553 ms
23/11/30 14:21:26 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:26 INFO DAGScheduler: Got job 58 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 80 (collect at Ast.scala:253)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 79)
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 80 (MapPartitionsRDD[197] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 24.9 KiB, free 431.0 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 431.0 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 80 (MapPartitionsRDD[197] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 80.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 80.0 (TID 58) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 80.0 (TID 58)
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 80.0 (TID 58). 4494 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 80.0 (TID 58) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 80.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 80 (collect at Ast.scala:253) finished in 0.008 s
23/11/30 14:21:26 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 80: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 58 finished: collect at Ast.scala:253, took 0.008753 s
23/11/30 14:21:26 INFO CodeGenerator: Code generated in 3.84302 ms
23/11/30 14:21:26 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:26 INFO DAGScheduler: Got job 59 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 81 (collect at Ast.scala:253)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[201] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 17.5 KiB, free 431.0 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 431.0 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[201] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 59) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 81.0 (TID 59)
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 81.0 (TID 59). 1826 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 59) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 81 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:21:26 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 59 finished: collect at Ast.scala:253, took 0.008197 s
23/11/30 14:21:26 INFO DAGScheduler: Registering RDD 202 (collect at Ast.scala:253) as input to shuffle 16
23/11/30 14:21:26 INFO DAGScheduler: Got map stage job 60 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ShuffleMapStage 82 (collect at Ast.scala:253)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[202] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 19.0 KiB, free 431.0 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 431.0 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[202] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 60) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 82.0 (TID 60)
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 82.0 (TID 60). 1793 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 60) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ShuffleMapStage 82 (collect at Ast.scala:253) finished in 0.008 s
23/11/30 14:21:26 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:26 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:26 INFO ShufflePartitionsUtil: For shuffle(16), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:26 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:26 INFO DAGScheduler: Got job 61 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 84 (collect at Ast.scala:253)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[205] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 24.9 KiB, free 430.9 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 430.9 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[205] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 61) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 84.0 (TID 61)
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 84.0 (TID 61). 4494 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 61) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 84 (collect at Ast.scala:253) finished in 0.009 s
23/11/30 14:21:26 INFO DAGScheduler: Job 61 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 61 finished: collect at Ast.scala:253, took 0.009550 s
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_65_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_66_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_61_piece0 on 10.25.86.80:43823 in memory (size: 14.5 KiB, free: 434.3 MiB)
23/11/30 14:21:26 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_57_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO DAGScheduler: Got job 62 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 85 (collect at Ast.scala:253)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 85 (MapPartitionsRDD[209] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_59_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_67_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 17.5 KiB, free 431.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 10.25.86.80:43823 in memory (size: 7.5 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_68_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 431.4 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 85 (MapPartitionsRDD[209] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_62_piece0 on 10.25.86.80:43823 in memory (size: 251.0 B, free: 434.4 MiB)
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 62) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 85.0 (TID 62)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_54_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 85.0 (TID 62). 1826 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 62) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 85 (collect at Ast.scala:253) finished in 0.008 s
23/11/30 14:21:26 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 85: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 62 finished: collect at Ast.scala:253, took 0.008978 s
23/11/30 14:21:26 INFO DAGScheduler: Registering RDD 210 (collect at Ast.scala:253) as input to shuffle 17
23/11/30 14:21:26 INFO DAGScheduler: Got map stage job 63 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ShuffleMapStage 86 (collect at Ast.scala:253)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ShuffleMapStage 86 (MapPartitionsRDD[210] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 19.0 KiB, free 434.4 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 86 (MapPartitionsRDD[210] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 86.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 86.0 (TID 63) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 86.0 (TID 63)
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 86.0 (TID 63). 1793 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 86.0 (TID 63) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 86.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ShuffleMapStage 86 (collect at Ast.scala:253) finished in 0.008 s
23/11/30 14:21:26 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:26 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:26 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:26 INFO ShufflePartitionsUtil: For shuffle(17), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:26 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:26 INFO DAGScheduler: Got job 64 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 88 (collect at Ast.scala:253)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 87)
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 88 (MapPartitionsRDD[213] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 24.9 KiB, free 434.3 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 88 (MapPartitionsRDD[213] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 64) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 88.0 (TID 64)
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 88.0 (TID 64). 4494 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 64) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 88 (collect at Ast.scala:253) finished in 0.008 s
23/11/30 14:21:26 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 88: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 64 finished: collect at Ast.scala:253, took 0.008553 s
23/11/30 14:21:26 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:150
23/11/30 14:21:26 INFO DAGScheduler: Got job 65 (show at SparkTest.worksheet.sc:150) with 1 output partitions
23/11/30 14:21:26 INFO DAGScheduler: Final stage: ResultStage 89 (show at SparkTest.worksheet.sc:150)
23/11/30 14:21:26 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:26 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:26 INFO DAGScheduler: Submitting ResultStage 89 (MapPartitionsRDD[215] at show at SparkTest.worksheet.sc:150), which has no missing parents
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 15.7 KiB, free 434.3 MiB)
23/11/30 14:21:26 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.3 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 89 (MapPartitionsRDD[215] at show at SparkTest.worksheet.sc:150) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:26 INFO TaskSchedulerImpl: Adding task set 89.0 with 1 tasks resource profile 0
23/11/30 14:21:26 INFO TaskSetManager: Starting task 0.0 in stage 89.0 (TID 65) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:26 INFO Executor: Running task 0.0 in stage 89.0 (TID 65)
23/11/30 14:21:26 INFO Executor: Finished task 0.0 in stage 89.0 (TID 65). 1640 bytes result sent to driver
23/11/30 14:21:26 INFO TaskSetManager: Finished task 0.0 in stage 89.0 (TID 65) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:26 INFO TaskSchedulerImpl: Removed TaskSet 89.0, whose tasks have all completed, from pool 
23/11/30 14:21:26 INFO DAGScheduler: ResultStage 89 (show at SparkTest.worksheet.sc:150) finished in 0.008 s
23/11/30 14:21:26 INFO DAGScheduler: Job 65 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 89: Stage finished
23/11/30 14:21:26 INFO DAGScheduler: Job 65 finished: show at SparkTest.worksheet.sc:150, took 0.009023 s
23/11/30 14:21:26 INFO CodeGenerator: Code generated in 5.8499 ms
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:26 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
2023.11.30 14:21:26 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 3s[0m
23/11/30 14:21:37 INFO CodeGenerator: Code generated in 4.378478 ms
23/11/30 14:21:37 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:62
23/11/30 14:21:37 INFO DAGScheduler: Got job 66 (show at SparkTest.worksheet.sc:62) with 1 output partitions
23/11/30 14:21:37 INFO DAGScheduler: Final stage: ResultStage 90 (show at SparkTest.worksheet.sc:62)
23/11/30 14:21:37 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:37 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:37 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[225] at show at SparkTest.worksheet.sc:62), which has no missing parents
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/11/30 14:21:37 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:37 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[225] at show at SparkTest.worksheet.sc:62) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:37 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0
23/11/30 14:21:37 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 66) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:37 INFO Executor: Running task 0.0 in stage 90.0 (TID 66)
23/11/30 14:21:37 INFO Executor: Finished task 0.0 in stage 90.0 (TID 66). 1634 bytes result sent to driver
23/11/30 14:21:37 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 66) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:37 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool 
23/11/30 14:21:37 INFO DAGScheduler: ResultStage 90 (show at SparkTest.worksheet.sc:62) finished in 0.023 s
23/11/30 14:21:37 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished
23/11/30 14:21:37 INFO DAGScheduler: Job 66 finished: show at SparkTest.worksheet.sc:62, took 0.024852 s
23/11/30 14:21:37 INFO CodeGenerator: Code generated in 4.38941 ms
23/11/30 14:21:37 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:37 INFO CodeGenerator: Code generated in 4.300994 ms
23/11/30 14:21:37 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:72
23/11/30 14:21:37 INFO DAGScheduler: Got job 67 (parquet at SparkTest.worksheet.sc:72) with 1 output partitions
23/11/30 14:21:37 INFO DAGScheduler: Final stage: ResultStage 91 (parquet at SparkTest.worksheet.sc:72)
23/11/30 14:21:37 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:37 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:37 INFO DAGScheduler: Submitting ResultStage 91 (MapPartitionsRDD[227] at parquet at SparkTest.worksheet.sc:72), which has no missing parents
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 215.6 KiB, free 434.2 MiB)
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 76.7 KiB, free 434.1 MiB)
23/11/30 14:21:37 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on 10.25.86.80:43823 (size: 76.7 KiB, free: 434.3 MiB)
23/11/30 14:21:37 INFO SparkContext: Created broadcast 75 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 91 (MapPartitionsRDD[227] at parquet at SparkTest.worksheet.sc:72) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:37 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0
23/11/30 14:21:37 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 67) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:37 INFO Executor: Running task 0.0 in stage 91.0 (TID 67)
23/11/30 14:21:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:37 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:37 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:21:37 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:21:37 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/30 14:21:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "index",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 index;
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/30 14:21:37 INFO FileOutputCommitter: Saved output of task 'attempt_202311301421373128400708458622884_0091_m_000000_67' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311301421373128400708458622884_0091_m_000000
23/11/30 14:21:37 INFO SparkHadoopMapRedUtil: attempt_202311301421373128400708458622884_0091_m_000000_67: Committed. Elapsed time: 0 ms.
23/11/30 14:21:37 INFO Executor: Finished task 0.0 in stage 91.0 (TID 67). 2699 bytes result sent to driver
23/11/30 14:21:37 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 67) in 36 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:37 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool 
23/11/30 14:21:37 INFO DAGScheduler: ResultStage 91 (parquet at SparkTest.worksheet.sc:72) finished in 0.054 s
23/11/30 14:21:37 INFO DAGScheduler: Job 67 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 91: Stage finished
23/11/30 14:21:37 INFO DAGScheduler: Job 67 finished: parquet at SparkTest.worksheet.sc:72, took 0.055904 s
23/11/30 14:21:37 INFO FileFormatWriter: Start to commit write Job 5c50840b-22ec-4c22-8e0e-6bb4c0bf3e31.
23/11/30 14:21:37 INFO FileFormatWriter: Write Job 5c50840b-22ec-4c22-8e0e-6bb4c0bf3e31 committed. Elapsed time: 8 ms.
23/11/30 14:21:37 INFO FileFormatWriter: Finished processing stats for write job 5c50840b-22ec-4c22-8e0e-6bb4c0bf3e31.
23/11/30 14:21:37 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
23/11/30 14:21:37 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:76
23/11/30 14:21:37 INFO DAGScheduler: Got job 68 (parquet at SparkTest.worksheet.sc:76) with 1 output partitions
23/11/30 14:21:37 INFO DAGScheduler: Final stage: ResultStage 92 (parquet at SparkTest.worksheet.sc:76)
23/11/30 14:21:37 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:37 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:37 INFO DAGScheduler: Submitting ResultStage 92 (MapPartitionsRDD[229] at parquet at SparkTest.worksheet.sc:76), which has no missing parents
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/11/30 14:21:37 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on 10.25.86.80:43823 (size: 36.9 KiB, free: 434.3 MiB)
23/11/30 14:21:37 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 92 (MapPartitionsRDD[229] at parquet at SparkTest.worksheet.sc:76) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:37 INFO TaskSchedulerImpl: Adding task set 92.0 with 1 tasks resource profile 0
23/11/30 14:21:37 INFO TaskSetManager: Starting task 0.0 in stage 92.0 (TID 68) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/11/30 14:21:37 INFO Executor: Running task 0.0 in stage 92.0 (TID 68)
23/11/30 14:21:37 INFO Executor: Finished task 0.0 in stage 92.0 (TID 68). 2042 bytes result sent to driver
23/11/30 14:21:37 INFO TaskSetManager: Finished task 0.0 in stage 92.0 (TID 68) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:37 INFO TaskSchedulerImpl: Removed TaskSet 92.0, whose tasks have all completed, from pool 
23/11/30 14:21:37 INFO DAGScheduler: ResultStage 92 (parquet at SparkTest.worksheet.sc:76) finished in 0.044 s
23/11/30 14:21:37 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 92: Stage finished
23/11/30 14:21:37 INFO DAGScheduler: Job 68 finished: parquet at SparkTest.worksheet.sc:76, took 0.045269 s
23/11/30 14:21:37 INFO FileSourceStrategy: Pushed Filters: 
23/11/30 14:21:37 INFO FileSourceStrategy: Post-Scan Filters: 
23/11/30 14:21:37 INFO CodeGenerator: Code generated in 11.168639 ms
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 200.8 KiB, free 433.8 MiB)
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
23/11/30 14:21:37 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on 10.25.86.80:43823 (size: 34.9 KiB, free: 434.2 MiB)
23/11/30 14:21:37 INFO SparkContext: Created broadcast 77 from show at SparkTest.worksheet.sc:81
23/11/30 14:21:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/11/30 14:21:37 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:81
23/11/30 14:21:37 INFO DAGScheduler: Got job 69 (show at SparkTest.worksheet.sc:81) with 1 output partitions
23/11/30 14:21:37 INFO DAGScheduler: Final stage: ResultStage 93 (show at SparkTest.worksheet.sc:81)
23/11/30 14:21:37 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:37 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:37 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[233] at show at SparkTest.worksheet.sc:81), which has no missing parents
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 16.6 KiB, free 433.7 MiB)
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 433.7 MiB)
23/11/30 14:21:37 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on 10.25.86.80:43823 (size: 6.8 KiB, free: 434.2 MiB)
23/11/30 14:21:37 INFO SparkContext: Created broadcast 78 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[233] at show at SparkTest.worksheet.sc:81) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:37 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0
23/11/30 14:21:37 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 69) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/11/30 14:21:37 INFO Executor: Running task 0.0 in stage 93.0 (TID 69)
23/11/30 14:21:37 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-fb8bc654-26ab-4211-8412-09619a0432dd-c000.snappy.parquet, range: 0-1246, partition values: [empty row]
23/11/30 14:21:37 INFO Executor: Finished task 0.0 in stage 93.0 (TID 69). 1928 bytes result sent to driver
23/11/30 14:21:37 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 69) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:37 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool 
23/11/30 14:21:37 INFO DAGScheduler: ResultStage 93 (show at SparkTest.worksheet.sc:81) finished in 0.016 s
23/11/30 14:21:37 INFO DAGScheduler: Job 69 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished
23/11/30 14:21:37 INFO DAGScheduler: Job 69 finished: show at SparkTest.worksheet.sc:81, took 0.016740 s
23/11/30 14:21:37 INFO CodeGenerator: Code generated in 5.321971 ms
23/11/30 14:21:37 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:94
23/11/30 14:21:37 INFO DAGScheduler: Got job 70 (show at SparkTest.worksheet.sc:94) with 1 output partitions
23/11/30 14:21:37 INFO DAGScheduler: Final stage: ResultStage 94 (show at SparkTest.worksheet.sc:94)
23/11/30 14:21:37 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:37 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:37 INFO DAGScheduler: Submitting ResultStage 94 (MapPartitionsRDD[235] at show at SparkTest.worksheet.sc:94), which has no missing parents
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 15.7 KiB, free 433.7 MiB)
23/11/30 14:21:37 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 433.7 MiB)
23/11/30 14:21:37 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.2 MiB)
23/11/30 14:21:37 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 94 (MapPartitionsRDD[235] at show at SparkTest.worksheet.sc:94) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:37 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0
23/11/30 14:21:37 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 70) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:37 INFO Executor: Running task 0.0 in stage 94.0 (TID 70)
23/11/30 14:21:37 INFO Executor: Finished task 0.0 in stage 94.0 (TID 70). 1640 bytes result sent to driver
23/11/30 14:21:37 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 70) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:37 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool 
23/11/30 14:21:37 INFO DAGScheduler: ResultStage 94 (show at SparkTest.worksheet.sc:94) finished in 0.009 s
23/11/30 14:21:37 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 94: Stage finished
23/11/30 14:21:37 INFO DAGScheduler: Job 70 finished: show at SparkTest.worksheet.sc:94, took 0.009794 s
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 3.446631 ms
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 4.35164 ms
23/11/30 14:21:38 INFO DAGScheduler: Registering RDD 237 (collect at SparkTest.worksheet.sc:102) as input to shuffle 18
23/11/30 14:21:38 INFO DAGScheduler: Got map stage job 71 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ShuffleMapStage 95 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ShuffleMapStage 95 (MapPartitionsRDD[237] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 19.2 KiB, free 433.7 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 433.7 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.2 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 95 (MapPartitionsRDD[237] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 95.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 95.0 (TID 71) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 95.0 (TID 71)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 95.0 (TID 71). 1930 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 95.0 (TID 71) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 95.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ShuffleMapStage 95 (collect at SparkTest.worksheet.sc:102) finished in 0.007 s
23/11/30 14:21:38 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:38 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 6.769999 ms
23/11/30 14:21:38 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:102
23/11/30 14:21:38 INFO DAGScheduler: Got job 72 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 97 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 96)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 97 (MapPartitionsRDD[240] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 14.3 KiB, free 433.6 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 433.6 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on 10.25.86.80:43823 (size: 6.6 KiB, free: 434.2 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 81 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 97 (MapPartitionsRDD[240] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.2 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_79_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.2 MiB)
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 72) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_75_piece0 on 10.25.86.80:43823 in memory (size: 76.7 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 97.0 (TID 72)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_80_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_78_piece0 on 10.25.86.80:43823 in memory (size: 6.8 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_76_piece0 on 10.25.86.80:43823 in memory (size: 36.9 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_77_piece0 on 10.25.86.80:43823 in memory (size: 34.9 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 97.0 (TID 72). 4084 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 72) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 97 (collect at SparkTest.worksheet.sc:102) finished in 0.017 s
23/11/30 14:21:38 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 97: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 72 finished: collect at SparkTest.worksheet.sc:102, took 0.018300 s
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 5.148111 ms
23/11/30 14:21:38 INFO SparkContext: Starting job: show at Ast.scala:95
23/11/30 14:21:38 INFO DAGScheduler: Got job 73 (show at Ast.scala:95) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 98 (show at Ast.scala:95)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 98 (MapPartitionsRDD[242] at show at Ast.scala:95), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 98 (MapPartitionsRDD[242] at show at Ast.scala:95) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 98.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 98.0 (TID 73) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 98.0 (TID 73)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 98.0 (TID 73). 1634 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 98.0 (TID 73) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 98.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 98 (show at Ast.scala:95) finished in 0.007 s
23/11/30 14:21:38 INFO DAGScheduler: Job 73 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 98: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 73 finished: show at Ast.scala:95, took 0.007924 s
23/11/30 14:21:38 INFO SparkContext: Starting job: show at Ast.scala:96
23/11/30 14:21:38 INFO DAGScheduler: Got job 74 (show at Ast.scala:96) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 99 (show at Ast.scala:96)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[244] at show at Ast.scala:96), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 15.5 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[244] at show at Ast.scala:96) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 74) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 99.0 (TID 74)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 99.0 (TID 74). 1634 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 74) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 99 (show at Ast.scala:96) finished in 0.007 s
23/11/30 14:21:38 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 74 finished: show at Ast.scala:96, took 0.008131 s
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_81_piece0 on 10.25.86.80:43823 in memory (size: 6.6 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_82_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_83_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO DAGScheduler: Registering RDD 246 (show at Ast.scala:108) as input to shuffle 19
23/11/30 14:21:38 INFO DAGScheduler: Got map stage job 75 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ShuffleMapStage 100 (show at Ast.scala:108)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[246] at show at Ast.scala:108), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 17.7 KiB, free 434.4 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.4 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 84 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[246] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 75) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 100.0 (TID 75)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 100.0 (TID 75). 1991 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 75) in 10 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ShuffleMapStage 100 (show at Ast.scala:108) finished in 0.022 s
23/11/30 14:21:38 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:38 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:38 INFO ShufflePartitionsUtil: For shuffle(19, 19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 9.520504 ms
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 4.417884 ms
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 3.825753 ms
23/11/30 14:21:38 INFO SparkContext: Starting job: show at Ast.scala:108
23/11/30 14:21:38 INFO DAGScheduler: Got job 76 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 102 (show at Ast.scala:108)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[253] at show at Ast.scala:108), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 40.1 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on 10.25.86.80:43823 (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[253] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 76) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 102.0 (TID 76)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 102.0 (TID 76). 4898 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 76) in 10 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 102 (show at Ast.scala:108) finished in 0.013 s
23/11/30 14:21:38 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 102: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 76 finished: show at Ast.scala:108, took 0.015404 s
23/11/30 14:21:38 INFO DAGScheduler: Registering RDD 255 (show at Ast.scala:112) as input to shuffle 20
23/11/30 14:21:38 INFO DAGScheduler: Got map stage job 77 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ShuffleMapStage 103 (show at Ast.scala:112)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ShuffleMapStage 103 (MapPartitionsRDD[255] at show at Ast.scala:112), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 17.7 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 103 (MapPartitionsRDD[255] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 77) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 103.0 (TID 77)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 103.0 (TID 77). 1991 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 77) in 10 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ShuffleMapStage 103 (show at Ast.scala:112) finished in 0.014 s
23/11/30 14:21:38 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:38 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:38 INFO ShufflePartitionsUtil: For shuffle(20, 20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:38 INFO SparkContext: Starting job: show at Ast.scala:112
23/11/30 14:21:38 INFO DAGScheduler: Got job 78 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 105 (show at Ast.scala:112)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[262] at show at Ast.scala:112), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 40.1 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.2 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on 10.25.86.80:43823 (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 87 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[262] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 78) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 105.0 (TID 78)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 105.0 (TID 78). 4898 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 78) in 10 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 105 (show at Ast.scala:112) finished in 0.014 s
23/11/30 14:21:38 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 78 finished: show at Ast.scala:112, took 0.016537 s
23/11/30 14:21:38 INFO SparkContext: Starting job: show at Ast.scala:113
23/11/30 14:21:38 INFO DAGScheduler: Got job 79 (show at Ast.scala:113) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 106 (show at Ast.scala:113)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 106 (MapPartitionsRDD[264] at show at Ast.scala:113), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 15.5 KiB, free 434.2 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.2 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 106 (MapPartitionsRDD[264] at show at Ast.scala:113) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 79) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 106.0 (TID 79)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 106.0 (TID 79). 1634 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 79) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 106 (show at Ast.scala:113) finished in 0.010 s
23/11/30 14:21:38 INFO DAGScheduler: Job 79 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 106: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 79 finished: show at Ast.scala:113, took 0.011454 s
23/11/30 14:21:38 INFO DAGScheduler: Registering RDD 266 (show at Ast.scala:126) as input to shuffle 21
23/11/30 14:21:38 INFO DAGScheduler: Got map stage job 80 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ShuffleMapStage 107 (show at Ast.scala:126)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ShuffleMapStage 107 (MapPartitionsRDD[266] at show at Ast.scala:126), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 17.7 KiB, free 434.2 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.2 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 107 (MapPartitionsRDD[266] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 107.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 107.0 (TID 80) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 107.0 (TID 80)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 107.0 (TID 80). 1991 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 107.0 (TID 80) in 10 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 107.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ShuffleMapStage 107 (show at Ast.scala:126) finished in 0.012 s
23/11/30 14:21:38 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:38 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:38 INFO ShufflePartitionsUtil: For shuffle(21, 21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 5.963894 ms
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 5.504997 ms
23/11/30 14:21:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:38 INFO DAGScheduler: Got job 81 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 109 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 108)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 109 (MapPartitionsRDD[273] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 38.7 KiB, free 434.2 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.1 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 90 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 109 (MapPartitionsRDD[273] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 81) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 109.0 (TID 81)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 109.0 (TID 81). 4897 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 81) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 109 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.009 s
23/11/30 14:21:38 INFO DAGScheduler: Job 81 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 109: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 81 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.010336 s
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 2.728166 ms
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 1024.1 KiB, free 433.1 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.1 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 91 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:38 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 4.717269 ms
23/11/30 14:21:38 INFO SparkContext: Starting job: show at Ast.scala:126
23/11/30 14:21:38 INFO DAGScheduler: Got job 82 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 111 (show at Ast.scala:126)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[276] at show at Ast.scala:126), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 15.1 KiB, free 433.1 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.1 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[276] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 82) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 111.0 (TID 82)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 111.0 (TID 82). 4122 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 82) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 111 (show at Ast.scala:126) finished in 0.006 s
23/11/30 14:21:38 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 82 finished: show at Ast.scala:126, took 0.006670 s
23/11/30 14:21:38 INFO DAGScheduler: Registering RDD 278 (show at SparkTest.worksheet.sc:115) as input to shuffle 22
23/11/30 14:21:38 INFO DAGScheduler: Got map stage job 83 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ShuffleMapStage 112 (show at SparkTest.worksheet.sc:115)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ShuffleMapStage 112 (MapPartitionsRDD[278] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 17.7 KiB, free 433.1 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.1 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 93 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 112 (MapPartitionsRDD[278] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 83) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 112.0 (TID 83)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 112.0 (TID 83). 1991 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 83) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ShuffleMapStage 112 (show at SparkTest.worksheet.sc:115) finished in 0.010 s
23/11/30 14:21:38 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:38 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:38 INFO ShufflePartitionsUtil: For shuffle(22, 22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:38 INFO DAGScheduler: Got job 84 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 114 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[285] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 38.7 KiB, free 433.1 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 433.0 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[285] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 84) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 114.0 (TID 84)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 114.0 (TID 84). 4897 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 84) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 114 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.009 s
23/11/30 14:21:38 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 114: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 84 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.011199 s
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 1024.1 KiB, free 432.0 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 337.0 B, free 432.0 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 95 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:38 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:38 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:115
23/11/30 14:21:38 INFO DAGScheduler: Got job 85 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 116 (show at SparkTest.worksheet.sc:115)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 115)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 116 (MapPartitionsRDD[288] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 15.1 KiB, free 432.0 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 432.0 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 96 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 116 (MapPartitionsRDD[288] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 116.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 116.0 (TID 85) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 116.0 (TID 85)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 116.0 (TID 85). 4122 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 116.0 (TID 85) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 116.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 116 (show at SparkTest.worksheet.sc:115) finished in 0.006 s
23/11/30 14:21:38 INFO DAGScheduler: Job 85 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 116: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 85 finished: show at SparkTest.worksheet.sc:115, took 0.006215 s
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 3.711382 ms
23/11/30 14:21:38 INFO DAGScheduler: Registering RDD 290 (isEmpty at SparkTest.worksheet.sc:120) as input to shuffle 23
23/11/30 14:21:38 INFO DAGScheduler: Got map stage job 86 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ShuffleMapStage 117 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ShuffleMapStage 117 (MapPartitionsRDD[290] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 17.3 KiB, free 432.0 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 432.0 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on 10.25.86.80:43823 (size: 7.5 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 117 (MapPartitionsRDD[290] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 86) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 117.0 (TID 86)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 117.0 (TID 86). 1991 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 86) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ShuffleMapStage 117 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.011 s
23/11/30 14:21:38 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:38 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:38 INFO ShufflePartitionsUtil: For shuffle(23, 23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 5.399811 ms
23/11/30 14:21:38 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:38 INFO DAGScheduler: Got job 87 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 119 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 118)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 119 (MapPartitionsRDD[297] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 35.3 KiB, free 432.0 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 14.4 KiB, free 431.9 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on 10.25.86.80:43823 (size: 14.4 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 119 (MapPartitionsRDD[297] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 119.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 119.0 (TID 87) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 119.0 (TID 87)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 119.0 (TID 87). 4817 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 119.0 (TID 87) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 119.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 119 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.008 s
23/11/30 14:21:38 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 119: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 87 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.009978 s
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 1024.1 KiB, free 430.9 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 251.0 B, free 430.9 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on 10.25.86.80:43823 (size: 251.0 B, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 99 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:38 INFO ShufflePartitionsUtil: For shuffle(23), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 4.628476 ms
23/11/30 14:21:38 INFO SparkContext: Starting job: isEmpty at SparkTest.worksheet.sc:120
23/11/30 14:21:38 INFO DAGScheduler: Got job 88 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 121 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 120)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 121 (MapPartitionsRDD[300] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 13.3 KiB, free 430.9 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 430.9 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 121 (MapPartitionsRDD[300] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 88) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 121.0 (TID 88)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 121.0 (TID 88). 3219 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 88) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 121 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.005 s
23/11/30 14:21:38 INFO DAGScheduler: Job 88 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 121: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 88 finished: isEmpty at SparkTest.worksheet.sc:120, took 0.006143 s
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 4.131801 ms
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_98_piece0 on 10.25.86.80:43823 in memory (size: 14.4 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_86_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_89_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_95_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_91_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_90_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_84_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO DAGScheduler: Got job 89 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 122 (collect at Ast.scala:253)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_94_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 122 (MapPartitionsRDD[304] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_97_piece0 on 10.25.86.80:43823 in memory (size: 7.5 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_88_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 17.5 KiB, free 433.2 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_92_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 433.2 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 122 (MapPartitionsRDD[304] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 122.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_99_piece0 on 10.25.86.80:43823 in memory (size: 251.0 B, free: 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_100_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 122.0 (TID 89) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_87_piece0 on 10.25.86.80:43823 in memory (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 122.0 (TID 89)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_85_piece0 on 10.25.86.80:43823 in memory (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_96_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_93_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 122.0 (TID 89). 1826 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 122.0 (TID 89) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 122.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 122 (collect at Ast.scala:253) finished in 0.008 s
23/11/30 14:21:38 INFO DAGScheduler: Job 89 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 122: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 89 finished: collect at Ast.scala:253, took 0.009106 s
23/11/30 14:21:38 INFO DAGScheduler: Registering RDD 305 (collect at Ast.scala:253) as input to shuffle 24
23/11/30 14:21:38 INFO DAGScheduler: Got map stage job 90 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ShuffleMapStage 123 (collect at Ast.scala:253)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ShuffleMapStage 123 (MapPartitionsRDD[305] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 19.0 KiB, free 434.4 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 102 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 123 (MapPartitionsRDD[305] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 123.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 90) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 123.0 (TID 90)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 123.0 (TID 90). 1793 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 90) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ShuffleMapStage 123 (collect at Ast.scala:253) finished in 0.013 s
23/11/30 14:21:38 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:38 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:38 INFO ShufflePartitionsUtil: For shuffle(24), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 4.678321 ms
23/11/30 14:21:38 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:38 INFO DAGScheduler: Got job 91 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 125 (collect at Ast.scala:253)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 124)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 125 (MapPartitionsRDD[308] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 24.9 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 125 (MapPartitionsRDD[308] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 125.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 125.0 (TID 91) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 125.0 (TID 91)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 125.0 (TID 91). 4494 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 125.0 (TID 91) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 125.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 125 (collect at Ast.scala:253) finished in 0.009 s
23/11/30 14:21:38 INFO DAGScheduler: Job 91 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 125: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 91 finished: collect at Ast.scala:253, took 0.010610 s
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 4.114278 ms
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_102_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_101_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Removed broadcast_103_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:38 INFO DAGScheduler: Got job 92 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 126 (collect at Ast.scala:253)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[312] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 17.5 KiB, free 434.4 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.4 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[312] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 92) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 126.0 (TID 92)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 126.0 (TID 92). 1826 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 92) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 126 (collect at Ast.scala:253) finished in 0.018 s
23/11/30 14:21:38 INFO DAGScheduler: Job 92 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 92 finished: collect at Ast.scala:253, took 0.018910 s
23/11/30 14:21:38 INFO DAGScheduler: Registering RDD 313 (collect at Ast.scala:253) as input to shuffle 25
23/11/30 14:21:38 INFO DAGScheduler: Got map stage job 93 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ShuffleMapStage 127 (collect at Ast.scala:253)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ShuffleMapStage 127 (MapPartitionsRDD[313] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 19.0 KiB, free 434.4 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 105 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 127 (MapPartitionsRDD[313] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 93) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 127.0 (TID 93)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 127.0 (TID 93). 1793 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 93) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ShuffleMapStage 127 (collect at Ast.scala:253) finished in 0.011 s
23/11/30 14:21:38 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:38 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:38 INFO ShufflePartitionsUtil: For shuffle(25), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:38 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:38 INFO DAGScheduler: Got job 94 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 129 (collect at Ast.scala:253)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 128)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[316] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 24.9 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[316] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 94) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 129.0 (TID 94)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 129.0 (TID 94). 4494 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 94) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 129 (collect at Ast.scala:253) finished in 0.008 s
23/11/30 14:21:38 INFO DAGScheduler: Job 94 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 94 finished: collect at Ast.scala:253, took 0.009763 s
23/11/30 14:21:38 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:38 INFO DAGScheduler: Got job 95 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 130 (collect at Ast.scala:253)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 130 (MapPartitionsRDD[320] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 17.5 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 130 (MapPartitionsRDD[320] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 95) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 130.0 (TID 95)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 130.0 (TID 95). 1826 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 95) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 130 (collect at Ast.scala:253) finished in 0.010 s
23/11/30 14:21:38 INFO DAGScheduler: Job 95 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 130: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 95 finished: collect at Ast.scala:253, took 0.011156 s
23/11/30 14:21:38 INFO DAGScheduler: Registering RDD 321 (collect at Ast.scala:253) as input to shuffle 26
23/11/30 14:21:38 INFO DAGScheduler: Got map stage job 96 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ShuffleMapStage 131 (collect at Ast.scala:253)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ShuffleMapStage 131 (MapPartitionsRDD[321] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 19.0 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 108 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 131 (MapPartitionsRDD[321] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 131.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 131.0 (TID 96) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 131.0 (TID 96)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 131.0 (TID 96). 1793 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 131.0 (TID 96) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 131.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ShuffleMapStage 131 (collect at Ast.scala:253) finished in 0.010 s
23/11/30 14:21:38 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:38 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:38 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:38 INFO ShufflePartitionsUtil: For shuffle(26), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:38 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:38 INFO DAGScheduler: Got job 97 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 133 (collect at Ast.scala:253)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 132)
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[324] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 24.9 KiB, free 434.2 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.2 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[324] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 97) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 133.0 (TID 97)
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 133.0 (TID 97). 4494 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 97) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 133 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:21:38 INFO DAGScheduler: Job 97 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 97 finished: collect at Ast.scala:253, took 0.008268 s
23/11/30 14:21:38 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:150
23/11/30 14:21:38 INFO DAGScheduler: Got job 98 (show at SparkTest.worksheet.sc:150) with 1 output partitions
23/11/30 14:21:38 INFO DAGScheduler: Final stage: ResultStage 134 (show at SparkTest.worksheet.sc:150)
23/11/30 14:21:38 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:38 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:38 INFO DAGScheduler: Submitting ResultStage 134 (MapPartitionsRDD[326] at show at SparkTest.worksheet.sc:150), which has no missing parents
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 15.7 KiB, free 434.2 MiB)
23/11/30 14:21:38 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.2 MiB)
23/11/30 14:21:38 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.3 MiB)
23/11/30 14:21:38 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 134 (MapPartitionsRDD[326] at show at SparkTest.worksheet.sc:150) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:38 INFO TaskSchedulerImpl: Adding task set 134.0 with 1 tasks resource profile 0
23/11/30 14:21:38 INFO TaskSetManager: Starting task 0.0 in stage 134.0 (TID 98) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:38 INFO Executor: Running task 0.0 in stage 134.0 (TID 98)
23/11/30 14:21:38 INFO Executor: Finished task 0.0 in stage 134.0 (TID 98). 1640 bytes result sent to driver
23/11/30 14:21:38 INFO TaskSetManager: Finished task 0.0 in stage 134.0 (TID 98) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:38 INFO TaskSchedulerImpl: Removed TaskSet 134.0, whose tasks have all completed, from pool 
23/11/30 14:21:38 INFO DAGScheduler: ResultStage 134 (show at SparkTest.worksheet.sc:150) finished in 0.006 s
23/11/30 14:21:38 INFO DAGScheduler: Job 98 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 134: Stage finished
23/11/30 14:21:38 INFO DAGScheduler: Job 98 finished: show at SparkTest.worksheet.sc:150, took 0.007095 s
23/11/30 14:21:38 INFO CodeGenerator: Code generated in 4.724034 ms
2023.11.30 14:21:38 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 2.08s[0m
23/11/30 14:21:39 INFO BlockManagerInfo: Removed broadcast_108_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:39 INFO BlockManagerInfo: Removed broadcast_104_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:39 INFO BlockManagerInfo: Removed broadcast_105_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:39 INFO BlockManagerInfo: Removed broadcast_110_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:39 INFO BlockManagerInfo: Removed broadcast_107_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:39 INFO BlockManagerInfo: Removed broadcast_109_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:39 INFO BlockManagerInfo: Removed broadcast_106_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:40 INFO CodeGenerator: Code generated in 4.020943 ms
23/11/30 14:21:40 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:62
23/11/30 14:21:40 INFO DAGScheduler: Got job 99 (show at SparkTest.worksheet.sc:62) with 1 output partitions
23/11/30 14:21:40 INFO DAGScheduler: Final stage: ResultStage 135 (show at SparkTest.worksheet.sc:62)
23/11/30 14:21:40 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:40 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:40 INFO DAGScheduler: Submitting ResultStage 135 (MapPartitionsRDD[336] at show at SparkTest.worksheet.sc:62), which has no missing parents
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/11/30 14:21:40 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:40 INFO SparkContext: Created broadcast 111 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 135 (MapPartitionsRDD[336] at show at SparkTest.worksheet.sc:62) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:40 INFO TaskSchedulerImpl: Adding task set 135.0 with 1 tasks resource profile 0
23/11/30 14:21:40 INFO TaskSetManager: Starting task 0.0 in stage 135.0 (TID 99) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:40 INFO Executor: Running task 0.0 in stage 135.0 (TID 99)
23/11/30 14:21:40 INFO Executor: Finished task 0.0 in stage 135.0 (TID 99). 1634 bytes result sent to driver
23/11/30 14:21:40 INFO TaskSetManager: Finished task 0.0 in stage 135.0 (TID 99) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:40 INFO TaskSchedulerImpl: Removed TaskSet 135.0, whose tasks have all completed, from pool 
23/11/30 14:21:40 INFO DAGScheduler: ResultStage 135 (show at SparkTest.worksheet.sc:62) finished in 0.028 s
23/11/30 14:21:40 INFO DAGScheduler: Job 99 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 135: Stage finished
23/11/30 14:21:40 INFO DAGScheduler: Job 99 finished: show at SparkTest.worksheet.sc:62, took 0.029347 s
23/11/30 14:21:40 INFO CodeGenerator: Code generated in 5.407221 ms
23/11/30 14:21:40 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:40 INFO CodeGenerator: Code generated in 3.299714 ms
23/11/30 14:21:40 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:72
23/11/30 14:21:40 INFO DAGScheduler: Got job 100 (parquet at SparkTest.worksheet.sc:72) with 1 output partitions
23/11/30 14:21:40 INFO DAGScheduler: Final stage: ResultStage 136 (parquet at SparkTest.worksheet.sc:72)
23/11/30 14:21:40 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:40 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:40 INFO DAGScheduler: Submitting ResultStage 136 (MapPartitionsRDD[338] at parquet at SparkTest.worksheet.sc:72), which has no missing parents
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 215.6 KiB, free 434.2 MiB)
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 76.7 KiB, free 434.1 MiB)
23/11/30 14:21:40 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on 10.25.86.80:43823 (size: 76.7 KiB, free: 434.3 MiB)
23/11/30 14:21:40 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 136 (MapPartitionsRDD[338] at parquet at SparkTest.worksheet.sc:72) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:40 INFO TaskSchedulerImpl: Adding task set 136.0 with 1 tasks resource profile 0
23/11/30 14:21:40 INFO TaskSetManager: Starting task 0.0 in stage 136.0 (TID 100) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:40 INFO Executor: Running task 0.0 in stage 136.0 (TID 100)
23/11/30 14:21:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:40 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:40 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:40 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:40 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:40 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:21:40 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:21:40 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/30 14:21:40 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "index",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 index;
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/30 14:21:40 INFO FileOutputCommitter: Saved output of task 'attempt_2023113014214019454558558979637_0136_m_000000_100' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_2023113014214019454558558979637_0136_m_000000
23/11/30 14:21:40 INFO SparkHadoopMapRedUtil: attempt_2023113014214019454558558979637_0136_m_000000_100: Committed. Elapsed time: 0 ms.
23/11/30 14:21:40 INFO Executor: Finished task 0.0 in stage 136.0 (TID 100). 2699 bytes result sent to driver
23/11/30 14:21:40 INFO TaskSetManager: Finished task 0.0 in stage 136.0 (TID 100) in 30 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:40 INFO TaskSchedulerImpl: Removed TaskSet 136.0, whose tasks have all completed, from pool 
23/11/30 14:21:40 INFO DAGScheduler: ResultStage 136 (parquet at SparkTest.worksheet.sc:72) finished in 0.045 s
23/11/30 14:21:40 INFO DAGScheduler: Job 100 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 136: Stage finished
23/11/30 14:21:40 INFO DAGScheduler: Job 100 finished: parquet at SparkTest.worksheet.sc:72, took 0.046533 s
23/11/30 14:21:40 INFO FileFormatWriter: Start to commit write Job 959030d6-cb8c-4039-9c13-8c51135e119c.
23/11/30 14:21:40 INFO FileFormatWriter: Write Job 959030d6-cb8c-4039-9c13-8c51135e119c committed. Elapsed time: 8 ms.
23/11/30 14:21:40 INFO FileFormatWriter: Finished processing stats for write job 959030d6-cb8c-4039-9c13-8c51135e119c.
23/11/30 14:21:40 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
23/11/30 14:21:40 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:76
23/11/30 14:21:40 INFO DAGScheduler: Got job 101 (parquet at SparkTest.worksheet.sc:76) with 1 output partitions
23/11/30 14:21:40 INFO DAGScheduler: Final stage: ResultStage 137 (parquet at SparkTest.worksheet.sc:76)
23/11/30 14:21:40 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:40 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:40 INFO DAGScheduler: Submitting ResultStage 137 (MapPartitionsRDD[340] at parquet at SparkTest.worksheet.sc:76), which has no missing parents
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/11/30 14:21:40 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on 10.25.86.80:43823 (size: 36.9 KiB, free: 434.3 MiB)
23/11/30 14:21:40 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 137 (MapPartitionsRDD[340] at parquet at SparkTest.worksheet.sc:76) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:40 INFO TaskSchedulerImpl: Adding task set 137.0 with 1 tasks resource profile 0
23/11/30 14:21:40 INFO TaskSetManager: Starting task 0.0 in stage 137.0 (TID 101) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/11/30 14:21:40 INFO Executor: Running task 0.0 in stage 137.0 (TID 101)
23/11/30 14:21:40 INFO Executor: Finished task 0.0 in stage 137.0 (TID 101). 2042 bytes result sent to driver
23/11/30 14:21:40 INFO TaskSetManager: Finished task 0.0 in stage 137.0 (TID 101) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:40 INFO TaskSchedulerImpl: Removed TaskSet 137.0, whose tasks have all completed, from pool 
23/11/30 14:21:40 INFO DAGScheduler: ResultStage 137 (parquet at SparkTest.worksheet.sc:76) finished in 0.016 s
23/11/30 14:21:40 INFO DAGScheduler: Job 101 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 137: Stage finished
23/11/30 14:21:40 INFO DAGScheduler: Job 101 finished: parquet at SparkTest.worksheet.sc:76, took 0.018290 s
23/11/30 14:21:40 INFO FileSourceStrategy: Pushed Filters: 
23/11/30 14:21:40 INFO FileSourceStrategy: Post-Scan Filters: 
23/11/30 14:21:40 INFO CodeGenerator: Code generated in 6.291174 ms
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 200.8 KiB, free 433.8 MiB)
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
23/11/30 14:21:40 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on 10.25.86.80:43823 (size: 34.9 KiB, free: 434.2 MiB)
23/11/30 14:21:40 INFO SparkContext: Created broadcast 114 from show at SparkTest.worksheet.sc:81
23/11/30 14:21:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/11/30 14:21:40 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:81
23/11/30 14:21:40 INFO DAGScheduler: Got job 102 (show at SparkTest.worksheet.sc:81) with 1 output partitions
23/11/30 14:21:40 INFO DAGScheduler: Final stage: ResultStage 138 (show at SparkTest.worksheet.sc:81)
23/11/30 14:21:40 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:40 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:40 INFO DAGScheduler: Submitting ResultStage 138 (MapPartitionsRDD[344] at show at SparkTest.worksheet.sc:81), which has no missing parents
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 16.6 KiB, free 433.7 MiB)
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 433.7 MiB)
23/11/30 14:21:40 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on 10.25.86.80:43823 (size: 6.8 KiB, free: 434.2 MiB)
23/11/30 14:21:40 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 138 (MapPartitionsRDD[344] at show at SparkTest.worksheet.sc:81) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:40 INFO TaskSchedulerImpl: Adding task set 138.0 with 1 tasks resource profile 0
23/11/30 14:21:40 INFO TaskSetManager: Starting task 0.0 in stage 138.0 (TID 102) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/11/30 14:21:40 INFO Executor: Running task 0.0 in stage 138.0 (TID 102)
23/11/30 14:21:40 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-0de9c9e6-a9bf-4654-9d9a-40697dd0b388-c000.snappy.parquet, range: 0-1246, partition values: [empty row]
23/11/30 14:21:40 INFO Executor: Finished task 0.0 in stage 138.0 (TID 102). 1928 bytes result sent to driver
23/11/30 14:21:40 INFO TaskSetManager: Finished task 0.0 in stage 138.0 (TID 102) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:40 INFO TaskSchedulerImpl: Removed TaskSet 138.0, whose tasks have all completed, from pool 
23/11/30 14:21:40 INFO DAGScheduler: ResultStage 138 (show at SparkTest.worksheet.sc:81) finished in 0.010 s
23/11/30 14:21:40 INFO DAGScheduler: Job 102 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 138: Stage finished
23/11/30 14:21:40 INFO DAGScheduler: Job 102 finished: show at SparkTest.worksheet.sc:81, took 0.010948 s
23/11/30 14:21:40 INFO CodeGenerator: Code generated in 4.340346 ms
23/11/30 14:21:40 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:94
23/11/30 14:21:40 INFO DAGScheduler: Got job 103 (show at SparkTest.worksheet.sc:94) with 1 output partitions
23/11/30 14:21:40 INFO DAGScheduler: Final stage: ResultStage 139 (show at SparkTest.worksheet.sc:94)
23/11/30 14:21:40 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:40 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:40 INFO DAGScheduler: Submitting ResultStage 139 (MapPartitionsRDD[346] at show at SparkTest.worksheet.sc:94), which has no missing parents
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 15.7 KiB, free 433.7 MiB)
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 433.7 MiB)
23/11/30 14:21:40 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.2 MiB)
23/11/30 14:21:40 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 139 (MapPartitionsRDD[346] at show at SparkTest.worksheet.sc:94) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:40 INFO TaskSchedulerImpl: Adding task set 139.0 with 1 tasks resource profile 0
23/11/30 14:21:40 INFO TaskSetManager: Starting task 0.0 in stage 139.0 (TID 103) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:40 INFO Executor: Running task 0.0 in stage 139.0 (TID 103)
23/11/30 14:21:40 INFO Executor: Finished task 0.0 in stage 139.0 (TID 103). 1640 bytes result sent to driver
23/11/30 14:21:40 INFO TaskSetManager: Finished task 0.0 in stage 139.0 (TID 103) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:40 INFO TaskSchedulerImpl: Removed TaskSet 139.0, whose tasks have all completed, from pool 
23/11/30 14:21:40 INFO DAGScheduler: ResultStage 139 (show at SparkTest.worksheet.sc:94) finished in 0.007 s
23/11/30 14:21:40 INFO DAGScheduler: Job 103 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 139: Stage finished
23/11/30 14:21:40 INFO DAGScheduler: Job 103 finished: show at SparkTest.worksheet.sc:94, took 0.007406 s
23/11/30 14:21:40 INFO CodeGenerator: Code generated in 3.030475 ms
23/11/30 14:21:40 INFO CodeGenerator: Code generated in 3.728526 ms
23/11/30 14:21:40 INFO DAGScheduler: Registering RDD 348 (collect at SparkTest.worksheet.sc:102) as input to shuffle 27
23/11/30 14:21:40 INFO DAGScheduler: Got map stage job 104 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:21:40 INFO DAGScheduler: Final stage: ShuffleMapStage 140 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:21:40 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:40 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:40 INFO DAGScheduler: Submitting ShuffleMapStage 140 (MapPartitionsRDD[348] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 19.2 KiB, free 433.7 MiB)
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 433.7 MiB)
23/11/30 14:21:40 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.2 MiB)
23/11/30 14:21:40 INFO SparkContext: Created broadcast 117 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 140 (MapPartitionsRDD[348] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:40 INFO TaskSchedulerImpl: Adding task set 140.0 with 1 tasks resource profile 0
23/11/30 14:21:40 INFO TaskSetManager: Starting task 0.0 in stage 140.0 (TID 104) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:40 INFO Executor: Running task 0.0 in stage 140.0 (TID 104)
23/11/30 14:21:40 INFO Executor: Finished task 0.0 in stage 140.0 (TID 104). 1930 bytes result sent to driver
23/11/30 14:21:40 INFO TaskSetManager: Finished task 0.0 in stage 140.0 (TID 104) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:40 INFO TaskSchedulerImpl: Removed TaskSet 140.0, whose tasks have all completed, from pool 
23/11/30 14:21:40 INFO DAGScheduler: ShuffleMapStage 140 (collect at SparkTest.worksheet.sc:102) finished in 0.006 s
23/11/30 14:21:40 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:40 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:40 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:40 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:40 INFO CodeGenerator: Code generated in 3.664873 ms
23/11/30 14:21:40 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:102
23/11/30 14:21:40 INFO DAGScheduler: Got job 105 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:21:40 INFO DAGScheduler: Final stage: ResultStage 142 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:21:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 141)
23/11/30 14:21:40 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:40 INFO DAGScheduler: Submitting ResultStage 142 (MapPartitionsRDD[351] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 14.3 KiB, free 433.6 MiB)
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 433.6 MiB)
23/11/30 14:21:40 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on 10.25.86.80:43823 (size: 6.6 KiB, free: 434.2 MiB)
23/11/30 14:21:40 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 142 (MapPartitionsRDD[351] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:40 INFO TaskSchedulerImpl: Adding task set 142.0 with 1 tasks resource profile 0
23/11/30 14:21:40 INFO TaskSetManager: Starting task 0.0 in stage 142.0 (TID 105) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:40 INFO Executor: Running task 0.0 in stage 142.0 (TID 105)
23/11/30 14:21:40 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:40 INFO Executor: Finished task 0.0 in stage 142.0 (TID 105). 3998 bytes result sent to driver
23/11/30 14:21:40 INFO TaskSetManager: Finished task 0.0 in stage 142.0 (TID 105) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:40 INFO TaskSchedulerImpl: Removed TaskSet 142.0, whose tasks have all completed, from pool 
23/11/30 14:21:40 INFO DAGScheduler: ResultStage 142 (collect at SparkTest.worksheet.sc:102) finished in 0.005 s
23/11/30 14:21:40 INFO DAGScheduler: Job 105 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 142: Stage finished
23/11/30 14:21:40 INFO DAGScheduler: Job 105 finished: collect at SparkTest.worksheet.sc:102, took 0.005653 s
23/11/30 14:21:40 INFO CodeGenerator: Code generated in 2.689621 ms
23/11/30 14:21:40 INFO SparkContext: Starting job: show at Ast.scala:95
23/11/30 14:21:40 INFO DAGScheduler: Got job 106 (show at Ast.scala:95) with 1 output partitions
23/11/30 14:21:40 INFO DAGScheduler: Final stage: ResultStage 143 (show at Ast.scala:95)
23/11/30 14:21:40 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:40 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:40 INFO DAGScheduler: Submitting ResultStage 143 (MapPartitionsRDD[353] at show at Ast.scala:95), which has no missing parents
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 15.5 KiB, free 433.6 MiB)
23/11/30 14:21:40 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 433.6 MiB)
23/11/30 14:21:40 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.2 MiB)
23/11/30 14:21:40 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 143 (MapPartitionsRDD[353] at show at Ast.scala:95) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:40 INFO TaskSchedulerImpl: Adding task set 143.0 with 1 tasks resource profile 0
23/11/30 14:21:40 INFO TaskSetManager: Starting task 0.0 in stage 143.0 (TID 106) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:40 INFO Executor: Running task 0.0 in stage 143.0 (TID 106)
23/11/30 14:21:40 INFO Executor: Finished task 0.0 in stage 143.0 (TID 106). 1634 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 143.0 (TID 106) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 143.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 143 (show at Ast.scala:95) finished in 0.008 s
23/11/30 14:21:41 INFO DAGScheduler: Job 106 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 143: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 106 finished: show at Ast.scala:95, took 0.008734 s
23/11/30 14:21:41 INFO SparkContext: Starting job: show at Ast.scala:96
23/11/30 14:21:41 INFO DAGScheduler: Got job 107 (show at Ast.scala:96) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 144 (show at Ast.scala:96)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 144 (MapPartitionsRDD[355] at show at Ast.scala:96), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 15.5 KiB, free 433.6 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 433.6 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.2 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 120 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 144 (MapPartitionsRDD[355] at show at Ast.scala:96) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 144.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 144.0 (TID 107) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 144.0 (TID 107)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 144.0 (TID 107). 1634 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 144.0 (TID 107) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 144.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 144 (show at Ast.scala:96) finished in 0.011 s
23/11/30 14:21:41 INFO DAGScheduler: Job 107 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 144: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 107 finished: show at Ast.scala:96, took 0.012217 s
23/11/30 14:21:41 INFO DAGScheduler: Registering RDD 357 (show at Ast.scala:108) as input to shuffle 28
23/11/30 14:21:41 INFO DAGScheduler: Got map stage job 108 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ShuffleMapStage 145 (show at Ast.scala:108)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ShuffleMapStage 145 (MapPartitionsRDD[357] at show at Ast.scala:108), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 17.7 KiB, free 433.6 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.6 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.2 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 145 (MapPartitionsRDD[357] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 145.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 145.0 (TID 108) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 145.0 (TID 108)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 145.0 (TID 108). 1991 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 145.0 (TID 108) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 145.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ShuffleMapStage 145 (show at Ast.scala:108) finished in 0.010 s
23/11/30 14:21:41 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:41 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:41 INFO ShufflePartitionsUtil: For shuffle(28, 28), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 8.107449 ms
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 4.272855 ms
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 4.253419 ms
23/11/30 14:21:41 INFO SparkContext: Starting job: show at Ast.scala:108
23/11/30 14:21:41 INFO DAGScheduler: Got job 109 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 147 (show at Ast.scala:108)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 146)
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 147 (MapPartitionsRDD[364] at show at Ast.scala:108), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 40.1 KiB, free 433.5 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 433.5 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on 10.25.86.80:43823 (size: 16.3 KiB, free: 434.2 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 147 (MapPartitionsRDD[364] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 147.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 147.0 (TID 109) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 147.0 (TID 109)
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 147.0 (TID 109). 4898 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 147.0 (TID 109) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 147.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 147 (show at Ast.scala:108) finished in 0.011 s
23/11/30 14:21:41 INFO DAGScheduler: Job 109 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 147: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 109 finished: show at Ast.scala:108, took 0.011833 s
23/11/30 14:21:41 INFO DAGScheduler: Registering RDD 366 (show at Ast.scala:112) as input to shuffle 29
23/11/30 14:21:41 INFO DAGScheduler: Got map stage job 110 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ShuffleMapStage 148 (show at Ast.scala:112)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ShuffleMapStage 148 (MapPartitionsRDD[366] at show at Ast.scala:112), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 17.7 KiB, free 433.5 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.5 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.2 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 123 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 148 (MapPartitionsRDD[366] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 148.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 148.0 (TID 110) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 148.0 (TID 110)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 148.0 (TID 110). 1991 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 148.0 (TID 110) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 148.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ShuffleMapStage 148 (show at Ast.scala:112) finished in 0.011 s
23/11/30 14:21:41 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:41 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:41 INFO ShufflePartitionsUtil: For shuffle(29, 29), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_113_piece0 on 10.25.86.80:43823 in memory (size: 36.9 KiB, free: 434.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_117_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_123_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_122_piece0 on 10.25.86.80:43823 in memory (size: 16.3 KiB, free: 434.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_112_piece0 on 10.25.86.80:43823 in memory (size: 76.7 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_115_piece0 on 10.25.86.80:43823 in memory (size: 6.8 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_116_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_118_piece0 on 10.25.86.80:43823 in memory (size: 6.6 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_114_piece0 on 10.25.86.80:43823 in memory (size: 34.9 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_119_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_120_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_121_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_111_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO SparkContext: Starting job: show at Ast.scala:112
23/11/30 14:21:41 INFO DAGScheduler: Got job 111 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 150 (show at Ast.scala:112)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 149)
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 150 (MapPartitionsRDD[373] at show at Ast.scala:112), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 40.1 KiB, free 434.4 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on 10.25.86.80:43823 (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 150 (MapPartitionsRDD[373] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 150.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 150.0 (TID 111) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 150.0 (TID 111)
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 150.0 (TID 111). 4898 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 150.0 (TID 111) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 150.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 150 (show at Ast.scala:112) finished in 0.012 s
23/11/30 14:21:41 INFO DAGScheduler: Job 111 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 150: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 111 finished: show at Ast.scala:112, took 0.013222 s
23/11/30 14:21:41 INFO SparkContext: Starting job: show at Ast.scala:113
23/11/30 14:21:41 INFO DAGScheduler: Got job 112 (show at Ast.scala:113) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 151 (show at Ast.scala:113)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 151 (MapPartitionsRDD[375] at show at Ast.scala:113), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 15.5 KiB, free 434.3 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 151 (MapPartitionsRDD[375] at show at Ast.scala:113) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 151.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 151.0 (TID 112) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 151.0 (TID 112)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 151.0 (TID 112). 1634 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 151.0 (TID 112) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 151.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 151 (show at Ast.scala:113) finished in 0.006 s
23/11/30 14:21:41 INFO DAGScheduler: Job 112 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 151: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 112 finished: show at Ast.scala:113, took 0.007127 s
23/11/30 14:21:41 INFO DAGScheduler: Registering RDD 377 (show at Ast.scala:126) as input to shuffle 30
23/11/30 14:21:41 INFO DAGScheduler: Got map stage job 113 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ShuffleMapStage 152 (show at Ast.scala:126)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ShuffleMapStage 152 (MapPartitionsRDD[377] at show at Ast.scala:126), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 17.7 KiB, free 434.3 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 126 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 152 (MapPartitionsRDD[377] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 152.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 152.0 (TID 113) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 152.0 (TID 113)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 152.0 (TID 113). 1991 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 152.0 (TID 113) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 152.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ShuffleMapStage 152 (show at Ast.scala:126) finished in 0.009 s
23/11/30 14:21:41 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:41 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:41 INFO ShufflePartitionsUtil: For shuffle(30, 30), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_124_piece0 on 10.25.86.80:43823 in memory (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_125_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_126_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 17.325324 ms
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 4.673289 ms
23/11/30 14:21:41 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:41 INFO DAGScheduler: Got job 114 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 154 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 153)
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 154 (MapPartitionsRDD[384] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 38.7 KiB, free 434.4 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 154 (MapPartitionsRDD[384] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 154.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 154.0 (TID 114) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 154.0 (TID 114)
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 154.0 (TID 114). 4897 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 154.0 (TID 114) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 154.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 154 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.020 s
23/11/30 14:21:41 INFO DAGScheduler: Job 114 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 154: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 114 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.021325 s
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 3.470144 ms
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 128 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:41 INFO ShufflePartitionsUtil: For shuffle(30), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 5.75964 ms
23/11/30 14:21:41 INFO SparkContext: Starting job: show at Ast.scala:126
23/11/30 14:21:41 INFO DAGScheduler: Got job 115 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 156 (show at Ast.scala:126)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 155)
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 156 (MapPartitionsRDD[387] at show at Ast.scala:126), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 15.1 KiB, free 433.3 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 156 (MapPartitionsRDD[387] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 156.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 156.0 (TID 115) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 156.0 (TID 115)
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 156.0 (TID 115). 4165 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 156.0 (TID 115) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 156.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 156 (show at Ast.scala:126) finished in 0.007 s
23/11/30 14:21:41 INFO DAGScheduler: Job 115 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 156: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 115 finished: show at Ast.scala:126, took 0.007624 s
23/11/30 14:21:41 INFO DAGScheduler: Registering RDD 389 (show at SparkTest.worksheet.sc:115) as input to shuffle 31
23/11/30 14:21:41 INFO DAGScheduler: Got map stage job 116 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ShuffleMapStage 157 (show at SparkTest.worksheet.sc:115)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ShuffleMapStage 157 (MapPartitionsRDD[389] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_130 stored as values in memory (estimated size 17.7 KiB, free 433.3 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_130_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_130_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 130 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 157 (MapPartitionsRDD[389] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 157.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 157.0 (TID 116) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 157.0 (TID 116)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 157.0 (TID 116). 1991 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 157.0 (TID 116) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 157.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ShuffleMapStage 157 (show at SparkTest.worksheet.sc:115) finished in 0.009 s
23/11/30 14:21:41 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:41 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:41 INFO ShufflePartitionsUtil: For shuffle(31, 31), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:41 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:41 INFO DAGScheduler: Got job 117 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 159 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 158)
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 159 (MapPartitionsRDD[396] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_131 stored as values in memory (estimated size 38.7 KiB, free 433.3 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_131_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 433.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_131_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 131 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 159 (MapPartitionsRDD[396] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 159.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 159.0 (TID 117) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 159.0 (TID 117)
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 159.0 (TID 117). 4897 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 159.0 (TID 117) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 159.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 159 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.011 s
23/11/30 14:21:41 INFO DAGScheduler: Job 117 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 159: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 117 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.012507 s
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_132 stored as values in memory (estimated size 1024.1 KiB, free 432.2 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_132_piece0 stored as bytes in memory (estimated size 337.0 B, free 432.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_132_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 132 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:41 INFO ShufflePartitionsUtil: For shuffle(31), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:41 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:115
23/11/30 14:21:41 INFO DAGScheduler: Got job 118 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 161 (show at SparkTest.worksheet.sc:115)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 160)
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 161 (MapPartitionsRDD[399] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_133 stored as values in memory (estimated size 15.1 KiB, free 432.2 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_133_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 432.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_133_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 133 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 161 (MapPartitionsRDD[399] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 161.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 161.0 (TID 118) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 161.0 (TID 118)
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 161.0 (TID 118). 4165 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 161.0 (TID 118) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 161.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 161 (show at SparkTest.worksheet.sc:115) finished in 0.008 s
23/11/30 14:21:41 INFO DAGScheduler: Job 118 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 161: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 118 finished: show at SparkTest.worksheet.sc:115, took 0.009120 s
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 4.8495 ms
23/11/30 14:21:41 INFO DAGScheduler: Registering RDD 401 (isEmpty at SparkTest.worksheet.sc:120) as input to shuffle 32
23/11/30 14:21:41 INFO DAGScheduler: Got map stage job 119 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ShuffleMapStage 162 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ShuffleMapStage 162 (MapPartitionsRDD[401] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_134 stored as values in memory (estimated size 17.3 KiB, free 432.2 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_134_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 432.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_134_piece0 in memory on 10.25.86.80:43823 (size: 7.5 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 134 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 162 (MapPartitionsRDD[401] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 162.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 162.0 (TID 119) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 162.0 (TID 119)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 162.0 (TID 119). 1991 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 162.0 (TID 119) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 162.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ShuffleMapStage 162 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.009 s
23/11/30 14:21:41 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:41 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:41 INFO ShufflePartitionsUtil: For shuffle(32, 32), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 5.241379 ms
23/11/30 14:21:41 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:41 INFO DAGScheduler: Got job 120 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 164 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 163)
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 164 (MapPartitionsRDD[408] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_135 stored as values in memory (estimated size 35.3 KiB, free 432.2 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_135_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 432.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_135_piece0 in memory on 10.25.86.80:43823 (size: 14.5 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 135 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 164 (MapPartitionsRDD[408] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 164.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 164.0 (TID 120) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 164.0 (TID 120)
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 164.0 (TID 120). 4817 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 164.0 (TID 120) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 164.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 164 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.010 s
23/11/30 14:21:41 INFO DAGScheduler: Job 120 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 164: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 120 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.011211 s
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_136 stored as values in memory (estimated size 1024.1 KiB, free 431.2 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_136_piece0 stored as bytes in memory (estimated size 251.0 B, free 431.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_136_piece0 in memory on 10.25.86.80:43823 (size: 251.0 B, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 136 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:41 INFO ShufflePartitionsUtil: For shuffle(32), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 3.587758 ms
23/11/30 14:21:41 INFO SparkContext: Starting job: isEmpty at SparkTest.worksheet.sc:120
23/11/30 14:21:41 INFO DAGScheduler: Got job 121 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 166 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 165)
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 166 (MapPartitionsRDD[411] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_137 stored as values in memory (estimated size 13.3 KiB, free 431.1 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_137_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 431.1 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_137_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 137 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 166 (MapPartitionsRDD[411] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 166.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 166.0 (TID 121) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 166.0 (TID 121)
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 166.0 (TID 121). 3219 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 166.0 (TID 121) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 166.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 166 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.004 s
23/11/30 14:21:41 INFO DAGScheduler: Job 121 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 166: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 121 finished: isEmpty at SparkTest.worksheet.sc:120, took 0.005712 s
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 3.239848 ms
23/11/30 14:21:41 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:41 INFO DAGScheduler: Got job 122 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 167 (collect at Ast.scala:253)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 167 (MapPartitionsRDD[415] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_138 stored as values in memory (estimated size 17.5 KiB, free 431.1 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_138_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 431.1 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_138_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 138 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 167 (MapPartitionsRDD[415] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 167.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 167.0 (TID 122) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 167.0 (TID 122)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 167.0 (TID 122). 1826 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 167.0 (TID 122) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 167.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 167 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:21:41 INFO DAGScheduler: Job 122 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 167: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 122 finished: collect at Ast.scala:253, took 0.007225 s
23/11/30 14:21:41 INFO DAGScheduler: Registering RDD 416 (collect at Ast.scala:253) as input to shuffle 33
23/11/30 14:21:41 INFO DAGScheduler: Got map stage job 123 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ShuffleMapStage 168 (collect at Ast.scala:253)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ShuffleMapStage 168 (MapPartitionsRDD[416] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_139 stored as values in memory (estimated size 19.0 KiB, free 431.1 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_139_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 431.1 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_139_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 139 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 168 (MapPartitionsRDD[416] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 168.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 168.0 (TID 123) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 168.0 (TID 123)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 168.0 (TID 123). 1793 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 168.0 (TID 123) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 168.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ShuffleMapStage 168 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:21:41 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:41 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:41 INFO ShufflePartitionsUtil: For shuffle(33), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 4.461274 ms
23/11/30 14:21:41 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:41 INFO DAGScheduler: Got job 124 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 170 (collect at Ast.scala:253)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 169)
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 170 (MapPartitionsRDD[419] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_140 stored as values in memory (estimated size 24.9 KiB, free 431.1 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_140_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 431.0 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_140_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 140 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 170 (MapPartitionsRDD[419] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 170.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 170.0 (TID 124) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 170.0 (TID 124)
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 170.0 (TID 124). 4494 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 170.0 (TID 124) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 170.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 170 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:21:41 INFO DAGScheduler: Job 124 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 170: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 124 finished: collect at Ast.scala:253, took 0.008430 s
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 5.112255 ms
23/11/30 14:21:41 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:41 INFO DAGScheduler: Got job 125 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 171 (collect at Ast.scala:253)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 171 (MapPartitionsRDD[423] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_141 stored as values in memory (estimated size 17.5 KiB, free 431.0 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_141_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 431.0 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_141_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 141 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 171 (MapPartitionsRDD[423] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 171.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 171.0 (TID 125) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 171.0 (TID 125)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 171.0 (TID 125). 1826 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 171.0 (TID 125) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 171.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 171 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:21:41 INFO DAGScheduler: Job 125 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 171: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 125 finished: collect at Ast.scala:253, took 0.007029 s
23/11/30 14:21:41 INFO DAGScheduler: Registering RDD 424 (collect at Ast.scala:253) as input to shuffle 34
23/11/30 14:21:41 INFO DAGScheduler: Got map stage job 126 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ShuffleMapStage 172 (collect at Ast.scala:253)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ShuffleMapStage 172 (MapPartitionsRDD[424] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_142 stored as values in memory (estimated size 19.0 KiB, free 431.0 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_142_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 431.0 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_142_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 142 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 172 (MapPartitionsRDD[424] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 172.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 172.0 (TID 126) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 172.0 (TID 126)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 172.0 (TID 126). 1793 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 172.0 (TID 126) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 172.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ShuffleMapStage 172 (collect at Ast.scala:253) finished in 0.008 s
23/11/30 14:21:41 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:41 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:41 INFO ShufflePartitionsUtil: For shuffle(34), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:41 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:41 INFO DAGScheduler: Got job 127 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 174 (collect at Ast.scala:253)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 173)
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 174 (MapPartitionsRDD[427] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_143 stored as values in memory (estimated size 24.9 KiB, free 431.0 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_143_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 431.0 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_143_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 143 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 174 (MapPartitionsRDD[427] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 174.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 174.0 (TID 127) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 174.0 (TID 127)
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 174.0 (TID 127). 4494 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 174.0 (TID 127) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 174.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 174 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:21:41 INFO DAGScheduler: Job 127 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 174: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 127 finished: collect at Ast.scala:253, took 0.008686 s
23/11/30 14:21:41 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:41 INFO DAGScheduler: Got job 128 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 175 (collect at Ast.scala:253)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 175 (MapPartitionsRDD[431] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_144 stored as values in memory (estimated size 17.5 KiB, free 430.9 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_144_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 430.9 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_144_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 144 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 175 (MapPartitionsRDD[431] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 175.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 175.0 (TID 128) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 175.0 (TID 128)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 175.0 (TID 128). 1826 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 175.0 (TID 128) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 175.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 175 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:21:41 INFO DAGScheduler: Job 128 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 175: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 128 finished: collect at Ast.scala:253, took 0.006277 s
23/11/30 14:21:41 INFO DAGScheduler: Registering RDD 432 (collect at Ast.scala:253) as input to shuffle 35
23/11/30 14:21:41 INFO DAGScheduler: Got map stage job 129 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ShuffleMapStage 176 (collect at Ast.scala:253)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ShuffleMapStage 176 (MapPartitionsRDD[432] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_145 stored as values in memory (estimated size 19.0 KiB, free 430.9 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_145_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 430.9 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_145_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 145 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 176 (MapPartitionsRDD[432] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 176.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 176.0 (TID 129) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 176.0 (TID 129)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 176.0 (TID 129). 1793 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 176.0 (TID 129) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 176.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ShuffleMapStage 176 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:21:41 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:41 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:41 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:41 INFO ShufflePartitionsUtil: For shuffle(35), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:41 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:41 INFO DAGScheduler: Got job 130 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 178 (collect at Ast.scala:253)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 177)
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 178 (MapPartitionsRDD[435] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_146 stored as values in memory (estimated size 24.9 KiB, free 430.9 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_146_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 430.9 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_146_piece0 in memory on 10.25.86.80:43823 (size: 10.7 KiB, free: 434.2 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 146 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 178 (MapPartitionsRDD[435] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 178.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 178.0 (TID 130) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 178.0 (TID 130)
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 178.0 (TID 130). 4494 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 178.0 (TID 130) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 178.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 178 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:21:41 INFO DAGScheduler: Job 130 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 178: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 130 finished: collect at Ast.scala:253, took 0.006280 s
23/11/30 14:21:41 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:150
23/11/30 14:21:41 INFO DAGScheduler: Got job 131 (show at SparkTest.worksheet.sc:150) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 179 (show at SparkTest.worksheet.sc:150)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 179 (MapPartitionsRDD[437] at show at SparkTest.worksheet.sc:150), which has no missing parents
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_147 stored as values in memory (estimated size 15.7 KiB, free 430.9 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_147_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 430.9 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_147_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.2 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 147 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 179 (MapPartitionsRDD[437] at show at SparkTest.worksheet.sc:150) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 179.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 179.0 (TID 131) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 179.0 (TID 131)
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 179.0 (TID 131). 1640 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 179.0 (TID 131) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 179.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 179 (show at SparkTest.worksheet.sc:150) finished in 0.006 s
23/11/30 14:21:41 INFO DAGScheduler: Job 131 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 179: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 131 finished: show at SparkTest.worksheet.sc:150, took 0.005956 s
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 3.323308 ms
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_140_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_132_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.2 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_144_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_146_piece0 on 10.25.86.80:43823 in memory (size: 10.7 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_128_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_135_piece0 on 10.25.86.80:43823 in memory (size: 14.5 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:159
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_139_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO DAGScheduler: Got job 132 (collect at SparkTest.worksheet.sc:159) with 1 output partitions
23/11/30 14:21:41 INFO DAGScheduler: Final stage: ResultStage 180 (collect at SparkTest.worksheet.sc:159)
23/11/30 14:21:41 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:41 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_138_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO DAGScheduler: Submitting ResultStage 180 (MapPartitionsRDD[445] at collect at SparkTest.worksheet.sc:159), which has no missing parents
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_136_piece0 on 10.25.86.80:43823 in memory (size: 251.0 B, free: 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_137_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_148 stored as values in memory (estimated size 15.4 KiB, free 434.1 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_145_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO MemoryStore: Block broadcast_148_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.1 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_131_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Added broadcast_148_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO SparkContext: Created broadcast 148 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_130_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 180 (MapPartitionsRDD[445] at collect at SparkTest.worksheet.sc:159) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:41 INFO TaskSchedulerImpl: Adding task set 180.0 with 1 tasks resource profile 0
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_134_piece0 on 10.25.86.80:43823 in memory (size: 7.5 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_141_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO TaskSetManager: Starting task 0.0 in stage 180.0 (TID 132) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_147_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.3 MiB)
23/11/30 14:21:41 INFO Executor: Running task 0.0 in stage 180.0 (TID 132)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_127_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_133_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_143_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_129_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_142_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 3.332199 ms
23/11/30 14:21:41 INFO Executor: Finished task 0.0 in stage 180.0 (TID 132). 1650 bytes result sent to driver
23/11/30 14:21:41 INFO TaskSetManager: Finished task 0.0 in stage 180.0 (TID 132) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:41 INFO TaskSchedulerImpl: Removed TaskSet 180.0, whose tasks have all completed, from pool 
23/11/30 14:21:41 INFO DAGScheduler: ResultStage 180 (collect at SparkTest.worksheet.sc:159) finished in 0.010 s
23/11/30 14:21:41 INFO DAGScheduler: Job 132 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 180: Stage finished
23/11/30 14:21:41 INFO DAGScheduler: Job 132 finished: collect at SparkTest.worksheet.sc:159, took 0.010798 s
23/11/30 14:21:41 INFO CodeGenerator: Code generated in 2.802627 ms
23/11/30 14:21:41 INFO BlockManagerInfo: Removed broadcast_148_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.4 MiB)
2023.11.30 14:21:41 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 1.79s[0m
23/11/30 14:21:42 INFO CodeGenerator: Code generated in 4.858982 ms
23/11/30 14:21:42 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:62
23/11/30 14:21:42 INFO DAGScheduler: Got job 133 (show at SparkTest.worksheet.sc:62) with 1 output partitions
23/11/30 14:21:42 INFO DAGScheduler: Final stage: ResultStage 181 (show at SparkTest.worksheet.sc:62)
23/11/30 14:21:42 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:42 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:42 INFO DAGScheduler: Submitting ResultStage 181 (MapPartitionsRDD[449] at show at SparkTest.worksheet.sc:62), which has no missing parents
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_149 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_149_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/11/30 14:21:42 INFO BlockManagerInfo: Added broadcast_149_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:42 INFO SparkContext: Created broadcast 149 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 181 (MapPartitionsRDD[449] at show at SparkTest.worksheet.sc:62) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:42 INFO TaskSchedulerImpl: Adding task set 181.0 with 1 tasks resource profile 0
23/11/30 14:21:42 INFO TaskSetManager: Starting task 0.0 in stage 181.0 (TID 133) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:42 INFO Executor: Running task 0.0 in stage 181.0 (TID 133)
23/11/30 14:21:42 INFO Executor: Finished task 0.0 in stage 181.0 (TID 133). 1634 bytes result sent to driver
23/11/30 14:21:42 INFO TaskSetManager: Finished task 0.0 in stage 181.0 (TID 133) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:42 INFO TaskSchedulerImpl: Removed TaskSet 181.0, whose tasks have all completed, from pool 
23/11/30 14:21:42 INFO DAGScheduler: ResultStage 181 (show at SparkTest.worksheet.sc:62) finished in 0.014 s
23/11/30 14:21:42 INFO DAGScheduler: Job 133 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 181: Stage finished
23/11/30 14:21:42 INFO DAGScheduler: Job 133 finished: show at SparkTest.worksheet.sc:62, took 0.014169 s
23/11/30 14:21:42 INFO CodeGenerator: Code generated in 3.688361 ms
23/11/30 14:21:42 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:42 INFO CodeGenerator: Code generated in 3.842915 ms
23/11/30 14:21:42 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:72
23/11/30 14:21:42 INFO DAGScheduler: Got job 134 (parquet at SparkTest.worksheet.sc:72) with 1 output partitions
23/11/30 14:21:42 INFO DAGScheduler: Final stage: ResultStage 182 (parquet at SparkTest.worksheet.sc:72)
23/11/30 14:21:42 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:42 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:42 INFO DAGScheduler: Submitting ResultStage 182 (MapPartitionsRDD[451] at parquet at SparkTest.worksheet.sc:72), which has no missing parents
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_150 stored as values in memory (estimated size 215.6 KiB, free 434.2 MiB)
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_150_piece0 stored as bytes in memory (estimated size 76.7 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO BlockManagerInfo: Added broadcast_150_piece0 in memory on 10.25.86.80:43823 (size: 76.7 KiB, free: 434.3 MiB)
23/11/30 14:21:42 INFO SparkContext: Created broadcast 150 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 182 (MapPartitionsRDD[451] at parquet at SparkTest.worksheet.sc:72) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:42 INFO TaskSchedulerImpl: Adding task set 182.0 with 1 tasks resource profile 0
23/11/30 14:21:42 INFO TaskSetManager: Starting task 0.0 in stage 182.0 (TID 134) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:42 INFO Executor: Running task 0.0 in stage 182.0 (TID 134)
23/11/30 14:21:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:42 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:21:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:21:42 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:21:42 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:21:42 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:21:42 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/30 14:21:42 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "index",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 index;
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/30 14:21:42 INFO FileOutputCommitter: Saved output of task 'attempt_202311301421424054258230488316217_0182_m_000000_134' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311301421424054258230488316217_0182_m_000000
23/11/30 14:21:42 INFO SparkHadoopMapRedUtil: attempt_202311301421424054258230488316217_0182_m_000000_134: Committed. Elapsed time: 0 ms.
23/11/30 14:21:42 INFO Executor: Finished task 0.0 in stage 182.0 (TID 134). 2699 bytes result sent to driver
23/11/30 14:21:42 INFO TaskSetManager: Finished task 0.0 in stage 182.0 (TID 134) in 23 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:42 INFO TaskSchedulerImpl: Removed TaskSet 182.0, whose tasks have all completed, from pool 
23/11/30 14:21:42 INFO DAGScheduler: ResultStage 182 (parquet at SparkTest.worksheet.sc:72) finished in 0.034 s
23/11/30 14:21:42 INFO DAGScheduler: Job 134 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 182: Stage finished
23/11/30 14:21:42 INFO DAGScheduler: Job 134 finished: parquet at SparkTest.worksheet.sc:72, took 0.034854 s
23/11/30 14:21:42 INFO FileFormatWriter: Start to commit write Job d4dbddfb-5375-462c-9cd5-6a7c39ecabd9.
23/11/30 14:21:42 INFO FileFormatWriter: Write Job d4dbddfb-5375-462c-9cd5-6a7c39ecabd9 committed. Elapsed time: 5 ms.
23/11/30 14:21:42 INFO FileFormatWriter: Finished processing stats for write job d4dbddfb-5375-462c-9cd5-6a7c39ecabd9.
23/11/30 14:21:42 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
23/11/30 14:21:42 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:76
23/11/30 14:21:42 INFO DAGScheduler: Got job 135 (parquet at SparkTest.worksheet.sc:76) with 1 output partitions
23/11/30 14:21:42 INFO DAGScheduler: Final stage: ResultStage 183 (parquet at SparkTest.worksheet.sc:76)
23/11/30 14:21:42 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:42 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:42 INFO DAGScheduler: Submitting ResultStage 183 (MapPartitionsRDD[453] at parquet at SparkTest.worksheet.sc:76), which has no missing parents
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_151 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_151_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/11/30 14:21:42 INFO BlockManagerInfo: Added broadcast_151_piece0 in memory on 10.25.86.80:43823 (size: 36.9 KiB, free: 434.3 MiB)
23/11/30 14:21:42 INFO SparkContext: Created broadcast 151 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 183 (MapPartitionsRDD[453] at parquet at SparkTest.worksheet.sc:76) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:42 INFO TaskSchedulerImpl: Adding task set 183.0 with 1 tasks resource profile 0
23/11/30 14:21:42 INFO TaskSetManager: Starting task 0.0 in stage 183.0 (TID 135) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/11/30 14:21:42 INFO Executor: Running task 0.0 in stage 183.0 (TID 135)
23/11/30 14:21:42 INFO Executor: Finished task 0.0 in stage 183.0 (TID 135). 2042 bytes result sent to driver
23/11/30 14:21:42 INFO TaskSetManager: Finished task 0.0 in stage 183.0 (TID 135) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:42 INFO TaskSchedulerImpl: Removed TaskSet 183.0, whose tasks have all completed, from pool 
23/11/30 14:21:42 INFO DAGScheduler: ResultStage 183 (parquet at SparkTest.worksheet.sc:76) finished in 0.013 s
23/11/30 14:21:42 INFO DAGScheduler: Job 135 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 183: Stage finished
23/11/30 14:21:42 INFO DAGScheduler: Job 135 finished: parquet at SparkTest.worksheet.sc:76, took 0.013774 s
23/11/30 14:21:42 INFO FileSourceStrategy: Pushed Filters: 
23/11/30 14:21:42 INFO FileSourceStrategy: Post-Scan Filters: 
23/11/30 14:21:42 INFO CodeGenerator: Code generated in 4.789493 ms
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_152 stored as values in memory (estimated size 200.8 KiB, free 433.8 MiB)
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_152_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
23/11/30 14:21:42 INFO BlockManagerInfo: Added broadcast_152_piece0 in memory on 10.25.86.80:43823 (size: 34.9 KiB, free: 434.2 MiB)
23/11/30 14:21:42 INFO SparkContext: Created broadcast 152 from show at SparkTest.worksheet.sc:81
23/11/30 14:21:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/11/30 14:21:42 INFO BlockManagerInfo: Removed broadcast_151_piece0 on 10.25.86.80:43823 in memory (size: 36.9 KiB, free: 434.3 MiB)
23/11/30 14:21:42 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:81
23/11/30 14:21:42 INFO BlockManagerInfo: Removed broadcast_149_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:21:42 INFO DAGScheduler: Got job 136 (show at SparkTest.worksheet.sc:81) with 1 output partitions
23/11/30 14:21:42 INFO DAGScheduler: Final stage: ResultStage 184 (show at SparkTest.worksheet.sc:81)
23/11/30 14:21:42 INFO BlockManagerInfo: Removed broadcast_150_piece0 on 10.25.86.80:43823 in memory (size: 76.7 KiB, free: 434.4 MiB)
23/11/30 14:21:42 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:42 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:42 INFO DAGScheduler: Submitting ResultStage 184 (MapPartitionsRDD[457] at show at SparkTest.worksheet.sc:81), which has no missing parents
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_153 stored as values in memory (estimated size 16.6 KiB, free 434.2 MiB)
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_153_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO BlockManagerInfo: Added broadcast_153_piece0 in memory on 10.25.86.80:43823 (size: 6.8 KiB, free: 434.4 MiB)
23/11/30 14:21:42 INFO SparkContext: Created broadcast 153 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 184 (MapPartitionsRDD[457] at show at SparkTest.worksheet.sc:81) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:42 INFO TaskSchedulerImpl: Adding task set 184.0 with 1 tasks resource profile 0
23/11/30 14:21:42 INFO TaskSetManager: Starting task 0.0 in stage 184.0 (TID 136) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/11/30 14:21:42 INFO Executor: Running task 0.0 in stage 184.0 (TID 136)
23/11/30 14:21:42 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-903c3787-8b45-463a-aac1-90a918ebe4df-c000.snappy.parquet, range: 0-1246, partition values: [empty row]
23/11/30 14:21:42 INFO Executor: Finished task 0.0 in stage 184.0 (TID 136). 1928 bytes result sent to driver
23/11/30 14:21:42 INFO TaskSetManager: Finished task 0.0 in stage 184.0 (TID 136) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:42 INFO TaskSchedulerImpl: Removed TaskSet 184.0, whose tasks have all completed, from pool 
23/11/30 14:21:42 INFO DAGScheduler: ResultStage 184 (show at SparkTest.worksheet.sc:81) finished in 0.010 s
23/11/30 14:21:42 INFO DAGScheduler: Job 136 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 184: Stage finished
23/11/30 14:21:42 INFO DAGScheduler: Job 136 finished: show at SparkTest.worksheet.sc:81, took 0.011163 s
23/11/30 14:21:42 INFO CodeGenerator: Code generated in 3.816606 ms
23/11/30 14:21:42 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:94
23/11/30 14:21:42 INFO DAGScheduler: Got job 137 (show at SparkTest.worksheet.sc:94) with 1 output partitions
23/11/30 14:21:42 INFO DAGScheduler: Final stage: ResultStage 185 (show at SparkTest.worksheet.sc:94)
23/11/30 14:21:42 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:42 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:42 INFO DAGScheduler: Submitting ResultStage 185 (MapPartitionsRDD[459] at show at SparkTest.worksheet.sc:94), which has no missing parents
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_154 stored as values in memory (estimated size 15.7 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_154_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO BlockManagerInfo: Added broadcast_154_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:42 INFO SparkContext: Created broadcast 154 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 185 (MapPartitionsRDD[459] at show at SparkTest.worksheet.sc:94) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:42 INFO TaskSchedulerImpl: Adding task set 185.0 with 1 tasks resource profile 0
23/11/30 14:21:42 INFO TaskSetManager: Starting task 0.0 in stage 185.0 (TID 137) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:42 INFO Executor: Running task 0.0 in stage 185.0 (TID 137)
23/11/30 14:21:42 INFO Executor: Finished task 0.0 in stage 185.0 (TID 137). 1640 bytes result sent to driver
23/11/30 14:21:42 INFO TaskSetManager: Finished task 0.0 in stage 185.0 (TID 137) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:42 INFO TaskSchedulerImpl: Removed TaskSet 185.0, whose tasks have all completed, from pool 
23/11/30 14:21:42 INFO DAGScheduler: ResultStage 185 (show at SparkTest.worksheet.sc:94) finished in 0.005 s
23/11/30 14:21:42 INFO DAGScheduler: Job 137 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 185: Stage finished
23/11/30 14:21:42 INFO DAGScheduler: Job 137 finished: show at SparkTest.worksheet.sc:94, took 0.006562 s
23/11/30 14:21:42 INFO CodeGenerator: Code generated in 2.726575 ms
23/11/30 14:21:42 INFO CodeGenerator: Code generated in 3.441186 ms
23/11/30 14:21:42 INFO DAGScheduler: Registering RDD 461 (collect at SparkTest.worksheet.sc:102) as input to shuffle 36
23/11/30 14:21:42 INFO DAGScheduler: Got map stage job 138 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:21:42 INFO DAGScheduler: Final stage: ShuffleMapStage 186 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:21:42 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:42 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:42 INFO DAGScheduler: Submitting ShuffleMapStage 186 (MapPartitionsRDD[461] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_155 stored as values in memory (estimated size 19.2 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_155_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO BlockManagerInfo: Added broadcast_155_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:21:42 INFO SparkContext: Created broadcast 155 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:42 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 186 (MapPartitionsRDD[461] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:42 INFO TaskSchedulerImpl: Adding task set 186.0 with 1 tasks resource profile 0
23/11/30 14:21:42 INFO TaskSetManager: Starting task 0.0 in stage 186.0 (TID 138) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:42 INFO Executor: Running task 0.0 in stage 186.0 (TID 138)
23/11/30 14:21:42 INFO BlockManagerInfo: Removed broadcast_154_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:42 INFO BlockManagerInfo: Removed broadcast_153_piece0 on 10.25.86.80:43823 in memory (size: 6.8 KiB, free: 434.4 MiB)
23/11/30 14:21:42 INFO Executor: Finished task 0.0 in stage 186.0 (TID 138). 2016 bytes result sent to driver
23/11/30 14:21:42 INFO TaskSetManager: Finished task 0.0 in stage 186.0 (TID 138) in 21 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:42 INFO TaskSchedulerImpl: Removed TaskSet 186.0, whose tasks have all completed, from pool 
23/11/30 14:21:42 INFO DAGScheduler: ShuffleMapStage 186 (collect at SparkTest.worksheet.sc:102) finished in 0.023 s
23/11/30 14:21:42 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:42 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:42 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:42 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:42 INFO CodeGenerator: Code generated in 5.621158 ms
23/11/30 14:21:42 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:102
23/11/30 14:21:42 INFO DAGScheduler: Got job 139 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:21:42 INFO DAGScheduler: Final stage: ResultStage 188 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:21:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 187)
23/11/30 14:21:42 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:42 INFO DAGScheduler: Submitting ResultStage 188 (MapPartitionsRDD[464] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_156 stored as values in memory (estimated size 14.3 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_156_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO BlockManagerInfo: Added broadcast_156_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:42 INFO SparkContext: Created broadcast 156 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 188 (MapPartitionsRDD[464] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:42 INFO TaskSchedulerImpl: Adding task set 188.0 with 1 tasks resource profile 0
23/11/30 14:21:42 INFO TaskSetManager: Starting task 0.0 in stage 188.0 (TID 139) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:42 INFO Executor: Running task 0.0 in stage 188.0 (TID 139)
23/11/30 14:21:42 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:42 INFO Executor: Finished task 0.0 in stage 188.0 (TID 139). 4084 bytes result sent to driver
23/11/30 14:21:42 INFO TaskSetManager: Finished task 0.0 in stage 188.0 (TID 139) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:42 INFO TaskSchedulerImpl: Removed TaskSet 188.0, whose tasks have all completed, from pool 
23/11/30 14:21:42 INFO DAGScheduler: ResultStage 188 (collect at SparkTest.worksheet.sc:102) finished in 0.006 s
23/11/30 14:21:42 INFO DAGScheduler: Job 139 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 188: Stage finished
23/11/30 14:21:42 INFO DAGScheduler: Job 139 finished: collect at SparkTest.worksheet.sc:102, took 0.007058 s
23/11/30 14:21:42 INFO CodeGenerator: Code generated in 4.240077 ms
23/11/30 14:21:42 INFO SparkContext: Starting job: show at Ast.scala:95
23/11/30 14:21:42 INFO DAGScheduler: Got job 140 (show at Ast.scala:95) with 1 output partitions
23/11/30 14:21:42 INFO DAGScheduler: Final stage: ResultStage 189 (show at Ast.scala:95)
23/11/30 14:21:42 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:42 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:42 INFO DAGScheduler: Submitting ResultStage 189 (MapPartitionsRDD[466] at show at Ast.scala:95), which has no missing parents
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_157 stored as values in memory (estimated size 15.5 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_157_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO BlockManagerInfo: Added broadcast_157_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:21:42 INFO SparkContext: Created broadcast 157 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 189 (MapPartitionsRDD[466] at show at Ast.scala:95) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:42 INFO TaskSchedulerImpl: Adding task set 189.0 with 1 tasks resource profile 0
23/11/30 14:21:42 INFO TaskSetManager: Starting task 0.0 in stage 189.0 (TID 140) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:42 INFO Executor: Running task 0.0 in stage 189.0 (TID 140)
23/11/30 14:21:42 INFO Executor: Finished task 0.0 in stage 189.0 (TID 140). 1634 bytes result sent to driver
23/11/30 14:21:42 INFO TaskSetManager: Finished task 0.0 in stage 189.0 (TID 140) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:42 INFO TaskSchedulerImpl: Removed TaskSet 189.0, whose tasks have all completed, from pool 
23/11/30 14:21:42 INFO DAGScheduler: ResultStage 189 (show at Ast.scala:95) finished in 0.006 s
23/11/30 14:21:42 INFO DAGScheduler: Job 140 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 189: Stage finished
23/11/30 14:21:42 INFO DAGScheduler: Job 140 finished: show at Ast.scala:95, took 0.007468 s
23/11/30 14:21:42 INFO SparkContext: Starting job: show at Ast.scala:96
23/11/30 14:21:42 INFO DAGScheduler: Got job 141 (show at Ast.scala:96) with 1 output partitions
23/11/30 14:21:42 INFO DAGScheduler: Final stage: ResultStage 190 (show at Ast.scala:96)
23/11/30 14:21:42 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:42 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:42 INFO DAGScheduler: Submitting ResultStage 190 (MapPartitionsRDD[468] at show at Ast.scala:96), which has no missing parents
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_158 stored as values in memory (estimated size 15.5 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO MemoryStore: Block broadcast_158_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.1 MiB)
23/11/30 14:21:42 INFO BlockManagerInfo: Added broadcast_158_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:21:42 INFO SparkContext: Created broadcast 158 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 190 (MapPartitionsRDD[468] at show at Ast.scala:96) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:42 INFO TaskSchedulerImpl: Adding task set 190.0 with 1 tasks resource profile 0
23/11/30 14:21:42 INFO TaskSetManager: Starting task 0.0 in stage 190.0 (TID 141) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:42 INFO Executor: Running task 0.0 in stage 190.0 (TID 141)
23/11/30 14:21:42 INFO Executor: Finished task 0.0 in stage 190.0 (TID 141). 1634 bytes result sent to driver
23/11/30 14:21:42 INFO TaskSetManager: Finished task 0.0 in stage 190.0 (TID 141) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:42 INFO TaskSchedulerImpl: Removed TaskSet 190.0, whose tasks have all completed, from pool 
23/11/30 14:21:42 INFO DAGScheduler: ResultStage 190 (show at Ast.scala:96) finished in 0.007 s
23/11/30 14:21:42 INFO DAGScheduler: Job 141 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:42 INFO TaskSchedulerImpl: Killing all running tasks in stage 190: Stage finished
23/11/30 14:21:42 INFO DAGScheduler: Job 141 finished: show at Ast.scala:96, took 0.007644 s
23/11/30 14:21:43 INFO DAGScheduler: Registering RDD 470 (show at Ast.scala:108) as input to shuffle 37
23/11/30 14:21:43 INFO DAGScheduler: Got map stage job 142 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ShuffleMapStage 191 (show at Ast.scala:108)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ShuffleMapStage 191 (MapPartitionsRDD[470] at show at Ast.scala:108), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_159 stored as values in memory (estimated size 17.7 KiB, free 434.1 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_159_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.1 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_159_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 159 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 191 (MapPartitionsRDD[470] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 191.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_152_piece0 on 10.25.86.80:43823 in memory (size: 34.9 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 191.0 (TID 142) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 191.0 (TID 142)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 191.0 (TID 142). 1991 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 191.0 (TID 142) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 191.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ShuffleMapStage 191 (show at Ast.scala:108) finished in 0.010 s
23/11/30 14:21:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:43 INFO ShufflePartitionsUtil: For shuffle(37, 37), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 8.764758 ms
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 4.492384 ms
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 3.554027 ms
23/11/30 14:21:43 INFO SparkContext: Starting job: show at Ast.scala:108
23/11/30 14:21:43 INFO DAGScheduler: Got job 143 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 193 (show at Ast.scala:108)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 192)
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 193 (MapPartitionsRDD[477] at show at Ast.scala:108), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_160 stored as values in memory (estimated size 40.1 KiB, free 434.2 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_160_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.2 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_160_piece0 in memory on 10.25.86.80:43823 (size: 16.3 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 160 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 193 (MapPartitionsRDD[477] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 193.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 193.0 (TID 143) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 193.0 (TID 143)
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 193.0 (TID 143). 4898 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 193.0 (TID 143) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 193.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 193 (show at Ast.scala:108) finished in 0.009 s
23/11/30 14:21:43 INFO DAGScheduler: Job 143 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 193: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 143 finished: show at Ast.scala:108, took 0.010108 s
23/11/30 14:21:43 INFO DAGScheduler: Registering RDD 479 (show at Ast.scala:112) as input to shuffle 38
23/11/30 14:21:43 INFO DAGScheduler: Got map stage job 144 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ShuffleMapStage 194 (show at Ast.scala:112)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ShuffleMapStage 194 (MapPartitionsRDD[479] at show at Ast.scala:112), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_161 stored as values in memory (estimated size 17.7 KiB, free 434.2 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_161_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.2 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_161_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 161 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 194 (MapPartitionsRDD[479] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 194.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 194.0 (TID 144) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 194.0 (TID 144)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 194.0 (TID 144). 1991 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 194.0 (TID 144) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 194.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ShuffleMapStage 194 (show at Ast.scala:112) finished in 0.009 s
23/11/30 14:21:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:43 INFO ShufflePartitionsUtil: For shuffle(38, 38), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:43 INFO SparkContext: Starting job: show at Ast.scala:112
23/11/30 14:21:43 INFO DAGScheduler: Got job 145 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 196 (show at Ast.scala:112)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 195)
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 196 (MapPartitionsRDD[486] at show at Ast.scala:112), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_162 stored as values in memory (estimated size 40.1 KiB, free 434.2 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_162_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.2 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_162_piece0 in memory on 10.25.86.80:43823 (size: 16.3 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 162 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 196 (MapPartitionsRDD[486] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 196.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 196.0 (TID 145) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 196.0 (TID 145)
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 196.0 (TID 145). 4898 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 196.0 (TID 145) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 196.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 196 (show at Ast.scala:112) finished in 0.007 s
23/11/30 14:21:43 INFO DAGScheduler: Job 145 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 196: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 145 finished: show at Ast.scala:112, took 0.008882 s
23/11/30 14:21:43 INFO SparkContext: Starting job: show at Ast.scala:113
23/11/30 14:21:43 INFO DAGScheduler: Got job 146 (show at Ast.scala:113) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 197 (show at Ast.scala:113)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 197 (MapPartitionsRDD[488] at show at Ast.scala:113), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_163 stored as values in memory (estimated size 15.5 KiB, free 434.1 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_163_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.1 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_163_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 163 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 197 (MapPartitionsRDD[488] at show at Ast.scala:113) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 197.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 197.0 (TID 146) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 197.0 (TID 146)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 197.0 (TID 146). 1634 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 197.0 (TID 146) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 197.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 197 (show at Ast.scala:113) finished in 0.006 s
23/11/30 14:21:43 INFO DAGScheduler: Job 146 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 197: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 146 finished: show at Ast.scala:113, took 0.006840 s
23/11/30 14:21:43 INFO DAGScheduler: Registering RDD 490 (show at Ast.scala:126) as input to shuffle 39
23/11/30 14:21:43 INFO DAGScheduler: Got map stage job 147 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ShuffleMapStage 198 (show at Ast.scala:126)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ShuffleMapStage 198 (MapPartitionsRDD[490] at show at Ast.scala:126), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_164 stored as values in memory (estimated size 17.7 KiB, free 434.1 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_164_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.1 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_164_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 164 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 198 (MapPartitionsRDD[490] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 198.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 198.0 (TID 147) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 198.0 (TID 147)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 198.0 (TID 147). 1991 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 198.0 (TID 147) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 198.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ShuffleMapStage 198 (show at Ast.scala:126) finished in 0.008 s
23/11/30 14:21:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:43 INFO ShufflePartitionsUtil: For shuffle(39, 39), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 5.724204 ms
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 3.423551 ms
23/11/30 14:21:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:43 INFO DAGScheduler: Got job 148 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 200 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 199)
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 200 (MapPartitionsRDD[497] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_165 stored as values in memory (estimated size 38.7 KiB, free 434.1 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_165_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.1 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_165_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 165 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 200 (MapPartitionsRDD[497] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 200.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 200.0 (TID 148) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 200.0 (TID 148)
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 200.0 (TID 148). 4897 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 200.0 (TID 148) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 200.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 200 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.007 s
23/11/30 14:21:43 INFO DAGScheduler: Job 148 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 200: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 148 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.008802 s
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 2.420067 ms
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_166 stored as values in memory (estimated size 1024.1 KiB, free 433.1 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_166_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.1 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_166_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 166 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:43 INFO ShufflePartitionsUtil: For shuffle(39), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 3.68869 ms
23/11/30 14:21:43 INFO SparkContext: Starting job: show at Ast.scala:126
23/11/30 14:21:43 INFO DAGScheduler: Got job 149 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 202 (show at Ast.scala:126)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 201)
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 202 (MapPartitionsRDD[500] at show at Ast.scala:126), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_167 stored as values in memory (estimated size 15.1 KiB, free 433.0 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_167_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.0 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_167_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 167 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 202 (MapPartitionsRDD[500] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 202.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 202.0 (TID 149) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 202.0 (TID 149)
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 202.0 (TID 149). 4079 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 202.0 (TID 149) in 2 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 202.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 202 (show at Ast.scala:126) finished in 0.005 s
23/11/30 14:21:43 INFO DAGScheduler: Job 149 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 202: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 149 finished: show at Ast.scala:126, took 0.005355 s
23/11/30 14:21:43 INFO DAGScheduler: Registering RDD 502 (show at SparkTest.worksheet.sc:115) as input to shuffle 40
23/11/30 14:21:43 INFO DAGScheduler: Got map stage job 150 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ShuffleMapStage 203 (show at SparkTest.worksheet.sc:115)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ShuffleMapStage 203 (MapPartitionsRDD[502] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_168 stored as values in memory (estimated size 17.7 KiB, free 433.0 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_168_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.0 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_168_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 168 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 203 (MapPartitionsRDD[502] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 203.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 203.0 (TID 150) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 203.0 (TID 150)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 203.0 (TID 150). 1991 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 203.0 (TID 150) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 203.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ShuffleMapStage 203 (show at SparkTest.worksheet.sc:115) finished in 0.009 s
23/11/30 14:21:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:43 INFO ShufflePartitionsUtil: For shuffle(40, 40), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:43 INFO DAGScheduler: Got job 151 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 205 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 204)
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 205 (MapPartitionsRDD[509] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_169 stored as values in memory (estimated size 38.7 KiB, free 433.0 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_169_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 433.0 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_169_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 169 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 205 (MapPartitionsRDD[509] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 205.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 205.0 (TID 151) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 205.0 (TID 151)
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 205.0 (TID 151). 4897 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 205.0 (TID 151) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 205.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 205 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.008 s
23/11/30 14:21:43 INFO DAGScheduler: Job 151 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 205: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 151 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.009010 s
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_170 stored as values in memory (estimated size 1024.1 KiB, free 432.0 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_170_piece0 stored as bytes in memory (estimated size 337.0 B, free 432.0 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_170_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 170 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:43 INFO ShufflePartitionsUtil: For shuffle(40), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:43 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:115
23/11/30 14:21:43 INFO DAGScheduler: Got job 152 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 207 (show at SparkTest.worksheet.sc:115)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 206)
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 207 (MapPartitionsRDD[512] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_171 stored as values in memory (estimated size 15.1 KiB, free 431.9 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_171_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 431.9 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_171_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 171 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 207 (MapPartitionsRDD[512] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 207.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 207.0 (TID 152) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 207.0 (TID 152)
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 207.0 (TID 152). 4079 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 207.0 (TID 152) in 2 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 207.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 207 (show at SparkTest.worksheet.sc:115) finished in 0.005 s
23/11/30 14:21:43 INFO DAGScheduler: Job 152 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 207: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 152 finished: show at SparkTest.worksheet.sc:115, took 0.005404 s
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 2.813275 ms
23/11/30 14:21:43 INFO DAGScheduler: Registering RDD 514 (isEmpty at SparkTest.worksheet.sc:120) as input to shuffle 41
23/11/30 14:21:43 INFO DAGScheduler: Got map stage job 153 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ShuffleMapStage 208 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ShuffleMapStage 208 (MapPartitionsRDD[514] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_172 stored as values in memory (estimated size 17.3 KiB, free 431.9 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_172_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 431.9 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_172_piece0 in memory on 10.25.86.80:43823 (size: 7.5 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 172 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 208 (MapPartitionsRDD[514] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 208.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 208.0 (TID 153) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 208.0 (TID 153)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 208.0 (TID 153). 1991 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 208.0 (TID 153) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 208.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ShuffleMapStage 208 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.008 s
23/11/30 14:21:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:43 INFO ShufflePartitionsUtil: For shuffle(41, 41), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 4.350363 ms
23/11/30 14:21:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:43 INFO DAGScheduler: Got job 154 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 210 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 209)
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 210 (MapPartitionsRDD[521] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_173 stored as values in memory (estimated size 35.3 KiB, free 431.9 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_173_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 431.9 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_173_piece0 in memory on 10.25.86.80:43823 (size: 14.5 KiB, free: 434.2 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 173 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 210 (MapPartitionsRDD[521] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 210.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 210.0 (TID 154) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 210.0 (TID 154)
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 210.0 (TID 154). 4817 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 210.0 (TID 154) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 210.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 210 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.007 s
23/11/30 14:21:43 INFO DAGScheduler: Job 154 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 210: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 154 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.008328 s
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_174 stored as values in memory (estimated size 1024.1 KiB, free 430.9 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_174_piece0 stored as bytes in memory (estimated size 251.0 B, free 430.9 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_174_piece0 in memory on 10.25.86.80:43823 (size: 251.0 B, free: 434.2 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 174 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:21:43 INFO ShufflePartitionsUtil: For shuffle(41), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 2.786716 ms
23/11/30 14:21:43 INFO SparkContext: Starting job: isEmpty at SparkTest.worksheet.sc:120
23/11/30 14:21:43 INFO DAGScheduler: Got job 155 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 212 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 211)
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 212 (MapPartitionsRDD[524] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_175 stored as values in memory (estimated size 13.3 KiB, free 430.8 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_175_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 430.8 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_175_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.2 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 175 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 212 (MapPartitionsRDD[524] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 212.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 212.0 (TID 155) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 212.0 (TID 155)
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 212.0 (TID 155). 3219 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 212.0 (TID 155) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 212.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 212 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.006 s
23/11/30 14:21:43 INFO DAGScheduler: Job 155 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 212: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 155 finished: isEmpty at SparkTest.worksheet.sc:120, took 0.006978 s
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 2.789612 ms
23/11/30 14:21:43 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:43 INFO DAGScheduler: Got job 156 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 213 (collect at Ast.scala:253)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 213 (MapPartitionsRDD[528] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_176 stored as values in memory (estimated size 17.5 KiB, free 430.8 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_176_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 430.8 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_176_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.2 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 176 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 213 (MapPartitionsRDD[528] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 213.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 213.0 (TID 156) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 213.0 (TID 156)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 213.0 (TID 156). 1826 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 213.0 (TID 156) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 213.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 213 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:21:43 INFO DAGScheduler: Job 156 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 213: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 156 finished: collect at Ast.scala:253, took 0.008304 s
23/11/30 14:21:43 INFO DAGScheduler: Registering RDD 529 (collect at Ast.scala:253) as input to shuffle 42
23/11/30 14:21:43 INFO DAGScheduler: Got map stage job 157 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ShuffleMapStage 214 (collect at Ast.scala:253)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ShuffleMapStage 214 (MapPartitionsRDD[529] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_177 stored as values in memory (estimated size 19.0 KiB, free 430.8 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_177_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 430.8 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_177_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.2 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 177 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 214 (MapPartitionsRDD[529] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 214.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 214.0 (TID 157) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 214.0 (TID 157)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 214.0 (TID 157). 1793 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 214.0 (TID 157) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 214.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ShuffleMapStage 214 (collect at Ast.scala:253) finished in 0.008 s
23/11/30 14:21:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:43 INFO ShufflePartitionsUtil: For shuffle(42), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_171_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.2 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_155_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.2 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_159_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.2 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_169_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_173_piece0 on 10.25.86.80:43823 in memory (size: 14.5 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_157_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_174_piece0 on 10.25.86.80:43823 in memory (size: 251.0 B, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_162_piece0 on 10.25.86.80:43823 in memory (size: 16.3 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_177_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_170_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_165_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_158_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_176_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_167_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_164_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_160_piece0 on 10.25.86.80:43823 in memory (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 5.525366 ms
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_175_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_172_piece0 on 10.25.86.80:43823 in memory (size: 7.5 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_156_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_166_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_168_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_161_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_163_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:43 INFO DAGScheduler: Got job 158 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 216 (collect at Ast.scala:253)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 215)
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 216 (MapPartitionsRDD[532] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_178 stored as values in memory (estimated size 24.9 KiB, free 434.4 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_178_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.4 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_178_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 178 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 216 (MapPartitionsRDD[532] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 216.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 216.0 (TID 158) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 216.0 (TID 158)
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 216.0 (TID 158). 4494 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 216.0 (TID 158) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 216.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 216 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:21:43 INFO DAGScheduler: Job 158 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 216: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 158 finished: collect at Ast.scala:253, took 0.007152 s
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 3.406776 ms
23/11/30 14:21:43 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:43 INFO DAGScheduler: Got job 159 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 217 (collect at Ast.scala:253)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 217 (MapPartitionsRDD[536] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_179 stored as values in memory (estimated size 17.5 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_179_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_179_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 179 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 217 (MapPartitionsRDD[536] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 217.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 217.0 (TID 159) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 217.0 (TID 159)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 217.0 (TID 159). 1826 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 217.0 (TID 159) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 217.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 217 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:21:43 INFO DAGScheduler: Job 159 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 217: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 159 finished: collect at Ast.scala:253, took 0.006661 s
23/11/30 14:21:43 INFO DAGScheduler: Registering RDD 537 (collect at Ast.scala:253) as input to shuffle 43
23/11/30 14:21:43 INFO DAGScheduler: Got map stage job 160 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ShuffleMapStage 218 (collect at Ast.scala:253)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ShuffleMapStage 218 (MapPartitionsRDD[537] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_180 stored as values in memory (estimated size 19.0 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_180_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_180_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 180 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 218 (MapPartitionsRDD[537] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 218.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 218.0 (TID 160) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 218.0 (TID 160)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 218.0 (TID 160). 1793 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 218.0 (TID 160) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 218.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ShuffleMapStage 218 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:21:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:43 INFO ShufflePartitionsUtil: For shuffle(43), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:43 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:43 INFO DAGScheduler: Got job 161 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 220 (collect at Ast.scala:253)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 219)
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 220 (MapPartitionsRDD[540] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_181 stored as values in memory (estimated size 24.9 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_181_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_181_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 181 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 220 (MapPartitionsRDD[540] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 220.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 220.0 (TID 161) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 220.0 (TID 161)
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 220.0 (TID 161). 4494 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 220.0 (TID 161) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 220.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 220 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:21:43 INFO DAGScheduler: Job 161 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 220: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 161 finished: collect at Ast.scala:253, took 0.006732 s
23/11/30 14:21:43 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:43 INFO DAGScheduler: Got job 162 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 221 (collect at Ast.scala:253)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 221 (MapPartitionsRDD[544] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_182 stored as values in memory (estimated size 17.5 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_182_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_182_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 182 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 221 (MapPartitionsRDD[544] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 221.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 221.0 (TID 162) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_180_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 221.0 (TID 162)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_181_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_179_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Removed broadcast_178_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 221.0 (TID 162). 1826 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 221.0 (TID 162) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 221.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 221 (collect at Ast.scala:253) finished in 0.013 s
23/11/30 14:21:43 INFO DAGScheduler: Job 162 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 221: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 162 finished: collect at Ast.scala:253, took 0.013900 s
23/11/30 14:21:43 INFO DAGScheduler: Registering RDD 545 (collect at Ast.scala:253) as input to shuffle 44
23/11/30 14:21:43 INFO DAGScheduler: Got map stage job 163 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ShuffleMapStage 222 (collect at Ast.scala:253)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ShuffleMapStage 222 (MapPartitionsRDD[545] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_183 stored as values in memory (estimated size 19.0 KiB, free 434.4 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_183_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_183_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 183 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 222 (MapPartitionsRDD[545] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 222.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 222.0 (TID 163) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 222.0 (TID 163)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 222.0 (TID 163). 1793 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 222.0 (TID 163) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 222.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ShuffleMapStage 222 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:21:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:21:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:21:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:21:43 INFO ShufflePartitionsUtil: For shuffle(44), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:21:43 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:21:43 INFO DAGScheduler: Got job 164 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 224 (collect at Ast.scala:253)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 223)
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 224 (MapPartitionsRDD[548] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_184 stored as values in memory (estimated size 24.9 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_184_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_184_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 184 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 224 (MapPartitionsRDD[548] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 224.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 224.0 (TID 164) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 224.0 (TID 164)
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:21:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 224.0 (TID 164). 4494 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 224.0 (TID 164) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 224.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 224 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:21:43 INFO DAGScheduler: Job 164 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 224: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 164 finished: collect at Ast.scala:253, took 0.006990 s
23/11/30 14:21:43 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:150
23/11/30 14:21:43 INFO DAGScheduler: Got job 165 (show at SparkTest.worksheet.sc:150) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 225 (show at SparkTest.worksheet.sc:150)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 225 (MapPartitionsRDD[550] at show at SparkTest.worksheet.sc:150), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_185 stored as values in memory (estimated size 15.7 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_185_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_185_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 185 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 225 (MapPartitionsRDD[550] at show at SparkTest.worksheet.sc:150) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 225.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 225.0 (TID 165) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 225.0 (TID 165)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 225.0 (TID 165). 1640 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 225.0 (TID 165) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 225.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 225 (show at SparkTest.worksheet.sc:150) finished in 0.006 s
23/11/30 14:21:43 INFO DAGScheduler: Job 165 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 225: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 165 finished: show at SparkTest.worksheet.sc:150, took 0.006682 s
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 3.159058 ms
23/11/30 14:21:43 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:159
23/11/30 14:21:43 INFO DAGScheduler: Got job 166 (collect at SparkTest.worksheet.sc:159) with 1 output partitions
23/11/30 14:21:43 INFO DAGScheduler: Final stage: ResultStage 226 (collect at SparkTest.worksheet.sc:159)
23/11/30 14:21:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:21:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:21:43 INFO DAGScheduler: Submitting ResultStage 226 (MapPartitionsRDD[558] at collect at SparkTest.worksheet.sc:159), which has no missing parents
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_186 stored as values in memory (estimated size 15.4 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO MemoryStore: Block broadcast_186_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.3 MiB)
23/11/30 14:21:43 INFO BlockManagerInfo: Added broadcast_186_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.4 MiB)
23/11/30 14:21:43 INFO SparkContext: Created broadcast 186 from broadcast at DAGScheduler.scala:1580
23/11/30 14:21:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 226 (MapPartitionsRDD[558] at collect at SparkTest.worksheet.sc:159) (first 15 tasks are for partitions Vector(0))
23/11/30 14:21:43 INFO TaskSchedulerImpl: Adding task set 226.0 with 1 tasks resource profile 0
23/11/30 14:21:43 INFO TaskSetManager: Starting task 0.0 in stage 226.0 (TID 166) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:21:43 INFO Executor: Running task 0.0 in stage 226.0 (TID 166)
23/11/30 14:21:43 INFO Executor: Finished task 0.0 in stage 226.0 (TID 166). 1650 bytes result sent to driver
23/11/30 14:21:43 INFO TaskSetManager: Finished task 0.0 in stage 226.0 (TID 166) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:21:43 INFO TaskSchedulerImpl: Removed TaskSet 226.0, whose tasks have all completed, from pool 
23/11/30 14:21:43 INFO DAGScheduler: ResultStage 226 (collect at SparkTest.worksheet.sc:159) finished in 0.006 s
23/11/30 14:21:43 INFO DAGScheduler: Job 166 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 226: Stage finished
23/11/30 14:21:43 INFO DAGScheduler: Job 166 finished: collect at SparkTest.worksheet.sc:159, took 0.006384 s
23/11/30 14:21:43 INFO CodeGenerator: Code generated in 2.953867 ms
2023.11.30 14:21:43 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 1.61s[0m
23/11/30 14:21:44 INFO BlockManagerInfo: Removed broadcast_182_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:21:44 INFO BlockManagerInfo: Removed broadcast_186_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/11/30 14:21:44 INFO BlockManagerInfo: Removed broadcast_183_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:21:44 INFO BlockManagerInfo: Removed broadcast_184_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:21:44 INFO BlockManagerInfo: Removed broadcast_185_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.4 MiB)
[31merror[39m: worksheets/SparkTest.worksheet.sc:106:21: identifier expected but end of file found
doubledDf.collect().
                    ^
2023.11.30 14:21:46 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.19s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:106:21: identifier expected but end of file found
doubledDf.collect().
                    ^
2023.11.30 14:22:17 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.17s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:106:21: identifier expected but . found
doubledDf.collect()..map(row => row.toSeq.mkString(", ")).mkString(" ")
                    ^
2023.11.30 14:22:20 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.12s[0m
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 4.43983 ms
23/11/30 14:22:24 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:62
23/11/30 14:22:24 INFO DAGScheduler: Got job 167 (show at SparkTest.worksheet.sc:62) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 227 (show at SparkTest.worksheet.sc:62)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 227 (MapPartitionsRDD[562] at show at SparkTest.worksheet.sc:62), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_187 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_187_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_187_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 187 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 227 (MapPartitionsRDD[562] at show at SparkTest.worksheet.sc:62) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 227.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 227.0 (TID 167) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 227.0 (TID 167)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 227.0 (TID 167). 1634 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 227.0 (TID 167) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 227.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 227 (show at SparkTest.worksheet.sc:62) finished in 0.024 s
23/11/30 14:22:24 INFO DAGScheduler: Job 167 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 227: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 167 finished: show at SparkTest.worksheet.sc:62, took 0.025091 s
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 3.19049 ms
23/11/30 14:22:24 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:22:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:22:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:22:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:22:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:22:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:22:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 2.845698 ms
23/11/30 14:22:24 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:72
23/11/30 14:22:24 INFO DAGScheduler: Got job 168 (parquet at SparkTest.worksheet.sc:72) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 228 (parquet at SparkTest.worksheet.sc:72)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 228 (MapPartitionsRDD[564] at parquet at SparkTest.worksheet.sc:72), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_188 stored as values in memory (estimated size 215.6 KiB, free 434.2 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_188_piece0 stored as bytes in memory (estimated size 76.7 KiB, free 434.1 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_188_piece0 in memory on 10.25.86.80:43823 (size: 76.7 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 188 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 228 (MapPartitionsRDD[564] at parquet at SparkTest.worksheet.sc:72) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 228.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 228.0 (TID 168) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 228.0 (TID 168)
23/11/30 14:22:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:22:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:22:24 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:22:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:22:24 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:22:24 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:22:24 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:22:24 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:22:24 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/30 14:22:24 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "index",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 index;
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/30 14:22:24 INFO FileOutputCommitter: Saved output of task 'attempt_20231130142224995689499146922240_0228_m_000000_168' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_20231130142224995689499146922240_0228_m_000000
23/11/30 14:22:24 INFO SparkHadoopMapRedUtil: attempt_20231130142224995689499146922240_0228_m_000000_168: Committed. Elapsed time: 0 ms.
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 228.0 (TID 168). 2699 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 228.0 (TID 168) in 25 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 228.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 228 (parquet at SparkTest.worksheet.sc:72) finished in 0.034 s
23/11/30 14:22:24 INFO DAGScheduler: Job 168 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 228: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 168 finished: parquet at SparkTest.worksheet.sc:72, took 0.035733 s
23/11/30 14:22:24 INFO FileFormatWriter: Start to commit write Job a5d7dddd-7f90-4bc4-b57c-0b01ed429fec.
23/11/30 14:22:24 INFO FileFormatWriter: Write Job a5d7dddd-7f90-4bc4-b57c-0b01ed429fec committed. Elapsed time: 6 ms.
23/11/30 14:22:24 INFO FileFormatWriter: Finished processing stats for write job a5d7dddd-7f90-4bc4-b57c-0b01ed429fec.
23/11/30 14:22:24 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
23/11/30 14:22:24 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:76
23/11/30 14:22:24 INFO DAGScheduler: Got job 169 (parquet at SparkTest.worksheet.sc:76) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 229 (parquet at SparkTest.worksheet.sc:76)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 229 (MapPartitionsRDD[566] at parquet at SparkTest.worksheet.sc:76), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_189 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_189_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_189_piece0 in memory on 10.25.86.80:43823 (size: 36.9 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 189 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 229 (MapPartitionsRDD[566] at parquet at SparkTest.worksheet.sc:76) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 229.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 229.0 (TID 169) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 229.0 (TID 169)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 229.0 (TID 169). 2042 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 229.0 (TID 169) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 229.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 229 (parquet at SparkTest.worksheet.sc:76) finished in 0.041 s
23/11/30 14:22:24 INFO DAGScheduler: Job 169 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 229: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 169 finished: parquet at SparkTest.worksheet.sc:76, took 0.042296 s
23/11/30 14:22:24 INFO FileSourceStrategy: Pushed Filters: 
23/11/30 14:22:24 INFO FileSourceStrategy: Post-Scan Filters: 
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 5.767039 ms
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_190 stored as values in memory (estimated size 200.8 KiB, free 433.8 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_190_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_190_piece0 in memory on 10.25.86.80:43823 (size: 34.9 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 190 from show at SparkTest.worksheet.sc:81
23/11/30 14:22:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/11/30 14:22:24 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:81
23/11/30 14:22:24 INFO DAGScheduler: Got job 170 (show at SparkTest.worksheet.sc:81) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 230 (show at SparkTest.worksheet.sc:81)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 230 (MapPartitionsRDD[570] at show at SparkTest.worksheet.sc:81), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_191 stored as values in memory (estimated size 16.6 KiB, free 433.7 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_191_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 433.7 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_191_piece0 in memory on 10.25.86.80:43823 (size: 6.8 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 191 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 230 (MapPartitionsRDD[570] at show at SparkTest.worksheet.sc:81) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 230.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 230.0 (TID 170) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 230.0 (TID 170)
23/11/30 14:22:24 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-36755562-c7d7-4792-b108-cb8347f9d932-c000.snappy.parquet, range: 0-1246, partition values: [empty row]
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 230.0 (TID 170). 1928 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 230.0 (TID 170) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 230.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 230 (show at SparkTest.worksheet.sc:81) finished in 0.008 s
23/11/30 14:22:24 INFO DAGScheduler: Job 170 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 230: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 170 finished: show at SparkTest.worksheet.sc:81, took 0.009162 s
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 4.289067 ms
23/11/30 14:22:24 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:94
23/11/30 14:22:24 INFO DAGScheduler: Got job 171 (show at SparkTest.worksheet.sc:94) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 231 (show at SparkTest.worksheet.sc:94)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 231 (MapPartitionsRDD[572] at show at SparkTest.worksheet.sc:94), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_192 stored as values in memory (estimated size 15.7 KiB, free 433.7 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_192_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 433.7 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_192_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 192 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 231 (MapPartitionsRDD[572] at show at SparkTest.worksheet.sc:94) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 231.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 231.0 (TID 171) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 231.0 (TID 171)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 231.0 (TID 171). 1640 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 231.0 (TID 171) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 231.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 231 (show at SparkTest.worksheet.sc:94) finished in 0.006 s
23/11/30 14:22:24 INFO DAGScheduler: Job 171 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 231: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 171 finished: show at SparkTest.worksheet.sc:94, took 0.007416 s
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 2.823715 ms
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 3.594682 ms
23/11/30 14:22:24 INFO DAGScheduler: Registering RDD 574 (collect at SparkTest.worksheet.sc:102) as input to shuffle 45
23/11/30 14:22:24 INFO DAGScheduler: Got map stage job 172 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ShuffleMapStage 232 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ShuffleMapStage 232 (MapPartitionsRDD[574] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_193 stored as values in memory (estimated size 19.2 KiB, free 433.7 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_193_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 433.7 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_193_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 193 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 232 (MapPartitionsRDD[574] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 232.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 232.0 (TID 172) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 232.0 (TID 172)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 232.0 (TID 172). 1930 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 232.0 (TID 172) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 232.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ShuffleMapStage 232 (collect at SparkTest.worksheet.sc:102) finished in 0.007 s
23/11/30 14:22:24 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:24 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 3.632539 ms
23/11/30 14:22:24 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:102
23/11/30 14:22:24 INFO DAGScheduler: Got job 173 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 234 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 233)
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 234 (MapPartitionsRDD[577] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_194 stored as values in memory (estimated size 14.3 KiB, free 433.6 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_194_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 433.6 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_194_piece0 in memory on 10.25.86.80:43823 (size: 6.6 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 194 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 234 (MapPartitionsRDD[577] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 234.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 234.0 (TID 173) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 234.0 (TID 173)
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 234.0 (TID 173). 4041 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 234.0 (TID 173) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 234.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 234 (collect at SparkTest.worksheet.sc:102) finished in 0.005 s
23/11/30 14:22:24 INFO DAGScheduler: Job 173 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 234: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 173 finished: collect at SparkTest.worksheet.sc:102, took 0.006073 s
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 2.665666 ms
23/11/30 14:22:24 INFO SparkContext: Starting job: show at Ast.scala:95
23/11/30 14:22:24 INFO DAGScheduler: Got job 174 (show at Ast.scala:95) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 235 (show at Ast.scala:95)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 235 (MapPartitionsRDD[579] at show at Ast.scala:95), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_195 stored as values in memory (estimated size 15.5 KiB, free 433.6 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_195_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 433.6 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_195_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 195 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 235 (MapPartitionsRDD[579] at show at Ast.scala:95) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 235.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 235.0 (TID 174) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 235.0 (TID 174)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 235.0 (TID 174). 1634 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 235.0 (TID 174) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 235.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 235 (show at Ast.scala:95) finished in 0.006 s
23/11/30 14:22:24 INFO DAGScheduler: Job 174 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 235: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 174 finished: show at Ast.scala:95, took 0.006731 s
23/11/30 14:22:24 INFO SparkContext: Starting job: show at Ast.scala:96
23/11/30 14:22:24 INFO DAGScheduler: Got job 175 (show at Ast.scala:96) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 236 (show at Ast.scala:96)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 236 (MapPartitionsRDD[581] at show at Ast.scala:96), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_196 stored as values in memory (estimated size 15.5 KiB, free 433.6 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_196_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 433.6 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_196_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 196 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 236 (MapPartitionsRDD[581] at show at Ast.scala:96) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 236.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 236.0 (TID 175) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 236.0 (TID 175)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 236.0 (TID 175). 1634 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 236.0 (TID 175) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 236.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 236 (show at Ast.scala:96) finished in 0.005 s
23/11/30 14:22:24 INFO DAGScheduler: Job 175 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 236: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 175 finished: show at Ast.scala:96, took 0.006287 s
23/11/30 14:22:24 INFO DAGScheduler: Registering RDD 583 (show at Ast.scala:108) as input to shuffle 46
23/11/30 14:22:24 INFO DAGScheduler: Got map stage job 176 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ShuffleMapStage 237 (show at Ast.scala:108)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ShuffleMapStage 237 (MapPartitionsRDD[583] at show at Ast.scala:108), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_197 stored as values in memory (estimated size 17.7 KiB, free 433.6 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_197_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.6 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_197_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 197 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 237 (MapPartitionsRDD[583] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 237.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 237.0 (TID 176) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 237.0 (TID 176)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 237.0 (TID 176). 1991 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 237.0 (TID 176) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 237.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ShuffleMapStage 237 (show at Ast.scala:108) finished in 0.008 s
23/11/30 14:22:24 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:24 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:24 INFO ShufflePartitionsUtil: For shuffle(46, 46), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 5.410535 ms
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 3.19599 ms
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 2.907053 ms
23/11/30 14:22:24 INFO SparkContext: Starting job: show at Ast.scala:108
23/11/30 14:22:24 INFO DAGScheduler: Got job 177 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 239 (show at Ast.scala:108)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 238)
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 239 (MapPartitionsRDD[590] at show at Ast.scala:108), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_198 stored as values in memory (estimated size 40.1 KiB, free 433.5 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_198_piece0 stored as bytes in memory (estimated size 16.2 KiB, free 433.5 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_198_piece0 in memory on 10.25.86.80:43823 (size: 16.2 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 198 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 239 (MapPartitionsRDD[590] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 239.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 239.0 (TID 177) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 239.0 (TID 177)
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 239.0 (TID 177). 4898 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 239.0 (TID 177) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 239.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 239 (show at Ast.scala:108) finished in 0.008 s
23/11/30 14:22:24 INFO DAGScheduler: Job 177 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 239: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 177 finished: show at Ast.scala:108, took 0.009793 s
23/11/30 14:22:24 INFO DAGScheduler: Registering RDD 592 (show at Ast.scala:112) as input to shuffle 47
23/11/30 14:22:24 INFO DAGScheduler: Got map stage job 178 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ShuffleMapStage 240 (show at Ast.scala:112)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ShuffleMapStage 240 (MapPartitionsRDD[592] at show at Ast.scala:112), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_199 stored as values in memory (estimated size 17.7 KiB, free 433.5 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_199_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.5 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_199_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 199 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 240 (MapPartitionsRDD[592] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 240.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 240.0 (TID 178) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 240.0 (TID 178)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 240.0 (TID 178). 1991 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 240.0 (TID 178) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 240.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ShuffleMapStage 240 (show at Ast.scala:112) finished in 0.008 s
23/11/30 14:22:24 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:24 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:24 INFO ShufflePartitionsUtil: For shuffle(47, 47), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:24 INFO SparkContext: Starting job: show at Ast.scala:112
23/11/30 14:22:24 INFO DAGScheduler: Got job 179 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 242 (show at Ast.scala:112)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 241)
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 242 (MapPartitionsRDD[599] at show at Ast.scala:112), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_200 stored as values in memory (estimated size 40.1 KiB, free 433.4 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_200_piece0 stored as bytes in memory (estimated size 16.2 KiB, free 433.4 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_200_piece0 in memory on 10.25.86.80:43823 (size: 16.2 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 200 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 242 (MapPartitionsRDD[599] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 242.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 242.0 (TID 179) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 242.0 (TID 179)
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 242.0 (TID 179). 4898 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 242.0 (TID 179) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 242.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 242 (show at Ast.scala:112) finished in 0.007 s
23/11/30 14:22:24 INFO DAGScheduler: Job 179 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 242: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 179 finished: show at Ast.scala:112, took 0.008679 s
23/11/30 14:22:24 INFO SparkContext: Starting job: show at Ast.scala:113
23/11/30 14:22:24 INFO DAGScheduler: Got job 180 (show at Ast.scala:113) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 243 (show at Ast.scala:113)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 243 (MapPartitionsRDD[601] at show at Ast.scala:113), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_201 stored as values in memory (estimated size 15.5 KiB, free 433.4 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_201_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 433.4 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_201_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 201 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 243 (MapPartitionsRDD[601] at show at Ast.scala:113) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 243.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 243.0 (TID 180) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 243.0 (TID 180)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 243.0 (TID 180). 1591 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 243.0 (TID 180) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 243.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 243 (show at Ast.scala:113) finished in 0.004 s
23/11/30 14:22:24 INFO DAGScheduler: Job 180 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 243: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 180 finished: show at Ast.scala:113, took 0.005371 s
23/11/30 14:22:24 INFO DAGScheduler: Registering RDD 603 (show at Ast.scala:126) as input to shuffle 48
23/11/30 14:22:24 INFO DAGScheduler: Got map stage job 181 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ShuffleMapStage 244 (show at Ast.scala:126)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ShuffleMapStage 244 (MapPartitionsRDD[603] at show at Ast.scala:126), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_202 stored as values in memory (estimated size 17.7 KiB, free 433.4 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_202_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.4 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_202_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.1 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 202 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 244 (MapPartitionsRDD[603] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 244.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_198_piece0 on 10.25.86.80:43823 in memory (size: 16.2 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 244.0 (TID 181) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 244.0 (TID 181)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_191_piece0 on 10.25.86.80:43823 in memory (size: 6.8 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_200_piece0 on 10.25.86.80:43823 in memory (size: 16.2 KiB, free: 434.2 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_188_piece0 on 10.25.86.80:43823 in memory (size: 76.7 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_195_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_194_piece0 on 10.25.86.80:43823 in memory (size: 6.6 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_187_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_193_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_196_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_192_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 244.0 (TID 181). 1991 bytes result sent to driver
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_190_piece0 on 10.25.86.80:43823 in memory (size: 34.9 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 244.0 (TID 181) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_201_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 244.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ShuffleMapStage 244 (show at Ast.scala:126) finished in 0.018 s
23/11/30 14:22:24 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:24 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_197_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_199_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_189_piece0 on 10.25.86.80:43823 in memory (size: 36.9 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO ShufflePartitionsUtil: For shuffle(48, 48), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 5.119231 ms
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 2.945093 ms
23/11/30 14:22:24 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:24 INFO DAGScheduler: Got job 182 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 246 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 245)
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 246 (MapPartitionsRDD[610] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_203 stored as values in memory (estimated size 38.7 KiB, free 434.3 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_203_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_203_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 203 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 246 (MapPartitionsRDD[610] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 246.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 246.0 (TID 182) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 246.0 (TID 182)
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 246.0 (TID 182). 4897 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 246.0 (TID 182) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 246.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 246 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.007 s
23/11/30 14:22:24 INFO DAGScheduler: Job 182 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 246: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 182 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.008574 s
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 2.452504 ms
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_204 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_204_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_204_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 204 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:24 INFO ShufflePartitionsUtil: For shuffle(48), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 3.752615 ms
23/11/30 14:22:24 INFO SparkContext: Starting job: show at Ast.scala:126
23/11/30 14:22:24 INFO DAGScheduler: Got job 183 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 248 (show at Ast.scala:126)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 247)
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 248 (MapPartitionsRDD[613] at show at Ast.scala:126), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_205 stored as values in memory (estimated size 15.1 KiB, free 433.3 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_205_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_205_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 205 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 248 (MapPartitionsRDD[613] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 248.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 248.0 (TID 183) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 248.0 (TID 183)
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 248.0 (TID 183). 4122 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 248.0 (TID 183) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 248.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 248 (show at Ast.scala:126) finished in 0.005 s
23/11/30 14:22:24 INFO DAGScheduler: Job 183 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 248: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 183 finished: show at Ast.scala:126, took 0.005846 s
23/11/30 14:22:24 INFO DAGScheduler: Registering RDD 615 (show at SparkTest.worksheet.sc:115) as input to shuffle 49
23/11/30 14:22:24 INFO DAGScheduler: Got map stage job 184 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ShuffleMapStage 249 (show at SparkTest.worksheet.sc:115)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ShuffleMapStage 249 (MapPartitionsRDD[615] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_206 stored as values in memory (estimated size 17.7 KiB, free 433.3 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_206_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_206_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 206 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 249 (MapPartitionsRDD[615] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 249.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 249.0 (TID 184) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 249.0 (TID 184)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_203_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_205_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_204_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Removed broadcast_202_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 249.0 (TID 184). 2077 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 249.0 (TID 184) in 22 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 249.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ShuffleMapStage 249 (show at SparkTest.worksheet.sc:115) finished in 0.024 s
23/11/30 14:22:24 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:24 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:24 INFO ShufflePartitionsUtil: For shuffle(49, 49), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:24 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:24 INFO DAGScheduler: Got job 185 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 251 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 250)
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 251 (MapPartitionsRDD[622] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_207 stored as values in memory (estimated size 38.7 KiB, free 434.3 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_207_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_207_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 207 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 251 (MapPartitionsRDD[622] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 251.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 251.0 (TID 185) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 251.0 (TID 185)
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 251.0 (TID 185). 4897 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 251.0 (TID 185) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 251.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 251 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.008 s
23/11/30 14:22:24 INFO DAGScheduler: Job 185 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 251: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 185 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.009276 s
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_208 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_208_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_208_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 208 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:24 INFO ShufflePartitionsUtil: For shuffle(49), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:24 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:115
23/11/30 14:22:24 INFO DAGScheduler: Got job 186 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 253 (show at SparkTest.worksheet.sc:115)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 252)
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 253 (MapPartitionsRDD[625] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_209 stored as values in memory (estimated size 15.1 KiB, free 433.3 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_209_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_209_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 209 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 253 (MapPartitionsRDD[625] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 253.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 253.0 (TID 186) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 253.0 (TID 186)
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 253.0 (TID 186). 4165 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 253.0 (TID 186) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 253.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 253 (show at SparkTest.worksheet.sc:115) finished in 0.006 s
23/11/30 14:22:24 INFO DAGScheduler: Job 186 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 253: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 186 finished: show at SparkTest.worksheet.sc:115, took 0.006424 s
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 3.825251 ms
23/11/30 14:22:24 INFO DAGScheduler: Registering RDD 627 (isEmpty at SparkTest.worksheet.sc:120) as input to shuffle 50
23/11/30 14:22:24 INFO DAGScheduler: Got map stage job 187 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ShuffleMapStage 254 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ShuffleMapStage 254 (MapPartitionsRDD[627] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_210 stored as values in memory (estimated size 17.3 KiB, free 433.3 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_210_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 433.3 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_210_piece0 in memory on 10.25.86.80:43823 (size: 7.5 KiB, free: 434.4 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 210 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 254 (MapPartitionsRDD[627] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 254.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 254.0 (TID 187) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 254.0 (TID 187)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 254.0 (TID 187). 1991 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 254.0 (TID 187) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 254.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ShuffleMapStage 254 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.009 s
23/11/30 14:22:24 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:24 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:24 INFO ShufflePartitionsUtil: For shuffle(50, 50), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 4.55857 ms
23/11/30 14:22:24 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:24 INFO DAGScheduler: Got job 188 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 256 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 255)
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 256 (MapPartitionsRDD[634] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_211 stored as values in memory (estimated size 35.3 KiB, free 433.2 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_211_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 433.2 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_211_piece0 in memory on 10.25.86.80:43823 (size: 14.5 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 211 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 256 (MapPartitionsRDD[634] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 256.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 256.0 (TID 188) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 256.0 (TID 188)
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 256.0 (TID 188). 4817 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 256.0 (TID 188) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 256.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 256 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.037 s
23/11/30 14:22:24 INFO DAGScheduler: Job 188 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 256: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 188 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.038097 s
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_212 stored as values in memory (estimated size 1024.1 KiB, free 432.2 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_212_piece0 stored as bytes in memory (estimated size 251.0 B, free 432.2 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_212_piece0 in memory on 10.25.86.80:43823 (size: 251.0 B, free: 434.3 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 212 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:24 INFO ShufflePartitionsUtil: For shuffle(50), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 4.300713 ms
23/11/30 14:22:24 INFO SparkContext: Starting job: isEmpty at SparkTest.worksheet.sc:120
23/11/30 14:22:24 INFO DAGScheduler: Got job 189 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 258 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 257)
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 258 (MapPartitionsRDD[637] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_213 stored as values in memory (estimated size 13.3 KiB, free 432.2 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_213_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 432.2 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_213_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 213 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 258 (MapPartitionsRDD[637] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 258.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 258.0 (TID 189) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 258.0 (TID 189)
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 258.0 (TID 189). 3176 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 258.0 (TID 189) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 258.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 258 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.005 s
23/11/30 14:22:24 INFO DAGScheduler: Job 189 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 258: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 189 finished: isEmpty at SparkTest.worksheet.sc:120, took 0.005989 s
23/11/30 14:22:24 INFO CodeGenerator: Code generated in 3.453782 ms
23/11/30 14:22:24 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:24 INFO DAGScheduler: Got job 190 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ResultStage 259 (collect at Ast.scala:253)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ResultStage 259 (MapPartitionsRDD[641] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_214 stored as values in memory (estimated size 17.5 KiB, free 432.2 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_214_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 432.2 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_214_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 214 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 259 (MapPartitionsRDD[641] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 259.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 259.0 (TID 190) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 259.0 (TID 190)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 259.0 (TID 190). 1826 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 259.0 (TID 190) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 259.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ResultStage 259 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:22:24 INFO DAGScheduler: Job 190 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 259: Stage finished
23/11/30 14:22:24 INFO DAGScheduler: Job 190 finished: collect at Ast.scala:253, took 0.008146 s
23/11/30 14:22:24 INFO DAGScheduler: Registering RDD 642 (collect at Ast.scala:253) as input to shuffle 51
23/11/30 14:22:24 INFO DAGScheduler: Got map stage job 191 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:24 INFO DAGScheduler: Final stage: ShuffleMapStage 260 (collect at Ast.scala:253)
23/11/30 14:22:24 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:24 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:24 INFO DAGScheduler: Submitting ShuffleMapStage 260 (MapPartitionsRDD[642] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_215 stored as values in memory (estimated size 19.0 KiB, free 432.2 MiB)
23/11/30 14:22:24 INFO MemoryStore: Block broadcast_215_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 432.2 MiB)
23/11/30 14:22:24 INFO BlockManagerInfo: Added broadcast_215_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:22:24 INFO SparkContext: Created broadcast 215 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 260 (MapPartitionsRDD[642] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:24 INFO TaskSchedulerImpl: Adding task set 260.0 with 1 tasks resource profile 0
23/11/30 14:22:24 INFO TaskSetManager: Starting task 0.0 in stage 260.0 (TID 191) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:24 INFO Executor: Running task 0.0 in stage 260.0 (TID 191)
23/11/30 14:22:24 INFO Executor: Finished task 0.0 in stage 260.0 (TID 191). 1793 bytes result sent to driver
23/11/30 14:22:24 INFO TaskSetManager: Finished task 0.0 in stage 260.0 (TID 191) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:24 INFO TaskSchedulerImpl: Removed TaskSet 260.0, whose tasks have all completed, from pool 
23/11/30 14:22:24 INFO DAGScheduler: ShuffleMapStage 260 (collect at Ast.scala:253) finished in 0.009 s
23/11/30 14:22:24 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:24 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:24 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:24 INFO ShufflePartitionsUtil: For shuffle(51), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:25 INFO CodeGenerator: Code generated in 3.861367 ms
23/11/30 14:22:25 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:25 INFO DAGScheduler: Got job 192 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:25 INFO DAGScheduler: Final stage: ResultStage 262 (collect at Ast.scala:253)
23/11/30 14:22:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 261)
23/11/30 14:22:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:25 INFO DAGScheduler: Submitting ResultStage 262 (MapPartitionsRDD[645] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_216 stored as values in memory (estimated size 24.9 KiB, free 432.1 MiB)
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_216_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 432.1 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Added broadcast_216_piece0 in memory on 10.25.86.80:43823 (size: 10.7 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO SparkContext: Created broadcast 216 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 262 (MapPartitionsRDD[645] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:25 INFO TaskSchedulerImpl: Adding task set 262.0 with 1 tasks resource profile 0
23/11/30 14:22:25 INFO TaskSetManager: Starting task 0.0 in stage 262.0 (TID 192) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:22:25 INFO Executor: Running task 0.0 in stage 262.0 (TID 192)
23/11/30 14:22:25 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:25 INFO Executor: Finished task 0.0 in stage 262.0 (TID 192). 4494 bytes result sent to driver
23/11/30 14:22:25 INFO TaskSetManager: Finished task 0.0 in stage 262.0 (TID 192) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:25 INFO TaskSchedulerImpl: Removed TaskSet 262.0, whose tasks have all completed, from pool 
23/11/30 14:22:25 INFO DAGScheduler: ResultStage 262 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:22:25 INFO DAGScheduler: Job 192 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 262: Stage finished
23/11/30 14:22:25 INFO DAGScheduler: Job 192 finished: collect at Ast.scala:253, took 0.007060 s
23/11/30 14:22:25 INFO CodeGenerator: Code generated in 2.956349 ms
23/11/30 14:22:25 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:25 INFO DAGScheduler: Got job 193 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:25 INFO DAGScheduler: Final stage: ResultStage 263 (collect at Ast.scala:253)
23/11/30 14:22:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:25 INFO DAGScheduler: Submitting ResultStage 263 (MapPartitionsRDD[649] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_217 stored as values in memory (estimated size 17.5 KiB, free 432.1 MiB)
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_217_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 432.1 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Added broadcast_217_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO SparkContext: Created broadcast 217 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 263 (MapPartitionsRDD[649] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:25 INFO TaskSchedulerImpl: Adding task set 263.0 with 1 tasks resource profile 0
23/11/30 14:22:25 INFO TaskSetManager: Starting task 0.0 in stage 263.0 (TID 193) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:25 INFO Executor: Running task 0.0 in stage 263.0 (TID 193)
23/11/30 14:22:25 INFO Executor: Finished task 0.0 in stage 263.0 (TID 193). 1826 bytes result sent to driver
23/11/30 14:22:25 INFO TaskSetManager: Finished task 0.0 in stage 263.0 (TID 193) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:25 INFO TaskSchedulerImpl: Removed TaskSet 263.0, whose tasks have all completed, from pool 
23/11/30 14:22:25 INFO DAGScheduler: ResultStage 263 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:22:25 INFO DAGScheduler: Job 193 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 263: Stage finished
23/11/30 14:22:25 INFO DAGScheduler: Job 193 finished: collect at Ast.scala:253, took 0.006360 s
23/11/30 14:22:25 INFO DAGScheduler: Registering RDD 650 (collect at Ast.scala:253) as input to shuffle 52
23/11/30 14:22:25 INFO DAGScheduler: Got map stage job 194 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:25 INFO DAGScheduler: Final stage: ShuffleMapStage 264 (collect at Ast.scala:253)
23/11/30 14:22:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:25 INFO DAGScheduler: Submitting ShuffleMapStage 264 (MapPartitionsRDD[650] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_218 stored as values in memory (estimated size 19.0 KiB, free 432.1 MiB)
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_218_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 432.1 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Added broadcast_218_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO SparkContext: Created broadcast 218 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 264 (MapPartitionsRDD[650] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:25 INFO TaskSchedulerImpl: Adding task set 264.0 with 1 tasks resource profile 0
23/11/30 14:22:25 INFO TaskSetManager: Starting task 0.0 in stage 264.0 (TID 194) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:25 INFO Executor: Running task 0.0 in stage 264.0 (TID 194)
23/11/30 14:22:25 INFO Executor: Finished task 0.0 in stage 264.0 (TID 194). 1793 bytes result sent to driver
23/11/30 14:22:25 INFO TaskSetManager: Finished task 0.0 in stage 264.0 (TID 194) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:25 INFO TaskSchedulerImpl: Removed TaskSet 264.0, whose tasks have all completed, from pool 
23/11/30 14:22:25 INFO DAGScheduler: ShuffleMapStage 264 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:22:25 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:25 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:25 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:25 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:25 INFO ShufflePartitionsUtil: For shuffle(52), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:25 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:25 INFO DAGScheduler: Got job 195 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:25 INFO DAGScheduler: Final stage: ResultStage 266 (collect at Ast.scala:253)
23/11/30 14:22:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 265)
23/11/30 14:22:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:25 INFO DAGScheduler: Submitting ResultStage 266 (MapPartitionsRDD[653] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_219 stored as values in memory (estimated size 24.9 KiB, free 432.0 MiB)
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_219_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 432.0 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Added broadcast_219_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO SparkContext: Created broadcast 219 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 266 (MapPartitionsRDD[653] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:25 INFO TaskSchedulerImpl: Adding task set 266.0 with 1 tasks resource profile 0
23/11/30 14:22:25 INFO TaskSetManager: Starting task 0.0 in stage 266.0 (TID 195) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:22:25 INFO Executor: Running task 0.0 in stage 266.0 (TID 195)
23/11/30 14:22:25 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:25 INFO Executor: Finished task 0.0 in stage 266.0 (TID 195). 4494 bytes result sent to driver
23/11/30 14:22:25 INFO TaskSetManager: Finished task 0.0 in stage 266.0 (TID 195) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:25 INFO TaskSchedulerImpl: Removed TaskSet 266.0, whose tasks have all completed, from pool 
23/11/30 14:22:25 INFO DAGScheduler: ResultStage 266 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:22:25 INFO DAGScheduler: Job 195 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 266: Stage finished
23/11/30 14:22:25 INFO DAGScheduler: Job 195 finished: collect at Ast.scala:253, took 0.006380 s
23/11/30 14:22:25 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:25 INFO DAGScheduler: Got job 196 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:25 INFO DAGScheduler: Final stage: ResultStage 267 (collect at Ast.scala:253)
23/11/30 14:22:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:25 INFO DAGScheduler: Submitting ResultStage 267 (MapPartitionsRDD[657] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_220 stored as values in memory (estimated size 17.5 KiB, free 432.0 MiB)
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_220_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 432.0 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Added broadcast_220_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO SparkContext: Created broadcast 220 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 267 (MapPartitionsRDD[657] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:25 INFO TaskSchedulerImpl: Adding task set 267.0 with 1 tasks resource profile 0
23/11/30 14:22:25 INFO TaskSetManager: Starting task 0.0 in stage 267.0 (TID 196) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:25 INFO Executor: Running task 0.0 in stage 267.0 (TID 196)
23/11/30 14:22:25 INFO Executor: Finished task 0.0 in stage 267.0 (TID 196). 1826 bytes result sent to driver
23/11/30 14:22:25 INFO TaskSetManager: Finished task 0.0 in stage 267.0 (TID 196) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:25 INFO TaskSchedulerImpl: Removed TaskSet 267.0, whose tasks have all completed, from pool 
23/11/30 14:22:25 INFO DAGScheduler: ResultStage 267 (collect at Ast.scala:253) finished in 0.005 s
23/11/30 14:22:25 INFO DAGScheduler: Job 196 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 267: Stage finished
23/11/30 14:22:25 INFO DAGScheduler: Job 196 finished: collect at Ast.scala:253, took 0.005939 s
23/11/30 14:22:25 INFO DAGScheduler: Registering RDD 658 (collect at Ast.scala:253) as input to shuffle 53
23/11/30 14:22:25 INFO DAGScheduler: Got map stage job 197 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:25 INFO DAGScheduler: Final stage: ShuffleMapStage 268 (collect at Ast.scala:253)
23/11/30 14:22:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:25 INFO DAGScheduler: Submitting ShuffleMapStage 268 (MapPartitionsRDD[658] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_221 stored as values in memory (estimated size 19.0 KiB, free 432.0 MiB)
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_221_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 432.0 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Added broadcast_221_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO SparkContext: Created broadcast 221 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 268 (MapPartitionsRDD[658] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:25 INFO TaskSchedulerImpl: Adding task set 268.0 with 1 tasks resource profile 0
23/11/30 14:22:25 INFO TaskSetManager: Starting task 0.0 in stage 268.0 (TID 197) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:25 INFO Executor: Running task 0.0 in stage 268.0 (TID 197)
23/11/30 14:22:25 INFO Executor: Finished task 0.0 in stage 268.0 (TID 197). 1793 bytes result sent to driver
23/11/30 14:22:25 INFO TaskSetManager: Finished task 0.0 in stage 268.0 (TID 197) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:25 INFO TaskSchedulerImpl: Removed TaskSet 268.0, whose tasks have all completed, from pool 
23/11/30 14:22:25 INFO DAGScheduler: ShuffleMapStage 268 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:22:25 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:25 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:25 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:25 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:25 INFO ShufflePartitionsUtil: For shuffle(53), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:25 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:25 INFO DAGScheduler: Got job 198 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:25 INFO DAGScheduler: Final stage: ResultStage 270 (collect at Ast.scala:253)
23/11/30 14:22:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 269)
23/11/30 14:22:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:25 INFO DAGScheduler: Submitting ResultStage 270 (MapPartitionsRDD[661] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_222 stored as values in memory (estimated size 24.9 KiB, free 432.0 MiB)
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_222_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 432.0 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Added broadcast_222_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO SparkContext: Created broadcast 222 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 270 (MapPartitionsRDD[661] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:25 INFO TaskSchedulerImpl: Adding task set 270.0 with 1 tasks resource profile 0
23/11/30 14:22:25 INFO TaskSetManager: Starting task 0.0 in stage 270.0 (TID 198) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:22:25 INFO Executor: Running task 0.0 in stage 270.0 (TID 198)
23/11/30 14:22:25 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:25 INFO Executor: Finished task 0.0 in stage 270.0 (TID 198). 4494 bytes result sent to driver
23/11/30 14:22:25 INFO TaskSetManager: Finished task 0.0 in stage 270.0 (TID 198) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:25 INFO TaskSchedulerImpl: Removed TaskSet 270.0, whose tasks have all completed, from pool 
23/11/30 14:22:25 INFO DAGScheduler: ResultStage 270 (collect at Ast.scala:253) finished in 0.005 s
23/11/30 14:22:25 INFO DAGScheduler: Job 198 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 270: Stage finished
23/11/30 14:22:25 INFO DAGScheduler: Job 198 finished: collect at Ast.scala:253, took 0.006080 s
23/11/30 14:22:25 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:150
23/11/30 14:22:25 INFO DAGScheduler: Got job 199 (show at SparkTest.worksheet.sc:150) with 1 output partitions
23/11/30 14:22:25 INFO DAGScheduler: Final stage: ResultStage 271 (show at SparkTest.worksheet.sc:150)
23/11/30 14:22:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:25 INFO DAGScheduler: Submitting ResultStage 271 (MapPartitionsRDD[663] at show at SparkTest.worksheet.sc:150), which has no missing parents
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_223 stored as values in memory (estimated size 15.7 KiB, free 431.9 MiB)
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_223_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 431.9 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Added broadcast_223_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO SparkContext: Created broadcast 223 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 271 (MapPartitionsRDD[663] at show at SparkTest.worksheet.sc:150) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:25 INFO TaskSchedulerImpl: Adding task set 271.0 with 1 tasks resource profile 0
23/11/30 14:22:25 INFO TaskSetManager: Starting task 0.0 in stage 271.0 (TID 199) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:25 INFO Executor: Running task 0.0 in stage 271.0 (TID 199)
23/11/30 14:22:25 INFO Executor: Finished task 0.0 in stage 271.0 (TID 199). 1640 bytes result sent to driver
23/11/30 14:22:25 INFO TaskSetManager: Finished task 0.0 in stage 271.0 (TID 199) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:25 INFO TaskSchedulerImpl: Removed TaskSet 271.0, whose tasks have all completed, from pool 
23/11/30 14:22:25 INFO DAGScheduler: ResultStage 271 (show at SparkTest.worksheet.sc:150) finished in 0.006 s
23/11/30 14:22:25 INFO DAGScheduler: Job 199 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 271: Stage finished
23/11/30 14:22:25 INFO DAGScheduler: Job 199 finished: show at SparkTest.worksheet.sc:150, took 0.006521 s
23/11/30 14:22:25 INFO CodeGenerator: Code generated in 2.928017 ms
23/11/30 14:22:25 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:159
23/11/30 14:22:25 INFO DAGScheduler: Got job 200 (collect at SparkTest.worksheet.sc:159) with 1 output partitions
23/11/30 14:22:25 INFO DAGScheduler: Final stage: ResultStage 272 (collect at SparkTest.worksheet.sc:159)
23/11/30 14:22:25 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:25 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:25 INFO DAGScheduler: Submitting ResultStage 272 (MapPartitionsRDD[671] at collect at SparkTest.worksheet.sc:159), which has no missing parents
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_224 stored as values in memory (estimated size 15.4 KiB, free 431.9 MiB)
23/11/30 14:22:25 INFO MemoryStore: Block broadcast_224_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 431.9 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Added broadcast_224_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO SparkContext: Created broadcast 224 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 272 (MapPartitionsRDD[671] at collect at SparkTest.worksheet.sc:159) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:25 INFO TaskSchedulerImpl: Adding task set 272.0 with 1 tasks resource profile 0
23/11/30 14:22:25 INFO TaskSetManager: Starting task 0.0 in stage 272.0 (TID 200) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:25 INFO Executor: Running task 0.0 in stage 272.0 (TID 200)
23/11/30 14:22:25 INFO Executor: Finished task 0.0 in stage 272.0 (TID 200). 1607 bytes result sent to driver
23/11/30 14:22:25 INFO TaskSetManager: Finished task 0.0 in stage 272.0 (TID 200) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:25 INFO TaskSchedulerImpl: Removed TaskSet 272.0, whose tasks have all completed, from pool 
23/11/30 14:22:25 INFO DAGScheduler: ResultStage 272 (collect at SparkTest.worksheet.sc:159) finished in 0.005 s
23/11/30 14:22:25 INFO DAGScheduler: Job 200 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 272: Stage finished
23/11/30 14:22:25 INFO DAGScheduler: Job 200 finished: collect at SparkTest.worksheet.sc:159, took 0.006057 s
23/11/30 14:22:25 INFO CodeGenerator: Code generated in 2.843408 ms
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_221_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_222_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_207_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_210_piece0 on 10.25.86.80:43823 in memory (size: 7.5 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_212_piece0 on 10.25.86.80:43823 in memory (size: 251.0 B, free: 434.3 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_211_piece0 on 10.25.86.80:43823 in memory (size: 14.5 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_217_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_220_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_214_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_223_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_218_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_216_piece0 on 10.25.86.80:43823 in memory (size: 10.7 KiB, free: 434.4 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_209_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_213_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_206_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_224_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_208_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_215_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:22:25 INFO BlockManagerInfo: Removed broadcast_219_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
2023.11.30 14:22:25 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 1.56s[0m
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 4.762641 ms
23/11/30 14:22:43 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:62
23/11/30 14:22:43 INFO DAGScheduler: Got job 201 (show at SparkTest.worksheet.sc:62) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 273 (show at SparkTest.worksheet.sc:62)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 273 (MapPartitionsRDD[675] at show at SparkTest.worksheet.sc:62), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_225 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_225_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_225_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 225 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 273 (MapPartitionsRDD[675] at show at SparkTest.worksheet.sc:62) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 273.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 273.0 (TID 201) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 273.0 (TID 201)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 273.0 (TID 201). 1634 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 273.0 (TID 201) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 273.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 273 (show at SparkTest.worksheet.sc:62) finished in 0.011 s
23/11/30 14:22:43 INFO DAGScheduler: Job 201 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 273: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 201 finished: show at SparkTest.worksheet.sc:62, took 0.011129 s
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 3.089255 ms
23/11/30 14:22:43 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:22:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:22:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:22:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:22:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:22:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:22:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 2.53451 ms
23/11/30 14:22:43 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:72
23/11/30 14:22:43 INFO DAGScheduler: Got job 202 (parquet at SparkTest.worksheet.sc:72) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 274 (parquet at SparkTest.worksheet.sc:72)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 274 (MapPartitionsRDD[677] at parquet at SparkTest.worksheet.sc:72), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_226 stored as values in memory (estimated size 215.6 KiB, free 434.2 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_226_piece0 stored as bytes in memory (estimated size 76.7 KiB, free 434.1 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_226_piece0 in memory on 10.25.86.80:43823 (size: 76.7 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 226 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 274 (MapPartitionsRDD[677] at parquet at SparkTest.worksheet.sc:72) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 274.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 274.0 (TID 202) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 274.0 (TID 202)
23/11/30 14:22:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:22:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:22:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:22:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/30 14:22:43 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/30 14:22:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/30 14:22:43 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:22:43 INFO CodecConfig: Compression: SNAPPY
23/11/30 14:22:43 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/30 14:22:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "index",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 index;
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/30 14:22:43 INFO FileOutputCommitter: Saved output of task 'attempt_202311301422436003512431838912199_0274_m_000000_202' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311301422436003512431838912199_0274_m_000000
23/11/30 14:22:43 INFO SparkHadoopMapRedUtil: attempt_202311301422436003512431838912199_0274_m_000000_202: Committed. Elapsed time: 0 ms.
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 274.0 (TID 202). 2699 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 274.0 (TID 202) in 21 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 274.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 274 (parquet at SparkTest.worksheet.sc:72) finished in 0.030 s
23/11/30 14:22:43 INFO DAGScheduler: Job 202 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 274: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 202 finished: parquet at SparkTest.worksheet.sc:72, took 0.030952 s
23/11/30 14:22:43 INFO FileFormatWriter: Start to commit write Job be88cf18-cd80-46a0-8330-c78bfb657b40.
23/11/30 14:22:43 INFO FileFormatWriter: Write Job be88cf18-cd80-46a0-8330-c78bfb657b40 committed. Elapsed time: 5 ms.
23/11/30 14:22:43 INFO FileFormatWriter: Finished processing stats for write job be88cf18-cd80-46a0-8330-c78bfb657b40.
23/11/30 14:22:43 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.
23/11/30 14:22:43 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:76
23/11/30 14:22:43 INFO DAGScheduler: Got job 203 (parquet at SparkTest.worksheet.sc:76) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 275 (parquet at SparkTest.worksheet.sc:76)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 275 (MapPartitionsRDD[679] at parquet at SparkTest.worksheet.sc:76), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_227 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_227_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_227_piece0 in memory on 10.25.86.80:43823 (size: 36.9 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 227 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 275 (MapPartitionsRDD[679] at parquet at SparkTest.worksheet.sc:76) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 275.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 275.0 (TID 203) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 275.0 (TID 203)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 275.0 (TID 203). 2042 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 275.0 (TID 203) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 275.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 275 (parquet at SparkTest.worksheet.sc:76) finished in 0.011 s
23/11/30 14:22:43 INFO DAGScheduler: Job 203 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 275: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 203 finished: parquet at SparkTest.worksheet.sc:76, took 0.012164 s
23/11/30 14:22:43 INFO FileSourceStrategy: Pushed Filters: 
23/11/30 14:22:43 INFO FileSourceStrategy: Post-Scan Filters: 
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 4.447928 ms
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_228 stored as values in memory (estimated size 200.8 KiB, free 433.8 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_228_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_228_piece0 in memory on 10.25.86.80:43823 (size: 34.9 KiB, free: 434.2 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 228 from show at SparkTest.worksheet.sc:81
23/11/30 14:22:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/11/30 14:22:43 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:81
23/11/30 14:22:43 INFO DAGScheduler: Got job 204 (show at SparkTest.worksheet.sc:81) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 276 (show at SparkTest.worksheet.sc:81)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 276 (MapPartitionsRDD[683] at show at SparkTest.worksheet.sc:81), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_229 stored as values in memory (estimated size 16.6 KiB, free 433.7 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_229_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 433.7 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_229_piece0 in memory on 10.25.86.80:43823 (size: 6.8 KiB, free: 434.2 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 229 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 276 (MapPartitionsRDD[683] at show at SparkTest.worksheet.sc:81) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 276.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 276.0 (TID 204) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 276.0 (TID 204)
23/11/30 14:22:43 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-e76bf2ab-5acc-4263-98b9-db6f9cddb55a-c000.snappy.parquet, range: 0-1246, partition values: [empty row]
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 276.0 (TID 204). 1928 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 276.0 (TID 204) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 276.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 276 (show at SparkTest.worksheet.sc:81) finished in 0.008 s
23/11/30 14:22:43 INFO DAGScheduler: Job 204 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 276: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 204 finished: show at SparkTest.worksheet.sc:81, took 0.009614 s
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_229_piece0 on 10.25.86.80:43823 in memory (size: 6.8 KiB, free: 434.2 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_227_piece0 on 10.25.86.80:43823 in memory (size: 36.9 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_225_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_226_piece0 on 10.25.86.80:43823 in memory (size: 76.7 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 13.655443 ms
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_228_piece0 on 10.25.86.80:43823 in memory (size: 34.9 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:94
23/11/30 14:22:43 INFO DAGScheduler: Got job 205 (show at SparkTest.worksheet.sc:94) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 277 (show at SparkTest.worksheet.sc:94)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 277 (MapPartitionsRDD[685] at show at SparkTest.worksheet.sc:94), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_230 stored as values in memory (estimated size 15.7 KiB, free 434.4 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_230_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_230_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 230 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 277 (MapPartitionsRDD[685] at show at SparkTest.worksheet.sc:94) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 277.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 277.0 (TID 205) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 277.0 (TID 205)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 277.0 (TID 205). 1640 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 277.0 (TID 205) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 277.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 277 (show at SparkTest.worksheet.sc:94) finished in 0.006 s
23/11/30 14:22:43 INFO DAGScheduler: Job 205 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 277: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 205 finished: show at SparkTest.worksheet.sc:94, took 0.007089 s
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 2.942512 ms
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 5.169042 ms
23/11/30 14:22:43 INFO DAGScheduler: Registering RDD 687 (collect at SparkTest.worksheet.sc:102) as input to shuffle 54
23/11/30 14:22:43 INFO DAGScheduler: Got map stage job 206 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ShuffleMapStage 278 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 278 (MapPartitionsRDD[687] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_231 stored as values in memory (estimated size 19.2 KiB, free 434.4 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_231_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_231_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 231 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 278 (MapPartitionsRDD[687] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 278.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 278.0 (TID 206) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 278.0 (TID 206)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 278.0 (TID 206). 1930 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 278.0 (TID 206) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 278.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ShuffleMapStage 278 (collect at SparkTest.worksheet.sc:102) finished in 0.006 s
23/11/30 14:22:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 3.372615 ms
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_230_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:102
23/11/30 14:22:43 INFO DAGScheduler: Got job 207 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 280 (collect at SparkTest.worksheet.sc:102)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 279)
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_231_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 280 (MapPartitionsRDD[690] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_232 stored as values in memory (estimated size 14.3 KiB, free 434.4 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_232_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_232_piece0 in memory on 10.25.86.80:43823 (size: 6.6 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 232 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 280 (MapPartitionsRDD[690] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 280.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 280.0 (TID 207) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 280.0 (TID 207)
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 280.0 (TID 207). 4041 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 280.0 (TID 207) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 280.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 280 (collect at SparkTest.worksheet.sc:102) finished in 0.012 s
23/11/30 14:22:43 INFO DAGScheduler: Job 207 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 280: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 207 finished: collect at SparkTest.worksheet.sc:102, took 0.013336 s
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 3.55067 ms
23/11/30 14:22:43 INFO SparkContext: Starting job: show at Ast.scala:95
23/11/30 14:22:43 INFO DAGScheduler: Got job 208 (show at Ast.scala:95) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 281 (show at Ast.scala:95)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 281 (MapPartitionsRDD[692] at show at Ast.scala:95), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_233 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_233_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_233_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 233 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 281 (MapPartitionsRDD[692] at show at Ast.scala:95) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 281.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 281.0 (TID 208) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 281.0 (TID 208)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 281.0 (TID 208). 1634 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 281.0 (TID 208) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 281.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 281 (show at Ast.scala:95) finished in 0.005 s
23/11/30 14:22:43 INFO DAGScheduler: Job 208 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 281: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 208 finished: show at Ast.scala:95, took 0.006629 s
23/11/30 14:22:43 INFO SparkContext: Starting job: show at Ast.scala:96
23/11/30 14:22:43 INFO DAGScheduler: Got job 209 (show at Ast.scala:96) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 282 (show at Ast.scala:96)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 282 (MapPartitionsRDD[694] at show at Ast.scala:96), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_234 stored as values in memory (estimated size 15.5 KiB, free 434.3 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_234_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_234_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 234 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 282 (MapPartitionsRDD[694] at show at Ast.scala:96) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 282.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 282.0 (TID 209) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 282.0 (TID 209)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 282.0 (TID 209). 1634 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 282.0 (TID 209) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 282.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 282 (show at Ast.scala:96) finished in 0.006 s
23/11/30 14:22:43 INFO DAGScheduler: Job 209 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 282: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 209 finished: show at Ast.scala:96, took 0.006594 s
23/11/30 14:22:43 INFO DAGScheduler: Registering RDD 696 (show at Ast.scala:108) as input to shuffle 55
23/11/30 14:22:43 INFO DAGScheduler: Got map stage job 210 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ShuffleMapStage 283 (show at Ast.scala:108)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 283 (MapPartitionsRDD[696] at show at Ast.scala:108), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_235 stored as values in memory (estimated size 17.7 KiB, free 434.3 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_235_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_235_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 235 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 283 (MapPartitionsRDD[696] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 283.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 283.0 (TID 210) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 283.0 (TID 210)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 283.0 (TID 210). 1991 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 283.0 (TID 210) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 283.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ShuffleMapStage 283 (show at Ast.scala:108) finished in 0.008 s
23/11/30 14:22:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:43 INFO ShufflePartitionsUtil: For shuffle(55, 55), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 5.453914 ms
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 3.153397 ms
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 32.202942 ms
23/11/30 14:22:43 INFO SparkContext: Starting job: show at Ast.scala:108
23/11/30 14:22:43 INFO DAGScheduler: Got job 211 (show at Ast.scala:108) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 285 (show at Ast.scala:108)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 284)
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 285 (MapPartitionsRDD[703] at show at Ast.scala:108), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_236 stored as values in memory (estimated size 40.1 KiB, free 434.3 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_236_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_236_piece0 in memory on 10.25.86.80:43823 (size: 16.3 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 236 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 285 (MapPartitionsRDD[703] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 285.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 285.0 (TID 211) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 285.0 (TID 211)
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 285.0 (TID 211). 4898 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 285.0 (TID 211) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 285.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 285 (show at Ast.scala:108) finished in 0.009 s
23/11/30 14:22:43 INFO DAGScheduler: Job 211 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 285: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 211 finished: show at Ast.scala:108, took 0.010759 s
23/11/30 14:22:43 INFO DAGScheduler: Registering RDD 705 (show at Ast.scala:112) as input to shuffle 56
23/11/30 14:22:43 INFO DAGScheduler: Got map stage job 212 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ShuffleMapStage 286 (show at Ast.scala:112)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 286 (MapPartitionsRDD[705] at show at Ast.scala:112), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_237 stored as values in memory (estimated size 17.7 KiB, free 434.2 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_237_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.2 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_237_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 237 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 286 (MapPartitionsRDD[705] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 286.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 286.0 (TID 212) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 286.0 (TID 212)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 286.0 (TID 212). 1991 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 286.0 (TID 212) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 286.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ShuffleMapStage 286 (show at Ast.scala:112) finished in 0.008 s
23/11/30 14:22:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:43 INFO ShufflePartitionsUtil: For shuffle(56, 56), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:43 INFO SparkContext: Starting job: show at Ast.scala:112
23/11/30 14:22:43 INFO DAGScheduler: Got job 213 (show at Ast.scala:112) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 288 (show at Ast.scala:112)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 287)
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 288 (MapPartitionsRDD[712] at show at Ast.scala:112), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_238 stored as values in memory (estimated size 40.1 KiB, free 434.2 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_238_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.2 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_238_piece0 in memory on 10.25.86.80:43823 (size: 16.3 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 238 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 288 (MapPartitionsRDD[712] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 288.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 288.0 (TID 213) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 288.0 (TID 213)
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 288.0 (TID 213). 4898 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 288.0 (TID 213) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 288.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 288 (show at Ast.scala:112) finished in 0.010 s
23/11/30 14:22:43 INFO DAGScheduler: Job 213 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 288: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 213 finished: show at Ast.scala:112, took 0.010678 s
23/11/30 14:22:43 INFO SparkContext: Starting job: show at Ast.scala:113
23/11/30 14:22:43 INFO DAGScheduler: Got job 214 (show at Ast.scala:113) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 289 (show at Ast.scala:113)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 289 (MapPartitionsRDD[714] at show at Ast.scala:113), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_239 stored as values in memory (estimated size 15.5 KiB, free 434.2 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_239_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.2 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_239_piece0 in memory on 10.25.86.80:43823 (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 239 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 289 (MapPartitionsRDD[714] at show at Ast.scala:113) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 289.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 289.0 (TID 214) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 289.0 (TID 214)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 289.0 (TID 214). 1591 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 289.0 (TID 214) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 289.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 289 (show at Ast.scala:113) finished in 0.006 s
23/11/30 14:22:43 INFO DAGScheduler: Job 214 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 289: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 214 finished: show at Ast.scala:113, took 0.006062 s
23/11/30 14:22:43 INFO DAGScheduler: Registering RDD 716 (show at Ast.scala:126) as input to shuffle 57
23/11/30 14:22:43 INFO DAGScheduler: Got map stage job 215 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ShuffleMapStage 290 (show at Ast.scala:126)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 290 (MapPartitionsRDD[716] at show at Ast.scala:126), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_240 stored as values in memory (estimated size 17.7 KiB, free 434.1 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_240_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.1 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_240_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 240 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 290 (MapPartitionsRDD[716] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 290.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 290.0 (TID 215) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 290.0 (TID 215)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 290.0 (TID 215). 1991 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 290.0 (TID 215) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 290.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ShuffleMapStage 290 (show at Ast.scala:126) finished in 0.010 s
23/11/30 14:22:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:43 INFO ShufflePartitionsUtil: For shuffle(57, 57), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 4.96946 ms
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 2.920289 ms
23/11/30 14:22:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:43 INFO DAGScheduler: Got job 216 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 292 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 291)
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 292 (MapPartitionsRDD[723] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_241 stored as values in memory (estimated size 38.7 KiB, free 434.1 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_241_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.1 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_241_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 241 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 292 (MapPartitionsRDD[723] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 292.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 292.0 (TID 216) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 292.0 (TID 216)
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 292.0 (TID 216). 4897 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 292.0 (TID 216) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 292.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 292 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.010 s
23/11/30 14:22:43 INFO DAGScheduler: Job 216 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 292: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 216 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.011276 s
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 2.270223 ms
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_242 stored as values in memory (estimated size 1024.1 KiB, free 433.1 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_242_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.1 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_242_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 242 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:43 INFO ShufflePartitionsUtil: For shuffle(57), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 3.655438 ms
23/11/30 14:22:43 INFO SparkContext: Starting job: show at Ast.scala:126
23/11/30 14:22:43 INFO DAGScheduler: Got job 217 (show at Ast.scala:126) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 294 (show at Ast.scala:126)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 293)
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 294 (MapPartitionsRDD[726] at show at Ast.scala:126), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_243 stored as values in memory (estimated size 15.1 KiB, free 433.1 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_243_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.1 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_243_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 243 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 294 (MapPartitionsRDD[726] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 294.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 294.0 (TID 217) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 294.0 (TID 217)
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 294.0 (TID 217). 4165 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 294.0 (TID 217) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 294.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 294 (show at Ast.scala:126) finished in 0.005 s
23/11/30 14:22:43 INFO DAGScheduler: Job 217 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 294: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 217 finished: show at Ast.scala:126, took 0.006004 s
23/11/30 14:22:43 INFO DAGScheduler: Registering RDD 728 (show at SparkTest.worksheet.sc:115) as input to shuffle 58
23/11/30 14:22:43 INFO DAGScheduler: Got map stage job 218 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ShuffleMapStage 295 (show at SparkTest.worksheet.sc:115)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 295 (MapPartitionsRDD[728] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_244 stored as values in memory (estimated size 17.7 KiB, free 433.0 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_244_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.0 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_244_piece0 in memory on 10.25.86.80:43823 (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 244 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 295 (MapPartitionsRDD[728] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 295.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 295.0 (TID 218) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 295.0 (TID 218)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 295.0 (TID 218). 1991 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 295.0 (TID 218) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 295.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ShuffleMapStage 295 (show at SparkTest.worksheet.sc:115) finished in 0.007 s
23/11/30 14:22:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:43 INFO ShufflePartitionsUtil: For shuffle(58, 58), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:43 INFO DAGScheduler: Got job 219 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 297 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 296)
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 297 (MapPartitionsRDD[735] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_245 stored as values in memory (estimated size 38.7 KiB, free 433.0 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_245_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 433.0 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_245_piece0 in memory on 10.25.86.80:43823 (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 245 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 297 (MapPartitionsRDD[735] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 297.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 297.0 (TID 219) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 297.0 (TID 219)
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 297.0 (TID 219). 4897 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 297.0 (TID 219) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 297.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 297 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.008 s
23/11/30 14:22:43 INFO DAGScheduler: Job 219 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 297: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 219 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.008680 s
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_246 stored as values in memory (estimated size 1024.1 KiB, free 432.0 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_246_piece0 stored as bytes in memory (estimated size 337.0 B, free 432.0 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_246_piece0 in memory on 10.25.86.80:43823 (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 246 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:43 INFO ShufflePartitionsUtil: For shuffle(58), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:43 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:115
23/11/30 14:22:43 INFO DAGScheduler: Got job 220 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 299 (show at SparkTest.worksheet.sc:115)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 298)
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 299 (MapPartitionsRDD[738] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_247 stored as values in memory (estimated size 15.1 KiB, free 432.0 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_247_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 432.0 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_247_piece0 in memory on 10.25.86.80:43823 (size: 6.9 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 247 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 299 (MapPartitionsRDD[738] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 299.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 299.0 (TID 220) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 299.0 (TID 220)
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 299.0 (TID 220). 4122 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 299.0 (TID 220) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 299.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 299 (show at SparkTest.worksheet.sc:115) finished in 0.005 s
23/11/30 14:22:43 INFO DAGScheduler: Job 220 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 299: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 220 finished: show at SparkTest.worksheet.sc:115, took 0.006037 s
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 2.566863 ms
23/11/30 14:22:43 INFO DAGScheduler: Registering RDD 740 (isEmpty at SparkTest.worksheet.sc:120) as input to shuffle 59
23/11/30 14:22:43 INFO DAGScheduler: Got map stage job 221 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ShuffleMapStage 300 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 300 (MapPartitionsRDD[740] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_248 stored as values in memory (estimated size 17.3 KiB, free 431.9 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_248_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 431.9 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_248_piece0 in memory on 10.25.86.80:43823 (size: 7.5 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 248 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 300 (MapPartitionsRDD[740] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 300.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 300.0 (TID 221) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 300.0 (TID 221)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 300.0 (TID 221). 1991 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 300.0 (TID 221) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 300.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ShuffleMapStage 300 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.007 s
23/11/30 14:22:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:43 INFO ShufflePartitionsUtil: For shuffle(59, 59), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 4.834472 ms
23/11/30 14:22:43 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:43 INFO DAGScheduler: Got job 222 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 302 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 301)
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 302 (MapPartitionsRDD[747] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_249 stored as values in memory (estimated size 35.3 KiB, free 431.9 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_249_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 431.9 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_249_piece0 in memory on 10.25.86.80:43823 (size: 14.5 KiB, free: 434.2 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 249 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 302 (MapPartitionsRDD[747] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 302.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 302.0 (TID 222) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 302.0 (TID 222)
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 302.0 (TID 222). 4817 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 302.0 (TID 222) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 302.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 302 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.006 s
23/11/30 14:22:43 INFO DAGScheduler: Job 222 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 302: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 222 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.007810 s
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_250 stored as values in memory (estimated size 1024.1 KiB, free 430.9 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_250_piece0 stored as bytes in memory (estimated size 251.0 B, free 430.9 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_250_piece0 in memory on 10.25.86.80:43823 (size: 251.0 B, free: 434.2 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 250 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/30 14:22:43 INFO ShufflePartitionsUtil: For shuffle(59), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 2.790855 ms
23/11/30 14:22:43 INFO SparkContext: Starting job: isEmpty at SparkTest.worksheet.sc:120
23/11/30 14:22:43 INFO DAGScheduler: Got job 223 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 304 (isEmpty at SparkTest.worksheet.sc:120)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 303)
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 304 (MapPartitionsRDD[750] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_251 stored as values in memory (estimated size 13.3 KiB, free 430.9 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_251_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 430.9 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_251_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.2 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 251 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 304 (MapPartitionsRDD[750] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 304.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 304.0 (TID 223) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 304.0 (TID 223)
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 304.0 (TID 223). 3176 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 304.0 (TID 223) in 2 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 304.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 304 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.005 s
23/11/30 14:22:43 INFO DAGScheduler: Job 223 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 304: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 223 finished: isEmpty at SparkTest.worksheet.sc:120, took 0.005750 s
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 3.28032 ms
23/11/30 14:22:43 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:43 INFO DAGScheduler: Got job 224 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 305 (collect at Ast.scala:253)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 305 (MapPartitionsRDD[754] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_252 stored as values in memory (estimated size 17.5 KiB, free 430.8 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_252_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 430.8 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_252_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.2 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 252 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 305 (MapPartitionsRDD[754] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 305.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 305.0 (TID 224) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 305.0 (TID 224)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 305.0 (TID 224). 1826 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 305.0 (TID 224) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 305.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 305 (collect at Ast.scala:253) finished in 0.005 s
23/11/30 14:22:43 INFO DAGScheduler: Job 224 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 305: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 224 finished: collect at Ast.scala:253, took 0.006614 s
23/11/30 14:22:43 INFO DAGScheduler: Registering RDD 755 (collect at Ast.scala:253) as input to shuffle 60
23/11/30 14:22:43 INFO DAGScheduler: Got map stage job 225 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ShuffleMapStage 306 (collect at Ast.scala:253)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 306 (MapPartitionsRDD[755] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_253 stored as values in memory (estimated size 19.0 KiB, free 430.8 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_253_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 430.8 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_253_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.2 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 253 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 306 (MapPartitionsRDD[755] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 306.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 306.0 (TID 225) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 306.0 (TID 225)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 306.0 (TID 225). 1793 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 306.0 (TID 225) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 306.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ShuffleMapStage 306 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:22:43 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:43 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:43 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:43 INFO ShufflePartitionsUtil: For shuffle(60), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 4.337479 ms
23/11/30 14:22:43 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:43 INFO DAGScheduler: Got job 226 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 308 (collect at Ast.scala:253)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 307)
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 308 (MapPartitionsRDD[758] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_254 stored as values in memory (estimated size 24.9 KiB, free 430.8 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_254_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 430.8 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_254_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.2 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 254 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 308 (MapPartitionsRDD[758] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 308.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 308.0 (TID 226) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 308.0 (TID 226)
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 308.0 (TID 226). 4494 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 308.0 (TID 226) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 308.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 308 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:22:43 INFO DAGScheduler: Job 226 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 308: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 226 finished: collect at Ast.scala:253, took 0.008411 s
23/11/30 14:22:43 INFO CodeGenerator: Code generated in 3.328351 ms
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_241_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.2 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_235_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.2 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_236_piece0 on 10.25.86.80:43823 in memory (size: 16.3 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_240_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_251_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO DAGScheduler: Got job 227 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ResultStage 309 (collect at Ast.scala:253)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ResultStage 309 (MapPartitionsRDD[762] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_246_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_248_piece0 on 10.25.86.80:43823 in memory (size: 7.5 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_255 stored as values in memory (estimated size 17.5 KiB, free 432.0 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_245_piece0 on 10.25.86.80:43823 in memory (size: 15.9 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_255_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 432.0 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_255_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 255 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_237_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 309 (MapPartitionsRDD[762] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 309.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_243_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 309.0 (TID 227) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_253_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 309.0 (TID 227)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_249_piece0 on 10.25.86.80:43823 in memory (size: 14.5 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_238_piece0 on 10.25.86.80:43823 in memory (size: 16.3 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_233_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_234_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_254_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_252_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_247_piece0 on 10.25.86.80:43823 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_232_piece0 on 10.25.86.80:43823 in memory (size: 6.6 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_244_piece0 on 10.25.86.80:43823 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_250_piece0 on 10.25.86.80:43823 in memory (size: 251.0 B, free: 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_242_piece0 on 10.25.86.80:43823 in memory (size: 337.0 B, free: 434.4 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Removed broadcast_239_piece0 on 10.25.86.80:43823 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO Executor: Finished task 0.0 in stage 309.0 (TID 227). 1826 bytes result sent to driver
23/11/30 14:22:43 INFO TaskSetManager: Finished task 0.0 in stage 309.0 (TID 227) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:43 INFO TaskSchedulerImpl: Removed TaskSet 309.0, whose tasks have all completed, from pool 
23/11/30 14:22:43 INFO DAGScheduler: ResultStage 309 (collect at Ast.scala:253) finished in 0.008 s
23/11/30 14:22:43 INFO DAGScheduler: Job 227 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 309: Stage finished
23/11/30 14:22:43 INFO DAGScheduler: Job 227 finished: collect at Ast.scala:253, took 0.008441 s
23/11/30 14:22:43 INFO DAGScheduler: Registering RDD 763 (collect at Ast.scala:253) as input to shuffle 61
23/11/30 14:22:43 INFO DAGScheduler: Got map stage job 228 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:43 INFO DAGScheduler: Final stage: ShuffleMapStage 310 (collect at Ast.scala:253)
23/11/30 14:22:43 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:43 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:43 INFO DAGScheduler: Submitting ShuffleMapStage 310 (MapPartitionsRDD[763] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_256 stored as values in memory (estimated size 19.0 KiB, free 434.4 MiB)
23/11/30 14:22:43 INFO MemoryStore: Block broadcast_256_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/11/30 14:22:43 INFO BlockManagerInfo: Added broadcast_256_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:22:43 INFO SparkContext: Created broadcast 256 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 310 (MapPartitionsRDD[763] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:43 INFO TaskSchedulerImpl: Adding task set 310.0 with 1 tasks resource profile 0
23/11/30 14:22:43 INFO TaskSetManager: Starting task 0.0 in stage 310.0 (TID 228) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:43 INFO Executor: Running task 0.0 in stage 310.0 (TID 228)
23/11/30 14:22:44 INFO Executor: Finished task 0.0 in stage 310.0 (TID 228). 1793 bytes result sent to driver
23/11/30 14:22:44 INFO TaskSetManager: Finished task 0.0 in stage 310.0 (TID 228) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:44 INFO TaskSchedulerImpl: Removed TaskSet 310.0, whose tasks have all completed, from pool 
23/11/30 14:22:44 INFO DAGScheduler: ShuffleMapStage 310 (collect at Ast.scala:253) finished in 0.007 s
23/11/30 14:22:44 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:44 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:44 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:44 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:44 INFO ShufflePartitionsUtil: For shuffle(61), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:44 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:44 INFO DAGScheduler: Got job 229 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:44 INFO DAGScheduler: Final stage: ResultStage 312 (collect at Ast.scala:253)
23/11/30 14:22:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 311)
23/11/30 14:22:44 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:44 INFO DAGScheduler: Submitting ResultStage 312 (MapPartitionsRDD[766] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_257 stored as values in memory (estimated size 24.9 KiB, free 434.3 MiB)
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_257_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.3 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Added broadcast_257_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO SparkContext: Created broadcast 257 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 312 (MapPartitionsRDD[766] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:44 INFO TaskSchedulerImpl: Adding task set 312.0 with 1 tasks resource profile 0
23/11/30 14:22:44 INFO TaskSetManager: Starting task 0.0 in stage 312.0 (TID 229) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:22:44 INFO Executor: Running task 0.0 in stage 312.0 (TID 229)
23/11/30 14:22:44 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:44 INFO Executor: Finished task 0.0 in stage 312.0 (TID 229). 4494 bytes result sent to driver
23/11/30 14:22:44 INFO TaskSetManager: Finished task 0.0 in stage 312.0 (TID 229) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:44 INFO TaskSchedulerImpl: Removed TaskSet 312.0, whose tasks have all completed, from pool 
23/11/30 14:22:44 INFO DAGScheduler: ResultStage 312 (collect at Ast.scala:253) finished in 0.005 s
23/11/30 14:22:44 INFO DAGScheduler: Job 229 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 312: Stage finished
23/11/30 14:22:44 INFO DAGScheduler: Job 229 finished: collect at Ast.scala:253, took 0.006004 s
23/11/30 14:22:44 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:44 INFO DAGScheduler: Got job 230 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:44 INFO DAGScheduler: Final stage: ResultStage 313 (collect at Ast.scala:253)
23/11/30 14:22:44 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:44 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:44 INFO DAGScheduler: Submitting ResultStage 313 (MapPartitionsRDD[770] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_258 stored as values in memory (estimated size 17.5 KiB, free 434.3 MiB)
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_258_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.3 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Added broadcast_258_piece0 in memory on 10.25.86.80:43823 (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO SparkContext: Created broadcast 258 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 313 (MapPartitionsRDD[770] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:44 INFO TaskSchedulerImpl: Adding task set 313.0 with 1 tasks resource profile 0
23/11/30 14:22:44 INFO TaskSetManager: Starting task 0.0 in stage 313.0 (TID 230) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:44 INFO Executor: Running task 0.0 in stage 313.0 (TID 230)
23/11/30 14:22:44 INFO Executor: Finished task 0.0 in stage 313.0 (TID 230). 1826 bytes result sent to driver
23/11/30 14:22:44 INFO TaskSetManager: Finished task 0.0 in stage 313.0 (TID 230) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:44 INFO TaskSchedulerImpl: Removed TaskSet 313.0, whose tasks have all completed, from pool 
23/11/30 14:22:44 INFO DAGScheduler: ResultStage 313 (collect at Ast.scala:253) finished in 0.005 s
23/11/30 14:22:44 INFO DAGScheduler: Job 230 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 313: Stage finished
23/11/30 14:22:44 INFO DAGScheduler: Job 230 finished: collect at Ast.scala:253, took 0.005869 s
23/11/30 14:22:44 INFO DAGScheduler: Registering RDD 771 (collect at Ast.scala:253) as input to shuffle 62
23/11/30 14:22:44 INFO DAGScheduler: Got map stage job 231 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:44 INFO DAGScheduler: Final stage: ShuffleMapStage 314 (collect at Ast.scala:253)
23/11/30 14:22:44 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:44 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:44 INFO DAGScheduler: Submitting ShuffleMapStage 314 (MapPartitionsRDD[771] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_259 stored as values in memory (estimated size 19.0 KiB, free 434.3 MiB)
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_259_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Added broadcast_259_piece0 in memory on 10.25.86.80:43823 (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO SparkContext: Created broadcast 259 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:44 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 314 (MapPartitionsRDD[771] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:44 INFO TaskSchedulerImpl: Adding task set 314.0 with 1 tasks resource profile 0
23/11/30 14:22:44 INFO TaskSetManager: Starting task 0.0 in stage 314.0 (TID 231) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/11/30 14:22:44 INFO Executor: Running task 0.0 in stage 314.0 (TID 231)
23/11/30 14:22:44 INFO Executor: Finished task 0.0 in stage 314.0 (TID 231). 1793 bytes result sent to driver
23/11/30 14:22:44 INFO TaskSetManager: Finished task 0.0 in stage 314.0 (TID 231) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:44 INFO TaskSchedulerImpl: Removed TaskSet 314.0, whose tasks have all completed, from pool 
23/11/30 14:22:44 INFO DAGScheduler: ShuffleMapStage 314 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:22:44 INFO DAGScheduler: looking for newly runnable stages
23/11/30 14:22:44 INFO DAGScheduler: running: HashSet()
23/11/30 14:22:44 INFO DAGScheduler: waiting: HashSet()
23/11/30 14:22:44 INFO DAGScheduler: failed: HashSet()
23/11/30 14:22:44 INFO ShufflePartitionsUtil: For shuffle(62), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/30 14:22:44 INFO SparkContext: Starting job: collect at Ast.scala:253
23/11/30 14:22:44 INFO DAGScheduler: Got job 232 (collect at Ast.scala:253) with 1 output partitions
23/11/30 14:22:44 INFO DAGScheduler: Final stage: ResultStage 316 (collect at Ast.scala:253)
23/11/30 14:22:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 315)
23/11/30 14:22:44 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:44 INFO DAGScheduler: Submitting ResultStage 316 (MapPartitionsRDD[774] at collect at Ast.scala:253), which has no missing parents
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_260 stored as values in memory (estimated size 24.9 KiB, free 434.2 MiB)
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_260_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.2 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Added broadcast_260_piece0 in memory on 10.25.86.80:43823 (size: 10.8 KiB, free: 434.3 MiB)
23/11/30 14:22:44 INFO SparkContext: Created broadcast 260 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 316 (MapPartitionsRDD[774] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:44 INFO TaskSchedulerImpl: Adding task set 316.0 with 1 tasks resource profile 0
23/11/30 14:22:44 INFO TaskSetManager: Starting task 0.0 in stage 316.0 (TID 232) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/11/30 14:22:44 INFO Executor: Running task 0.0 in stage 316.0 (TID 232)
23/11/30 14:22:44 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/30 14:22:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/30 14:22:44 INFO Executor: Finished task 0.0 in stage 316.0 (TID 232). 4494 bytes result sent to driver
23/11/30 14:22:44 INFO TaskSetManager: Finished task 0.0 in stage 316.0 (TID 232) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:44 INFO TaskSchedulerImpl: Removed TaskSet 316.0, whose tasks have all completed, from pool 
23/11/30 14:22:44 INFO DAGScheduler: ResultStage 316 (collect at Ast.scala:253) finished in 0.006 s
23/11/30 14:22:44 INFO DAGScheduler: Job 232 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 316: Stage finished
23/11/30 14:22:44 INFO DAGScheduler: Job 232 finished: collect at Ast.scala:253, took 0.006313 s
23/11/30 14:22:44 INFO BlockManagerInfo: Removed broadcast_260_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Removed broadcast_255_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Removed broadcast_259_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Removed broadcast_257_piece0 on 10.25.86.80:43823 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Removed broadcast_256_piece0 on 10.25.86.80:43823 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Removed broadcast_258_piece0 on 10.25.86.80:43823 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:150
23/11/30 14:22:44 INFO DAGScheduler: Got job 233 (show at SparkTest.worksheet.sc:150) with 1 output partitions
23/11/30 14:22:44 INFO DAGScheduler: Final stage: ResultStage 317 (show at SparkTest.worksheet.sc:150)
23/11/30 14:22:44 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:44 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:44 INFO DAGScheduler: Submitting ResultStage 317 (MapPartitionsRDD[776] at show at SparkTest.worksheet.sc:150), which has no missing parents
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_261 stored as values in memory (estimated size 15.7 KiB, free 434.4 MiB)
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_261_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.4 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Added broadcast_261_piece0 in memory on 10.25.86.80:43823 (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO SparkContext: Created broadcast 261 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 317 (MapPartitionsRDD[776] at show at SparkTest.worksheet.sc:150) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:44 INFO TaskSchedulerImpl: Adding task set 317.0 with 1 tasks resource profile 0
23/11/30 14:22:44 INFO TaskSetManager: Starting task 0.0 in stage 317.0 (TID 233) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:44 INFO Executor: Running task 0.0 in stage 317.0 (TID 233)
23/11/30 14:22:44 INFO Executor: Finished task 0.0 in stage 317.0 (TID 233). 1640 bytes result sent to driver
23/11/30 14:22:44 INFO TaskSetManager: Finished task 0.0 in stage 317.0 (TID 233) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:44 INFO TaskSchedulerImpl: Removed TaskSet 317.0, whose tasks have all completed, from pool 
23/11/30 14:22:44 INFO DAGScheduler: ResultStage 317 (show at SparkTest.worksheet.sc:150) finished in 0.013 s
23/11/30 14:22:44 INFO DAGScheduler: Job 233 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 317: Stage finished
23/11/30 14:22:44 INFO DAGScheduler: Job 233 finished: show at SparkTest.worksheet.sc:150, took 0.013586 s
23/11/30 14:22:44 INFO CodeGenerator: Code generated in 3.250844 ms
23/11/30 14:22:44 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:159
23/11/30 14:22:44 INFO DAGScheduler: Got job 234 (collect at SparkTest.worksheet.sc:159) with 1 output partitions
23/11/30 14:22:44 INFO DAGScheduler: Final stage: ResultStage 318 (collect at SparkTest.worksheet.sc:159)
23/11/30 14:22:44 INFO DAGScheduler: Parents of final stage: List()
23/11/30 14:22:44 INFO DAGScheduler: Missing parents: List()
23/11/30 14:22:44 INFO DAGScheduler: Submitting ResultStage 318 (MapPartitionsRDD[784] at collect at SparkTest.worksheet.sc:159), which has no missing parents
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_262 stored as values in memory (estimated size 15.4 KiB, free 434.4 MiB)
23/11/30 14:22:44 INFO MemoryStore: Block broadcast_262_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Added broadcast_262_piece0 in memory on 10.25.86.80:43823 (size: 6.4 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO SparkContext: Created broadcast 262 from broadcast at DAGScheduler.scala:1580
23/11/30 14:22:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 318 (MapPartitionsRDD[784] at collect at SparkTest.worksheet.sc:159) (first 15 tasks are for partitions Vector(0))
23/11/30 14:22:44 INFO TaskSchedulerImpl: Adding task set 318.0 with 1 tasks resource profile 0
23/11/30 14:22:44 INFO TaskSetManager: Starting task 0.0 in stage 318.0 (TID 234) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/11/30 14:22:44 INFO Executor: Running task 0.0 in stage 318.0 (TID 234)
23/11/30 14:22:44 INFO Executor: Finished task 0.0 in stage 318.0 (TID 234). 1650 bytes result sent to driver
23/11/30 14:22:44 INFO TaskSetManager: Finished task 0.0 in stage 318.0 (TID 234) in 4 ms on 10.25.86.80 (executor driver) (1/1)
23/11/30 14:22:44 INFO TaskSchedulerImpl: Removed TaskSet 318.0, whose tasks have all completed, from pool 
23/11/30 14:22:44 INFO DAGScheduler: ResultStage 318 (collect at SparkTest.worksheet.sc:159) finished in 0.006 s
23/11/30 14:22:44 INFO DAGScheduler: Job 234 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/30 14:22:44 INFO TaskSchedulerImpl: Killing all running tasks in stage 318: Stage finished
23/11/30 14:22:44 INFO DAGScheduler: Job 234 finished: collect at SparkTest.worksheet.sc:159, took 0.006674 s
23/11/30 14:22:44 INFO CodeGenerator: Code generated in 2.999369 ms
2023.11.30 14:22:44 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 1.59s[0m
23/11/30 14:22:44 INFO BlockManagerInfo: Removed broadcast_261_piece0 on 10.25.86.80:43823 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/30 14:22:44 INFO BlockManagerInfo: Removed broadcast_262_piece0 on 10.25.86.80:43823 in memory (size: 6.4 KiB, free: 434.4 MiB)
2023.11.30 14:23:53 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.11.30 14:23:53 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.11.30 14:23:53 INFO  Starting debug proxy for [startup.integration_testing.httpServerSuite(test1)][0m
2023.11.30 14:23:53 INFO  Loaded expression compiler in 1 millisecond[0m
2023.11.30 14:23:53 INFO  Loaded step filter in 0 milliseconds[0m
2023.11.30 14:23:54 INFO  Loaded all sources and classes in 1 second[0m
2023.11.30 14:23:57 INFO  Trying to attach to remote debuggee VM localhost:41267 .[0m
2023.11.30 14:23:57 INFO  Attaching to debuggee VM succeeded.[0m
2023.11.30 14:24:07 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.11.30 14:24:07 ERROR 23/11/30 14:24:07 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)[0m
2023.11.30 14:24:07 ERROR 23/11/30 14:24:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address[0m
2023.11.30 14:24:16 ERROR 23/11/30 14:24:16 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.11.30 14:24:16 ERROR 23/11/30 14:24:17 INFO SparkContext: Running Spark version 3.5.0[0m
2023.11.30 14:24:16 ERROR 23/11/30 14:24:17 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64[0m
2023.11.30 14:24:16 ERROR 23/11/30 14:24:17 INFO SparkContext: Java version 11.0.20[0m
2023.11.30 14:24:16 ERROR 23/11/30 14:24:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable[0m
2023.11.30 14:24:16 ERROR Setting Spark log level to "WARN".[0m
2023.11.30 14:24:17 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.11.30 14:24:17 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.5.0/spark-unsafe_2.13-3.5.0.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.11.30 14:24:17 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.11.30 14:24:17 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.11.30 14:24:17 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.11.30 14:24:17 ERROR 23/11/30 14:24:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.[0m
2023.11.30 14:26:08 ERROR java.lang.IllegalStateException: UT000002: The response has already been started[0m
2023.11.30 14:26:08 ERROR 	at io.undertow.server.HttpServerExchange.setStatusCode(HttpServerExchange.java:1480)[0m
2023.11.30 14:26:08 ERROR 	at cask.main.Main$.writeResponse(Main.scala:174)[0m
2023.11.30 14:26:08 ERROR 	at cask.main.Main$DefaultHandler.$anonfun$2(Main.scala:99)[0m
2023.11.30 14:26:08 ERROR 	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)[0m
2023.11.30 14:26:08 ERROR 	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)[0m
2023.11.30 14:26:08 ERROR 	at cask.main.Main$DefaultHandler.handleRequest(Main.scala:117)[0m
2023.11.30 14:26:08 ERROR 	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387)[0m
2023.11.30 14:26:08 ERROR 	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852)[0m
2023.11.30 14:26:08 ERROR 	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)[0m
2023.11.30 14:26:08 ERROR 	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019)[0m
2023.11.30 14:26:08 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558)[0m
2023.11.30 14:26:08 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1423)[0m
2023.11.30 14:26:08 ERROR 	at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1282)[0m
2023.11.30 14:26:08 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.11.30 14:26:12 INFO  Canceling debug proxy for [startup.integration_testing.httpServerSuite(test1)][0m
2023.11.30 14:26:12 INFO  Closing debug server tcp://0.0.0.0:33515[0m
2023.11.30 14:26:12 ERROR Failed to initialize communication: Socket closed[0m
2023.11.30 14:28:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:28:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.37s[0m
2023.11.30 14:28:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:28:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.11.30 14:28:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:28:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.11.30 14:30:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:30:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 76ms[0m
2023.11.30 14:30:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:30:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 47ms[0m
2023.11.30 14:30:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:30:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 76ms[0m
2023.11.30 14:30:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:30:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 87ms[0m
2023.11.30 14:31:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:31:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.4s[0m
2023.11.30 14:31:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:31:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:31:21 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:31:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:31:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:31:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:31:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:31:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:31:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:31:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:31:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:31:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:31:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:31:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:31:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.64s[0m
2023.11.30 14:31:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:31:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:32:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:32:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.11.30 14:32:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:32:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:32:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:32:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:32:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:32:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:32:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:32:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 14:32:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:32:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 14:32:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:32:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:32:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:32:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:33:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:33:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 14:34:13 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:16 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:16 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:17 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:34:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:34:18 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:19 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:34:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:34:20 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:32 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:34:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:34:33 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:52 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:53 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:53 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:34:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 14:34:54 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:57 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:58 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:34:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:34:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:34:59 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:35:05 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:35:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:35:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:35:06 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:35:26 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:35:28 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:35:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:35:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:35:29 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:35:30 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:35:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:35:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:35:31 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:35:34 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:35:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:35:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.11.30 14:35:35 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:35:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:35:36 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 14:35:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.4s[0m
2023.11.30 14:35:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:35:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.11.30 14:36:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:36:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.4s[0m
2023.11.30 14:36:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:36:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.11.30 14:37:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:37:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:37:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:37:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 50ms[0m
2023.11.30 14:37:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:37:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:37:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:37:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:37:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:37:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 46ms[0m
2023.11.30 14:37:39 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Computation.scala[0m
2023.11.30 14:37:46 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Computation.scala[0m
2023.11.30 14:37:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:37:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 45ms[0m
2023.11.30 14:37:48 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Computation.scala[0m
2023.11.30 14:37:49 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Computation.scala[0m
2023.11.30 14:37:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:37:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 44ms[0m
2023.11.30 14:37:50 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Computation.scala[0m
2023.11.30 14:37:58 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Computation.scala[0m
2023.11.30 14:37:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:37:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 45ms[0m
2023.11.30 14:38:01 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Computation.scala[0m
2023.11.30 14:38:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:38:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 50ms[0m
2023.11.30 14:38:02 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Computation.scala[0m
2023.11.30 14:38:06 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Computation.scala[0m
2023.11.30 14:38:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:38:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.1s[0m
2023.11.30 14:38:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:38:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 14:40:11 INFO  time: code lens generation in 1.9s[0m
2023.11.30 14:43:57 INFO  running '/home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals10591375982118718519/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'[0m
2023.11.30 14:43:58 INFO  [info] welcome to sbt 1.9.6 (Eclipse Adoptium Java 11.0.20)[0m
2023.11.30 14:43:58 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build-build from metals.sbt ...[0m
2023.11.30 14:43:58 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/project[0m
2023.11.30 14:43:59 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build from metals.sbt ...[0m
2023.11.30 14:43:59 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project[0m
2023.11.30 14:44:00 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-build.json[0m
2023.11.30 14:44:00 INFO  [success] Total time: 1 s, completed Nov 30, 2023, 2:44:00 PM[0m
2023.11.30 14:44:00 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085 from build.sbt ...[0m
2023.11.30 14:44:00 INFO  [info] set current project to myScala3Project (in build file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/)[0m
2023.11.30 14:44:03 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-test.json[0m
2023.11.30 14:44:03 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085.json[0m
2023.11.30 14:44:03 INFO  [success] Total time: 2 s, completed Nov 30, 2023, 2:44:03 PM[0m
2023.11.30 14:44:03 INFO  time: ran 'sbt bloopInstall' in 5.9s[0m
2023.11.30 14:44:03 INFO  Disconnecting from Bloop session...[0m
2023.11.30 14:44:03 INFO  Shut down connection with build server.[0m
2023.11.30 14:44:03 INFO  Shut down connection with build server.[0m
2023.11.30 14:44:03 INFO  Attempting to connect to the build server...[0m
2023.11.30 14:44:03 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 14:44:03 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 14:44:03 INFO  Attempting to connect to the build server...[0m
2023.11.30 14:44:03 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 14:44:03 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 14:44:03 INFO  time: Connected to build server in 0.12s[0m
2023.11.30 14:44:03 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 14:44:04 INFO  time: indexed workspace in 1.24s[0m
2023.11.30 14:44:08 INFO  Shutting down server[0m
2023.11.30 14:44:08 INFO  shutting down Metals[0m
2023.11.30 14:44:08 INFO  Shut down connection with build server.[0m
2023.11.30 14:44:08 INFO  Shut down connection with build server.[0m
2023.11.30 14:44:08 INFO  Exiting server[0m
23/11/30 14:44:08 INFO SparkContext: Invoking stop() from shutdown hook
23/11/30 14:44:08 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/11/30 14:44:08 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4040
23/11/30 14:44:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/11/30 14:44:08 INFO MemoryStore: MemoryStore cleared
23/11/30 14:44:08 INFO BlockManager: BlockManager stopped
23/11/30 14:44:08 INFO BlockManagerMaster: BlockManagerMaster stopped
23/11/30 14:44:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/11/30 14:44:08 INFO SparkContext: Successfully stopped SparkContext
23/11/30 14:44:08 INFO ShutdownHookManager: Shutdown hook called
23/11/30 14:44:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-75a8269b-4896-41a0-8b35-8421fe10ce4d
2023.11.30 14:44:21 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.30 14:44:21 INFO  Attempting to connect to the build server...[0m
2023.11.30 14:44:21 INFO  skipping build import with status 'Dismissed'[0m
2023.11.30 14:44:21 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 14:44:21 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 14:44:21 INFO  Attempting to connect to the build server...[0m
2023.11.30 14:44:21 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 14:44:21 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 14:44:22 INFO  time: Connected to build server in 0.51s[0m
2023.11.30 14:44:22 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 14:44:24 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.11.30 14:44:26 INFO  time: indexed workspace in 1.83s[0m
2023.11.30 14:46:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:46:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.1s[0m
2023.11.30 14:46:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:46:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 14:46:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:46:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 95ms[0m
2023.11.30 14:46:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:46:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 41ms[0m
2023.11.30 14:46:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:46:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 40ms[0m
2023.11.30 14:46:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:46:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 41ms[0m
2023.11.30 14:47:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:47:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:47:53 INFO  Shutting down server[0m
2023.11.30 14:47:53 INFO  shutting down Metals[0m
2023.11.30 14:47:53 INFO  Shut down connection with build server.[0m
2023.11.30 14:47:53 INFO  Shut down connection with build server.[0m
2023.11.30 14:47:53 INFO  Exiting server[0m
2023.11.30 14:48:02 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.30 14:48:03 INFO  Attempting to connect to the build server...[0m
2023.11.30 14:48:03 INFO  skipping build import with status 'Installed'[0m
2023.11.30 14:48:03 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 14:48:03 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 14:48:03 INFO  Attempting to connect to the build server...[0m
2023.11.30 14:48:03 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 14:48:03 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 14:48:03 INFO  time: Connected to build server in 0.58s[0m
2023.11.30 14:48:04 INFO  Connected to Build server: Bloop v1.5.11[0m
Nov 30, 2023 2:48:04 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 15
Nov 30, 2023 2:48:04 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16
2023.11.30 14:48:06 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.11.30 14:48:07 INFO  time: indexed workspace in 1.65s[0m
2023.11.30 14:48:25 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.11.30 14:48:25 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.11.30 14:48:25 INFO  Starting debug proxy for [startup.integration_testing.httpServerSuite(test1)][0m
2023.11.30 14:48:25 INFO  Loaded expression compiler in 1 millisecond[0m
2023.11.30 14:48:25 INFO  Loaded step filter in 0 milliseconds[0m
2023.11.30 14:48:25 INFO  Loaded all sources and classes in 898 milliseconds[0m
2023.11.30 14:48:28 INFO  Trying to attach to remote debuggee VM localhost:57151 .[0m
2023.11.30 14:48:28 INFO  Attaching to debuggee VM succeeded.[0m
2023.11.30 14:48:43 ERROR Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties[0m
2023.11.30 14:48:43 ERROR 23/11/30 14:48:43 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)[0m
2023.11.30 14:48:43 ERROR 23/11/30 14:48:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address[0m
2023.11.30 14:48:43 ERROR 23/11/30 14:48:43 INFO SparkContext: Running Spark version 3.5.0[0m
2023.11.30 14:48:43 ERROR 23/11/30 14:48:43 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64[0m
2023.11.30 14:48:43 ERROR 23/11/30 14:48:43 INFO SparkContext: Java version 11.0.20[0m
2023.11.30 14:48:43 ERROR 23/11/30 14:48:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable[0m
2023.11.30 14:48:43 ERROR Setting Spark log level to "WARN".[0m
2023.11.30 14:48:43 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.11.30 14:48:43 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.5.0/spark-unsafe_2.13-3.5.0.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.11.30 14:48:43 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.11.30 14:48:43 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.11.30 14:48:43 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.11.30 14:49:01 ERROR java.lang.IllegalStateException: UT000002: The response has already been started[0m
2023.11.30 14:49:01 ERROR 	at io.undertow.server.HttpServerExchange.setStatusCode(HttpServerExchange.java:1480)[0m
2023.11.30 14:49:01 ERROR 	at cask.main.Main$.writeResponse(Main.scala:174)[0m
2023.11.30 14:49:01 ERROR 	at cask.main.Main$DefaultHandler.$anonfun$2(Main.scala:99)[0m
2023.11.30 14:49:01 ERROR 	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)[0m
2023.11.30 14:49:01 ERROR 	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)[0m
2023.11.30 14:49:01 ERROR 	at cask.main.Main$DefaultHandler.handleRequest(Main.scala:117)[0m
2023.11.30 14:49:01 ERROR 	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387)[0m
2023.11.30 14:49:01 ERROR 	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852)[0m
2023.11.30 14:49:01 ERROR 	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)[0m
2023.11.30 14:49:01 ERROR 	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019)[0m
2023.11.30 14:49:01 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558)[0m
2023.11.30 14:49:01 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1423)[0m
2023.11.30 14:49:01 ERROR 	at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1282)[0m
2023.11.30 14:49:01 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.11.30 14:49:40 INFO  Closing debug server tcp://0.0.0.0:35043[0m
2023.11.30 14:49:40 INFO  Canceling debug proxy for [startup.integration_testing.httpServerSuite(test1)][0m
2023.11.30 14:49:40 ERROR Failed to initialize communication: Socket closed[0m
2023.11.30 14:50:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:50:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.11.30 14:51:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:51:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 88ms[0m
2023.11.30 14:51:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:51:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.11.30 14:51:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:51:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:51:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:51:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:51:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:51:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:51:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:51:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.11.30 14:51:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:51:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 80ms[0m
2023.11.30 14:51:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:51:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 78ms[0m
2023.11.30 14:51:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:51:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 83ms[0m
2023.11.30 14:51:54 ERROR /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/app/App.scala:3: error: ; expected but { found
import startup.computation._{runComputation2, dfShowString}
                            ^
scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/app/App.scala:3: error: ; expected but { found
import startup.computation._{runComputation2, dfShowString}
                            ^
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:159)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Nov 30, 2023 2:51:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/app/App.scala:3: error: ; expected but { found
import startup.computation._{runComputation2, dfShowString}
                            ^
java.util.concurrent.CompletionException: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/app/App.scala:3: error: ; expected but { found
import startup.computation._{runComputation2, dfShowString}
                            ^
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/app/App.scala:3: error: ; expected but { found
import startup.computation._{runComputation2, dfShowString}
                            ^
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:159)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more

2023.11.30 14:51:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:51:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 15ms[0m
2023.11.30 14:51:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:51:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 14:52:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:52:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.11.30 14:53:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:53:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:53:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:53:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:54:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:54:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.1s[0m
2023.11.30 14:54:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:54:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 14:54:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:54:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 1.29s[0m
2023.11.30 14:54:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:54:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 14:54:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:54:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 14:54:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:54:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.11.30 14:54:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:54:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.11.30 14:54:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:54:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 99ms[0m
2023.11.30 14:54:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:54:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.68s[0m
2023.11.30 14:54:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:54:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 14:55:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 14:55:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.57s[0m
2023.11.30 14:55:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:55:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 14:55:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 14:55:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 14:55:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 14:55:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.65s[0m
2023.11.30 14:55:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 14:55:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.67s[0m
2023.11.30 14:55:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 14:55:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.65s[0m
2023.11.30 14:55:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 14:55:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 14:56:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 14:56:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.83s[0m
2023.11.30 14:56:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:56:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.11.30 14:57:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:57:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.1s[0m
2023.11.30 14:57:51 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala[0m
2023.11.30 14:57:53 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala[0m
2023.11.30 14:57:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:57:54 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala[0m
2023.11.30 14:57:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.52s[0m
2023.11.30 14:58:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:58:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.54s[0m
2023.11.30 14:58:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:58:03 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala[0m
2023.11.30 14:58:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.55s[0m
2023.11.30 14:58:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:58:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.49s[0m
2023.11.30 14:58:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:58:11 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala[0m
2023.11.30 14:58:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.11.30 14:58:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:58:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.48s[0m
2023.11.30 14:58:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:58:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.47s[0m
2023.11.30 14:58:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:58:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.52s[0m
2023.11.30 14:58:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:58:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.46s[0m
2023.11.30 14:58:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:58:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.11.30 14:59:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:59:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.46s[0m
2023.11.30 14:59:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:59:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.52s[0m
2023.11.30 14:59:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:59:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.45s[0m
2023.11.30 14:59:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:59:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.5s[0m
2023.11.30 14:59:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:59:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.44s[0m
2023.11.30 14:59:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:59:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.53s[0m
2023.11.30 14:59:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:59:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.44s[0m
2023.11.30 14:59:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:59:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.11.30 14:59:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:59:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.46s[0m
2023.11.30 14:59:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 14:59:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.49s[0m
2023.11.30 15:00:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 15:00:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.11.30 15:00:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 15:00:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.69s[0m
2023.11.30 15:01:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:01:30 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala[0m
2023.11.30 15:01:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.49s[0m
2023.11.30 15:01:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:01:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 15:01:30 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala[0m
2023.11.30 15:01:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 15:01:35 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:01:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.44s[0m
2023.11.30 15:01:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:01:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 15:01:36 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:01:56 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:01:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 15:01:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 97ms[0m
2023.11.30 15:01:57 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:00 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:00 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:01 WARN  Using indexes to guess the definition of DataFrame[0m
2023.11.30 15:02:00 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:00 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:00 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:00 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:01 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 15:02:03 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.47s[0m
2023.11.30 15:02:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:02:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.11.30 15:02:03 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:11 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 15:02:13 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.47s[0m
2023.11.30 15:02:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:02:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.11.30 15:02:13 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:20 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 15:02:21 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.46s[0m
2023.11.30 15:02:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:02:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 15:02:22 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 15:02:23 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.46s[0m
2023.11.30 15:02:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:02:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.30 15:02:23 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 15:02:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 15:02:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.67s[0m
2023.11.30 15:02:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:02:52 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 15:02:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.11.30 15:02:52 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 15:02:56 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala[0m
2023.11.30 15:04:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:04:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.11.30 15:04:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:04:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 15:04:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:04:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 15:05:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:05:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 15:05:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:05:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 15:05:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:05:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 15:05:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:05:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 15:05:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:05:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 15:05:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:05:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 15:06:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:06:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 15:06:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:06:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.30 15:06:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:06:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 15:06:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:06:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.30 15:06:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 15:06:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.11.30 15:06:41 INFO  Shutting down server[0m
2023.11.30 15:06:41 INFO  shutting down Metals[0m
2023.11.30 15:06:41 INFO  Shut down connection with build server.[0m
2023.11.30 15:06:41 INFO  Shut down connection with build server.[0m
2023.11.30 15:06:41 INFO  Exiting server[0m
2023.11.30 15:06:49 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.30 15:06:50 INFO  Attempting to connect to the build server...[0m
2023.11.30 15:06:50 INFO  skipping build import with status 'Installed'[0m
2023.11.30 15:06:50 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 15:06:51 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 15:06:51 INFO  Attempting to connect to the build server...[0m
2023.11.30 15:06:51 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 15:06:51 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 15:06:51 INFO  time: Connected to build server in 0.5s[0m
2023.11.30 15:06:51 INFO  Connected to Build server: Bloop v1.5.11[0m
Nov 30, 2023 3:06:51 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 12
2023.11.30 15:06:53 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.11.30 15:06:55 INFO  time: indexed workspace in 1.79s[0m
2023.11.30 15:15:43 INFO  Shutting down server[0m
2023.11.30 15:15:43 INFO  shutting down Metals[0m
2023.11.30 15:15:43 INFO  Shut down connection with build server.[0m
2023.11.30 15:15:43 INFO  Shut down connection with build server.[0m
2023.11.30 15:15:43 INFO  Exiting server[0m
2023.11.30 15:15:51 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.30 15:15:52 INFO  Attempting to connect to the build server...[0m
2023.11.30 15:15:52 INFO  skipping build import with status 'Installed'[0m
2023.11.30 15:15:52 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 15:15:52 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 15:15:52 INFO  Attempting to connect to the build server...[0m
2023.11.30 15:15:52 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 15:15:52 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 15:15:52 INFO  time: Connected to build server in 0.55s[0m
2023.11.30 15:15:52 INFO  Connected to Build server: Bloop v1.5.11[0m
Nov 30, 2023 3:15:52 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
Nov 30, 2023 3:15:52 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2023.11.30 15:15:54 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.11.30 15:15:57 INFO  time: indexed workspace in 2.54s[0m
Nov 30, 2023 3:15:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 19
2023.11.30 15:16:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:16:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 15:20:52 INFO  Shutting down server[0m
2023.11.30 15:20:52 INFO  shutting down Metals[0m
2023.11.30 15:20:52 INFO  Shut down connection with build server.[0m
2023.11.30 15:20:52 INFO  Shut down connection with build server.[0m
2023.11.30 15:20:52 INFO  Exiting server[0m
2023.11.30 15:21:01 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.30 15:21:02 INFO  Attempting to connect to the build server...[0m
2023.11.30 15:21:02 INFO  skipping build import with status 'Installed'[0m
2023.11.30 15:21:02 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 15:21:03 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 15:21:03 INFO  Attempting to connect to the build server...[0m
2023.11.30 15:21:03 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 15:21:03 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 15:21:03 INFO  time: Connected to build server in 0.42s[0m
2023.11.30 15:21:03 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 15:21:04 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.11.30 15:21:06 INFO  time: indexed workspace in 1.63s[0m
2023.11.30 15:28:16 INFO  time: code lens generation in 1.59s[0m
Nov 30, 2023 3:33:02 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 44
2023.11.30 15:33:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:33:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 15:33:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:33:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.11.30 15:33:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:33:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.11.30 15:34:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:34:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 54ms[0m
2023.11.30 15:34:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:34:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 55ms[0m
2023.11.30 15:34:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:34:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 55ms[0m
2023.11.30 15:34:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:34:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 19ms[0m
2023.11.30 15:34:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:34:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 50ms[0m
2023.11.30 15:38:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:38:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 56ms[0m
2023.11.30 15:38:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:38:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 30ms[0m
2023.11.30 15:38:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:38:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.11.30 15:38:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:38:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 15:38:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:38:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 15:51:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:51:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 15:51:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:51:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 56ms[0m
2023.11.30 15:51:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:51:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 69ms[0m
2023.11.30 15:51:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:51:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.46s[0m
2023.11.30 15:52:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:52:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.45s[0m
2023.11.30 15:53:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:53:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 15:53:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:53:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.11.30 15:53:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:53:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 15:53:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 15:53:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.11.30 16:05:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:05:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.11.30 16:05:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:05:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.11.30 16:05:06 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
scala.meta.tokenizers.TokenizeException: <input>:75: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 16:05:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:05:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 16:05:07 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
scala.meta.tokenizers.TokenizeException: <input>:75: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 16:05:11 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
scala.meta.tokenizers.TokenizeException: <input>:75: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 16:05:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:05:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 16:05:12 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
scala.meta.tokenizers.TokenizeException: <input>:75: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 16:05:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:05:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.30 16:05:13 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
scala.meta.tokenizers.TokenizeException: <input>:75: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.30 16:05:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:05:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.11.30 16:05:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:05:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.11.30 16:05:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:05:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.11.30 16:10:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:10:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 22ms[0m
Nov 30, 2023 4:10:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 632
2023.11.30 16:11:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:11:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 44ms[0m
2023.11.30 16:11:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:11:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 44ms[0m
2023.11.30 16:11:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:11:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 42ms[0m
2023.11.30 16:11:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:11:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 24ms[0m
2023.11.30 16:12:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:12:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 19ms[0m
2023.11.30 16:12:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:12:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 43ms[0m
2023.11.30 16:12:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:12:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 46ms[0m
2023.11.30 16:12:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:12:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 24ms[0m
2023.11.30 16:12:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:12:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 38ms[0m
2023.11.30 16:13:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:13:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 43ms[0m
2023.11.30 16:13:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:13:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 44ms[0m
2023.11.30 16:13:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:13:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 42ms[0m
2023.11.30 16:13:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:13:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 37ms[0m
2023.11.30 16:13:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:13:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 16:14:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:14:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 16:14:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:14:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 16:14:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:14:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 16:14:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:14:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.37s[0m
2023.11.30 16:15:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:15:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.38s[0m
2023.11.30 16:15:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:15:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.11.30 16:15:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:15:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.37s[0m
2023.11.30 16:15:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:15:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.41s[0m
2023.11.30 16:15:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:15:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.38s[0m
2023.11.30 16:15:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:15:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 16:15:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:15:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 40ms[0m
2023.11.30 16:15:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:15:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 37ms[0m
2023.11.30 16:15:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:15:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 37ms[0m
2023.11.30 16:16:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:16:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 40ms[0m
2023.11.30 16:16:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:16:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 45ms[0m
2023.11.30 16:16:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:16:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 39ms[0m
2023.11.30 16:16:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:16:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 47ms[0m
2023.11.30 16:16:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:16:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 43ms[0m
2023.11.30 16:16:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:16:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 46ms[0m
2023.11.30 16:17:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:17:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 38ms[0m
2023.11.30 16:17:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:17:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 16:17:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:17:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 16:17:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:17:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 16:18:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:18:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 16:18:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:18:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 40ms[0m
2023.11.30 16:19:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:19:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 40ms[0m
2023.11.30 16:19:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:19:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 44ms[0m
2023.11.30 16:19:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:19:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 41ms[0m
2023.11.30 16:19:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:19:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 37ms[0m
2023.11.30 16:20:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:20:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 41ms[0m
2023.11.30 16:20:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:20:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 43ms[0m
2023.11.30 16:20:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:20:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 39ms[0m
2023.11.30 16:20:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:20:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 40ms[0m
2023.11.30 16:20:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:20:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 98ms[0m
2023.11.30 16:23:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:23:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 50ms[0m
2023.11.30 16:23:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:23:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 35ms[0m
2023.11.30 16:23:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:23:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 34ms[0m
2023.11.30 16:23:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:23:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 34ms[0m
2023.11.30 16:23:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:23:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 31ms[0m
2023.11.30 16:23:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:23:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 37ms[0m
2023.11.30 16:24:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:24:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.11.30 16:25:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:25:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 97ms[0m
2023.11.30 16:25:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:25:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.1s[0m
2023.11.30 16:27:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:27:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 93ms[0m
2023.11.30 16:27:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:27:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 37ms[0m
2023.11.30 16:27:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:27:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 22ms[0m
2023.11.30 16:27:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:27:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 22ms[0m
2023.11.30 16:27:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:27:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.11.30 16:27:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:27:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 23ms[0m
2023.11.30 16:27:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:27:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 31ms[0m
2023.11.30 16:27:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 16:27:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 33ms[0m
2023.11.30 21:12:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 21:12:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 37ms[0m
2023.11.30 21:12:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 21:12:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 32ms[0m
2023.11.30 21:12:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 21:12:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 32ms[0m
2023.11.30 21:12:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.30 21:12:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 37ms[0m
2023.11.30 21:12:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:12:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.11.30 21:12:51 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:12:51 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:12:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:12:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 21:12:53 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:12:59 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:12:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:12:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 21:13:00 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:13:01 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:13:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:13:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 21:13:02 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:13:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:13:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 21:13:29 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:13:40 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:13:41 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:13:42 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:13:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:13:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 21:13:43 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:13:46 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:13:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:13:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.11.30 21:13:48 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:03 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:14:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.30 21:14:04 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:19 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:14:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 21:14:21 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:25 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:14:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 21:14:26 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:38 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:14:39 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.47s[0m
2023.11.30 21:14:40 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:41 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:14:42 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:14:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.48s[0m
2023.11.30 21:14:43 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:15:29 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:15:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:15:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.24s[0m
2023.11.30 21:15:30 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:15:31 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:15:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:15:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 21:15:33 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:15:34 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:15:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:15:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 21:15:35 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:15:36 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:15:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:15:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 21:15:37 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:10 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:10 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:10 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:10 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:21 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:16:22 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.5s[0m
2023.11.30 21:16:22 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:34 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:16:35 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.11.30 21:16:35 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:16:36 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.48s[0m
2023.11.30 21:16:37 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:42 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:16:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:16:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 75ms[0m
2023.11.30 21:16:43 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:17:33 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:17:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:17:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.11.30 21:17:34 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:17:37 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:17:38 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:17:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:17:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 21:17:39 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:17:42 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:17:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:17:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.11.30 21:17:43 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:17:45 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:17:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:17:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 21:17:46 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:17:56 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:18:06 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:18:06 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:18:07 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:18:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:18:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 55ms[0m
2023.11.30 21:18:08 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:18:19 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:18:19 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:18:21 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:18:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:18:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 21:18:22 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:00 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:00 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.11.30 21:19:03 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:04 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 21:19:06 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:06 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 21:19:08 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:11 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:12 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.11.30 21:19:14 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:15 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 70ms[0m
2023.11.30 21:19:16 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:18 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:19 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.11.30 21:19:20 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:23 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.11.30 21:19:24 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:26 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.11.30 21:19:27 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:34 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:36 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.11.30 21:19:37 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.11.30 21:19:38 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:38 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:39 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.11.30 21:19:40 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:44 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:19:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:19:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.11.30 21:19:45 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
Nov 30, 2023 9:19:57 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2023.11.30 21:20:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:20:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.11.30 21:20:17 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:21:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:21:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.11.30 21:21:11 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:21:18 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:21:18 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:21:18 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:21:18 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:21:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:21:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
Nov 30, 2023 9:21:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2761
2023.11.30 21:21:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:21:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 57ms[0m
2023.11.30 21:21:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:21:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.30 21:21:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:21:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.30 21:22:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:22:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.11.30 21:22:24 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:22:24 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:22:24 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:22:24 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:22:25 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:22:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:22:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.11.30 21:22:26 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:22:32 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:22:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:22:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.11.30 21:22:33 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:22:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:22:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.11.30 21:22:34 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:22:40 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:22:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:22:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 67ms[0m
2023.11.30 21:22:41 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:22:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:22:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.11.30 21:22:42 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:23:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:23:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.11.30 21:23:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:23:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 21:23:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 21:23:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 21:23:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:23:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.30 21:23:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 21:23:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 21:23:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.30 21:23:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 21:23:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 21:23:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.30 21:24:12 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:24:19 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:24:19 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.30 21:24:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 21:24:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 96ms[0m
2023.11.30 21:24:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 21:24:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 93ms[0m
2023.11.30 21:24:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 21:24:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 89ms[0m
2023.11.30 21:24:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 21:24:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 21:24:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 21:24:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 93ms[0m
2023.11.30 21:24:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.11.30 21:24:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 92ms[0m
2023.11.30 21:24:43 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
Nov 30, 2023 9:26:18 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3106
2023.11.30 21:59:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 21:59:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 21:59:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 21:59:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.30 22:00:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:00:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.30 22:00:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:00:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
Nov 30, 2023 10:01:27 PM scala.meta.internal.mtags.SymbolIndexBucket addMtagsSourceFile
WARNING: Error indexing /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:371)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:422)
	at java.base/java.nio.file.Files.readAllBytes(Files.java:3206)
	at scala.meta.internal.io.PlatformFileIO$.slurp(PlatformFileIO.scala:45)
	at scala.meta.internal.io.FileIO$.slurp(FileIO.scala:24)
	at scala.meta.internal.mtags.ScalametaCommonEnrichments$XtensionAbsolutePath.toInput(ScalametaCommonEnrichments.scala:383)
	at scala.meta.internal.mtags.SymbolIndexBucket.addMtagsSourceFile(SymbolIndexBucket.scala:270)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1$adapted(SymbolIndexBucket.scala:190)
	at scala.collection.immutable.Set$Set3.foreach(Set.scala:261)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definition(OnDemandSymbolIndex.scala:48)
	at scala.meta.internal.metals.Docstrings.indexSymbol(Docstrings.scala:118)
	at scala.meta.internal.metals.Docstrings.documentation(Docstrings.scala:44)
	at scala.meta.internal.metals.MetalsSymbolSearch.documentation(MetalsSymbolSearch.scala:43)
	at scala.meta.internal.mtags.MtagsEnrichments$.symbolDocumentation(MtagsEnrichments.scala:209)
	at scala.meta.internal.pc.HoverProvider$.$anonfun$3(HoverProvider.scala:137)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.pc.HoverProvider$.hover(HoverProvider.scala:137)
	at scala.meta.internal.pc.ScalaPresentationCompiler.hover$$anonfun$1(ScalaPresentationCompiler.scala:329)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:146)
	at scala.meta.internal.pc.CompilerAccess.withNonInterruptableCompiler$$anonfun$1(CompilerAccess.scala:132)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:232)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

Nov 30, 2023 10:01:27 PM scala.meta.internal.mtags.SymbolIndexBucket addMtagsSourceFile
WARNING: Error indexing /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:371)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:422)
	at java.base/java.nio.file.Files.readAllBytes(Files.java:3206)
	at scala.meta.internal.io.PlatformFileIO$.slurp(PlatformFileIO.scala:45)
	at scala.meta.internal.io.FileIO$.slurp(FileIO.scala:24)
	at scala.meta.internal.mtags.ScalametaCommonEnrichments$XtensionAbsolutePath.toInput(ScalametaCommonEnrichments.scala:383)
	at scala.meta.internal.mtags.SymbolIndexBucket.addMtagsSourceFile(SymbolIndexBucket.scala:270)
	at scala.meta.internal.mtags.SymbolIndexBucket.addMtagsSourceFile(SymbolIndexBucket.scala:286)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1$adapted(SymbolIndexBucket.scala:190)
	at scala.collection.immutable.Set$Set3.foreach(Set.scala:261)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definition(OnDemandSymbolIndex.scala:48)
	at scala.meta.internal.metals.Docstrings.indexSymbol(Docstrings.scala:118)
	at scala.meta.internal.metals.Docstrings.documentation(Docstrings.scala:44)
	at scala.meta.internal.metals.MetalsSymbolSearch.documentation(MetalsSymbolSearch.scala:43)
	at scala.meta.internal.mtags.MtagsEnrichments$.symbolDocumentation(MtagsEnrichments.scala:209)
	at scala.meta.internal.pc.HoverProvider$.$anonfun$3(HoverProvider.scala:137)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.pc.HoverProvider$.hover(HoverProvider.scala:137)
	at scala.meta.internal.pc.ScalaPresentationCompiler.hover$$anonfun$1(ScalaPresentationCompiler.scala:329)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:146)
	at scala.meta.internal.pc.CompilerAccess.withNonInterruptableCompiler$$anonfun$1(CompilerAccess.scala:132)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:232)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

Nov 30, 2023 10:01:27 PM scala.meta.internal.mtags.SymbolIndexBucket addMtagsSourceFile
WARNING: Error indexing /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/WebServer.scala
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/WebServer.scala
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:371)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:422)
	at java.base/java.nio.file.Files.readAllBytes(Files.java:3206)
	at scala.meta.internal.io.PlatformFileIO$.slurp(PlatformFileIO.scala:45)
	at scala.meta.internal.io.FileIO$.slurp(FileIO.scala:24)
	at scala.meta.internal.mtags.ScalametaCommonEnrichments$XtensionAbsolutePath.toInput(ScalametaCommonEnrichments.scala:383)
	at scala.meta.internal.mtags.SymbolIndexBucket.addMtagsSourceFile(SymbolIndexBucket.scala:270)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1$adapted(SymbolIndexBucket.scala:190)
	at scala.collection.immutable.Set$Set3.foreach(Set.scala:261)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definition(OnDemandSymbolIndex.scala:48)
	at scala.meta.internal.metals.Docstrings.indexSymbol(Docstrings.scala:118)
	at scala.meta.internal.metals.Docstrings.documentation(Docstrings.scala:44)
	at scala.meta.internal.metals.MetalsSymbolSearch.documentation(MetalsSymbolSearch.scala:43)
	at scala.meta.internal.mtags.MtagsEnrichments$.symbolDocumentation(MtagsEnrichments.scala:209)
	at scala.meta.internal.pc.HoverProvider$.$anonfun$3(HoverProvider.scala:137)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.pc.HoverProvider$.hover(HoverProvider.scala:137)
	at scala.meta.internal.pc.ScalaPresentationCompiler.hover$$anonfun$1(ScalaPresentationCompiler.scala:329)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:146)
	at scala.meta.internal.pc.CompilerAccess.withNonInterruptableCompiler$$anonfun$1(CompilerAccess.scala:132)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:232)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

Nov 30, 2023 10:01:27 PM scala.meta.internal.mtags.SymbolIndexBucket addMtagsSourceFile
WARNING: Error indexing /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/WebServer.scala
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/WebServer.scala
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:371)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:422)
	at java.base/java.nio.file.Files.readAllBytes(Files.java:3206)
	at scala.meta.internal.io.PlatformFileIO$.slurp(PlatformFileIO.scala:45)
	at scala.meta.internal.io.FileIO$.slurp(FileIO.scala:24)
	at scala.meta.internal.mtags.ScalametaCommonEnrichments$XtensionAbsolutePath.toInput(ScalametaCommonEnrichments.scala:383)
	at scala.meta.internal.mtags.SymbolIndexBucket.addMtagsSourceFile(SymbolIndexBucket.scala:270)
	at scala.meta.internal.mtags.SymbolIndexBucket.addMtagsSourceFile(SymbolIndexBucket.scala:286)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1$adapted(SymbolIndexBucket.scala:190)
	at scala.collection.immutable.Set$Set3.foreach(Set.scala:261)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definition(OnDemandSymbolIndex.scala:48)
	at scala.meta.internal.metals.Docstrings.indexSymbol(Docstrings.scala:118)
	at scala.meta.internal.metals.Docstrings.documentation(Docstrings.scala:44)
	at scala.meta.internal.metals.MetalsSymbolSearch.documentation(MetalsSymbolSearch.scala:43)
	at scala.meta.internal.mtags.MtagsEnrichments$.symbolDocumentation(MtagsEnrichments.scala:209)
	at scala.meta.internal.pc.HoverProvider$.$anonfun$3(HoverProvider.scala:137)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.pc.HoverProvider$.hover(HoverProvider.scala:137)
	at scala.meta.internal.pc.ScalaPresentationCompiler.hover$$anonfun$1(ScalaPresentationCompiler.scala:329)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:146)
	at scala.meta.internal.pc.CompilerAccess.withNonInterruptableCompiler$$anonfun$1(CompilerAccess.scala:132)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:232)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

2023.11.30 22:02:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:02:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:02:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:02:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
Nov 30, 2023 10:03:12 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3262
2023.11.30 22:03:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:03:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.11.30 22:03:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:03:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.30 22:04:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:04:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 22:04:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:04:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:04:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:04:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:04:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:04:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:05:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:05:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.30 22:05:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:05:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.30 22:05:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:05:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.30 22:05:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:05:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.30 22:06:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:06:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:06:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:06:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 22:06:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:06:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.11.30 22:06:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:06:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 22:07:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:07:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:07:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.11.30 22:07:16 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/spark/DataframeApi.scala[0m
2023.11.30 22:07:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 22:07:16 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/spark/DataframeApi.scala[0m
2023.11.30 22:07:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:07:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.30 22:07:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:07:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.11.30 22:07:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:07:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 22:07:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:07:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.11.30 22:08:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:08:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.30 22:08:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:08:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 22:08:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:08:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.11.30 22:08:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:08:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.11.30 22:08:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:08:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.11.30 22:08:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:08:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.46s[0m
Nov 30, 2023 10:08:52 PM scala.meta.internal.mtags.SymbolIndexBucket addMtagsSourceFile
WARNING: Error indexing /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:371)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:422)
	at java.base/java.nio.file.Files.readAllBytes(Files.java:3206)
	at scala.meta.internal.io.PlatformFileIO$.slurp(PlatformFileIO.scala:45)
	at scala.meta.internal.io.FileIO$.slurp(FileIO.scala:24)
	at scala.meta.internal.mtags.ScalametaCommonEnrichments$XtensionAbsolutePath.toInput(ScalametaCommonEnrichments.scala:383)
	at scala.meta.internal.mtags.SymbolIndexBucket.addMtagsSourceFile(SymbolIndexBucket.scala:270)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1$adapted(SymbolIndexBucket.scala:190)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:210)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definition(OnDemandSymbolIndex.scala:48)
	at scala.meta.internal.metals.Docstrings.indexSymbol(Docstrings.scala:118)
	at scala.meta.internal.metals.Docstrings.documentation(Docstrings.scala:44)
	at scala.meta.internal.metals.MetalsSymbolSearch.documentation(MetalsSymbolSearch.scala:43)
	at scala.meta.internal.mtags.MtagsEnrichments$.symbolDocumentation(MtagsEnrichments.scala:209)
	at scala.meta.internal.pc.CompletionItemResolver$.resolve(CompletionItemResolver.scala:27)
	at scala.meta.internal.pc.ScalaPresentationCompiler.completionItemResolve$$anonfun$1(ScalaPresentationCompiler.scala:192)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:146)
	at scala.meta.internal.pc.CompilerAccess.withNonInterruptableCompiler$$anonfun$1(CompilerAccess.scala:132)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:232)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

Nov 30, 2023 10:08:52 PM scala.meta.internal.mtags.SymbolIndexBucket addMtagsSourceFile
WARNING: Error indexing /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/app/App.scala
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:371)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:422)
	at java.base/java.nio.file.Files.readAllBytes(Files.java:3206)
	at scala.meta.internal.io.PlatformFileIO$.slurp(PlatformFileIO.scala:45)
	at scala.meta.internal.io.FileIO$.slurp(FileIO.scala:24)
	at scala.meta.internal.mtags.ScalametaCommonEnrichments$XtensionAbsolutePath.toInput(ScalametaCommonEnrichments.scala:383)
	at scala.meta.internal.mtags.SymbolIndexBucket.addMtagsSourceFile(SymbolIndexBucket.scala:270)
	at scala.meta.internal.mtags.SymbolIndexBucket.addMtagsSourceFile(SymbolIndexBucket.scala:286)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.$anonfun$query0$1$adapted(SymbolIndexBucket.scala:190)
	at scala.collection.immutable.Set$Set2.foreach(Set.scala:210)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:190)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definition(OnDemandSymbolIndex.scala:48)
	at scala.meta.internal.metals.Docstrings.indexSymbol(Docstrings.scala:118)
	at scala.meta.internal.metals.Docstrings.documentation(Docstrings.scala:44)
	at scala.meta.internal.metals.MetalsSymbolSearch.documentation(MetalsSymbolSearch.scala:43)
	at scala.meta.internal.mtags.MtagsEnrichments$.symbolDocumentation(MtagsEnrichments.scala:209)
	at scala.meta.internal.pc.CompletionItemResolver$.resolve(CompletionItemResolver.scala:27)
	at scala.meta.internal.pc.ScalaPresentationCompiler.completionItemResolve$$anonfun$1(ScalaPresentationCompiler.scala:192)
	at scala.meta.internal.pc.CompilerAccess.withSharedCompiler(CompilerAccess.scala:146)
	at scala.meta.internal.pc.CompilerAccess.withNonInterruptableCompiler$$anonfun$1(CompilerAccess.scala:132)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:232)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

2023.11.30 22:08:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:08:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.11.30 22:08:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:08:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.11.30 22:09:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:09:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.11.30 22:10:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:10:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.30 22:10:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:10:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.30 22:11:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:11:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.11.30 22:11:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:11:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
Nov 30, 2023 10:11:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3838
2023.11.30 22:12:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:12:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.30 22:12:05 WARN  Using indexes to guess the definition of SparkJob[0m
2023.11.30 22:12:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:12:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.11.30 22:12:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:12:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.11.30 22:12:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:12:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.11.30 22:13:00 WARN  Using indexes to guess the definition of SparkJob[0m
2023.11.30 22:13:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:13:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.11.30 22:13:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:13:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.11.30 22:13:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:13:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.11.30 22:13:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:13:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.30 22:14:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:14:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.11.30 22:14:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:14:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.30 22:15:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:15:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:16:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:16:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:16:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:16:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:16:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:16:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:16:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:16:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:16:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:16:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:18:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:18:29 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.11.30 22:18:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 22:18:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:18:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.30 22:18:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:18:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 22:18:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:18:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.30 22:18:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:18:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 22:18:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:18:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 22:19:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:19:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.30 22:19:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:19:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 22:19:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:19:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.30 22:20:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:20:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:20:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:20:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 22:20:10 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.11.30 22:20:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:20:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:20:11 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.11.30 22:20:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:20:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:20:15 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/sparkjobs/SparkJobSuite.scala[0m
2023.11.30 22:20:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:20:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 22:20:16 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/sparkjobs/SparkJobSuite.scala[0m
2023.11.30 22:20:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:20:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:20:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:20:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:21:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:21:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:21:26 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/sparkjobs/SparkJobSuite.scala[0m
2023.11.30 22:21:28 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.11.30 22:21:29 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/sparkjobs/SparkJobSuite.scala[0m
2023.11.30 22:21:30 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.11.30 22:21:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:21:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 22:21:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:21:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:22:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:22:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.11.30 22:23:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:23:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:24:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:24:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:25:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:25:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:25:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:25:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:25:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:25:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:25:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:25:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:25:21 WARN  Using indexes to guess the definition of MinimalRoutesMain[0m
2023.11.30 22:25:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:25:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 22:25:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:25:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:25:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:25:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:25:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
Nov 30, 2023 10:25:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4563
2023.11.30 22:25:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 22:26:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:26:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.30 22:26:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:26:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 22:26:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:26:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 22:26:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:26:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.30 22:26:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:26:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.11.30 22:26:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:26:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.30 22:26:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:26:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.30 22:27:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:27:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:27:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:27:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.30 22:27:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:27:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.11.30 22:27:58 INFO  Shutting down server[0m
2023.11.30 22:27:58 INFO  shutting down Metals[0m
2023.11.30 22:27:58 INFO  Shut down connection with build server.[0m
2023.11.30 22:27:58 INFO  Shut down connection with build server.[0m
2023.11.30 22:27:58 INFO  Exiting server[0m
2023.11.30 22:29:51 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.30 22:29:52 INFO  Attempting to connect to the build server...[0m
2023.11.30 22:29:52 INFO  skipping build import with status 'Installed'[0m
2023.11.30 22:29:52 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 22:29:52 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 22:29:52 INFO  Attempting to connect to the build server...[0m
2023.11.30 22:29:52 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 22:29:52 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 22:29:52 INFO  time: Connected to build server in 0.54s[0m
2023.11.30 22:29:52 INFO  Connected to Build server: Bloop v1.5.11[0m
Nov 30, 2023 10:29:53 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 13
Nov 30, 2023 10:29:53 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 14
2023.11.30 22:29:54 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/web/IntegrationSuite.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.11.30 22:29:56 INFO  time: indexed workspace in 1.75s[0m
2023.11.30 22:29:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:29:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 1.15s[0m
2023.11.30 22:29:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:29:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.11.30 22:29:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:29:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.11.30 22:30:06 INFO  Disconnecting from Bloop session...[0m
2023.11.30 22:30:06 INFO  Shut down connection with build server.[0m
2023.11.30 22:30:06 INFO  Shut down connection with build server.[0m
2023.11.30 22:30:06 INFO  Deleted directories inside .bloop[0m
2023.11.30 22:30:06 INFO  Attempting to connect to the build server...[0m
2023.11.30 22:30:06 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 22:30:07 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 22:30:07 INFO  Attempting to connect to the build server...[0m
2023.11.30 22:30:07 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.30 22:30:07 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.30 22:30:07 INFO  time: Connected to build server in 1.19s[0m
2023.11.30 22:30:07 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.30 22:30:08 INFO  time: indexed workspace in 1.25s[0m
2023.11.30 22:30:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:30:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 2.1s[0m
2023.11.30 22:30:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:30:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.64s[0m
2023.11.30 22:30:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:30:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.67s[0m
2023.11.30 22:30:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:30:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.48s[0m
2023.11.30 22:30:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:30:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.11.30 22:30:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:30:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.30 22:31:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:31:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.24s[0m
2023.11.30 22:31:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:31:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.11.30 22:31:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:31:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.30 22:31:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.30 22:31:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.37s[0m
2023.12.01 08:49:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:49:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.01 08:51:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:51:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
Dec 01, 2023 8:51:17 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 194
2023.12.01 08:51:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:51:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.01 08:51:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:51:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.01 08:51:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:51:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.01 08:51:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:51:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.01 08:51:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:51:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 08:51:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:51:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.01 08:52:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:52:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.01 08:52:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:52:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.12.01 08:52:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:52:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.01 08:52:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:52:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.01 08:52:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:52:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.12.01 08:52:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:52:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.01 08:52:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:52:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
Dec 01, 2023 8:52:40 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 371
2023.12.01 08:52:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:52:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.12.01 08:52:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:52:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 08:53:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:53:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.01 08:53:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:53:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 08:53:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:53:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.12.01 08:53:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:53:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 08:53:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:53:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.24s[0m
Dec 01, 2023 8:53:55 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085)_08-53-55-589.md
2023.12.01 08:56:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:56:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 08:56:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:56:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 08:56:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:56:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 08:56:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:56:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
Dec 01, 2023 8:56:18 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 504
2023.12.01 08:56:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:56:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 08:56:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:56:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 08:56:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:56:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 08:56:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:56:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 08:56:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 08:56:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.12.01 09:15:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:15:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.45s[0m
2023.12.01 09:15:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:15:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.12.01 09:15:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:15:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.01 09:16:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:16:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.01 09:16:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:16:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.01 09:16:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:16:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:16:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:16:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:16:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:16:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:16:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:16:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 09:16:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:16:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 09:16:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:16:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.12.01 09:16:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:16:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:16:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:16:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:16:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:16:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:17:07 WARN  Using indexes to guess the definition of Dataset[0m
2023.12.01 09:17:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:17:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.01 09:17:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:17:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.12.01 09:17:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:17:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.37s[0m
2023.12.01 09:17:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:17:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 09:17:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:17:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 09:17:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:17:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:17:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:17:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 09:18:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:18:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:18:21 WARN  Using indexes to guess the definition of Dataset[0m
2023.12.01 09:18:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:18:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 09:18:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:18:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.12.01 09:18:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:18:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.12.01 09:18:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:18:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.01 09:18:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:18:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.12.01 09:18:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:18:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.12.01 09:18:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:18:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.01 09:18:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:18:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.01 09:18:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:18:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:18:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:18:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:19:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:19:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:19:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:19:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:19:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:19:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:20:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:20:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:20:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:20:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:20:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:20:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:20:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:20:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
Dec 01, 2023 9:21:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085)_09-21-33-938.md
Dec 01, 2023 9:21:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085)_09-21-34-384.md
2023.12.01 09:22:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:22:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:22:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:22:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:22:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:22:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 09:23:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:23:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:23:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:23:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:23:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:23:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:23:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:23:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:24:14 WARN  Using indexes to guess the definition of Expression[0m
2023.12.01 09:24:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:24:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:24:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:24:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:24:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:24:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:24:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:24:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:24:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:24:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:24:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:24:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 09:24:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:24:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:25:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:25:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:25:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:25:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:26:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:26:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:26:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:26:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:26:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:26:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:26:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:26:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:26:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:26:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 09:27:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:27:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:27:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:27:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:27:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:27:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:27:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:27:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:27:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:27:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:28:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:28:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.01 09:28:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:28:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:28:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:28:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:28:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:28:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:28:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:28:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:28:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:28:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:28:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:28:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:29:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:29:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:29:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:29:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:29:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:29:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:29:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:29:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:29:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:29:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 09:29:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:29:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:29:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:29:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:29:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:29:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:30:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:30:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:30:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:30:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:30:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:30:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:31:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:31:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:31:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:31:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:32:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:32:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:32:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:32:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:32:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:32:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:32:38 WARN  Using indexes to guess the definition of StructField[0m
2023.12.01 09:32:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:32:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 09:32:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:32:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:32:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:32:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:32:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:32:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:34:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:34:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:34:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:34:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
Dec 01, 2023 9:34:46 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2244
2023.12.01 09:34:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:34:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:34:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:34:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:35:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:35:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:35:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:35:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:35:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:35:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:35:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:35:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:35:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:35:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:35:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:35:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:36:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:36:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.01 09:36:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:36:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:36:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:36:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:36:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:36:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:36:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:36:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:37:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:37:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:37:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:37:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:37:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:37:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:37:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:37:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 09:37:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:37:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:37:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:37:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:38:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:38:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.01 09:38:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:38:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:38:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:38:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:38:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:38:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:38:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:38:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:38:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:38:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:38:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:39:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:39:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:39:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:39:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:39:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:39:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:39:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:39:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:39:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:39:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:39:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:39:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:40:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:40:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:40:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:40:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:40:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:40:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:40:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:40:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:41:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:41:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:41:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:41:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:41:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:41:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 09:42:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:42:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.12.01 09:42:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:42:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:42:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:42:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:42:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:42:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:42:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:42:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:42:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:42:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:42:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:42:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:42:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:42:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:42:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:42:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:42:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:42:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:43:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:43:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:43:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:43:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:43:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:43:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:43:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:43:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.12.01 09:43:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:43:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:43:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:43:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:43:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:43:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:43:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:43:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:48:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:48:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:48:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:48:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:48:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:48:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:48:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:48:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:48:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:48:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:48:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:48:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:49:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:49:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:49:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:49:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:49:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:49:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:49:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:49:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:49:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:49:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:49:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:49:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:49:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:49:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:50:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:50:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.01 09:50:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:50:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:50:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:50:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:50:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:50:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:50:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:50:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:50:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:50:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:50:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:50:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:50:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:50:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:50:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:50:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.01 09:51:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:51:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:51:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:51:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.01 09:51:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:51:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:51:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:51:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:51:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:51:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 09:51:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:51:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:51:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:51:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:51:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:51:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.74s[0m
2023.12.01 09:52:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:52:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:52:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:52:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:52:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:52:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 09:52:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:52:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 09:52:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:52:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:52:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:52:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:52:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:52:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 09:52:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:52:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 09:53:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:53:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 09:53:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:53:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:53:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:53:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:53:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:53:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:53:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:53:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:53:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:53:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:54:28 WARN  Using indexes to guess the definition of Row[0m
2023.12.01 09:54:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:54:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:54:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:54:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:54:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:54:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:54:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:54:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:54:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:54:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:54:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:54:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:56:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:56:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:56:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:56:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:57:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:57:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:57:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:57:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:57:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:57:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 09:57:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:57:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:57:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:57:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:58:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:58:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:58:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:58:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:58:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:58:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 09:58:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:58:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:58:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:58:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:58:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:58:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 09:58:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:58:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:58:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:58:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:58:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:58:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:58:48 WARN  Using indexes to guess the definition of Expression[0m
2023.12.01 09:58:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:58:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:58:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:58:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 09:59:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:59:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:59:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:59:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:59:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:59:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 09:59:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 09:59:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:00:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:00:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:00:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:00:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:00:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:00:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:00:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:00:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:02:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:02:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:03:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:03:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 10:03:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:03:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 10:03:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:03:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 10:03:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:03:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 10:03:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:03:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:03:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:03:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:03:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:03:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 10:03:51 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/sparkjobs/SparkJob.scala
scala.meta.tokenizers.TokenizeException: <input>:73: error: unclosed character literal
    val result = runMakeDummyDf().flatMap(x => x.ma')
                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 10:03:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:03:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 10:03:52 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/sparkjobs/SparkJob.scala
scala.meta.tokenizers.TokenizeException: <input>:73: error: unclosed character literal
    val result = runMakeDummyDf().flatMap(x => x.ma')
                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 10:03:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:03:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 10:03:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:03:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:04:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:04:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:05:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:05:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 10:05:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:05:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:05:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:05:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 10:05:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:05:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:05:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:05:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:05:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:05:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:05:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:05:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:05:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:05:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:05:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:05:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:06:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:06:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 10:06:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:06:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:06:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:06:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:06:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:06:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:06:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:06:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.01 10:06:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:06:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 10:06:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:06:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:06:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:06:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:06:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:06:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:06:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:06:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 10:06:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:06:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:07:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:07:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:07:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:07:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 10:07:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:07:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:07:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:07:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 10:08:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:08:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 10:09:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:09:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:09:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:09:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:09:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:09:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:09:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:09:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:09:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:09:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:09:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:09:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:09:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:09:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 10:10:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:10:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:11:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:11:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:11:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:11:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:11:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:11:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:11:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:11:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:11:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:11:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:12:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:12:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:12:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:12:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:12:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:12:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:12:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:12:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:12:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:12:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:13:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:13:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:13:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:13:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:13:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:13:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:13:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:13:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:14:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:14:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
Dec 01, 2023 10:14:11 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5748
2023.12.01 10:14:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:14:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:14:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:14:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:15:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:15:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:16:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:16:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:16:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:16:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:16:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:16:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:16:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:16:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:16:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:16:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:16:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:16:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:17:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:17:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:17:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:17:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:18:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:18:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:18:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:18:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:18:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:18:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
Dec 01, 2023 10:19:32 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6066
2023.12.01 10:19:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:19:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:20:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:20:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:20:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:20:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 10:20:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:20:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.57s[0m
2023.12.01 10:20:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:20:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.01 10:21:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:21:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 10:21:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:21:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.12.01 10:21:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:21:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 10:21:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:21:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.01 10:21:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:21:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 10:21:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:21:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:21:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:21:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 10:26:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:26:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:26:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:26:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
Dec 01, 2023 10:26:15 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6413
2023.12.01 10:26:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:26:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:26:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:26:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:26:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:26:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:26:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:26:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 10:27:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:27:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 3.1s[0m
2023.12.01 10:27:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:27:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
Dec 01, 2023 10:27:39 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085)_10-27-39-119.md
2023.12.01 10:27:47 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:27:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.12s[0m
2023.12.01 10:27:48 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:27:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.93s[0m
2023.12.01 10:28:11 INFO  Disconnecting from Bloop session...[0m
2023.12.01 10:28:11 INFO  Shut down connection with build server.[0m
2023.12.01 10:28:11 INFO  Shut down connection with build server.[0m
2023.12.01 10:28:11 INFO  Deleted directories inside .bloop[0m
2023.12.01 10:28:11 INFO  Attempting to connect to the build server...[0m
2023.12.01 10:28:11 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 10:28:12 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 10:28:12 INFO  Attempting to connect to the build server...[0m
2023.12.01 10:28:12 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 10:28:12 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 10:28:12 INFO  time: Connected to build server in 1.09s[0m
2023.12.01 10:28:12 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.12.01 10:28:13 INFO  time: indexed workspace in 1.24s[0m
2023.12.01 10:28:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 10:28:19 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:28:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 5.59s[0m
2023.12.01 10:28:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.46s[0m
2023.12.01 10:30:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:30:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 10:30:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:30:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:30:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:30:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:30:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:30:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 30ms[0m
2023.12.01 10:30:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:30:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 51ms[0m
2023.12.01 10:30:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:30:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.01 10:31:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:31:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:32:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:32:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.1s[0m
2023.12.01 10:33:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:33:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.01 10:33:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:33:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 95ms[0m
2023.12.01 10:33:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:33:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 94ms[0m
2023.12.01 10:35:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:35:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 92ms[0m
2023.12.01 10:36:16 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:36:16 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.12.01 10:36:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.89s[0m
2023.12.01 10:36:17 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.12.01 10:36:20 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:36:20 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/sparkjobs/SparkJobSuite.scala[0m
2023.12.01 10:36:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.89s[0m
2023.12.01 10:36:21 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/sparkjobs/SparkJobSuite.scala[0m
2023.12.01 10:36:25 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:36:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.94s[0m
2023.12.01 10:37:26 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:37:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.81s[0m
2023.12.01 10:37:33 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:37:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.84s[0m
2023.12.01 10:37:47 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:37:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.84s[0m
2023.12.01 10:37:57 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:37:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.78s[0m
2023.12.01 10:38:27 INFO  Shutting down server[0m
2023.12.01 10:38:27 INFO  shutting down Metals[0m
2023.12.01 10:38:27 INFO  Shut down connection with build server.[0m
2023.12.01 10:38:27 INFO  Shut down connection with build server.[0m
2023.12.01 10:38:27 INFO  Exiting server[0m
2023.12.01 10:38:37 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.12.01 10:38:38 INFO  Attempting to connect to the build server...[0m
2023.12.01 10:38:38 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 10:38:38 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 10:38:38 INFO  Attempting to connect to the build server...[0m
2023.12.01 10:38:38 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 10:38:38 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 10:38:38 INFO  time: Connected to build server in 0.49s[0m
2023.12.01 10:38:38 INFO  Connected to Build server: Bloop v1.5.11[0m
Dec 01, 2023 10:38:39 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 25
Dec 01, 2023 10:38:39 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 26
Dec 01, 2023 10:38:39 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 27
2023.12.01 10:38:40 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/sparkjobs/SparkJob.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.12.01 10:38:40 INFO  running '/home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals8517310378557000074/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'[0m
2023.12.01 10:38:41 INFO  [info] welcome to sbt 1.9.6 (Eclipse Adoptium Java 11.0.20)[0m
2023.12.01 10:38:41 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build-build from metals.sbt ...[0m
2023.12.01 10:38:43 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/project[0m
2023.12.01 10:38:43 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build from metals.sbt ...[0m
2023.12.01 10:38:43 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project[0m
2023.12.01 10:38:45 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-build.json[0m
2023.12.01 10:38:45 INFO  [success] Total time: 1 s, completed Dec 1, 2023, 10:38:45 AM[0m
2023.12.01 10:38:45 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085 from build.sbt ...[0m
2023.12.01 10:38:45 INFO  [info] set current project to myScala3Project (in build file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/)[0m
2023.12.01 10:38:45 INFO  time: indexed workspace in 4.79s[0m
2023.12.01 10:38:46 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085.json[0m
2023.12.01 10:38:46 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-test.json[0m
2023.12.01 10:38:46 INFO  [success] Total time: 1 s, completed Dec 1, 2023, 10:38:46 AM[0m
2023.12.01 10:38:46 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:38:46 INFO  time: ran 'sbt bloopInstall' in 5.77s[0m
2023.12.01 10:38:46 INFO  Cancelling compilation on Bloop server[0m
2023.12.01 10:38:46 INFO  Disconnecting from Bloop session...[0m
2023.12.01 10:38:46 INFO  Shut down connection with build server.[0m
2023.12.01 10:38:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.13s[0m
2023.12.01 10:38:46 INFO  Shut down connection with build server.[0m
2023.12.01 10:38:46 INFO  Attempting to connect to the build server...[0m
2023.12.01 10:38:46 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 10:38:46 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 10:38:46 INFO  Attempting to connect to the build server...[0m
2023.12.01 10:38:46 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 10:38:46 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 10:38:46 INFO  time: Connected to build server in 0.13s[0m
2023.12.01 10:38:46 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.12.01 10:38:48 INFO  time: indexed workspace in 1.84s[0m
2023.12.01 10:38:49 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:38:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.63s[0m
error: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/.metals/.tmp/Main-5183317794563868355.scala is not a file
2023.12.01 10:38:54 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:38:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.79s[0m
2023.12.01 10:38:57 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:38:57 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.12.01 10:38:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.77s[0m
2023.12.01 10:38:57 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.12.01 10:39:07 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:39:07 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/sparkjobs/SparkJobSuite.scala[0m
2023.12.01 10:39:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.75s[0m
2023.12.01 10:39:07 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/sparkjobs/SparkJobSuite.scala[0m
2023.12.01 10:39:10 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:39:10 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.12.01 10:39:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.75s[0m
2023.12.01 10:39:11 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.12.01 10:39:14 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:39:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.82s[0m
2023.12.01 10:39:24 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:39:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.78s[0m
2023.12.01 10:39:29 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:39:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.76s[0m
2023.12.01 10:39:33 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:39:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.81s[0m
2023.12.01 10:39:45 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:39:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.7s[0m
2023.12.01 10:40:17 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:40:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.19s[0m
2023.12.01 10:40:46 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/web/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:129: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 10:40:46 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:40:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.17s[0m
2023.12.01 10:40:47 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/web/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:129: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 10:40:51 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (8 scala sources)[0m
2023.12.01 10:40:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.52s[0m
2023.12.01 10:41:25 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 10:41:25 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 10:41:25 INFO  Starting debug proxy for [startup.property_based_testing.StartUpPropertiesSuite()][0m
2023.12.01 10:41:25 INFO  Trying to attach to remote debuggee VM localhost:44635 .[0m
2023.12.01 10:41:25 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 10:41:26 INFO  Canceling debug proxy for [startup.property_based_testing.StartUpPropertiesSuite()][0m
2023.12.01 10:41:25 INFO  Closing debug server tcp://0.0.0.0:36353[0m
2023.12.01 10:41:37 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 10:41:37 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 10:41:37 INFO  Starting debug proxy for [startup.unit_testing.ComputationSuite()][0m
2023.12.01 10:41:37 INFO  Trying to attach to remote debuggee VM localhost:60197 .[0m
2023.12.01 10:41:37 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 10:41:38 INFO  Canceling debug proxy for [startup.unit_testing.ComputationSuite()][0m
2023.12.01 10:41:37 INFO  Closing debug server tcp://0.0.0.0:37173[0m
2023.12.01 10:41:44 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 10:41:44 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 10:41:44 INFO  Starting debug proxy for [startup.unit_testing.StartUpSuite()][0m
2023.12.01 10:41:45 INFO  Trying to attach to remote debuggee VM localhost:55991 .[0m
2023.12.01 10:41:45 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 10:41:44 INFO  Canceling debug proxy for [startup.unit_testing.StartUpSuite()][0m
2023.12.01 10:41:45 INFO  Closing debug server tcp://0.0.0.0:39535[0m
2023.12.01 10:42:09 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 10:42:09 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 10:42:09 INFO  Starting debug proxy for [web.WebServerSuite(MinimalApplication)][0m
2023.12.01 10:42:09 INFO  Trying to attach to remote debuggee VM localhost:39675 .[0m
2023.12.01 10:42:09 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 10:42:09 INFO  Closing debug server tcp://0.0.0.0:34717[0m
2023.12.01 10:42:10 INFO  Canceling debug proxy for [web.WebServerSuite(MinimalApplication)][0m
2023.12.01 10:42:49 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 10:42:49 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 10:42:49 INFO  Starting debug proxy for [web.httpServerSuite(test1)][0m
2023.12.01 10:42:49 INFO  Trying to attach to remote debuggee VM localhost:34107 .[0m
2023.12.01 10:42:49 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 10:42:49 INFO  Closing debug server tcp://0.0.0.0:33027[0m
2023.12.01 10:42:50 INFO  Canceling debug proxy for [web.httpServerSuite(test1)][0m
2023.12.01 10:42:56 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 10:42:56 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 10:42:56 INFO  Starting debug proxy for [web.httpServerSuite(test2)][0m
2023.12.01 10:42:56 INFO  Trying to attach to remote debuggee VM localhost:55843 .[0m
2023.12.01 10:42:56 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 10:42:56 INFO  Closing debug server tcp://0.0.0.0:38071[0m
2023.12.01 10:42:57 INFO  Canceling debug proxy for [web.httpServerSuite(test2)][0m
2023.12.01 10:43:03 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 10:43:03 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 10:43:03 INFO  Starting debug proxy for [web.httpServerSuite(test3)][0m
2023.12.01 10:43:03 INFO  Trying to attach to remote debuggee VM localhost:57501 .[0m
2023.12.01 10:43:03 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 10:43:03 INFO  Closing debug server tcp://0.0.0.0:33765[0m
2023.12.01 10:43:04 INFO  Canceling debug proxy for [web.httpServerSuite(test3)][0m
2023.12.01 10:43:12 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 10:43:12 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 10:43:12 INFO  Starting debug proxy for [web.httpServerSuite(test5)][0m
2023.12.01 10:43:12 INFO  Trying to attach to remote debuggee VM localhost:49395 .[0m
2023.12.01 10:43:12 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 10:43:12 INFO  Closing debug server tcp://0.0.0.0:35121[0m
2023.12.01 10:43:13 INFO  Canceling debug proxy for [web.httpServerSuite(test5)][0m
2023.12.01 10:43:22 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 10:43:22 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 10:43:22 INFO  Starting debug proxy for [web.httpServerSuite(test6)][0m
2023.12.01 10:43:22 INFO  Trying to attach to remote debuggee VM localhost:50999 .[0m
2023.12.01 10:43:22 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 10:43:22 INFO  Closing debug server tcp://0.0.0.0:38839[0m
2023.12.01 10:43:23 INFO  Canceling debug proxy for [web.httpServerSuite(test6)][0m
Dec 01, 2023 10:43:29 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 428
2023.12.01 10:46:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:46:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:46:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:46:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:46:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:46:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
Dec 01, 2023 10:46:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085)_10-46-34-651.md
2023.12.01 10:46:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:46:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.42s[0m
2023.12.01 10:46:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:46:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.4s[0m
2023.12.01 10:46:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:46:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:46:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:46:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 10:47:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:47:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 10:47:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:47:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 10:47:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:47:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 10:47:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:47:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:47:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:47:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 10:47:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:47:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:47:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:47:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:47:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:47:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:48:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:48:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:48:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:48:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 10:48:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:48:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:48:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:48:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.01 10:48:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:48:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:48:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:48:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 10:48:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:48:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
Dec 01, 2023 10:49:44 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085)_10-49-44-259.md
2023.12.01 10:49:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:49:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 10:49:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:49:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 10:50:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:50:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 10:50:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:50:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 10:50:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:50:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 10:50:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:50:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 10:50:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:50:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:50:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:50:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 10:51:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:51:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.12.01 10:51:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:51:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 10:51:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:51:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:51:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:51:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 10:52:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:52:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 10:52:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:52:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 10:52:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:52:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 10:52:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:52:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 10:52:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:52:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 10:52:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:52:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 10:52:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:52:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.01 10:52:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:52:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 10:53:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:53:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 10:54:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 10:54:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:13:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:13:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:13:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:13:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:13:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:13:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 11:13:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:13:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:13:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:13:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:13:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:13:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 70ms[0m
2023.12.01 11:13:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:13:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 69ms[0m
2023.12.01 11:14:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:14:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.01 11:14:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:14:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 66ms[0m
2023.12.01 11:14:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:14:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
Dec 01, 2023 11:14:11 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1739
2023.12.01 11:16:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:16:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 11:16:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:16:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:16:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:16:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 11:16:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:16:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.12.01 11:17:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:17:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.42s[0m
2023.12.01 11:18:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:18:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 11:18:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:18:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.52s[0m
2023.12.01 11:18:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:18:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.47s[0m
2023.12.01 11:18:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:18:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 11:18:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:18:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 11:18:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:18:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 11:18:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:18:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 11:18:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:18:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 11:18:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:18:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.38s[0m
2023.12.01 11:18:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:18:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 11:18:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:18:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.4s[0m
2023.12.01 11:19:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:19:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:19:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:19:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 11:19:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:19:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 11:19:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:19:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 11:19:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:19:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.4s[0m
2023.12.01 11:20:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:20:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.37s[0m
2023.12.01 11:25:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:25:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.12.01 11:25:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:25:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 35ms[0m
2023.12.01 11:25:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:25:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.01 11:25:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:25:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 37ms[0m
2023.12.01 11:25:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:25:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 11:25:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:25:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 11:25:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:25:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 11:25:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:25:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 11:26:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:26:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 11:26:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:26:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 11:26:10 WARN  Using indexes to guess the definition of MinimalRoutes[0m
2023.12.01 11:26:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:26:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:26:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:26:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 11:26:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:26:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 11:26:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:26:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 11:26:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:26:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 11:26:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:26:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 11:27:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:27:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 11:27:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:27:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 11:27:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:27:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 11:27:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:27:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 11:27:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:27:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 11:28:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:28:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 11:28:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:28:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 11:29:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.01 11:29:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.37s[0m
2023.12.01 11:31:19 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:31:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.39s[0m
2023.12.01 11:31:51 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:31:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.53s[0m
2023.12.01 11:31:56 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:31:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.23s[0m
2023.12.01 11:31:57 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:31:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.23s[0m
2023.12.01 11:33:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:33:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.01 11:33:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:33:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 25ms[0m
2023.12.01 11:33:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:33:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 24ms[0m
2023.12.01 11:33:39 WARN  Using indexes to guess the definition of RoutesMain[0m
2023.12.01 11:33:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:33:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 95ms[0m
2023.12.01 11:33:48 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:33:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.4s[0m
2023.12.01 11:34:12 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:34:12 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.12.01 11:34:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.31s[0m
2023.12.01 11:34:13 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/MyAppSuite.scala[0m
2023.12.01 11:34:30 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (3 scala sources)[0m
2023.12.01 11:34:30 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/WebServerSuite.scala[0m
2023.12.01 11:34:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.28s[0m
2023.12.01 11:34:32 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (3 scala sources)[0m
2023.12.01 11:34:32 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/WebServerSuite.scala[0m
2023.12.01 11:34:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.39s[0m
2023.12.01 11:34:33 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/WebServerSuite.scala[0m
2023.12.01 11:34:33 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/WebServerSuite.scala[0m
2023.12.01 11:34:40 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (3 scala sources)[0m
2023.12.01 11:34:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.25s[0m
2023.12.01 11:34:44 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (3 scala sources)[0m
2023.12.01 11:34:44 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/WebServerSuite.scala[0m
2023.12.01 11:34:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.22s[0m
2023.12.01 11:34:45 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/WebServerSuite.scala[0m
2023.12.01 11:34:54 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (3 scala sources)[0m
2023.12.01 11:34:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.29s[0m
2023.12.01 11:34:55 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (3 scala sources)[0m
2023.12.01 11:34:55 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/WebServerSuite.scala[0m
2023.12.01 11:34:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.28s[0m
2023.12.01 11:34:56 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/WebServerSuite.scala[0m
2023.12.01 11:35:03 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (3 scala sources)[0m
2023.12.01 11:35:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.2s[0m
Dec 01, 2023 11:35:10 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3228
2023.12.01 11:35:10 WARN  Could not find semantic tokens for: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/WebServerSuite.scala[0m
2023.12.01 11:35:15 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:35:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.23s[0m
2023.12.01 11:35:16 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:35:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.25s[0m
2023.12.01 11:35:17 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:35:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.27s[0m
2023.12.01 11:35:33 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:35:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.21s[0m
2023.12.01 11:35:42 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:35:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.24s[0m
2023.12.01 11:35:45 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:35:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.2s[0m
2023.12.01 11:35:55 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:35:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.06s[0m
2023.12.01 11:36:07 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:36:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.13s[0m
2023.12.01 11:36:14 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:36:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.08s[0m
2023.12.01 11:36:19 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:36:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.08s[0m
2023.12.01 11:36:24 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:36:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.16s[0m
2023.12.01 11:36:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:36:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.1s[0m
2023.12.01 11:36:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:36:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.01 11:36:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:36:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 86ms[0m
2023.12.01 11:37:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:37:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 93ms[0m
2023.12.01 11:37:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:37:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 86ms[0m
2023.12.01 11:37:09 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:37:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.18s[0m
2023.12.01 11:37:14 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:37:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.14s[0m
2023.12.01 11:37:37 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:37:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.12s[0m
2023.12.01 11:37:41 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:37:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.09s[0m
2023.12.01 11:37:48 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:37:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.09s[0m
2023.12.01 11:39:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:39:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 93ms[0m
2023.12.01 11:39:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:39:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 86ms[0m
2023.12.01 11:39:19 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:39:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.15s[0m
2023.12.01 11:39:24 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:39:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.16s[0m
2023.12.01 11:40:19 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:40:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.06s[0m
2023.12.01 11:40:24 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:40:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.02s[0m
2023.12.01 11:40:35 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:40:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.96s[0m
2023.12.01 11:40:39 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:40:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.75s[0m
2023.12.01 11:40:45 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:40:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.84s[0m
2023.12.01 11:40:48 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:40:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.48s[0m
2023.12.01 11:40:52 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.01 11:40:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.27s[0m
2023.12.01 11:40:59 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 11:40:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.21s[0m
Dec 01, 2023 11:46:12 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4000
Dec 01, 2023 11:46:12 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4001
Dec 01, 2023 11:46:12 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4002
Dec 01, 2023 11:46:12 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4003
Dec 01, 2023 11:46:12 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4004
Dec 01, 2023 11:46:12 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4005
Dec 01, 2023 11:46:12 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4006
2023.12.01 11:52:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:52:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:52:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:52:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 76ms[0m
2023.12.01 11:52:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:52:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.01 11:52:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:52:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.01 11:52:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:52:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:53:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:53:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:53:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 11:53:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 11:55:16 ERROR Unable to run scalafix, please check logs for more info.
java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Dec 01, 2023 11:55:16 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.util.concurrent.ExecutionException: Boxed Exception
java.util.concurrent.CompletionException: java.util.concurrent.ExecutionException: Boxed Exception
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.util.concurrent.ExecutionException: Boxed Exception
	at scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolve(Promise.scala:99)
	at scala.concurrent.impl.Promise$DefaultPromise.<init>(Promise.scala:108)
	at scala.concurrent.Promise$.failed(Promise.scala:147)
	at scala.concurrent.Future$.failed(Future.scala:651)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:141)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
Caused by: java.util.ServiceConfigurationError: scalafix.v1.Rule: scalafix.internal.rule.DisableSyntax not a subtype
	at java.base/java.util.ServiceLoader.fail(ServiceLoader.java:589)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNextService(ServiceLoader.java:1237)
	at java.base/java.util.ServiceLoader$LazyClassPathLookupIterator.hasNext(ServiceLoader.java:1265)
	at java.base/java.util.ServiceLoader$2.hasNext(ServiceLoader.java:1300)
	at java.base/java.util.ServiceLoader$3.hasNext(ServiceLoader.java:1385)
	at scala.collection.convert.JavaCollectionWrappers$JIteratorWrapper.hasNext(JavaCollectionWrappers.scala:46)
	at scala.collection.immutable.List.prependedAll(List.scala:152)
	at scala.collection.IterableOnceOps.toList(IterableOnce.scala:1315)
	at scala.collection.IterableOnceOps.toList$(IterableOnce.scala:1315)
	at scala.collection.AbstractIterator.toList(Iterator.scala:1300)
	at scalafix.internal.v1.Rules$.all(Rules.scala:104)
	at scalafix.v1.RuleDecoder$$anon$1.<init>(RuleDecoder.scala:106)
	at scalafix.v1.RuleDecoder$.decoder(RuleDecoder.scala:105)
	at scalafix.internal.v1.Args.ruleDecoder(Args.scala:253)
	at scalafix.internal.v1.Args.configuredRules(Args.scala:287)
	at scalafix.internal.v1.Args.$anonfun$validate$1(Args.scala:419)
	at metaconfig.Configured.andThen(Configured.scala:45)
	at scalafix.internal.v1.Args.validate(Args.scala:415)
	at scalafix.internal.interfaces.ScalafixArgumentsImpl.evaluate(ScalafixArgumentsImpl.scala:43)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$6(ScalafixProvider.scala:402)
	at scala.util.Success.map(Try.scala:262)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$scalafixEvaluate$5(ScalafixProvider.scala:374)
	at scala.util.Success.flatMap(Try.scala:258)
	at scala.meta.internal.metals.ScalafixProvider.scalafixEvaluate(ScalafixProvider.scala:373)
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:132)
	... 4 more

2023.12.01 11:55:43 INFO  Shutting down server[0m
2023.12.01 11:55:43 INFO  shutting down Metals[0m
2023.12.01 11:55:43 INFO  Shut down connection with build server.[0m
2023.12.01 11:55:43 INFO  Shut down connection with build server.[0m
2023.12.01 11:55:43 INFO  Exiting server[0m
2023.12.01 11:55:51 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.12.01 11:55:51 INFO  Attempting to connect to the build server...[0m
2023.12.01 11:55:51 INFO  skipping build import with status 'Installed'[0m
2023.12.01 11:55:51 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 11:55:52 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 11:55:52 INFO  Attempting to connect to the build server...[0m
2023.12.01 11:55:52 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 11:55:52 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 11:55:52 INFO  time: Connected to build server in 0.54s[0m
2023.12.01 11:55:52 INFO  Connected to Build server: Bloop v1.5.11[0m
Dec 01, 2023 11:55:53 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 25
Dec 01, 2023 11:55:53 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 26
Dec 01, 2023 11:55:53 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 27
Dec 01, 2023 11:55:53 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 28
2023.12.01 11:55:54 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/sparkjobs/SparkJob.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.12.01 11:55:56 INFO  time: indexed workspace in 1.63s[0m
2023.12.01 11:56:36 INFO  time: code lens generation in 1.73s[0m
Dec 01, 2023 11:57:24 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 66
Dec 01, 2023 11:57:24 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 67
Dec 01, 2023 11:57:24 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 68
Dec 01, 2023 11:57:24 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 70
Dec 01, 2023 11:57:24 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 72
Dec 01, 2023 11:57:24 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 73
Dec 01, 2023 12:22:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085-build)_12-22-00-539.md
Dec 01, 2023 12:22:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085-build)_12-22-01-308.md
Dec 01, 2023 12:22:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085-build)_12-22-01-692.md
2023.12.01 12:28:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 12:28:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 12:28:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 12:28:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 12:28:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 12:28:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
Dec 01, 2023 12:31:43 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 291
2023.12.01 12:52:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 12:52:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.12.01 12:56:20 INFO  Disconnecting from Bloop session...[0m
2023.12.01 12:56:20 INFO  Shut down connection with build server.[0m
2023.12.01 12:56:20 INFO  Shut down connection with build server.[0m
2023.12.01 12:56:20 INFO  Deleted directories inside .bloop[0m
2023.12.01 12:56:20 INFO  Attempting to connect to the build server...[0m
2023.12.01 12:56:20 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 12:56:20 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 12:56:21 INFO  Attempting to connect to the build server...[0m
2023.12.01 12:56:21 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 12:56:21 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 12:56:21 INFO  time: Connected to build server in 1.1s[0m
2023.12.01 12:56:21 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.12.01 12:56:23 INFO  time: indexed workspace in 1.25s[0m
2023.12.01 12:56:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 12:56:28 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (7 scala sources)[0m
2023.12.01 12:56:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 5.44s[0m
2023.12.01 12:56:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 1.03s[0m
Dec 01, 2023 12:59:16 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2023.12.01 12:59:26 INFO  Shutting down server[0m
2023.12.01 12:59:26 INFO  shutting down Metals[0m
2023.12.01 12:59:27 INFO  Shut down connection with build server.[0m
2023.12.01 12:59:27 INFO  Shut down connection with build server.[0m
2023.12.01 12:59:26 INFO  Exiting server[0m
2023.12.01 12:59:46 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.12.01 12:59:46 INFO  Attempting to connect to the build server...[0m
2023.12.01 12:59:46 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 12:59:46 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 12:59:47 INFO  Attempting to connect to the build server...[0m
2023.12.01 12:59:47 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 12:59:47 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 12:59:47 INFO  time: Connected to build server in 0.48s[0m
2023.12.01 12:59:47 INFO  Connected to Build server: Bloop v1.5.11[0m
Dec 01, 2023 12:59:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 13
Dec 01, 2023 12:59:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 14
2023.12.01 12:59:48 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/sparkjobs/SparkJob.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.12.01 12:59:50 INFO  running '/home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals11767819379734127128/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'[0m
2023.12.01 12:59:52 INFO  [info] welcome to sbt 1.9.6 (Eclipse Adoptium Java 11.0.20)[0m
2023.12.01 12:59:52 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build-build from metals.sbt ...[0m
2023.12.01 12:59:53 INFO  time: indexed workspace in 3.95s[0m
2023.12.01 12:59:53 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/project[0m
2023.12.01 12:59:53 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build from metals.sbt ...[0m
2023.12.01 12:59:53 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project[0m
2023.12.01 12:59:55 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-build.json[0m
2023.12.01 12:59:55 INFO  [success] Total time: 2 s, completed Dec 1, 2023, 12:59:55 PM[0m
2023.12.01 12:59:55 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085 from build.sbt ...[0m
2023.12.01 12:59:55 INFO  [info] set current project to myScala3Project (in build file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/)[0m
2023.12.01 12:59:59 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085.json[0m
2023.12.01 12:59:59 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-test.json[0m
2023.12.01 12:59:59 INFO  [success] Total time: 3 s, completed Dec 1, 2023, 12:59:59 PM[0m
2023.12.01 12:59:59 INFO  time: ran 'sbt bloopInstall' in 8.96s[0m
2023.12.01 12:59:59 INFO  Disconnecting from Bloop session...[0m
2023.12.01 12:59:59 INFO  Shut down connection with build server.[0m
2023.12.01 12:59:59 INFO  Shut down connection with build server.[0m
2023.12.01 12:59:59 INFO  Attempting to connect to the build server...[0m
2023.12.01 12:59:59 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 12:59:59 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 12:59:59 INFO  Attempting to connect to the build server...[0m
2023.12.01 12:59:59 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 12:59:59 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 12:59:59 INFO  time: Connected to build server in 0.12s[0m
2023.12.01 12:59:59 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.12.01 13:00:01 INFO  time: indexed workspace in 1.75s[0m
2023.12.01 13:00:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 13:00:04 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (7 scala sources)[0m
2023.12.01 13:00:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 2.31s[0m
2023.12.01 13:00:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.69s[0m
2023.12.01 13:05:14 INFO  time: code lens generation in 1.37s[0m
2023.12.01 13:08:22 INFO  Disconnecting from Bloop session...[0m
2023.12.01 13:08:22 INFO  Shut down connection with build server.[0m
2023.12.01 13:08:22 INFO  Shut down connection with build server.[0m
2023.12.01 13:08:22 INFO  Deleted directories inside .bloop[0m
2023.12.01 13:08:22 INFO  Attempting to connect to the build server...[0m
2023.12.01 13:08:22 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 13:08:22 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 13:08:23 INFO  Attempting to connect to the build server...[0m
2023.12.01 13:08:23 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 13:08:23 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 13:08:23 INFO  time: Connected to build server in 1.07s[0m
2023.12.01 13:08:23 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.12.01 13:08:24 INFO  time: indexed workspace in 1.18s[0m
Dec 01, 2023 1:21:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085-build)_13-21-34-869.md
2023.12.01 13:23:00 INFO  skipping build import with status 'Dismissed'[0m
2023.12.01 13:23:05 INFO  skipping build import with status 'Dismissed'[0m
2023.12.01 13:24:09 INFO  skipping build import with status 'Dismissed'[0m
2023.12.01 13:24:10 INFO  skipping build import with status 'Dismissed'[0m
2023.12.01 13:24:13 INFO  skipping build import with status 'Dismissed'[0m
2023.12.01 13:24:34 INFO  skipping build import with status 'Dismissed'[0m
2023.12.01 13:24:39 INFO  skipping build import with status 'Dismissed'[0m
2023.12.01 13:24:45 INFO  Shutting down server[0m
2023.12.01 13:24:45 INFO  shutting down Metals[0m
2023.12.01 13:24:45 INFO  Shut down connection with build server.[0m
2023.12.01 13:24:45 INFO  Shut down connection with build server.[0m
2023.12.01 13:24:45 INFO  Exiting server[0m
2023.12.01 13:24:54 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.12.01 13:24:54 INFO  Attempting to connect to the build server...[0m
2023.12.01 13:24:54 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 13:24:54 INFO  skipping build import with status 'Dismissed'[0m
2023.12.01 13:24:54 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 13:24:54 INFO  Attempting to connect to the build server...[0m
2023.12.01 13:24:54 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 13:24:54 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 13:24:54 INFO  time: Connected to build server in 0.47s[0m
2023.12.01 13:24:54 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.12.01 13:25:00 INFO  time: indexed workspace in 5.03s[0m
2023.12.01 13:26:57 INFO  time: code lens generation in 1.41s[0m
2023.12.01 13:27:08 INFO  running '/home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /tmp/metals1732935247375029907/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'[0m
2023.12.01 13:27:09 INFO  [info] welcome to sbt 1.9.6 (Eclipse Adoptium Java 11.0.20)[0m
2023.12.01 13:27:09 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build-build from metals.sbt ...[0m
2023.12.01 13:27:09 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/project[0m
2023.12.01 13:27:10 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085-build from metals.sbt ...[0m
2023.12.01 13:27:10 INFO  [info] loading project definition from /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project[0m
2023.12.01 13:27:11 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-build.json[0m
2023.12.01 13:27:11 INFO  [success] Total time: 1 s, completed Dec 1, 2023, 1:27:11 PM[0m
2023.12.01 13:27:12 INFO  [info] loading settings for project project-effective-scala-c1-s14-3039-4085 from build.sbt ...[0m
2023.12.01 13:27:12 INFO  [info] set current project to myScala3Project (in build file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/)[0m
2023.12.01 13:27:15 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085-test.json[0m
2023.12.01 13:27:15 INFO  [success] Generated .bloop/project-effective-scala-c1-s14-3039-4085.json[0m
2023.12.01 13:27:15 INFO  [success] Total time: 2 s, completed Dec 1, 2023, 1:27:15 PM[0m
2023.12.01 13:27:15 INFO  time: ran 'sbt bloopInstall' in 6.88s[0m
2023.12.01 13:27:15 INFO  Disconnecting from Bloop session...[0m
2023.12.01 13:27:15 INFO  Shut down connection with build server.[0m
2023.12.01 13:27:15 INFO  Shut down connection with build server.[0m
2023.12.01 13:27:15 INFO  Attempting to connect to the build server...[0m
2023.12.01 13:27:15 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 13:27:15 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 13:27:15 INFO  Attempting to connect to the build server...[0m
2023.12.01 13:27:15 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.01 13:27:15 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.01 13:27:15 INFO  time: Connected to build server in 0.13s[0m
2023.12.01 13:27:15 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.12.01 13:27:17 INFO  time: indexed workspace in 1.38s[0m
2023.12.01 13:33:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.01 13:33:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 5.81s[0m
2023.12.01 13:36:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:36:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 13:36:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:36:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.12.01 13:37:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:37:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 51ms[0m
2023.12.01 13:37:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:37:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 13:37:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:37:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 13:38:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:38:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
Dec 01, 2023 1:38:11 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 177
2023.12.01 13:38:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:38:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.01 13:38:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:38:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 99ms[0m
2023.12.01 13:38:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:38:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
Dec 01, 2023 1:41:58 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
Dec 01, 2023 1:42:49 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2023.12.01 13:47:10 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 5.67s[0m
2023.12.01 13:47:12 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 1.76s[0m
2023.12.01 13:47:14 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 1.71s[0m
2023.12.01 13:48:36 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 1.38s[0m
2023.12.01 13:49:23 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/worksheets/ApiTest.worksheet.sc
scala.meta.tokenizers.TokenizeException: <input>:115: error: unclosed comment
  /*
  ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:114:1: unclosed comment
/*
^
2023.12.01 13:49:24 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.17s[0m
2023.12.01 13:49:25 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/worksheets/ApiTest.worksheet.sc
scala.meta.tokenizers.TokenizeException: <input>:115: error: unclosed comment
  /*
  ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 13:49:30 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/worksheets/ApiTest.worksheet.sc
scala.meta.tokenizers.TokenizeException: <input>:115: error: unclosed comment
  /*
  ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 13:49:31 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.69s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:166:1: identifier expected but end of file found

^
2023.12.01 13:49:50 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.14s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:166:1: identifier expected but end of file found

^
2023.12.01 13:50:02 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.14s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:166:1: identifier expected but end of file found

^
2023.12.01 13:50:17 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.17s[0m
2023.12.01 13:50:18 WARN  Using indexes to guess the definition of SparkJob[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:164:18: 
unused import
import sparkjobs.SparkJob
                 ^^^^^^^^
2023.12.01 13:50:20 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.72s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:166:1: identifier expected but end of file found

^
2023.12.01 13:50:21 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.16s[0m
2023.12.01 13:50:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:50:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:166:1: identifier expected but end of file found

^
2023.12.01 13:50:44 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.22s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:164:27: 
unused import
import sparkjobs.SparkJob.makeDummyDf
                          ^^^^^^^^^^^
2023.12.01 13:50:47 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.73s[0m
2023.12.01 13:50:47 ERROR No files to fix
scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: No files to fix
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:159)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
Dec 01, 2023 1:50:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: No files to fix
java.util.concurrent.CompletionException: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: No files to fix
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: No files to fix
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:159)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more

[31merror[39m: worksheets/ApiTest.worksheet.sc:164:38: ; expected but ( found
import sparkjobs.SparkJob.makeDummyDf()
                                     ^
2023.12.01 13:50:50 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.13s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:164:27: 
unused import
import sparkjobs.SparkJob.makeDummyDf
                          ^^^^^^^^^^^
2023.12.01 13:50:55 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.59s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:166:1: 
Not found: ma
ma
^^
2023.12.01 13:50:57 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.38s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 13:51:05 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.8s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 13:52:47 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.61s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 13:52:50 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.58s[0m
2023.12.01 13:54:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:54:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 13:55:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:55:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 13:55:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:55:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 13:55:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:55:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 13:55:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:55:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 13:55:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:55:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 13:55:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:55:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.12.01 13:55:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:55:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.12.01 13:55:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:55:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 13:55:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:55:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 13:56:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:56:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 99ms[0m
2023.12.01 13:56:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:56:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 13:56:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:56:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 13:56:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:56:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 13:56:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 13:56:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 90ms[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 13:57:32 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.74s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 13:57:33 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.54s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 13:58:15 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/01 13:58:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/01 13:58:15 INFO SparkContext: Running Spark version 3.5.0
23/12/01 13:58:15 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 13:58:15 INFO SparkContext: Java version 11.0.20
23/12/01 13:58:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023.12.01 13:58:17 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 3.22s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 13:58:17 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.57s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 13:58:30 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 1.98s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 13:58:31 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.61s[0m
23/12/01 13:58:57 WARN RemoteEndpoint: Unmatched cancel notification for request id 927
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:00:07 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.62s[0m
23/12/01 14:01:52 WARN RemoteEndpoint: Unmatched cancel notification for request id 939
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:01:53 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.73s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:01:55 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.6s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:02:01 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.65s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:02:08 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.59s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:02:13 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.63s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:02:14 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.57s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:02:46 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.53s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:02:52 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.6s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:03:09 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.56s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:03:30 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.57s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:03:34 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.5s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:04:09 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.62s[0m
2023.12.01 14:05:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 14:05:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 14:05:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 14:05:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 14:05:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 14:05:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 14:06:15 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/01 14:06:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/01 14:06:15 INFO SparkContext: Running Spark version 3.5.0
23/12/01 14:06:15 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 14:06:15 INFO SparkContext: Java version 11.0.20
23/12/01 14:06:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/01 14:06:15 INFO ResourceUtils: ==============================================================
23/12/01 14:06:15 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/01 14:06:15 INFO ResourceUtils: ==============================================================
23/12/01 14:06:15 INFO SparkContext: Submitted application: sparkApp
23/12/01 14:06:15 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/01 14:06:15 INFO ResourceProfile: Limiting resource is cpu
23/12/01 14:06:15 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/01 14:06:15 INFO SecurityManager: Changing view acls to: bsoleille
23/12/01 14:06:15 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/01 14:06:15 INFO SecurityManager: Changing view acls groups to: 
23/12/01 14:06:15 INFO SecurityManager: Changing modify acls groups to: 
23/12/01 14:06:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/01 14:06:16 INFO Utils: Successfully started service 'sparkDriver' on port 46553.
23/12/01 14:06:16 INFO SparkEnv: Registering MapOutputTracker
23/12/01 14:06:16 INFO SparkEnv: Registering BlockManagerMaster
23/12/01 14:06:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/01 14:06:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/01 14:06:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/01 14:06:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dd78f5f2-a984-4124-8d67-bdb3735edc5f
23/12/01 14:06:16 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/01 14:06:16 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/01 14:06:16 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/01 14:06:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/01 14:06:16 INFO Utils: Successfully started service 'SparkUI' on port 4041.
23/12/01 14:06:16 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/01 14:06:16 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 14:06:16 INFO Executor: Java version 11.0.20
23/12/01 14:06:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/01 14:06:16 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@98ac0fe for default.
23/12/01 14:06:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42381.
23/12/01 14:06:16 INFO NettyBlockTransferService: Server created on 10.25.86.80:42381
23/12/01 14:06:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/01 14:06:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 42381, None)
23/12/01 14:06:16 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:42381 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 42381, None)
23/12/01 14:06:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 42381, None)
23/12/01 14:06:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 42381, None)
23/12/01 14:06:16 WARN SharedState: URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
23/12/01 14:06:16 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/01 14:06:16 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/01 14:06:17 INFO CodeGenerator: Code generated in 95.170813 ms
23/12/01 14:06:18 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 14:06:18 INFO DAGScheduler: Got job 0 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 14:06:18 INFO DAGScheduler: Final stage: ResultStage 0 (show at ApiTest.worksheet.sc:166)
23/12/01 14:06:18 INFO DAGScheduler: Parents of final stage: List()
23/12/01 14:06:18 INFO DAGScheduler: Missing parents: List()
23/12/01 14:06:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 14:06:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 14:06:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 14:06:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:42381 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 14:06:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/01 14:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 14:06:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/01 14:06:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 14:06:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/01 14:06:18 INFO CodeGenerator: Code generated in 9.855458 ms
23/12/01 14:06:18 INFO CodeGenerator: Code generated in 27.07453 ms
23/12/01 14:06:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1677 bytes result sent to driver
23/12/01 14:06:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 149 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 14:06:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/01 14:06:18 INFO DAGScheduler: ResultStage 0 (show at ApiTest.worksheet.sc:166) finished in 0.249 s
23/12/01 14:06:18 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 14:06:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/01 14:06:18 INFO DAGScheduler: Job 0 finished: show at ApiTest.worksheet.sc:166, took 0.269522 s
23/12/01 14:06:18 INFO CodeGenerator: Code generated in 11.845163 ms
2023.12.01 14:06:18 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 3.8s[0m
23/12/01 14:06:18 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.25.86.80:42381 in memory (size: 6.3 KiB, free: 434.4 MiB)
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 14:06:18 INFO CodeGenerator: Code generated in 7.796168 ms
23/12/01 14:06:18 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 14:06:18 INFO DAGScheduler: Got job 1 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 14:06:18 INFO DAGScheduler: Final stage: ResultStage 1 (show at ApiTest.worksheet.sc:166)
23/12/01 14:06:18 INFO DAGScheduler: Parents of final stage: List()
23/12/01 14:06:18 INFO DAGScheduler: Missing parents: List()
23/12/01 14:06:18 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 14:06:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 14:06:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 14:06:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.25.86.80:42381 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 14:06:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
23/12/01 14:06:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 14:06:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/12/01 14:06:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 14:06:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/12/01 14:06:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1634 bytes result sent to driver
23/12/01 14:06:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 14:06:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/12/01 14:06:18 INFO DAGScheduler: ResultStage 1 (show at ApiTest.worksheet.sc:166) finished in 0.018 s
23/12/01 14:06:18 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 14:06:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/12/01 14:06:18 INFO DAGScheduler: Job 1 finished: show at ApiTest.worksheet.sc:166, took 0.019744 s
23/12/01 14:06:18 INFO CodeGenerator: Code generated in 7.586941 ms
23/12/01 14:06:18 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.25.86.80:42381 in memory (size: 6.3 KiB, free: 434.4 MiB)
2023.12.01 14:06:18 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.59s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:46:49 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.51s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
2023.12.01 14:46:52 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.5s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 14:47:04 INFO CodeGenerator: Code generated in 8.44424 ms
23/12/01 14:47:04 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 14:47:04 INFO DAGScheduler: Got job 2 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 14:47:04 INFO DAGScheduler: Final stage: ResultStage 2 (show at ApiTest.worksheet.sc:166)
23/12/01 14:47:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 14:47:04 INFO DAGScheduler: Missing parents: List()
23/12/01 14:47:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 14:47:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 14:47:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 14:47:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 14:47:04 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
23/12/01 14:47:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 14:47:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
23/12/01 14:47:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 14:47:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/12/01 14:47:05 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1677 bytes result sent to driver
23/12/01 14:47:05 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 17 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 14:47:05 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/12/01 14:47:05 INFO DAGScheduler: ResultStage 2 (show at ApiTest.worksheet.sc:166) finished in 0.059 s
23/12/01 14:47:05 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 14:47:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/12/01 14:47:05 INFO DAGScheduler: Job 2 finished: show at ApiTest.worksheet.sc:166, took 0.061582 s
23/12/01 14:47:05 INFO CodeGenerator: Code generated in 7.660221 ms
23/12/01 14:47:05 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
2023.12.01 14:47:05 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.68s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 15:37:12 INFO CodeGenerator: Code generated in 8.801434 ms
23/12/01 15:37:12 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 15:37:12 INFO DAGScheduler: Got job 3 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 15:37:12 INFO DAGScheduler: Final stage: ResultStage 3 (show at ApiTest.worksheet.sc:166)
23/12/01 15:37:12 INFO DAGScheduler: Parents of final stage: List()
23/12/01 15:37:12 INFO DAGScheduler: Missing parents: List()
23/12/01 15:37:12 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 15:37:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 15:37:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 15:37:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 15:37:12 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
23/12/01 15:37:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 15:37:12 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
23/12/01 15:37:12 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 15:37:12 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/12/01 15:37:12 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1677 bytes result sent to driver
23/12/01 15:37:12 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 15:37:12 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/12/01 15:37:12 INFO DAGScheduler: ResultStage 3 (show at ApiTest.worksheet.sc:166) finished in 0.073 s
23/12/01 15:37:12 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 15:37:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
23/12/01 15:37:12 INFO DAGScheduler: Job 3 finished: show at ApiTest.worksheet.sc:166, took 0.076059 s
23/12/01 15:37:12 INFO CodeGenerator: Code generated in 7.669022 ms
23/12/01 15:37:12 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
2023.12.01 15:37:12 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.66s[0m
23/12/01 16:07:58 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/01 16:07:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/01 16:07:58 INFO SparkContext: Running Spark version 3.5.0
23/12/01 16:07:58 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:07:58 INFO SparkContext: Java version 11.0.20
23/12/01 16:07:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/01 16:07:59 INFO ResourceUtils: ==============================================================
23/12/01 16:07:59 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/01 16:07:59 INFO ResourceUtils: ==============================================================
23/12/01 16:07:59 INFO SparkContext: Submitted application: Spark Parquet Example
23/12/01 16:07:59 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/01 16:07:59 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
23/12/01 16:07:59 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/01 16:07:59 INFO SecurityManager: Changing view acls to: bsoleille
23/12/01 16:07:59 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/01 16:07:59 INFO SecurityManager: Changing view acls groups to: 
23/12/01 16:07:59 INFO SecurityManager: Changing modify acls groups to: 
23/12/01 16:07:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/01 16:07:59 INFO Utils: Successfully started service 'sparkDriver' on port 40271.
23/12/01 16:07:59 INFO SparkEnv: Registering MapOutputTracker
23/12/01 16:07:59 INFO SparkEnv: Registering BlockManagerMaster
23/12/01 16:07:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/01 16:07:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/01 16:07:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/01 16:07:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-82212edc-6bea-4532-94f2-9ee9645b988b
23/12/01 16:07:59 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/01 16:07:59 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/01 16:07:59 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/01 16:07:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/01 16:07:59 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/01 16:07:59 INFO Utils: Successfully started service 'SparkUI' on port 4042.
23/12/01 16:07:59 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/01 16:07:59 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:07:59 INFO Executor: Java version 11.0.20
23/12/01 16:07:59 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/01 16:07:59 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5d46bed7 for default.
23/12/01 16:07:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34297.
23/12/01 16:07:59 INFO NettyBlockTransferService: Server created on 10.25.86.80:34297
23/12/01 16:07:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/01 16:07:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 34297, None)
23/12/01 16:07:59 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:34297 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 34297, None)
23/12/01 16:07:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 34297, None)
23/12/01 16:07:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 34297, None)
23/12/01 16:07:59 WARN SharedState: URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
23/12/01 16:07:59 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/01 16:07:59 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/01 16:08:01 INFO CodeGenerator: Code generated in 119.825005 ms
23/12/01 16:08:01 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:62
23/12/01 16:08:01 INFO DAGScheduler: Got job 0 (show at SparkTest.worksheet.sc:62) with 1 output partitions
23/12/01 16:08:01 INFO DAGScheduler: Final stage: ResultStage 0 (show at SparkTest.worksheet.sc:62)
23/12/01 16:08:01 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:01 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:01 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:62), which has no missing parents
23/12/01 16:08:01 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:08:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 16:08:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:34297 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:01 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:62) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/01 16:08:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:01 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/01 16:08:01 INFO CodeGenerator: Code generated in 9.331211 ms
23/12/01 16:08:01 INFO CodeGenerator: Code generated in 27.657261 ms
23/12/01 16:08:01 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1677 bytes result sent to driver
23/12/01 16:08:01 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 143 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:01 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/01 16:08:01 INFO DAGScheduler: ResultStage 0 (show at SparkTest.worksheet.sc:62) finished in 0.302 s
23/12/01 16:08:01 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:01 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/01 16:08:01 INFO DAGScheduler: Job 0 finished: show at SparkTest.worksheet.sc:62, took 0.329990 s
23/12/01 16:08:01 INFO CodeGenerator: Code generated in 7.616697 ms
23/12/01 16:08:01 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/12/01 16:08:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/12/01 16:08:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/12/01 16:08:01 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/12/01 16:08:01 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/12/01 16:08:01 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/12/01 16:08:01 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/12/01 16:08:01 INFO CodeGenerator: Code generated in 6.182013 ms
23/12/01 16:08:01 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:72
23/12/01 16:08:01 INFO DAGScheduler: Got job 1 (parquet at SparkTest.worksheet.sc:72) with 1 output partitions
23/12/01 16:08:01 INFO DAGScheduler: Final stage: ResultStage 1 (parquet at SparkTest.worksheet.sc:72)
23/12/01 16:08:01 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:01 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:01 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:72), which has no missing parents
23/12/01 16:08:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 215.6 KiB, free 434.2 MiB)
23/12/01 16:08:01 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.25.86.80:34297 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 76.7 KiB, free 434.1 MiB)
23/12/01 16:08:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.25.86.80:34297 (size: 76.7 KiB, free: 434.3 MiB)
23/12/01 16:08:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:72) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:01 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/12/01 16:08:01 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 16:08:01 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/12/01 16:08:02 INFO CodeGenerator: Code generated in 6.376131 ms
23/12/01 16:08:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/12/01 16:08:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/12/01 16:08:02 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/12/01 16:08:02 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/12/01 16:08:02 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/12/01 16:08:02 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/12/01 16:08:02 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "index",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required int32 index;
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/12/01 16:08:02 INFO CodecPool: Got brand-new compressor [.snappy]
23/12/01 16:08:02 INFO FileOutputCommitter: Saved output of task 'attempt_202312011608014166816365865289635_0001_m_000000_1' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202312011608014166816365865289635_0001_m_000000
23/12/01 16:08:02 INFO SparkHadoopMapRedUtil: attempt_202312011608014166816365865289635_0001_m_000000_1: Committed. Elapsed time: 0 ms.
23/12/01 16:08:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2785 bytes result sent to driver
23/12/01 16:08:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 549 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/12/01 16:08:02 INFO DAGScheduler: ResultStage 1 (parquet at SparkTest.worksheet.sc:72) finished in 0.591 s
23/12/01 16:08:02 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/12/01 16:08:02 INFO DAGScheduler: Job 1 finished: parquet at SparkTest.worksheet.sc:72, took 0.594133 s
23/12/01 16:08:02 INFO FileFormatWriter: Start to commit write Job aecacddf-8b99-4682-8172-557c073396a7.
23/12/01 16:08:02 INFO FileFormatWriter: Write Job aecacddf-8b99-4682-8172-557c073396a7 committed. Elapsed time: 10 ms.
23/12/01 16:08:02 INFO FileFormatWriter: Finished processing stats for write job aecacddf-8b99-4682-8172-557c073396a7.
23/12/01 16:08:02 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
23/12/01 16:08:02 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:76
23/12/01 16:08:02 INFO DAGScheduler: Got job 2 (parquet at SparkTest.worksheet.sc:76) with 1 output partitions
23/12/01 16:08:02 INFO DAGScheduler: Final stage: ResultStage 2 (parquet at SparkTest.worksheet.sc:76)
23/12/01 16:08:02 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:02 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:76), which has no missing parents
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/12/01 16:08:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.25.86.80:34297 (size: 36.9 KiB, free: 434.3 MiB)
23/12/01 16:08:02 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:76) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
23/12/01 16:08:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/12/01 16:08:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
23/12/01 16:08:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2128 bytes result sent to driver
23/12/01 16:08:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 57 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/12/01 16:08:02 INFO DAGScheduler: ResultStage 2 (parquet at SparkTest.worksheet.sc:76) finished in 0.069 s
23/12/01 16:08:02 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/12/01 16:08:02 INFO DAGScheduler: Job 2 finished: parquet at SparkTest.worksheet.sc:76, took 0.071356 s
23/12/01 16:08:02 INFO FileSourceStrategy: Pushed Filters: 
23/12/01 16:08:02 INFO FileSourceStrategy: Post-Scan Filters: 
23/12/01 16:08:02 INFO CodeGenerator: Code generated in 19.697954 ms
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 200.8 KiB, free 433.8 MiB)
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
23/12/01 16:08:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.25.86.80:34297 (size: 34.9 KiB, free: 434.3 MiB)
23/12/01 16:08:02 INFO SparkContext: Created broadcast 3 from show at SparkTest.worksheet.sc:81
23/12/01 16:08:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/12/01 16:08:02 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.25.86.80:34297 in memory (size: 76.7 KiB, free: 434.3 MiB)
23/12/01 16:08:02 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:81
23/12/01 16:08:02 INFO DAGScheduler: Got job 3 (show at SparkTest.worksheet.sc:81) with 1 output partitions
23/12/01 16:08:02 INFO DAGScheduler: Final stage: ResultStage 3 (show at SparkTest.worksheet.sc:81)
23/12/01 16:08:02 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:02 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:02 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:81), which has no missing parents
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.6 KiB, free 434.0 MiB)
23/12/01 16:08:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.8 KiB, free 434.0 MiB)
23/12/01 16:08:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.25.86.80:34297 (size: 6.8 KiB, free: 434.3 MiB)
23/12/01 16:08:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:81) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
23/12/01 16:08:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/12/01 16:08:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
23/12/01 16:08:02 INFO CodeGenerator: Code generated in 15.732603 ms
23/12/01 16:08:02 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-f284260d-afb0-4820-980b-c93c8a88bce7-c000.snappy.parquet, range: 0-1246, partition values: [empty row]
23/12/01 16:08:02 INFO CodecPool: Got brand-new decompressor [.snappy]
23/12/01 16:08:02 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.25.86.80:34297 in memory (size: 36.9 KiB, free: 434.4 MiB)
23/12/01 16:08:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1971 bytes result sent to driver
23/12/01 16:08:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 115 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/12/01 16:08:02 INFO DAGScheduler: ResultStage 3 (show at SparkTest.worksheet.sc:81) finished in 0.137 s
23/12/01 16:08:02 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
23/12/01 16:08:02 INFO DAGScheduler: Job 3 finished: show at SparkTest.worksheet.sc:81, took 0.142872 s
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 7.974989 ms
23/12/01 16:08:03 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:94
23/12/01 16:08:03 INFO DAGScheduler: Got job 4 (show at SparkTest.worksheet.sc:94) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ResultStage 4 (show at SparkTest.worksheet.sc:94)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:94), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.7 KiB, free 434.1 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.25.86.80:34297 (size: 6.5 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:94) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 7.397198 ms
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1640 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 17 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ResultStage 4 (show at SparkTest.worksheet.sc:94) finished in 0.023 s
23/12/01 16:08:03 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
23/12/01 16:08:03 INFO DAGScheduler: Job 4 finished: show at SparkTest.worksheet.sc:94, took 0.025370 s
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 5.995176 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 11.596649 ms
23/12/01 16:08:03 INFO DAGScheduler: Registering RDD 15 (collect at SparkTest.worksheet.sc:102) as input to shuffle 0
23/12/01 16:08:03 INFO DAGScheduler: Got map stage job 5 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (collect at SparkTest.worksheet.sc:102)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[15] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 19.2 KiB, free 434.1 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.1 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.25.86.80:34297 (size: 8.2 KiB, free: 434.3 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.25.86.80:34297 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[15] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.25.86.80:34297 in memory (size: 34.9 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.25.86.80:34297 in memory (size: 6.8 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8138 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 10.114158 ms
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1930 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 57 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ShuffleMapStage 5 (collect at SparkTest.worksheet.sc:102) finished in 0.110 s
23/12/01 16:08:03 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:03 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:03 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:03 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 9.612574 ms
23/12/01 16:08:03 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:102
23/12/01 16:08:03 INFO DAGScheduler: Got job 6 (collect at SparkTest.worksheet.sc:102) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ResultStage 7 (collect at SparkTest.worksheet.sc:102)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[18] at collect at SparkTest.worksheet.sc:102), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.3 KiB, free 434.4 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.6 KiB, free 434.4 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.25.86.80:34297 (size: 6.6 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[18] at collect at SparkTest.worksheet.sc:102) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 6) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 7.0 (TID 6)
23/12/01 16:08:03 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 6.711882 ms
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 7.0 (TID 6). 4084 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 6) in 52 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ResultStage 7 (collect at SparkTest.worksheet.sc:102) finished in 0.060 s
23/12/01 16:08:03 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
23/12/01 16:08:03 INFO DAGScheduler: Job 6 finished: collect at SparkTest.worksheet.sc:102, took 0.069896 s
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 4.618758 ms
23/12/01 16:08:03 INFO SparkContext: Starting job: show at Ast.scala:95
23/12/01 16:08:03 INFO DAGScheduler: Got job 7 (show at Ast.scala:95) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ResultStage 8 (show at Ast.scala:95)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[20] at show at Ast.scala:95), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.5 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.25.86.80:34297 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[20] at show at Ast.scala:95) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 7) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 8.0 (TID 7)
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 8.0 (TID 7). 1634 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 7) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ResultStage 8 (show at Ast.scala:95) finished in 0.014 s
23/12/01 16:08:03 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
23/12/01 16:08:03 INFO DAGScheduler: Job 7 finished: show at Ast.scala:95, took 0.017157 s
23/12/01 16:08:03 INFO SparkContext: Starting job: show at Ast.scala:96
23/12/01 16:08:03 INFO DAGScheduler: Got job 8 (show at Ast.scala:96) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ResultStage 9 (show at Ast.scala:96)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[22] at show at Ast.scala:96), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 15.5 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.25.86.80:34297 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[22] at show at Ast.scala:96) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 8) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 9.0 (TID 8)
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 9.0 (TID 8). 1634 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 8) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ResultStage 9 (show at Ast.scala:96) finished in 0.014 s
23/12/01 16:08:03 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/12/01 16:08:03 INFO DAGScheduler: Job 8 finished: show at Ast.scala:96, took 0.016066 s
23/12/01 16:08:03 INFO DAGScheduler: Registering RDD 24 (show at Ast.scala:108) as input to shuffle 1
23/12/01 16:08:03 INFO DAGScheduler: Got map stage job 9 (show at Ast.scala:108) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (show at Ast.scala:108)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[24] at show at Ast.scala:108), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 17.7 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.25.86.80:34297 (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.25.86.80:34297 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[24] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.25.86.80:34297 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 9) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 10.0 (TID 9)
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.25.86.80:34297 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.25.86.80:34297 in memory (size: 6.6 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 6.584303 ms
23/12/01 16:08:03 INFO Executor: Finished task 0.0 in stage 10.0 (TID 9). 1991 bytes result sent to driver
23/12/01 16:08:03 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 9) in 25 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:03 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/12/01 16:08:03 INFO DAGScheduler: ShuffleMapStage 10 (show at Ast.scala:108) finished in 0.044 s
23/12/01 16:08:03 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:03 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:03 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:03 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:03 INFO ShufflePartitionsUtil: For shuffle(1, 1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 19.930057 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 6.776074 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 5.711414 ms
23/12/01 16:08:03 INFO SparkContext: Starting job: show at Ast.scala:108
23/12/01 16:08:03 INFO DAGScheduler: Got job 10 (show at Ast.scala:108) with 1 output partitions
23/12/01 16:08:03 INFO DAGScheduler: Final stage: ResultStage 12 (show at Ast.scala:108)
23/12/01 16:08:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
23/12/01 16:08:03 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:03 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[31] at show at Ast.scala:108), which has no missing parents
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 40.1 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.3 MiB)
23/12/01 16:08:03 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.25.86.80:34297 (size: 16.3 KiB, free: 434.4 MiB)
23/12/01 16:08:03 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[31] at show at Ast.scala:108) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:03 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
23/12/01 16:08:03 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 10) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/12/01 16:08:03 INFO Executor: Running task 0.0 in stage 12.0 (TID 10)
23/12/01 16:08:03 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 6.275348 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 14.634942 ms
23/12/01 16:08:03 INFO CodeGenerator: Code generated in 3.977138 ms
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 6.754925 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 11.223649 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 12.0 (TID 10). 4898 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 10) in 99 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 12 (show at Ast.scala:108) finished in 0.110 s
23/12/01 16:08:04 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 10 finished: show at Ast.scala:108, took 0.113726 s
23/12/01 16:08:04 INFO DAGScheduler: Registering RDD 33 (show at Ast.scala:112) as input to shuffle 2
23/12/01 16:08:04 INFO DAGScheduler: Got map stage job 11 (show at Ast.scala:112) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (show at Ast.scala:112)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[33] at show at Ast.scala:112), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 17.7 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.25.86.80:34297 (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[33] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 11) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 13.0 (TID 11)
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 13.0 (TID 11). 1991 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 11) in 12 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ShuffleMapStage 13 (show at Ast.scala:112) finished in 0.018 s
23/12/01 16:08:04 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:04 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(2, 2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO SparkContext: Starting job: show at Ast.scala:112
23/12/01 16:08:04 INFO DAGScheduler: Got job 12 (show at Ast.scala:112) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 15 (show at Ast.scala:112)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[40] at show at Ast.scala:112), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 40.1 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.3 KiB, free 434.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.25.86.80:34297 (size: 16.3 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[40] at show at Ast.scala:112) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 12) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 15.0 (TID 12)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 15.0 (TID 12). 4898 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 12) in 12 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 15 (show at Ast.scala:112) finished in 0.021 s
23/12/01 16:08:04 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 12 finished: show at Ast.scala:112, took 0.024646 s
23/12/01 16:08:04 INFO SparkContext: Starting job: show at Ast.scala:113
23/12/01 16:08:04 INFO DAGScheduler: Got job 13 (show at Ast.scala:113) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 16 (show at Ast.scala:113)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[42] at show at Ast.scala:113), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 15.5 KiB, free 434.2 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.25.86.80:34297 (size: 6.4 KiB, free: 434.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.25.86.80:34297 in memory (size: 16.3 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[42] at show at Ast.scala:113) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 13) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 16.0 (TID 13)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.25.86.80:34297 in memory (size: 16.3 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.25.86.80:34297 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.25.86.80:34297 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 16.0 (TID 13). 1634 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 13) in 10 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 16 (show at Ast.scala:113) finished in 0.026 s
23/12/01 16:08:04 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 13 finished: show at Ast.scala:113, took 0.028865 s
23/12/01 16:08:04 INFO DAGScheduler: Registering RDD 44 (show at Ast.scala:126) as input to shuffle 3
23/12/01 16:08:04 INFO DAGScheduler: Got map stage job 14 (show at Ast.scala:126) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ShuffleMapStage 17 (show at Ast.scala:126)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[44] at show at Ast.scala:126), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 17.7 KiB, free 434.4 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.25.86.80:34297 (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[44] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 14) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 17.0 (TID 14)
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 17.0 (TID 14). 1991 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 14) in 14 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ShuffleMapStage 17 (show at Ast.scala:126) finished in 0.023 s
23/12/01 16:08:04 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:04 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(3, 3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 11.220167 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 9.983091 ms
23/12/01 16:08:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO DAGScheduler: Got job 15 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 38.7 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.25.86.80:34297 (size: 15.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[51] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 15) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 19.0 (TID 15)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 7.920069 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 10.494762 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 19.0 (TID 15). 4897 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 15) in 34 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 19 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.040 s
23/12/01 16:08:04 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 15 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.060623 s
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 4.251137 ms
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.25.86.80:34297 (size: 337.0 B, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 17 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 8.084337 ms
23/12/01 16:08:04 INFO SparkContext: Starting job: show at Ast.scala:126
23/12/01 16:08:04 INFO DAGScheduler: Got job 16 (show at Ast.scala:126) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 21 (show at Ast.scala:126)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[54] at show at Ast.scala:126), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 15.1 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.25.86.80:34297 (size: 6.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[54] at show at Ast.scala:126) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 16) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 21.0 (TID 16)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 7.452804 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 21.0 (TID 16). 4165 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 16) in 14 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 21 (show at Ast.scala:126) finished in 0.020 s
23/12/01 16:08:04 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 16 finished: show at Ast.scala:126, took 0.022829 s
23/12/01 16:08:04 INFO DAGScheduler: Registering RDD 56 (show at SparkTest.worksheet.sc:115) as input to shuffle 4
23/12/01 16:08:04 INFO DAGScheduler: Got map stage job 17 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (show at SparkTest.worksheet.sc:115)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[56] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 17.7 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.25.86.80:34297 (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.25.86.80:34297 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[56] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 17) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 22.0 (TID 17)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 10.25.86.80:34297 in memory (size: 337.0 B, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 10.25.86.80:34297 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 10.25.86.80:34297 in memory (size: 15.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.25.86.80:34297 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 22.0 (TID 17). 1991 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 17) in 12 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ShuffleMapStage 22 (show at SparkTest.worksheet.sc:115) finished in 0.029 s
23/12/01 16:08:04 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:04 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(4, 4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO DAGScheduler: Got job 18 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 24 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[63] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 38.7 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.25.86.80:34297 (size: 15.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[63] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 18) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 24.0 (TID 18)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 24.0 (TID 18). 4897 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 18) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 24 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.016 s
23/12/01 16:08:04 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 18 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.018536 s
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 1024.1 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 337.0 B, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.25.86.80:34297 (size: 337.0 B, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 21 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:115
23/12/01 16:08:04 INFO DAGScheduler: Got job 19 (show at SparkTest.worksheet.sc:115) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 26 (show at SparkTest.worksheet.sc:115)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[66] at show at SparkTest.worksheet.sc:115), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 15.1 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 6.9 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.25.86.80:34297 (size: 6.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[66] at show at SparkTest.worksheet.sc:115) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 19) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 26.0 (TID 19)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 26.0 (TID 19). 4165 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 19) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 26 (show at SparkTest.worksheet.sc:115) finished in 0.014 s
23/12/01 16:08:04 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 19 finished: show at SparkTest.worksheet.sc:115, took 0.015829 s
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 3.884453 ms
23/12/01 16:08:04 INFO DAGScheduler: Registering RDD 68 (isEmpty at SparkTest.worksheet.sc:120) as input to shuffle 5
23/12/01 16:08:04 INFO DAGScheduler: Got map stage job 20 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (isEmpty at SparkTest.worksheet.sc:120)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[68] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 17.3 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 433.3 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.25.86.80:34297 (size: 7.5 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[68] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 20) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 27.0 (TID 20)
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 3.777078 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 27.0 (TID 20). 1991 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 20) in 17 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ShuffleMapStage 27 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.021 s
23/12/01 16:08:04 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:04 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:04 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(5, 5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 23.968396 ms
23/12/01 16:08:04 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO DAGScheduler: Got job 21 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[75] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 35.3 KiB, free 433.2 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 433.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.25.86.80:34297 (size: 14.5 KiB, free: 434.3 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[75] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 21) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 29.0 (TID 21)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 7.013913 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 29.0 (TID 21). 4817 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 21) in 17 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.022 s
23/12/01 16:08:04 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 21 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.025596 s
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 1024.1 KiB, free 432.2 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 251.0 B, free 432.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.25.86.80:34297 (size: 251.0 B, free: 434.3 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 25 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/12/01 16:08:04 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 4.138849 ms
23/12/01 16:08:04 INFO SparkContext: Starting job: isEmpty at SparkTest.worksheet.sc:120
23/12/01 16:08:04 INFO DAGScheduler: Got job 22 (isEmpty at SparkTest.worksheet.sc:120) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 31 (isEmpty at SparkTest.worksheet.sc:120)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[78] at isEmpty at SparkTest.worksheet.sc:120), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 13.3 KiB, free 432.2 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 432.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.25.86.80:34297 (size: 6.4 KiB, free: 434.3 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[78] at isEmpty at SparkTest.worksheet.sc:120) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 22) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7714 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 31.0 (TID 22)
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Getting 1 (300.0 B) non-empty blocks including 1 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 4.760254 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 31.0 (TID 22). 3262 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 22) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 31 (isEmpty at SparkTest.worksheet.sc:120) finished in 0.015 s
23/12/01 16:08:04 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 22 finished: isEmpty at SparkTest.worksheet.sc:120, took 0.017356 s
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 4.147157 ms
23/12/01 16:08:04 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:04 INFO DAGScheduler: Got job 23 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:04 INFO DAGScheduler: Final stage: ResultStage 32 (collect at Ast.scala:253)
23/12/01 16:08:04 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:04 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:04 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[82] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 17.5 KiB, free 432.2 MiB)
23/12/01 16:08:04 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 432.2 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 10.25.86.80:34297 in memory (size: 15.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.25.86.80:34297 (size: 7.4 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[82] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:04 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks resource profile 0
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 10.25.86.80:34297 in memory (size: 6.9 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 23) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:04 INFO Executor: Running task 0.0 in stage 32.0 (TID 23)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 10.25.86.80:34297 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 10.25.86.80:34297 in memory (size: 337.0 B, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 10.25.86.80:34297 in memory (size: 251.0 B, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 10.25.86.80:34297 in memory (size: 7.5 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 10.25.86.80:34297 in memory (size: 14.5 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 10.25.86.80:34297 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:04 INFO CodeGenerator: Code generated in 4.797122 ms
23/12/01 16:08:04 INFO Executor: Finished task 0.0 in stage 32.0 (TID 23). 1826 bytes result sent to driver
23/12/01 16:08:04 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 23) in 20 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:04 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
23/12/01 16:08:04 INFO DAGScheduler: ResultStage 32 (collect at Ast.scala:253) finished in 0.037 s
23/12/01 16:08:04 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 32: Stage finished
23/12/01 16:08:04 INFO DAGScheduler: Job 23 finished: collect at Ast.scala:253, took 0.039498 s
23/12/01 16:08:05 INFO DAGScheduler: Registering RDD 83 (collect at Ast.scala:253) as input to shuffle 6
23/12/01 16:08:05 INFO DAGScheduler: Got map stage job 24 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[83] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 19.0 KiB, free 434.4 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.25.86.80:34297 (size: 8.2 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[83] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 24) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 33.0 (TID 24)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 33.0 (TID 24). 1793 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 24) in 12 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ShuffleMapStage 33 (collect at Ast.scala:253) finished in 0.019 s
23/12/01 16:08:05 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:05 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:05 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 6.031625 ms
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:05 INFO DAGScheduler: Got job 25 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 35 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[86] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 24.9 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.25.86.80:34297 (size: 10.8 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[86] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 25) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 35.0 (TID 25)
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 5.46639 ms
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 35.0 (TID 25). 4494 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 25) in 14 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 35 (collect at Ast.scala:253) finished in 0.018 s
23/12/01 16:08:05 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 35: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 25 finished: collect at Ast.scala:253, took 0.020155 s
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 5.815795 ms
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:05 INFO DAGScheduler: Got job 26 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 36 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[90] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 17.5 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.25.86.80:34297 (size: 7.4 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[90] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 26) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 36.0 (TID 26)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 36.0 (TID 26). 1826 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 26) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 36 (collect at Ast.scala:253) finished in 0.015 s
23/12/01 16:08:05 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 26 finished: collect at Ast.scala:253, took 0.016196 s
23/12/01 16:08:05 INFO DAGScheduler: Registering RDD 91 (collect at Ast.scala:253) as input to shuffle 7
23/12/01 16:08:05 INFO DAGScheduler: Got map stage job 27 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[91] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 19.0 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.25.86.80:34297 (size: 8.2 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[91] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 27) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 37.0 (TID 27)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 37.0 (TID 27). 1793 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 27) in 23 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ShuffleMapStage 37 (collect at Ast.scala:253) finished in 0.027 s
23/12/01 16:08:05 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:05 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:05 INFO ShufflePartitionsUtil: For shuffle(7), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:05 INFO DAGScheduler: Got job 28 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 39 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[94] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 24.9 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.25.86.80:34297 (size: 10.7 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[94] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 28) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 39.0 (TID 28)
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 39.0 (TID 28). 4494 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 28) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 39 (collect at Ast.scala:253) finished in 0.009 s
23/12/01 16:08:05 INFO DAGScheduler: Job 28 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 28 finished: collect at Ast.scala:253, took 0.011702 s
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:05 INFO DAGScheduler: Got job 29 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 40 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 40 (MapPartitionsRDD[98] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 17.5 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.25.86.80:34297 (size: 7.4 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 40 (MapPartitionsRDD[98] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 29) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 40.0 (TID 29)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 40.0 (TID 29). 1826 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 29) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 40 (collect at Ast.scala:253) finished in 0.012 s
23/12/01 16:08:05 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 40: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 29 finished: collect at Ast.scala:253, took 0.013996 s
23/12/01 16:08:05 INFO DAGScheduler: Registering RDD 99 (collect at Ast.scala:253) as input to shuffle 8
23/12/01 16:08:05 INFO DAGScheduler: Got map stage job 30 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ShuffleMapStage 41 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[99] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 19.0 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 8.2 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.25.86.80:34297 (size: 8.2 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[99] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 30) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8143 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 41.0 (TID 30)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 41.0 (TID 30). 1793 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 30) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ShuffleMapStage 41 (collect at Ast.scala:253) finished in 0.015 s
23/12/01 16:08:05 INFO DAGScheduler: looking for newly runnable stages
23/12/01 16:08:05 INFO DAGScheduler: running: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: waiting: HashSet()
23/12/01 16:08:05 INFO DAGScheduler: failed: HashSet()
23/12/01 16:08:05 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at Ast.scala:253
23/12/01 16:08:05 INFO DAGScheduler: Got job 31 (collect at Ast.scala:253) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 43 (collect at Ast.scala:253)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 42)
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[102] at collect at Ast.scala:253), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 24.9 KiB, free 434.2 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 10.8 KiB, free 434.1 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.25.86.80:34297 (size: 10.8 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 43 (MapPartitionsRDD[102] at collect at Ast.scala:253) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 31) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7695 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 43.0 (TID 31)
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/12/01 16:08:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 43.0 (TID 31). 4494 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 31) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 43 (collect at Ast.scala:253) finished in 0.011 s
23/12/01 16:08:05 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 43: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 31 finished: collect at Ast.scala:253, took 0.013565 s
23/12/01 16:08:05 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:150
23/12/01 16:08:05 INFO DAGScheduler: Got job 32 (show at SparkTest.worksheet.sc:150) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 44 (show at SparkTest.worksheet.sc:150)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 44 (MapPartitionsRDD[104] at show at SparkTest.worksheet.sc:150), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 15.7 KiB, free 434.1 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.25.86.80:34297 (size: 6.5 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 44 (MapPartitionsRDD[104] at show at SparkTest.worksheet.sc:150) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 44.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 32) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 44.0 (TID 32)
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 44.0 (TID 32). 1683 bytes result sent to driver
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 10.25.86.80:34297 in memory (size: 7.4 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 32) in 18 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 44 (show at SparkTest.worksheet.sc:150) finished in 0.021 s
23/12/01 16:08:05 INFO DAGScheduler: Job 32 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 44: Stage finished
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 10.25.86.80:34297 in memory (size: 7.4 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 10.25.86.80:34297 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO DAGScheduler: Job 32 finished: show at SparkTest.worksheet.sc:150, took 0.024068 s
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 10.25.86.80:34297 in memory (size: 8.2 KiB, free: 434.3 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 10.25.86.80:34297 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 10.25.86.80:34297 in memory (size: 8.2 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 10.25.86.80:34297 in memory (size: 10.7 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 10.25.86.80:34297 in memory (size: 7.4 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 10.25.86.80:34297 in memory (size: 10.8 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 7.442277 ms
23/12/01 16:08:05 INFO SparkContext: Starting job: collect at SparkTest.worksheet.sc:159
23/12/01 16:08:05 INFO DAGScheduler: Got job 33 (collect at SparkTest.worksheet.sc:159) with 1 output partitions
23/12/01 16:08:05 INFO DAGScheduler: Final stage: ResultStage 45 (collect at SparkTest.worksheet.sc:159)
23/12/01 16:08:05 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:05 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:05 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[112] at collect at SparkTest.worksheet.sc:159), which has no missing parents
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 15.4 KiB, free 434.4 MiB)
23/12/01 16:08:05 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.25.86.80:34297 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[112] at collect at SparkTest.worksheet.sc:159) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:05 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
23/12/01 16:08:05 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 33) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:08:05 INFO Executor: Running task 0.0 in stage 45.0 (TID 33)
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 6.143042 ms
23/12/01 16:08:05 INFO Executor: Finished task 0.0 in stage 45.0 (TID 33). 1650 bytes result sent to driver
23/12/01 16:08:05 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 33) in 13 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:05 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
23/12/01 16:08:05 INFO DAGScheduler: ResultStage 45 (collect at SparkTest.worksheet.sc:159) finished in 0.016 s
23/12/01 16:08:05 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:05 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
23/12/01 16:08:05 INFO DAGScheduler: Job 33 finished: collect at SparkTest.worksheet.sc:159, took 0.018172 s
23/12/01 16:08:05 INFO CodeGenerator: Code generated in 5.201567 ms
2023.12.01 16:08:05 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 7.48s[0m
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 10.25.86.80:34297 in memory (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:05 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 10.25.86.80:34297 in memory (size: 6.5 KiB, free: 434.4 MiB)
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 16:08:06 INFO CodeGenerator: Code generated in 14.492557 ms
23/12/01 16:08:06 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 16:08:06 INFO DAGScheduler: Got job 4 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 16:08:06 INFO DAGScheduler: Final stage: ResultStage 4 (show at ApiTest.worksheet.sc:166)
23/12/01 16:08:06 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:06 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:06 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 16:08:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:08:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:08:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:06 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:06 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
23/12/01 16:08:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 16:08:06 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
23/12/01 16:08:06 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1634 bytes result sent to driver
23/12/01 16:08:06 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 11 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:06 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/12/01 16:08:06 INFO DAGScheduler: ResultStage 4 (show at ApiTest.worksheet.sc:166) finished in 0.044 s
23/12/01 16:08:06 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
23/12/01 16:08:06 INFO DAGScheduler: Job 4 finished: show at ApiTest.worksheet.sc:166, took 0.045205 s
23/12/01 16:08:06 INFO CodeGenerator: Code generated in 6.628521 ms
23/12/01 16:08:06 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
2023.12.01 16:08:06 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.71s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:168:1: 
Not found: MakeExpression
MakeExpression
^^^^^^^^^^^^^^
2023.12.01 16:08:10 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.4s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:165:1: } expected but \n\n found

^
2023.12.01 16:08:17 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.15s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:168:1: 
Not found: MakeExpression
MakeExpression
^^^^^^^^^^^^^^
2023.12.01 16:08:21 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.37s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:164:41: identifier expected but } found
import sparkjobs.SparkJob.{makeDummyDf, }
                                        ^
2023.12.01 16:08:22 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.1s[0m
2023.12.01 16:08:26 WARN  Using indexes to guess the definition of MakeExpression[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 16:08:27 INFO CodeGenerator: Code generated in 6.548793 ms
23/12/01 16:08:27 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:166
23/12/01 16:08:27 INFO DAGScheduler: Got job 5 (show at ApiTest.worksheet.sc:166) with 1 output partitions
23/12/01 16:08:27 INFO DAGScheduler: Final stage: ResultStage 5 (show at ApiTest.worksheet.sc:166)
23/12/01 16:08:27 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:08:27 INFO DAGScheduler: Missing parents: List()
23/12/01 16:08:27 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at show at ApiTest.worksheet.sc:166), which has no missing parents
23/12/01 16:08:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:08:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:08:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:08:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
23/12/01 16:08:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at show at ApiTest.worksheet.sc:166) (first 15 tasks are for partitions Vector(0))
23/12/01 16:08:27 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
23/12/01 16:08:27 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 16:08:27 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
23/12/01 16:08:27 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1634 bytes result sent to driver
23/12/01 16:08:27 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:08:27 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
23/12/01 16:08:27 INFO DAGScheduler: ResultStage 5 (show at ApiTest.worksheet.sc:166) finished in 0.019 s
23/12/01 16:08:27 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:08:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
23/12/01 16:08:27 INFO DAGScheduler: Job 5 finished: show at ApiTest.worksheet.sc:166, took 0.020319 s
23/12/01 16:08:27 INFO CodeGenerator: Code generated in 6.346334 ms
23/12/01 16:08:27 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
2023.12.01 16:08:27 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.63s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:168:16: identifier expected but end of file found
MakeExpression.
               ^
2023.12.01 16:08:40 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.1s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:168:18: identifier expected but end of file found
MakeExpression().
                 ^
2023.12.01 16:08:47 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 91ms[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:168:1: 
missing argument for parameter df of method MakeExpression in object SparkJob: (df: org.apache.spark.sql.DataFrame):
  startup.ast.Expression[org.apache.spark.sql.DataFrame]
MakeExpression()
^^^^^^^^^^^^^^^^
2023.12.01 16:08:51 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.36s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:168:1: 
missing argument for parameter df of method MakeExpression in object SparkJob: (df: org.apache.spark.sql.DataFrame):
  startup.ast.Expression[org.apache.spark.sql.DataFrame]
MakeExpression()
^^^^^^^^^^^^^^^^
2023.12.01 16:08:58 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.4s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:168:1: 
missing argument for parameter df of method MakeExpression in object SparkJob: (df: org.apache.spark.sql.DataFrame):
  startup.ast.Expression[org.apache.spark.sql.DataFrame]
MakeExpression()
^^^^^^^^^^^^^^^^
2023.12.01 16:09:06 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.34s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:169:1: 
missing argument for parameter df of method MakeExpression in object SparkJob: (df: org.apache.spark.sql.DataFrame):
  startup.ast.Expression[org.apache.spark.sql.DataFrame]
MakeExpression()
^^^^^^^^^^^^^^^^
2023.12.01 16:09:08 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.36s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Unit
      df.show()


[31merror[39m: worksheets/ApiTest.worksheet.sc:169:1: 
missing argument for parameter df of method MakeExpression in object SparkJob: (df: org.apache.spark.sql.DataFrame):
  startup.ast.Expression[org.apache.spark.sql.DataFrame]
MakeExpression()
^^^^^^^^^^^^^^^^
2023.12.01 16:09:11 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.38s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:169:1: 
missing argument for parameter df of method MakeExpression in object SparkJob: (df: org.apache.spark.sql.DataFrame):
  startup.ast.Expression[org.apache.spark.sql.DataFrame]
MakeExpression()
^^^^^^^^^^^^^^^^
2023.12.01 16:09:15 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.32s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 16:09:18 INFO CodeGenerator: Code generated in 6.466909 ms
23/12/01 16:09:18 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:09:18 INFO DAGScheduler: Got job 6 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:09:18 INFO DAGScheduler: Final stage: ResultStage 6 (show at ApiTest.worksheet.sc:170)
23/12/01 16:09:18 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:09:18 INFO DAGScheduler: Missing parents: List()
23/12/01 16:09:18 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[27] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:09:18 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:09:18 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:09:18 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:18 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
23/12/01 16:09:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[27] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:09:18 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
23/12/01 16:09:18 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:09:18 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
23/12/01 16:09:18 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1634 bytes result sent to driver
23/12/01 16:09:18 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:09:18 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
23/12/01 16:09:18 INFO DAGScheduler: ResultStage 6 (show at ApiTest.worksheet.sc:170) finished in 0.015 s
23/12/01 16:09:18 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:09:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
23/12/01 16:09:18 INFO DAGScheduler: Job 6 finished: show at ApiTest.worksheet.sc:170, took 0.016153 s
23/12/01 16:09:18 INFO CodeGenerator: Code generated in 6.224049 ms
23/12/01 16:09:18 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
2023.12.01 16:09:18 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.55s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 16:09:25 INFO CodeGenerator: Code generated in 6.951902 ms
23/12/01 16:09:25 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:09:25 INFO DAGScheduler: Got job 7 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:09:25 INFO DAGScheduler: Final stage: ResultStage 7 (show at ApiTest.worksheet.sc:170)
23/12/01 16:09:25 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:09:25 INFO DAGScheduler: Missing parents: List()
23/12/01 16:09:25 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[31] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:09:25 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:09:25 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:09:25 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:25 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
23/12/01 16:09:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[31] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:09:25 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/12/01 16:09:25 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:09:25 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
23/12/01 16:09:25 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 1634 bytes result sent to driver
23/12/01 16:09:25 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:09:25 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/12/01 16:09:25 INFO DAGScheduler: ResultStage 7 (show at ApiTest.worksheet.sc:170) finished in 0.019 s
23/12/01 16:09:25 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:09:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
23/12/01 16:09:25 INFO DAGScheduler: Job 7 finished: show at ApiTest.worksheet.sc:170, took 0.021162 s
23/12/01 16:09:25 INFO CodeGenerator: Code generated in 5.702782 ms
23/12/01 16:09:25 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
2023.12.01 16:09:25 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.65s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 16:09:47 INFO CodeGenerator: Code generated in 5.729062 ms
23/12/01 16:09:47 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:09:47 INFO DAGScheduler: Got job 8 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:09:47 INFO DAGScheduler: Final stage: ResultStage 8 (show at ApiTest.worksheet.sc:170)
23/12/01 16:09:47 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:09:47 INFO DAGScheduler: Missing parents: List()
23/12/01 16:09:47 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[35] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:09:47 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:09:47 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:09:47 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:47 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
23/12/01 16:09:47 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[35] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:09:47 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
23/12/01 16:09:47 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:09:47 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
23/12/01 16:09:47 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1634 bytes result sent to driver
23/12/01 16:09:47 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:09:47 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/12/01 16:09:47 INFO DAGScheduler: ResultStage 8 (show at ApiTest.worksheet.sc:170) finished in 0.031 s
23/12/01 16:09:47 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:09:47 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
23/12/01 16:09:47 INFO DAGScheduler: Job 8 finished: show at ApiTest.worksheet.sc:170, took 0.032614 s
23/12/01 16:09:47 INFO CodeGenerator: Code generated in 6.048962 ms
23/12/01 16:09:47 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
2023.12.01 16:09:47 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.61s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:171:1: 
Not found: runMakeDummyDf
runMakeDummyDf()
^^^^^^^^^^^^^^
2023.12.01 16:09:49 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.36s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 16:09:56 INFO CodeGenerator: Code generated in 5.580613 ms
23/12/01 16:09:56 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:09:56 INFO DAGScheduler: Got job 9 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:09:56 INFO DAGScheduler: Final stage: ResultStage 9 (show at ApiTest.worksheet.sc:170)
23/12/01 16:09:56 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:09:56 INFO DAGScheduler: Missing parents: List()
23/12/01 16:09:56 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[39] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:09:56 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:09:56 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.4 KiB, free 434.4 MiB)
23/12/01 16:09:56 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.25.86.80:42381 (size: 6.4 KiB, free: 434.4 MiB)
23/12/01 16:09:56 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
23/12/01 16:09:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[39] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:09:56 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
23/12/01 16:09:56 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:09:56 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
23/12/01 16:09:56 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1634 bytes result sent to driver
23/12/01 16:09:56 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:09:56 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/12/01 16:09:56 INFO DAGScheduler: ResultStage 9 (show at ApiTest.worksheet.sc:170) finished in 0.013 s
23/12/01 16:09:56 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:09:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/12/01 16:09:56 INFO DAGScheduler: Job 9 finished: show at ApiTest.worksheet.sc:170, took 0.014806 s
23/12/01 16:09:56 INFO CodeGenerator: Code generated in 5.397501 ms
23/12/01 16:09:56 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.25.86.80:42381 in memory (size: 6.4 KiB, free: 434.4 MiB)
2023.12.01 16:09:56 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.56s[0m
2023.12.01 16:12:28 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (7 scala sources)[0m
2023.12.01 16:12:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.58s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 16:12:30 INFO CodeGenerator: Code generated in 6.060437 ms
23/12/01 16:12:30 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:12:30 INFO DAGScheduler: Got job 10 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:12:30 INFO DAGScheduler: Final stage: ResultStage 10 (show at ApiTest.worksheet.sc:170)
23/12/01 16:12:30 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:12:30 INFO DAGScheduler: Missing parents: List()
23/12/01 16:12:30 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[45] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:12:30 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:12:30 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 16:12:30 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.25.86.80:42381 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:12:30 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
23/12/01 16:12:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[45] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:12:30 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
23/12/01 16:12:30 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:12:30 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
23/12/01 16:12:30 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 1634 bytes result sent to driver
23/12/01 16:12:30 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:12:30 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/12/01 16:12:30 INFO DAGScheduler: ResultStage 10 (show at ApiTest.worksheet.sc:170) finished in 0.019 s
23/12/01 16:12:30 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:12:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
23/12/01 16:12:30 INFO DAGScheduler: Job 10 finished: show at ApiTest.worksheet.sc:170, took 0.020348 s
23/12/01 16:12:30 INFO CodeGenerator: Code generated in 5.422827 ms
23/12/01 16:12:30 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.25.86.80:42381 in memory (size: 6.3 KiB, free: 434.4 MiB)
2023.12.01 16:12:30 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.59s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:173:1: 
Not found: runConvertDummyDfAsString
runConvertDummyDfAsString
^^^^^^^^^^^^^^^^^^^^^^^^^
2023.12.01 16:12:34 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.35s[0m
[31merror[39m: worksheets/ApiTest.worksheet.sc:173:1: 
Not found: runConvertDummyDfAsString
runConvertDummyDfAsString()
^^^^^^^^^^^^^^^^^^^^^^^^^
2023.12.01 16:12:36 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.36s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 16:12:42 INFO CodeGenerator: Code generated in 5.537141 ms
23/12/01 16:12:42 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:12:42 INFO DAGScheduler: Got job 11 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:12:42 INFO DAGScheduler: Final stage: ResultStage 11 (show at ApiTest.worksheet.sc:170)
23/12/01 16:12:42 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:12:42 INFO DAGScheduler: Missing parents: List()
23/12/01 16:12:42 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[51] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:12:42 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:12:42 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 16:12:42 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.25.86.80:42381 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:12:42 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
23/12/01 16:12:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[51] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:12:42 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
23/12/01 16:12:42 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:12:42 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
23/12/01 16:12:43 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1677 bytes result sent to driver
23/12/01 16:12:43 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 17 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:12:43 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
23/12/01 16:12:43 INFO DAGScheduler: ResultStage 11 (show at ApiTest.worksheet.sc:170) finished in 0.024 s
23/12/01 16:12:43 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:12:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
23/12/01 16:12:43 INFO DAGScheduler: Job 11 finished: show at ApiTest.worksheet.sc:170, took 0.026085 s
23/12/01 16:12:43 INFO CodeGenerator: Code generated in 5.34749 ms
23/12/01 16:12:43 INFO CodeGenerator: Code generated in 4.077823 ms
23/12/01 16:12:43 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/01 16:12:43 INFO DAGScheduler: Got job 12 (collect at SparkJob.scala:13) with 1 output partitions
23/12/01 16:12:43 INFO DAGScheduler: Final stage: ResultStage 12 (collect at SparkJob.scala:13)
23/12/01 16:12:43 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:12:43 INFO DAGScheduler: Missing parents: List()
23/12/01 16:12:43 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[57] at collect at SparkJob.scala:13), which has no missing parents
23/12/01 16:12:43 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/01 16:12:43 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 434.4 MiB)
23/12/01 16:12:43 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.25.86.80:42381 (size: 6.1 KiB, free: 434.4 MiB)
23/12/01 16:12:43 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
23/12/01 16:12:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[57] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/01 16:12:43 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
23/12/01 16:12:43 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:12:43 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
23/12/01 16:12:43 INFO CodeGenerator: Code generated in 5.477899 ms
23/12/01 16:12:43 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 1657 bytes result sent to driver
23/12/01 16:12:43 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 14 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:12:43 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
23/12/01 16:12:43 INFO DAGScheduler: ResultStage 12 (collect at SparkJob.scala:13) finished in 0.030 s
23/12/01 16:12:43 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:12:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
23/12/01 16:12:43 INFO DAGScheduler: Job 12 finished: collect at SparkJob.scala:13, took 0.032039 s
23/12/01 16:12:43 INFO CodeGenerator: Code generated in 5.389266 ms
2023.12.01 16:12:43 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.62s[0m
23/12/01 16:12:43 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.25.86.80:42381 in memory (size: 6.1 KiB, free: 434.4 MiB)
23/12/01 16:12:43 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.25.86.80:42381 in memory (size: 6.3 KiB, free: 434.4 MiB)
[31merror[39m: worksheets/ApiTest.worksheet.sc:166:10: 
value df is not a member of org.apache.spark.sql.DataFrame
val df = makeDummyDf().
         ^
2023.12.01 16:13:16 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.34s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


[31merror[39m: worksheets/ApiTest.worksheet.sc:169:16: 
Found:    (MdocApp.this.df : Long)
Required: org.apache.spark.sql.DataFrame
MakeExpression(df)
               ^^
2023.12.01 16:13:18 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.39s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


[31merror[39m: worksheets/ApiTest.worksheet.sc:169:16: 
Found:    (MdocApp.this.df : Long)
Required: org.apache.spark.sql.DataFrame
MakeExpression(df)
               ^^
2023.12.01 16:13:20 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.47s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


2023.12.01 16:13:31 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.36s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


2023.12.01 16:13:50 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.37s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


2023.12.01 16:14:24 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.38s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


2023.12.01 16:14:27 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.34s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


2023.12.01 16:14:36 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.42s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


[31merror[39m: worksheets/ApiTest.worksheet.sc:169:16: 
Found:    (MdocApp.this.df : Long)
Required: org.apache.spark.sql.DataFrame
MakeExpression(df)
               ^^
2023.12.01 16:14:43 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.37s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


2023.12.01 16:14:46 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.35s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


2023.12.01 16:14:48 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.35s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


2023.12.01 16:14:58 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.42s[0m
[31merror[39m: 
ApiTest.worksheet.sc:170 (mdoc generated code) 
 value show is not a member of Long
      df.show()


[31merror[39m: worksheets/ApiTest.worksheet.sc:169:16: 
Found:    (MdocApp.this.df : Long)
Required: org.apache.spark.sql.DataFrame
MakeExpression(df)
               ^^
2023.12.01 16:15:02 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.36s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 16:15:07 INFO CodeGenerator: Code generated in 5.65055 ms
23/12/01 16:15:07 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:15:07 INFO DAGScheduler: Got job 13 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:15:07 INFO DAGScheduler: Final stage: ResultStage 13 (show at ApiTest.worksheet.sc:170)
23/12/01 16:15:07 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:15:07 INFO DAGScheduler: Missing parents: List()
23/12/01 16:15:07 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[61] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:15:07 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:15:07 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 16:15:07 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.25.86.80:42381 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:15:07 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
23/12/01 16:15:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[61] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:15:07 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
23/12/01 16:15:07 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:15:07 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
23/12/01 16:15:07 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1634 bytes result sent to driver
23/12/01 16:15:07 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:15:07 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/12/01 16:15:07 INFO DAGScheduler: ResultStage 13 (show at ApiTest.worksheet.sc:170) finished in 0.013 s
23/12/01 16:15:07 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:15:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
23/12/01 16:15:07 INFO DAGScheduler: Job 13 finished: show at ApiTest.worksheet.sc:170, took 0.015201 s
23/12/01 16:15:07 INFO CodeGenerator: Code generated in 5.882555 ms
23/12/01 16:15:07 INFO CodeGenerator: Code generated in 4.215756 ms
23/12/01 16:15:07 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/01 16:15:07 INFO DAGScheduler: Got job 14 (collect at SparkJob.scala:13) with 1 output partitions
23/12/01 16:15:07 INFO DAGScheduler: Final stage: ResultStage 14 (collect at SparkJob.scala:13)
23/12/01 16:15:07 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:15:07 INFO DAGScheduler: Missing parents: List()
23/12/01 16:15:07 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[67] at collect at SparkJob.scala:13), which has no missing parents
23/12/01 16:15:07 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.25.86.80:42381 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:15:07 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/01 16:15:07 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/12/01 16:15:07 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.25.86.80:42381 (size: 6.2 KiB, free: 434.4 MiB)
23/12/01 16:15:07 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580
23/12/01 16:15:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[67] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/01 16:15:07 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
23/12/01 16:15:07 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:15:07 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
23/12/01 16:15:07 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 1657 bytes result sent to driver
23/12/01 16:15:07 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 6 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:15:07 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
23/12/01 16:15:07 INFO DAGScheduler: ResultStage 14 (collect at SparkJob.scala:13) finished in 0.009 s
23/12/01 16:15:07 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:15:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
23/12/01 16:15:07 INFO DAGScheduler: Job 14 finished: collect at SparkJob.scala:13, took 0.019402 s
23/12/01 16:15:07 INFO CodeGenerator: Code generated in 5.433901 ms
23/12/01 16:15:07 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.25.86.80:42381 in memory (size: 6.2 KiB, free: 434.4 MiB)
2023.12.01 16:15:07 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 0.58s[0m
2023.12.01 16:15:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:15:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.52s[0m
2023.12.01 16:15:41 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala
scala.meta.tokenizers.TokenizeException: <input>:23: error: unclosed comment
    /*
    ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:15:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:15:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 52ms[0m
2023.12.01 16:15:42 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala
scala.meta.tokenizers.TokenizeException: <input>:23: error: unclosed comment
    /*
    ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:15:45 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala
scala.meta.tokenizers.TokenizeException: <input>:23: error: unclosed comment
    /*
    ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:15:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:15:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 48ms[0m
2023.12.01 16:15:46 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala
scala.meta.tokenizers.TokenizeException: <input>:23: error: unclosed comment
    /*
    ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:15:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:15:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 16:15:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:15:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 16:16:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:16:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.39s[0m
2023.12.01 16:16:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:16:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 16:16:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:16:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.4s[0m
2023.12.01 16:16:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:16:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.45s[0m
2023.12.01 16:16:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:16:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 16:17:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:17:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.46s[0m
[33mwarning[39m: worksheets/ApiTest.worksheet.sc:4:59: 
unused import
import startup.ast.{Expression, ArithmeticOperation, Num, Mult, Plus, myStart, Arg, ExpressionToSerialize}
                                                          ^^^^
23/12/01 16:20:21 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/12/01 16:20:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/12/01 16:20:21 INFO SparkContext: Running Spark version 3.5.0
23/12/01 16:20:21 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:20:21 INFO SparkContext: Java version 11.0.20
23/12/01 16:20:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/12/01 16:20:22 INFO ResourceUtils: ==============================================================
23/12/01 16:20:22 INFO ResourceUtils: No custom resources configured for spark.driver.
23/12/01 16:20:22 INFO ResourceUtils: ==============================================================
23/12/01 16:20:22 INFO SparkContext: Submitted application: sparkApp
23/12/01 16:20:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/12/01 16:20:22 INFO ResourceProfile: Limiting resource is cpu
23/12/01 16:20:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/12/01 16:20:22 INFO SecurityManager: Changing view acls to: bsoleille
23/12/01 16:20:22 INFO SecurityManager: Changing modify acls to: bsoleille
23/12/01 16:20:22 INFO SecurityManager: Changing view acls groups to: 
23/12/01 16:20:22 INFO SecurityManager: Changing modify acls groups to: 
23/12/01 16:20:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/12/01 16:20:22 INFO Utils: Successfully started service 'sparkDriver' on port 39933.
23/12/01 16:20:22 INFO SparkEnv: Registering MapOutputTracker
23/12/01 16:20:22 INFO SparkEnv: Registering BlockManagerMaster
23/12/01 16:20:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/12/01 16:20:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/12/01 16:20:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/12/01 16:20:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-be9188a4-7bff-4d06-a0b4-e354a89f54ce
23/12/01 16:20:22 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/12/01 16:20:22 INFO SparkEnv: Registering OutputCommitCoordinator
23/12/01 16:20:22 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/12/01 16:20:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/12/01 16:20:22 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
23/12/01 16:20:22 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
23/12/01 16:20:22 INFO Utils: Successfully started service 'SparkUI' on port 4043.
23/12/01 16:20:22 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/12/01 16:20:22 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64
23/12/01 16:20:22 INFO Executor: Java version 11.0.20
23/12/01 16:20:22 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/12/01 16:20:22 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@186989dc for default.
23/12/01 16:20:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41709.
23/12/01 16:20:22 INFO NettyBlockTransferService: Server created on 10.25.86.80:41709
23/12/01 16:20:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/12/01 16:20:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 41709, None)
23/12/01 16:20:22 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:41709 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 41709, None)
23/12/01 16:20:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 41709, None)
23/12/01 16:20:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 41709, None)
23/12/01 16:20:22 WARN SharedState: URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
23/12/01 16:20:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/12/01 16:20:22 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 129.907236 ms
23/12/01 16:20:24 INFO SparkContext: Starting job: show at ApiTest.worksheet.sc:170
23/12/01 16:20:24 INFO DAGScheduler: Got job 0 (show at ApiTest.worksheet.sc:170) with 1 output partitions
23/12/01 16:20:24 INFO DAGScheduler: Final stage: ResultStage 0 (show at ApiTest.worksheet.sc:170)
23/12/01 16:20:24 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:20:24 INFO DAGScheduler: Missing parents: List()
23/12/01 16:20:24 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at show at ApiTest.worksheet.sc:170), which has no missing parents
23/12/01 16:20:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 15.5 KiB, free 434.4 MiB)
23/12/01 16:20:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.3 KiB, free 434.4 MiB)
23/12/01 16:20:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:41709 (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:20:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/12/01 16:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at ApiTest.worksheet.sc:170) (first 15 tasks are for partitions Vector(0))
23/12/01 16:20:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/12/01 16:20:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) 
23/12/01 16:20:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 13.511278 ms
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 31.665589 ms
23/12/01 16:20:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1677 bytes result sent to driver
23/12/01 16:20:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 196 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:20:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/12/01 16:20:24 INFO DAGScheduler: ResultStage 0 (show at ApiTest.worksheet.sc:170) finished in 0.341 s
23/12/01 16:20:24 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:20:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/12/01 16:20:24 INFO DAGScheduler: Job 0 finished: show at ApiTest.worksheet.sc:170, took 0.385060 s
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 7.978941 ms
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 7.084814 ms
23/12/01 16:20:24 INFO SparkContext: Starting job: collect at SparkJob.scala:13
23/12/01 16:20:24 INFO DAGScheduler: Got job 1 (collect at SparkJob.scala:13) with 1 output partitions
23/12/01 16:20:24 INFO DAGScheduler: Final stage: ResultStage 1 (collect at SparkJob.scala:13)
23/12/01 16:20:24 INFO DAGScheduler: Parents of final stage: List()
23/12/01 16:20:24 INFO DAGScheduler: Missing parents: List()
23/12/01 16:20:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at collect at SparkJob.scala:13), which has no missing parents
23/12/01 16:20:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.8 KiB, free 434.4 MiB)
23/12/01 16:20:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 434.4 MiB)
23/12/01 16:20:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.25.86.80:41709 (size: 6.1 KiB, free: 434.4 MiB)
23/12/01 16:20:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
23/12/01 16:20:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))
23/12/01 16:20:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
23/12/01 16:20:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8149 bytes) 
23/12/01 16:20:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 6.463147 ms
23/12/01 16:20:24 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.25.86.80:41709 in memory (size: 6.3 KiB, free: 434.4 MiB)
23/12/01 16:20:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1700 bytes result sent to driver
23/12/01 16:20:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 42 ms on 10.25.86.80 (executor driver) (1/1)
23/12/01 16:20:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/12/01 16:20:24 INFO DAGScheduler: ResultStage 1 (collect at SparkJob.scala:13) finished in 0.046 s
23/12/01 16:20:24 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/12/01 16:20:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/12/01 16:20:24 INFO DAGScheduler: Job 1 finished: collect at SparkJob.scala:13, took 0.048438 s
23/12/01 16:20:24 INFO CodeGenerator: Code generated in 10.889675 ms
2023.12.01 16:20:24 INFO  time: evaluated worksheet 'ApiTest.worksheet.sc' in 3.95s[0m
23/12/01 16:21:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.25.86.80:41709 in memory (size: 6.1 KiB, free: 434.4 MiB)
2023.12.01 16:22:19 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:22:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.26s[0m
2023.12.01 16:22:20 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:22:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.24s[0m
2023.12.01 16:22:24 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:22:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.22s[0m
2023.12.01 16:22:27 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:22:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.14s[0m
2023.12.01 16:22:29 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:22:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.26s[0m
2023.12.01 16:23:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:23:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.39s[0m
2023.12.01 16:23:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:23:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.38s[0m
2023.12.01 16:28:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:28:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.01 16:28:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:28:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 16:28:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:28:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 16:28:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:28:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 16:28:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:28:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.01 16:28:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:28:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 16:28:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:28:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 69ms[0m
2023.12.01 16:28:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:28:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.01 16:28:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:28:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 76ms[0m
2023.12.01 16:28:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:28:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 72ms[0m
2023.12.01 16:28:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:28:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 73ms[0m
2023.12.01 16:29:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:29:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 76ms[0m
2023.12.01 16:29:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:29:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 76ms[0m
2023.12.01 16:29:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:29:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 70ms[0m
2023.12.01 16:29:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:29:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 70ms[0m
2023.12.01 16:29:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:29:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 67ms[0m
2023.12.01 16:29:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:29:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 16:30:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:30:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 16:30:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:30:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 16:30:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:30:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.01 16:30:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:30:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 16:31:29 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:31:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.13s[0m
2023.12.01 16:31:43 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:31:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.32s[0m
2023.12.01 16:31:43 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:42: error: unclosed multi-line string literal
            data = """",
                   ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getRawStringLit(LegacyScanner.scala:567)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:366)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:31:44 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:31:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 74ms[0m
2023.12.01 16:31:44 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:42: error: unclosed multi-line string literal
            data = """",
                   ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getRawStringLit(LegacyScanner.scala:567)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:366)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:31:45 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:31:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.23s[0m
2023.12.01 16:31:47 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:31:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.22s[0m
2023.12.01 16:32:05 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:32:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.23s[0m
2023.12.01 16:32:08 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:32:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.22s[0m
2023.12.01 16:32:10 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:32:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.21s[0m
2023.12.01 16:32:32 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 16:32:32 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 16:32:32 INFO  Starting debug proxy for [app.httpServerSuite(test0)][0m
2023.12.01 16:32:33 INFO  Loaded expression compiler in 410 milliseconds[0m
2023.12.01 16:32:33 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/ch/epfl/scala/scala-debug-step-filter_3/3.1.4/scala-debug-step-filter_3-3.1.4.jar[0m
2023.12.01 16:32:33 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/tasty-core_3/3.3.1/tasty-core_3-3.3.1.jar[0m
2023.12.01 16:32:33 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala3-library_3/3.3.1/scala3-library_3-3.3.1.jar[0m
2023.12.01 16:32:33 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/ch/epfl/scala/tasty-query_3/0.8.4/tasty-query_3-0.8.4.jar[0m
2023.12.01 16:32:33 INFO  /home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.13.10/scala-library-2.13.10.jar[0m
2023.12.01 16:32:33 INFO  Loaded step filter in 21 milliseconds[0m
2023.12.01 16:32:34 INFO  Loaded all sources and classes in 1 second[0m
2023.12.01 16:32:37 INFO  Trying to attach to remote debuggee VM localhost:38615 .[0m
2023.12.01 16:32:37 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 16:32:49 ERROR 23/12/01 16:32:49 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:32:49 ERROR 23/12/01 16:32:49 INFO xnio: XNIO version 3.8.7.Final[0m
2023.12.01 16:32:49 ERROR 23/12/01 16:32:49 INFO nio: XNIO NIO Implementation Version 3.8.7.Final[0m
2023.12.01 16:32:49 ERROR 23/12/01 16:32:49 INFO threads: JBoss Threads version 3.1.0.Final[0m
2023.12.01 16:32:49 ERROR 23/12/01 16:32:49 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:32:49 ERROR 23/12/01 16:32:49 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:32:59 ERROR 23/12/01 16:32:59 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:33:26 ERROR 23/12/01 16:33:26 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)[0m
2023.12.01 16:33:26 ERROR 23/12/01 16:33:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address[0m
2023.12.01 16:33:55 ERROR java.util.concurrent.TimeoutException: Future timed out after [10 seconds][0m
2023.12.01 16:33:55 ERROR 	at scala.concurrent.impl.Promise$DefaultPromise.tryAwait0(Promise.scala:248)[0m
2023.12.01 16:33:55 ERROR 	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:261)[0m
2023.12.01 16:33:55 ERROR 	at scala.concurrent.Await$.$anonfun$result$1(package.scala:201)[0m
2023.12.01 16:33:55 ERROR 	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)[0m
2023.12.01 16:33:55 ERROR 	at scala.concurrent.Await$.result(package.scala:124)[0m
2023.12.01 16:33:55 ERROR 	at web.MinimalRoutes$.showDf(WebServer.scala:27)[0m
2023.12.01 16:33:55 ERROR 	at web.MinimalRoutes$.$anonfun$3$$anonfun$1(WebServer.scala:67)[0m
2023.12.01 16:33:55 ERROR 	at cask.router.Result$Success.map(Result.scala:21)[0m
2023.12.01 16:33:55 ERROR 	at web.MinimalRoutes$.$anonfun$3(WebServer.scala:67)[0m
2023.12.01 16:33:55 ERROR 	at cask.router.EntryPoint.invoke(EntryPoint.scala:46)[0m
2023.12.01 16:33:55 ERROR 	at cask.router.Decorator$.invoke$$anonfun$2(Decorators.scala:58)[0m
2023.12.01 16:33:55 ERROR 	at cask.endpoints.WebEndpoint.wrapFunction(WebEndpoints.scala:14)[0m
2023.12.01 16:33:55 ERROR 	at cask.endpoints.WebEndpoint.wrapFunction$(WebEndpoints.scala:10)[0m
2023.12.01 16:33:55 ERROR 	at cask.endpoints.get.wrapFunction(WebEndpoints.scala:31)[0m
2023.12.01 16:33:55 ERROR 	at cask.router.Decorator$.invoke(Decorators.scala:59)[0m
2023.12.01 16:33:55 ERROR 	at cask.main.Main$DefaultHandler.handleRequest(Main.scala:115)[0m
2023.12.01 16:33:55 ERROR 	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387)[0m
2023.12.01 16:33:55 ERROR 	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852)[0m
2023.12.01 16:33:55 ERROR 	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)[0m
2023.12.01 16:33:55 ERROR 	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019)[0m
2023.12.01 16:33:55 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558)[0m
2023.12.01 16:33:55 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1423)[0m
2023.12.01 16:33:55 ERROR 	at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1282)[0m
2023.12.01 16:33:55 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.12.01 16:33:55 ERROR java.lang.IllegalStateException: UT000002: The response has already been started[0m
2023.12.01 16:33:55 ERROR 	at io.undertow.server.HttpServerExchange.setStatusCode(HttpServerExchange.java:1480)[0m
2023.12.01 16:33:55 ERROR 	at cask.main.Main$.writeResponse(Main.scala:174)[0m
2023.12.01 16:33:55 ERROR 	at cask.main.Main$DefaultHandler.handleRequest(Main.scala:121)[0m
2023.12.01 16:33:55 ERROR 	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387)[0m
2023.12.01 16:33:55 ERROR 	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852)[0m
2023.12.01 16:33:55 ERROR 	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)[0m
2023.12.01 16:33:55 ERROR 	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019)[0m
2023.12.01 16:33:55 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558)[0m
2023.12.01 16:33:55 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1423)[0m
2023.12.01 16:33:55 ERROR 	at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1282)[0m
2023.12.01 16:33:55 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.12.01 16:33:55 ERROR 23/12/01 16:33:55 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:33:55 ERROR [error response][variables]: Failed to get variables. Reason: com.sun.jdi.InvalidStackFrameException: Thread has been resumed[0m
2023.12.01 16:34:14 ERROR 23/12/01 16:34:14 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:34:14 ERROR 23/12/01 16:34:14 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:34:14 ERROR 23/12/01 16:34:14 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:34:14 ERROR 23/12/01 16:34:14 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:34:14 ERROR 23/12/01 16:34:14 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:34:14 ERROR 23/12/01 16:34:14 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:34:34 ERROR 23/12/01 16:34:34 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:35:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:35:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.39s[0m
2023.12.01 16:35:38 ERROR Failed to initialize communication: Socket closed[0m
2023.12.01 16:35:38 INFO  Closing debug server tcp://0.0.0.0:39155[0m
2023.12.01 16:35:38 INFO  Canceling debug proxy for [app.httpServerSuite(test0)][0m
2023.12.01 16:36:09 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:36:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.21s[0m
2023.12.01 16:36:14 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.01 16:36:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.22s[0m
2023.12.01 16:38:23 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 16:38:23 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 16:38:23 INFO  Starting debug proxy for [app.httpServerSuite(test0)][0m
2023.12.01 16:38:23 INFO  Loaded expression compiler in 2 milliseconds[0m
2023.12.01 16:38:23 INFO  Loaded step filter in 0 milliseconds[0m
2023.12.01 16:38:24 INFO  Loaded all sources and classes in 1 second[0m
2023.12.01 16:38:27 INFO  Trying to attach to remote debuggee VM localhost:60451 .[0m
2023.12.01 16:38:27 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 16:38:35 ERROR 23/12/01 16:38:35 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:38:35 ERROR 23/12/01 16:38:35 INFO xnio: XNIO version 3.8.7.Final[0m
2023.12.01 16:38:35 ERROR 23/12/01 16:38:35 INFO nio: XNIO NIO Implementation Version 3.8.7.Final[0m
2023.12.01 16:38:35 ERROR 23/12/01 16:38:35 INFO threads: JBoss Threads version 3.1.0.Final[0m
2023.12.01 16:38:55 ERROR 23/12/01 16:38:55 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:38:55 ERROR 23/12/01 16:38:55 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:39:05 ERROR 23/12/01 16:39:05 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:39:08 ERROR 23/12/01 16:39:08 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)[0m
2023.12.01 16:39:08 ERROR 23/12/01 16:39:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SparkContext: Running Spark version 3.5.0[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SparkContext: Java version 11.0.20[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO ResourceUtils: ==============================================================[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO ResourceUtils: No custom resources configured for spark.driver.[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO ResourceUtils: ==============================================================[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SparkContext: Submitted application: sparkApp[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO ResourceProfile: Limiting resource is cpu[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO ResourceProfileManager: Added ResourceProfile id: 0[0m
2023.12.01 16:39:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SecurityManager: Changing view acls to: bsoleille[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SecurityManager: Changing modify acls to: bsoleille[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SecurityManager: Changing view acls groups to: [0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SecurityManager: Changing modify acls groups to: [0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO Utils: Successfully started service 'sparkDriver' on port 34317.[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SparkEnv: Registering MapOutputTracker[0m
2023.12.01 16:39:35 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.12.01 16:39:35 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.5.0/spark-unsafe_2.13-3.5.0.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.12.01 16:39:35 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.12.01 16:39:35 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.12.01 16:39:35 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SparkEnv: Registering BlockManagerMaster[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SparkEnv: Registering BlockManagerMasterHeartbeat[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-327c3112-38c8-4e4f-976e-da4f58bafbcb[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO MemoryStore: MemoryStore started with capacity 9.1 GiB[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO SparkEnv: Registering OutputCommitCoordinator[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO Utils: Successfully started service 'SparkUI' on port 4044.[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO Executor: Starting executor ID driver on host 10.25.86.80[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO Executor: Java version 11.0.20[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@10c6d899 for default.[0m
2023.12.01 16:39:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45783.[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO NettyBlockTransferService: Server created on 10.25.86.80:45783[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 45783, None)[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:45783 with 9.1 GiB RAM, BlockManagerId(driver, 10.25.86.80, 45783, None)[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 45783, None)[0m
2023.12.01 16:39:35 ERROR 23/12/01 16:39:35 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 45783, None)[0m
2023.12.01 16:39:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:39:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:39:35 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:39:36 ERROR 23/12/01 16:39:36 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.[0m
2023.12.01 16:39:36 ERROR 23/12/01 16:39:36 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:51 INFO CodeGenerator: Code generated in 135.796806 ms[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO SparkContext: Starting job: collect at SparkJob.scala:13[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO DAGScheduler: Got job 0 (collect at SparkJob.scala:13) with 1 output partitions[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkJob.scala:13)[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO DAGScheduler: Parents of final stage: List()[0m
2023.12.01 16:39:52 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO DAGScheduler: Missing parents: List()[0m
2023.12.01 16:39:52 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13), which has no missing parents[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 9.1 GiB)[0m
2023.12.01 16:39:52 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 9.1 GiB)[0m
2023.12.01 16:39:52 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:45783 (size: 6.1 KiB, free: 9.1 GiB)[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) [0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO CodeGenerator: Code generated in 7.747346 ms[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO CodeGenerator: Code generated in 32.980556 ms[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1700 bytes result sent to driver[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 666 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool [0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO DAGScheduler: ResultStage 0 (collect at SparkJob.scala:13) finished in 0.768 s[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO DAGScheduler: Job 0 finished: collect at SparkJob.scala:13, took 0.795147 s[0m
2023.12.01 16:39:51 ERROR 23/12/01 16:39:52 INFO CodeGenerator: Code generated in 7.55883 ms[0m
2023.12.01 16:39:59 ERROR java.lang.IllegalStateException: UT000002: The response has already been started[0m
2023.12.01 16:39:59 ERROR 	at io.undertow.server.HttpServerExchange.setStatusCode(HttpServerExchange.java:1480)[0m
2023.12.01 16:39:59 ERROR 	at cask.main.Main$.writeResponse(Main.scala:174)[0m
2023.12.01 16:39:59 ERROR 	at cask.main.Main$DefaultHandler.$anonfun$2(Main.scala:99)[0m
2023.12.01 16:39:59 ERROR 	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)[0m
2023.12.01 16:39:59 ERROR 	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)[0m
2023.12.01 16:39:59 ERROR 	at cask.main.Main$DefaultHandler.handleRequest(Main.scala:117)[0m
2023.12.01 16:39:59 ERROR 	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387)[0m
2023.12.01 16:39:59 ERROR 	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852)[0m
2023.12.01 16:39:59 ERROR 	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)[0m
2023.12.01 16:39:59 ERROR 	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019)[0m
2023.12.01 16:39:59 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558)[0m
2023.12.01 16:39:59 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1423)[0m
2023.12.01 16:39:59 ERROR 	at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1282)[0m
2023.12.01 16:39:59 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.12.01 16:39:59 ERROR 23/12/01 16:39:59 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:40:07 ERROR 23/12/01 16:40:07 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:40:07 ERROR 23/12/01 16:40:07 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:40:07 ERROR 23/12/01 16:40:07 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:40:07 ERROR 23/12/01 16:40:07 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:40:07 ERROR 23/12/01 16:40:07 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:40:07 ERROR 23/12/01 16:40:07 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:40:11 INFO  Canceling debug proxy for [app.httpServerSuite(test0)][0m
2023.12.01 16:40:11 INFO  Closing debug server tcp://0.0.0.0:36365[0m
2023.12.01 16:40:11 ERROR Failed to initialize communication: Socket closed[0m
2023.12.01 16:41:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:41:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 16:42:08 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 16:42:08 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 16:42:08 INFO  Starting debug proxy for [app.httpServerSuite(test0)][0m
2023.12.01 16:42:08 INFO  Loaded expression compiler in 1 millisecond[0m
2023.12.01 16:42:08 INFO  Loaded step filter in 0 milliseconds[0m
2023.12.01 16:42:08 INFO  Loaded all sources and classes in 925 milliseconds[0m
2023.12.01 16:42:12 INFO  Trying to attach to remote debuggee VM localhost:39723 .[0m
2023.12.01 16:42:12 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 16:42:17 ERROR 23/12/01 16:42:17 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:42:17 ERROR 23/12/01 16:42:17 INFO xnio: XNIO version 3.8.7.Final[0m
2023.12.01 16:42:17 ERROR 23/12/01 16:42:17 INFO nio: XNIO NIO Implementation Version 3.8.7.Final[0m
2023.12.01 16:42:17 ERROR 23/12/01 16:42:17 INFO threads: JBoss Threads version 3.1.0.Final[0m
2023.12.01 16:42:23 ERROR 23/12/01 16:42:23 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:42:23 ERROR 23/12/01 16:42:23 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:42:26 ERROR 23/12/01 16:42:26 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)[0m
2023.12.01 16:42:26 ERROR 23/12/01 16:42:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address[0m
2023.12.01 16:42:33 ERROR 23/12/01 16:42:33 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SparkContext: Running Spark version 3.5.0[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SparkContext: OS info Linux, 6.2.0-37-generic, amd64[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SparkContext: Java version 11.0.20[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO ResourceUtils: ==============================================================[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO ResourceUtils: No custom resources configured for spark.driver.[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO ResourceUtils: ==============================================================[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SparkContext: Submitted application: sparkApp[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)[0m
2023.12.01 16:42:52 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO ResourceProfile: Limiting resource is cpu[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO ResourceProfileManager: Added ResourceProfile id: 0[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SecurityManager: Changing view acls to: bsoleille[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SecurityManager: Changing modify acls to: bsoleille[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SecurityManager: Changing view acls groups to: [0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SecurityManager: Changing modify acls groups to: [0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO Utils: Successfully started service 'sparkDriver' on port 35303.[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SparkEnv: Registering MapOutputTracker[0m
2023.12.01 16:42:52 ERROR WARNING: An illegal reflective access operation has occurred[0m
2023.12.01 16:42:52 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/bsoleille/.cache/coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.13/3.5.0/spark-unsafe_2.13-3.5.0.jar) to constructor java.nio.DirectByteBuffer(long,int)[0m
2023.12.01 16:42:52 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform[0m
2023.12.01 16:42:52 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations[0m
2023.12.01 16:42:52 ERROR WARNING: All illegal access operations will be denied in a future release[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SparkEnv: Registering BlockManagerMaster[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-07526d0e-5cb3-4aad-be10-1bb8f3863cec[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO MemoryStore: MemoryStore started with capacity 9.1 GiB[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:52 INFO SparkEnv: Registering OutputCommitCoordinator[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO Utils: Successfully started service 'SparkUI' on port 4044.[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO Executor: Starting executor ID driver on host 10.25.86.80[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO Executor: OS info Linux, 6.2.0-37-generic, amd64[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO Executor: Java version 11.0.20[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''[0m
2023.12.01 16:42:52 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@71dc044c for default.[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40739.[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO NettyBlockTransferService: Server created on 10.25.86.80:40739[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 40739, None)[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:40739 with 9.1 GiB RAM, BlockManagerId(driver, 10.25.86.80, 40739, None)[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 40739, None)[0m
2023.12.01 16:42:52 ERROR 23/12/01 16:42:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 40739, None)[0m
2023.12.01 16:42:52 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:42:52 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:42:52 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:42:53 ERROR 23/12/01 16:42:53 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.[0m
2023.12.01 16:42:53 ERROR 23/12/01 16:42:53 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO CodeGenerator: Code generated in 139.313405 ms[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO SparkContext: Starting job: collect at SparkJob.scala:13[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO DAGScheduler: Got job 0 (collect at SparkJob.scala:13) with 1 output partitions[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO DAGScheduler: Final stage: ResultStage 0 (collect at SparkJob.scala:13)[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO DAGScheduler: Parents of final stage: List()[0m
2023.12.01 16:43:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO DAGScheduler: Missing parents: List()[0m
2023.12.01 16:43:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13), which has no missing parents[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.8 KiB, free 9.1 GiB)[0m
2023.12.01 16:43:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 9.1 GiB)[0m
2023.12.01 16:43:05 ERROR searching for `#` failed
java.lang.RuntimeException: invalid symbol format
#
^
	at scala.sys.package$.error(package.scala:27)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.fail(Scala.scala:202)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.readChar(Scala.scala:215)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseValue(Scala.scala:233)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.parseDescriptor(Scala.scala:258)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser.entryPoint(Scala.scala:281)
	at scala.meta.internal.semanticdb.Scala$DescriptorParser$.apply(Scala.scala:289)
	at scala.meta.internal.semanticdb.Scala$ScalaSymbolOps$.owner$extension(Scala.scala:103)
	at scala.meta.internal.mtags.Symbol.toplevel(Symbol.scala:56)
	at scala.meta.internal.mtags.SymbolIndexBucket.query0(SymbolIndexBucket.scala:186)
	at scala.meta.internal.mtags.SymbolIndexBucket.query(SymbolIndexBucket.scala:163)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.$anonfun$findSymbolDefinition$1(OnDemandSymbolIndex.scala:141)
	at scala.collection.immutable.List.flatMap(List.scala:293)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.findSymbolDefinition(OnDemandSymbolIndex.scala:141)
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:58)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:463)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:501)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:542)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:197)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:67)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:72)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:347)
	at scala.collection.IterableOnceOps.collectFirst(IterableOnce.scala:1142)
	at scala.collection.IterableOnceOps.collectFirst$(IterableOnce.scala:1134)
	at scala.collection.AbstractIterable.collectFirst(Iterable.scala:933)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:72)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:70)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:213)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:182)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:73)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:40739 (size: 6.1 KiB, free: 9.1 GiB)[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at collect at SparkJob.scala:13) (first 15 tasks are for partitions Vector(0))[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8154 bytes) [0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:05 INFO CodeGenerator: Code generated in 7.410289 ms[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:06 INFO CodeGenerator: Code generated in 28.07724 ms[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:06 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1700 bytes result sent to driver[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:06 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 688 ms on 10.25.86.80 (executor driver) (1/1)[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:06 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool [0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:06 INFO DAGScheduler: ResultStage 0 (collect at SparkJob.scala:13) finished in 0.783 s[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:06 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:06 INFO DAGScheduler: Job 0 finished: collect at SparkJob.scala:13, took 0.807342 s[0m
2023.12.01 16:43:05 ERROR 23/12/01 16:43:06 INFO CodeGenerator: Code generated in 9.653941 ms[0m
2023.12.01 16:44:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:44:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.01 16:44:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:44:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 16:44:16 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed comment
    /*
    ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:44:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:44:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 44ms[0m
2023.12.01 16:44:17 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed comment
    /*
    ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:44:18 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed comment
    /*
    ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:44:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:44:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 48ms[0m
2023.12.01 16:44:19 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed comment
    /*
    ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.01 16:44:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:44:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.45s[0m
2023.12.01 16:44:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:44:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.39s[0m
2023.12.01 16:44:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 16:44:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.37s[0m
2023.12.01 16:44:33 INFO  Canceling debug proxy for [app.httpServerSuite(test0)][0m
2023.12.01 16:44:33 INFO  Closing debug server tcp://0.0.0.0:39435[0m
2023.12.01 16:44:33 ERROR Failed to initialize communication: Socket closed[0m
23/12/01 16:44:55 WARN RemoteEndpoint: Unmatched cancel notification for request id 3357
2023.12.01 16:45:14 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.01 16:45:14 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.01 16:45:14 INFO  Starting debug proxy for [app.httpServerSuite(test0)][0m
2023.12.01 16:45:14 INFO  Loaded expression compiler in 1 millisecond[0m
2023.12.01 16:45:14 INFO  Loaded step filter in 0 milliseconds[0m
2023.12.01 16:45:14 INFO  Loaded all sources and classes in 952 milliseconds[0m
2023.12.01 16:45:17 INFO  Trying to attach to remote debuggee VM localhost:34725 .[0m
2023.12.01 16:45:17 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.01 16:45:25 ERROR 23/12/01 16:45:25 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:45:25 ERROR 23/12/01 16:45:25 INFO xnio: XNIO version 3.8.7.Final[0m
2023.12.01 16:45:25 ERROR 23/12/01 16:45:25 INFO nio: XNIO NIO Implementation Version 3.8.7.Final[0m
2023.12.01 16:45:25 ERROR 23/12/01 16:45:25 INFO threads: JBoss Threads version 3.1.0.Final[0m
2023.12.01 16:45:37 ERROR 23/12/01 16:45:37 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:45:37 ERROR 23/12/01 16:45:37 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:45:47 ERROR 23/12/01 16:45:47 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:46:00 ERROR 23/12/01 16:46:00 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)[0m
2023.12.01 16:46:00 ERROR 23/12/01 16:46:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address[0m
2023.12.01 16:46:27 ERROR java.lang.IllegalStateException: UT000002: The response has already been started[0m
2023.12.01 16:46:27 ERROR 	at io.undertow.server.HttpServerExchange.setStatusCode(HttpServerExchange.java:1480)[0m
2023.12.01 16:46:27 ERROR 	at cask.main.Main$.writeResponse(Main.scala:174)[0m
2023.12.01 16:46:27 ERROR 	at cask.main.Main$DefaultHandler.$anonfun$2(Main.scala:99)[0m
2023.12.01 16:46:27 ERROR 	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:15)[0m
2023.12.01 16:46:27 ERROR 	at scala.runtime.function.JProcedure1.apply(JProcedure1.java:10)[0m
2023.12.01 16:46:27 ERROR 	at cask.main.Main$DefaultHandler.handleRequest(Main.scala:117)[0m
2023.12.01 16:46:27 ERROR 	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387)[0m
2023.12.01 16:46:27 ERROR 	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852)[0m
2023.12.01 16:46:27 ERROR 	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)[0m
2023.12.01 16:46:27 ERROR 	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019)[0m
2023.12.01 16:46:27 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558)[0m
2023.12.01 16:46:27 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1423)[0m
2023.12.01 16:46:27 ERROR 	at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1282)[0m
2023.12.01 16:46:27 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.12.01 16:46:27 ERROR 23/12/01 16:46:27 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:47:04 ERROR 23/12/01 16:47:04 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:47:04 ERROR 23/12/01 16:47:04 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:47:04 ERROR 23/12/01 16:47:04 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:47:04 ERROR 23/12/01 16:47:04 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:47:04 ERROR 23/12/01 16:47:04 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:47:04 ERROR 23/12/01 16:47:04 INFO undertow: starting server: Undertow - 2.2.20.Final[0m
2023.12.01 16:47:24 ERROR 23/12/01 16:47:24 INFO undertow: stopping server: Undertow - 2.2.20.Final[0m
2023.12.01 16:47:32 INFO  Canceling debug proxy for [app.httpServerSuite(test0)][0m
2023.12.01 16:47:32 INFO  Closing debug server tcp://0.0.0.0:37131[0m
2023.12.01 16:47:32 ERROR Failed to initialize communication: Socket closed[0m
2023.12.01 17:01:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:01:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 17:02:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:02:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 17:02:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:02:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 17:02:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:02:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 17:02:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:02:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:02:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:02:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 17:02:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:02:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 17:03:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:03:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:03:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:03:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.53s[0m
2023.12.01 17:03:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:03:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 17:04:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:04:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 17:04:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:04:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 17:04:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:04:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:06:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:06:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:06:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:06:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 17:06:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:06:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.01 17:06:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:06:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.01 17:06:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:06:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.01 17:06:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:06:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:07:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:07:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:07:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:07:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 17:07:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:07:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:07:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:07:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:07:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:07:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:07:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:07:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 17:07:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:07:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 17:08:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:08:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 17:08:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:08:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 17:08:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:08:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 17:08:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:08:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.01 17:08:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:08:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 17:08:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:08:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 17:09:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:09:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.12.01 17:10:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:10:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.58s[0m
2023.12.01 17:10:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:10:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.56s[0m
2023.12.01 17:10:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:10:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.49s[0m
2023.12.01 17:10:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:10:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.12.01 17:11:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:11:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.5s[0m
2023.12.01 17:11:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:11:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.01 17:11:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:11:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:11:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:11:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.01 17:11:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:11:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.12.01 17:12:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:12:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.12.01 17:13:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:13:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 17:13:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:13:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.12.01 17:13:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:13:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:14:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:14:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.01 17:19:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:19:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:19:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:19:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.01 17:19:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:19:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.01 17:19:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:19:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 17:19:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:19:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.12.01 17:19:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:19:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.01 17:19:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:19:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 17:20:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:20:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 17:20:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:20:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 17:20:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:20:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 17:20:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:20:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:20:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:20:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:20:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:20:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.12.01 17:20:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:20:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.01 17:20:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:20:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 17:21:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:21:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.01 17:21:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:21:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:21:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:21:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:21:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:21:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:21:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:21:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:21:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:21:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.01 17:21:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:21:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.01 17:22:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:22:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.01 17:22:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:22:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.01 17:22:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:22:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.12.01 17:22:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:22:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
23/12/01 17:24:09 ERROR CompilerAccess: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-01/r_compiler-error_(project-effective-scala-c1-s14-3039-4085)_17-24-09-833.md
2023.12.01 17:26:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:26:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 17:26:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:26:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 17:26:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:26:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 17:26:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:26:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.01 17:28:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:28:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.01 17:28:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:28:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:29:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:29:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.01 17:29:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:29:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:29:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:29:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:30:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:30:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 57ms[0m
2023.12.01 17:30:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:30:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.01 17:35:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:35:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:35:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:35:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.24s[0m
2023.12.01 17:35:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:35:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 53ms[0m
2023.12.01 17:35:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:35:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 50ms[0m
2023.12.01 17:35:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:35:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 17:35:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:35:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 17:35:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:35:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 17:35:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:35:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:35:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:35:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:36:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:36:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 17:36:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:36:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 17:36:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:36:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 17:36:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:36:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:36:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:36:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.01 17:36:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:36:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:36:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:36:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:36:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:36:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.37s[0m
2023.12.01 17:37:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:37:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 17:38:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:38:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.01 17:39:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:39:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:39:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:39:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.01 17:40:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:40:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:40:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:40:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 17:40:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:40:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:41:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:41:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 17:41:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:41:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:41:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:41:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:41:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:41:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:41:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:41:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:41:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:41:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 17:44:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:44:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:45:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:45:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 17:45:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:45:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 17:45:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:45:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.49s[0m
2023.12.01 17:45:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:45:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.5s[0m
2023.12.01 17:45:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 17:45:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.49s[0m
23/12/01 23:24:38 WARN RemoteEndpoint: Unmatched cancel notification for request id 6192
2023.12.01 23:24:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:24:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.12.01 23:24:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:24:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.12.01 23:24:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:24:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:24:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:24:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.01 23:24:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:24:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:25:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:25:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:25:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:25:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:25:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:25:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.01 23:25:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:25:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:42:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:42:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:42:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:42:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:43:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:43:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:43:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:43:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:43:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:43:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:43:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:43:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.24s[0m
2023.12.01 23:44:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:44:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.01 23:44:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:44:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.24s[0m
2023.12.01 23:44:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:44:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.01 23:44:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:44:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.24s[0m
2023.12.01 23:44:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:44:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.01 23:44:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:44:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.01 23:45:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:45:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:45:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:45:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:45:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:45:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.01 23:45:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:45:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:45:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:45:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:45:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:45:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.01 23:46:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:46:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:46:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:46:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.01 23:46:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:46:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.01 23:47:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:47:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.01 23:47:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:47:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:47:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:47:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:47:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:47:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
23/12/01 23:47:21 WARN RemoteEndpoint: Unmatched cancel notification for request id 6988
2023.12.01 23:47:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:47:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:48:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:48:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:48:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:48:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:48:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:48:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:48:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:48:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:49:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:49:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.01 23:51:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:51:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:51:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:51:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.01 23:51:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:51:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.01 23:51:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:51:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
23/12/01 23:51:56 WARN RemoteEndpoint: Unmatched cancel notification for request id 7260
2023.12.01 23:52:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:52:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.24s[0m
2023.12.01 23:52:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:52:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.01 23:52:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:52:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.12.01 23:53:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.01 23:53:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.12.02 00:18:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:18:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.12.02 00:18:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:18:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.02 00:18:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:18:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.62s[0m
2023.12.02 00:18:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:18:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.49s[0m
2023.12.02 00:18:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:18:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.5s[0m
2023.12.02 00:18:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:18:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.02 00:18:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:18:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.02 00:19:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:19:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.02 00:19:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:19:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.12.02 00:19:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:19:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.02 00:19:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:19:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.02 00:19:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:19:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.02 00:19:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:19:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.02 00:21:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:21:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.02 00:21:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:21:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.02 00:23:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:23:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.02 00:23:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:23:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.02 00:23:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:23:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.02 00:23:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:23:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.02 00:23:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:23:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.02 00:23:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:23:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.02 00:24:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:24:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.02 00:24:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:24:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.02 00:24:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:24:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.02 00:24:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:24:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.02 00:24:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:24:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.02 00:25:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:25:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.02 00:25:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:25:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.02 00:25:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:25:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 77ms[0m
2023.12.02 00:25:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:25:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.02 00:25:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:25:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.02 00:25:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:25:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.02 00:26:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:26:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 69ms[0m
2023.12.02 00:26:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 00:26:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.02 08:02:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:02:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.02 08:02:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:02:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.02 08:02:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:02:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.02 08:02:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:02:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.02 08:02:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:02:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.02 08:02:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:02:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.02 08:03:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:03:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.02 08:03:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:03:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.02 08:03:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:03:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.02 08:03:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:03:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.02 08:03:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:03:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.02 08:03:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:03:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.02 08:03:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:03:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.02 08:03:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:03:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.02 08:03:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:03:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.02 08:04:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:04:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.02 08:04:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:04:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.02 08:04:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:04:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.02 08:04:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:04:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.02 08:04:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:04:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.02 08:05:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:05:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.02 08:05:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:05:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.02 08:05:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:05:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.02 08:05:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:05:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.02 08:05:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:05:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.02 08:05:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:05:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.02 08:05:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:05:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.02 08:05:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:05:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.02 08:06:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:06:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.02 08:06:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:06:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.02 08:06:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:06:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.02 08:06:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:06:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.02 08:07:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:07:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.02 08:07:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:07:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.02 08:07:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 08:07:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.02 08:07:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:07:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.02 08:07:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:07:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.02 08:07:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:07:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.02 08:07:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:07:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.02 08:07:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:07:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.55s[0m
2023.12.02 08:23:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:23:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.55s[0m
2023.12.02 08:23:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:23:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.55s[0m
2023.12.02 08:23:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:23:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.02 08:23:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:23:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.75s[0m
2023.12.02 08:23:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:23:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.02 08:23:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:23:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.56s[0m
2023.12.02 08:23:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:23:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.55s[0m
2023.12.02 08:23:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:23:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.84s[0m
2023.12.02 08:24:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:24:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.12.02 08:24:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:24:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.02 08:24:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:24:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.02 08:24:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:24:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.02 08:24:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:24:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 80ms[0m
2023.12.02 08:25:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:25:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.02 08:25:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 08:25:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.02 12:39:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 12:39:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.02 12:39:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 12:39:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.35s[0m
2023.12.02 12:39:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 12:39:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.02 12:40:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 12:40:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.02 12:40:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 12:40:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.02 12:40:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 12:40:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.02 12:40:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 12:40:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.38s[0m
2023.12.02 12:40:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 12:40:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
23/12/02 13:50:46 WARN RemoteEndpoint: Unmatched cancel notification for request id 9527
23/12/02 13:52:11 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:12 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:15 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:17 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:33 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:36 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:40 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:44 INFO GenericEndpoint: Unsupported notification method: $/setTrace
23/12/02 13:52:47 INFO GenericEndpoint: Unsupported notification method: $/setTrace
2023.12.02 13:52:57 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-server.trace.json or /home/bsoleille/.cache/metals/dap-server.trace.json[0m
2023.12.02 13:52:57 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/dap-client.trace.json or /home/bsoleille/.cache/metals/dap-client.trace.json[0m
2023.12.02 13:52:57 INFO  Starting debug proxy for [app.RoutesMain][0m
2023.12.02 13:52:57 INFO  Loaded expression compiler in 1 millisecond[0m
2023.12.02 13:52:57 INFO  Loaded step filter in 0 milliseconds[0m
2023.12.02 13:52:57 INFO  Loaded all sources and classes in 769 milliseconds[0m
2023.12.02 13:52:59 INFO  Trying to attach to remote debuggee VM localhost:36051 .[0m
2023.12.02 13:52:59 INFO  Attaching to debuggee VM succeeded.[0m
2023.12.02 13:53:41 ERROR java.lang.ExceptionInInitializerError[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.SparkConf$.<clinit>(SparkConf.scala:656)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.SparkConf.set(SparkConf.scala:94)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.SparkConf.set(SparkConf.scala:83)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.SparkConf.setAppName(SparkConf.scala:120)[0m
2023.12.02 13:53:41 ERROR 	at sparkjobs.SparkJob$.<clinit>(SparkJob.scala:27)[0m
2023.12.02 13:53:41 ERROR 	at web.MinimalRoutes$.$anonfun$12(WebServer.scala:43)[0m
2023.12.02 13:53:41 ERROR 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678)[0m
2023.12.02 13:53:41 ERROR 	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)[0m
2023.12.02 13:53:41 ERROR 	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1426)[0m
2023.12.02 13:53:41 ERROR 	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)[0m
2023.12.02 13:53:41 ERROR 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)[0m
2023.12.02 13:53:41 ERROR 	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)[0m
2023.12.02 13:53:41 ERROR 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)[0m
2023.12.02 13:53:41 ERROR 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)[0m
2023.12.02 13:53:41 ERROR Caused by: java.lang.NullPointerException: stream[0m
2023.12.02 13:53:41 ERROR 	at java.base/java.util.Objects.requireNonNull(Objects.java:246)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.status.StatusConsoleListener.<init>(StatusConsoleListener.java:70)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.status.StatusConsoleListener.<init>(StatusConsoleListener.java:62)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.config.status.StatusConfiguration.registerNewStatusConsoleListener(StatusConfiguration.java:211)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.config.status.StatusConfiguration.initialize(StatusConfiguration.java:186)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.config.builder.impl.DefaultConfigurationBuilder.build(DefaultConfigurationBuilder.java:222)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.config.builder.impl.DefaultConfigurationBuilder.build(DefaultConfigurationBuilder.java:70)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.config.properties.PropertiesConfigurationBuilder.build(PropertiesConfigurationBuilder.java:197)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.config.properties.PropertiesConfigurationFactory.getConfiguration(PropertiesConfigurationFactory.java:56)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.config.properties.PropertiesConfigurationFactory.getConfiguration(PropertiesConfigurationFactory.java:35)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.config.ConfigurationFactory$Factory.getConfiguration(ConfigurationFactory.java:533)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.config.ConfigurationFactory$Factory.getConfiguration(ConfigurationFactory.java:457)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.config.ConfigurationFactory.getConfiguration(ConfigurationFactory.java:318)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:690)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:711)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:253)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:155)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:47)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.logging.log4j.LogManager.getContext(LogManager.java:157)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.internal.Logging$.islog4j2DefaultConfigured(Logging.scala:258)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.internal.Logging.initializeLogging(Logging.scala:133)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.internal.Logging.initializeLogIfNecessary(Logging.scala:114)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.internal.Logging.initializeLogIfNecessary$(Logging.scala:108)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.util.Utils$.initializeLogIfNecessary(Utils.scala:94)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.internal.Logging.initializeLogIfNecessary(Logging.scala:105)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.internal.Logging.initializeLogIfNecessary$(Logging.scala:104)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.util.Utils$.initializeLogIfNecessary(Utils.scala:94)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.internal.Logging.log(Logging.scala:52)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.internal.Logging.log$(Logging.scala:50)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.util.Utils$.log(Utils.scala:94)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.internal.Logging.logWarning(Logging.scala:72)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.internal.Logging.logWarning$(Logging.scala:71)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.util.Utils$.logWarning(Utils.scala:94)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.util.Utils$.$anonfun$findLocalInetAddress$1(Utils.scala:977)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.util.Utils$.$anonfun$findLocalInetAddress$1$adapted(Utils.scala:967)[0m
2023.12.02 13:53:41 ERROR 	at scala.collection.immutable.List.foreach(List.scala:333)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.util.Utils$.findLocalInetAddress(Utils.scala:967)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.util.Utils$.localIpAddress$lzycompute(Utils.scala:950)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.util.Utils$.localIpAddress(Utils.scala:950)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.util.Utils$.$anonfun$localCanonicalHostName$1(Utils.scala:1007)[0m
2023.12.02 13:53:41 ERROR 	at scala.Option.getOrElse(Option.scala:201)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.util.Utils$.localCanonicalHostName(Utils.scala:1007)[0m
2023.12.02 13:53:41 ERROR 	at org.apache.spark.internal.config.package$.<clinit>(package.scala:1063)[0m
2023.12.02 13:53:41 ERROR 	... 14 more[0m
2023.12.02 13:53:41 ERROR [error response][variables]: Failed to get variables. Reason: com.sun.jdi.InvalidStackFrameException: Thread has been resumed[0m
2023.12.02 13:53:56 ERROR java.util.concurrent.TimeoutException: Future timed out after [10 seconds][0m
2023.12.02 13:53:56 ERROR 	at scala.concurrent.impl.Promise$DefaultPromise.tryAwait0(Promise.scala:248)[0m
2023.12.02 13:53:56 ERROR 	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:261)[0m
2023.12.02 13:53:56 ERROR 	at scala.concurrent.Await$.$anonfun$result$1(package.scala:201)[0m
2023.12.02 13:53:56 ERROR 	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)[0m
2023.12.02 13:53:56 ERROR 	at scala.concurrent.Await$.result(package.scala:124)[0m
2023.12.02 13:53:56 ERROR 	at web.MinimalRoutes$.showDf(WebServer.scala:50)[0m
2023.12.02 13:53:56 ERROR 	at web.MinimalRoutes$.$anonfun$5$$anonfun$1(WebServer.scala:62)[0m
2023.12.02 13:53:56 ERROR 	at cask.router.Result$Success.map(Result.scala:21)[0m
2023.12.02 13:53:56 ERROR 	at web.MinimalRoutes$.$anonfun$5(WebServer.scala:62)[0m
2023.12.02 13:53:56 ERROR 	at cask.router.EntryPoint.invoke(EntryPoint.scala:46)[0m
2023.12.02 13:53:56 ERROR 	at cask.router.Decorator$.invoke$$anonfun$2(Decorators.scala:58)[0m
2023.12.02 13:53:56 ERROR 	at cask.endpoints.WebEndpoint.wrapFunction(WebEndpoints.scala:14)[0m
2023.12.02 13:53:56 ERROR 	at cask.endpoints.WebEndpoint.wrapFunction$(WebEndpoints.scala:10)[0m
2023.12.02 13:53:56 ERROR 	at cask.endpoints.get.wrapFunction(WebEndpoints.scala:31)[0m
2023.12.02 13:53:56 ERROR 	at cask.router.Decorator$.invoke(Decorators.scala:59)[0m
2023.12.02 13:53:56 ERROR 	at cask.main.Main$DefaultHandler.handleRequest(Main.scala:115)[0m
2023.12.02 13:53:56 ERROR 	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387)[0m
2023.12.02 13:53:56 ERROR 	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852)[0m
2023.12.02 13:53:56 ERROR 	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)[0m
2023.12.02 13:53:56 ERROR 	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019)[0m
2023.12.02 13:53:56 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558)[0m
2023.12.02 13:53:56 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1423)[0m
2023.12.02 13:53:56 ERROR 	at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1282)[0m
2023.12.02 13:53:56 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.12.02 13:54:51 ERROR java.lang.NoClassDefFoundError: Could not initialize class sparkjobs.SparkJob$[0m
2023.12.02 13:54:51 ERROR 	at web.MinimalRoutes$.$anonfun$12(WebServer.scala:43)[0m
2023.12.02 13:54:51 ERROR 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678)[0m
2023.12.02 13:54:51 ERROR 	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)[0m
2023.12.02 13:54:51 ERROR 	at java.base/java.util.concurrent.ForkJoinTask$RunnableExecuteAction.exec(ForkJoinTask.java:1426)[0m
2023.12.02 13:54:51 ERROR 	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)[0m
2023.12.02 13:54:51 ERROR 	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)[0m
2023.12.02 13:54:51 ERROR 	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)[0m
2023.12.02 13:54:51 ERROR 	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)[0m
2023.12.02 13:54:51 ERROR 	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)[0m
2023.12.02 13:55:31 ERROR java.util.concurrent.TimeoutException: Future timed out after [10 seconds][0m
2023.12.02 13:55:31 ERROR 	at scala.concurrent.impl.Promise$DefaultPromise.tryAwait0(Promise.scala:248)[0m
2023.12.02 13:55:31 ERROR 	at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:261)[0m
2023.12.02 13:55:31 ERROR 	at scala.concurrent.Await$.$anonfun$result$1(package.scala:201)[0m
2023.12.02 13:55:31 ERROR 	at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:62)[0m
2023.12.02 13:55:31 ERROR 	at scala.concurrent.Await$.result(package.scala:124)[0m
2023.12.02 13:55:31 ERROR 	at web.MinimalRoutes$.showDf(WebServer.scala:50)[0m
2023.12.02 13:55:31 ERROR 	at web.MinimalRoutes$.$anonfun$5$$anonfun$1(WebServer.scala:62)[0m
2023.12.02 13:55:31 ERROR 	at cask.router.Result$Success.map(Result.scala:21)[0m
2023.12.02 13:55:31 ERROR 	at web.MinimalRoutes$.$anonfun$5(WebServer.scala:62)[0m
2023.12.02 13:55:31 ERROR 	at cask.router.EntryPoint.invoke(EntryPoint.scala:46)[0m
2023.12.02 13:55:31 ERROR 	at cask.router.Decorator$.invoke$$anonfun$2(Decorators.scala:58)[0m
2023.12.02 13:55:31 ERROR 	at cask.endpoints.WebEndpoint.wrapFunction(WebEndpoints.scala:14)[0m
2023.12.02 13:55:31 ERROR 	at cask.endpoints.WebEndpoint.wrapFunction$(WebEndpoints.scala:10)[0m
2023.12.02 13:55:31 ERROR 	at cask.endpoints.get.wrapFunction(WebEndpoints.scala:31)[0m
2023.12.02 13:55:31 ERROR 	at cask.router.Decorator$.invoke(Decorators.scala:59)[0m
2023.12.02 13:55:31 ERROR 	at cask.main.Main$DefaultHandler.handleRequest(Main.scala:115)[0m
2023.12.02 13:55:31 ERROR 	at io.undertow.server.Connectors.executeRootHandler(Connectors.java:387)[0m
2023.12.02 13:55:31 ERROR 	at io.undertow.server.HttpServerExchange$1.run(HttpServerExchange.java:852)[0m
2023.12.02 13:55:31 ERROR 	at org.jboss.threads.ContextClassLoaderSavingRunnable.run(ContextClassLoaderSavingRunnable.java:35)[0m
2023.12.02 13:55:31 ERROR 	at org.jboss.threads.EnhancedQueueExecutor.safeRun(EnhancedQueueExecutor.java:2019)[0m
2023.12.02 13:55:31 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.doRunTask(EnhancedQueueExecutor.java:1558)[0m
2023.12.02 13:55:31 ERROR 	at org.jboss.threads.EnhancedQueueExecutor$ThreadBody.run(EnhancedQueueExecutor.java:1449)[0m
2023.12.02 13:55:31 ERROR 	at org.xnio.XnioWorker$WorkerThreadFactory$1$1.run(XnioWorker.java:1282)[0m
2023.12.02 13:55:31 ERROR 	at java.base/java.lang.Thread.run(Thread.java:829)[0m
2023.12.02 14:43:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 14:43:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.02 14:43:41 INFO  Canceling debug proxy for [app.RoutesMain][0m
2023.12.02 14:43:41 INFO  Closing debug server tcp://0.0.0.0:40657[0m
2023.12.02 14:44:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 14:44:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.02 22:31:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:31:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.02 22:31:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:31:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 67ms[0m
2023.12.02 22:31:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:31:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.02 22:31:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:31:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 69ms[0m
2023.12.02 22:32:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:32:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.02 22:32:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:32:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 83ms[0m
2023.12.02 22:32:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:32:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.02 22:32:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:32:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.02 22:32:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:32:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 57ms[0m
2023.12.02 22:32:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:32:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.02 22:32:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:32:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.02 22:32:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:32:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.02 22:32:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:32:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.02 22:32:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:32:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 56ms[0m
2023.12.02 22:32:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:32:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.02 22:33:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:33:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.02 22:33:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:33:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.02 22:33:31 WARN  Using indexes to guess the definition of Session[0m
2023.12.02 22:33:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:33:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 56ms[0m
2023.12.02 22:33:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:33:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 55ms[0m
2023.12.02 22:33:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:33:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 56ms[0m
2023.12.02 22:33:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:33:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 54ms[0m
2023.12.02 22:33:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:33:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 52ms[0m
2023.12.02 22:34:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:34:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
23/12/02 22:34:17 WARN RemoteEndpoint: Unmatched cancel notification for request id 10108
2023.12.02 22:34:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:34:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 57ms[0m
2023.12.02 22:34:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:34:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.02 22:34:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:34:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.02 22:34:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:34:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.02 22:34:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:34:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.02 22:34:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:34:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:35:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:35:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:35:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:35:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.02 22:35:24 WARN  Attempt to organize your imports failed. It looks like you have compilation issues causing your semanticdb to be stale. Ensure everything is compiling and try again.[0m
2023.12.02 22:35:24 WARN  Attempt to organize your imports failed. It looks like you have compilation issues causing your semanticdb to be stale. Ensure everything is compiling and try again.[0m
2023.12.02 22:35:24 WARN  Attempt to organize your imports failed. It looks like you have compilation issues causing your semanticdb to be stale. Ensure everything is compiling and try again.[0m
2023.12.02 22:35:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:35:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.02 22:35:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:35:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:35:26 WARN  Attempt to organize your imports failed. It looks like you have compilation issues causing your semanticdb to be stale. Ensure everything is compiling and try again.[0m
2023.12.02 22:35:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:35:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.02 22:35:44 WARN  Using indexes to guess the definition of SparkJob[0m
2023.12.02 22:35:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:35:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:35:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:35:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:36:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:36:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.02 22:36:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:36:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.02 22:36:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:36:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:36:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:36:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:36:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:36:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.02 22:36:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:36:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.02 22:36:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:36:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.02 22:36:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:36:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.02 22:36:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:36:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.02 22:37:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:37:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:37:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:37:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.02 22:40:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:40:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.02 22:40:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:40:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 67ms[0m
2023.12.02 22:40:48 WARN  Using indexes to guess the definition of Session[0m
2023.12.02 22:40:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:40:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 69ms[0m
2023.12.02 22:40:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:40:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.02 22:41:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:41:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 68ms[0m
2023.12.02 22:41:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:41:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 66ms[0m
2023.12.02 22:41:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:41:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 68ms[0m
2023.12.02 22:42:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:42:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 68ms[0m
2023.12.02 22:42:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:42:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 68ms[0m
2023.12.02 22:42:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:42:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 75ms[0m
2023.12.02 22:42:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:42:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.02 22:42:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:42:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.02 22:42:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:42:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.02 22:42:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.02 22:42:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:42:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:42:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.17s[0m
2023.12.02 22:43:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:43:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
23/12/02 22:43:36 WARN RemoteEndpoint: Unmatched cancel notification for request id 10932
2023.12.02 22:43:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:43:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.12.02 22:43:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:43:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.38s[0m
2023.12.02 22:43:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:43:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:43:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:43:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.37s[0m
2023.12.02 22:43:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:43:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.02 22:45:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:45:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.45s[0m
2023.12.02 22:45:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:45:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:45:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:45:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.37s[0m
2023.12.02 22:45:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:45:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
2023.12.02 22:45:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.02 22:45:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.5s[0m
2023.12.02 22:45:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
23/12/02 22:45:17 WARN RemoteEndpoint: Unmatched cancel notification for request id 11042
2023.12.02 22:45:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:45:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.02 22:45:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.02 22:45:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.02 22:45:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:45:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.02 22:45:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:45:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.02 22:45:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.02 22:45:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.12.02 22:45:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.76s[0m
2023.12.02 22:45:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:45:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 78ms[0m
2023.12.02 22:45:52 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala[0m
2023.12.02 22:45:53 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala[0m
2023.12.02 22:45:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.02 22:45:54 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Ast.scala[0m
2023.12.02 22:45:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.45s[0m
2023.12.03 07:09:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:09:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.12.03 07:09:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:09:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 36ms[0m
2023.12.03 07:09:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:09:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:09:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:09:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 87ms[0m
2023.12.03 07:09:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:09:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 89ms[0m
2023.12.03 07:10:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:10:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 99ms[0m
2023.12.03 07:10:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:10:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 90ms[0m
2023.12.03 07:10:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:10:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 90ms[0m
2023.12.03 07:10:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:10:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 30ms[0m
2023.12.03 07:10:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:10:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.12.03 07:10:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:10:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 07:10:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:10:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.03 07:10:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:10:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 90ms[0m
2023.12.03 07:10:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:10:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 90ms[0m
2023.12.03 07:17:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:17:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:17:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:17:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 30ms[0m
2023.12.03 07:17:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:17:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 88ms[0m
2023.12.03 07:17:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:17:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 07:17:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:17:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:17:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:17:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 29ms[0m
2023.12.03 07:18:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 34ms[0m
2023.12.03 07:18:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 34ms[0m
2023.12.03 07:18:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 34ms[0m
2023.12.03 07:18:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 34ms[0m
2023.12.03 07:18:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 07:18:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 29ms[0m
2023.12.03 07:18:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:18:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 93ms[0m
2023.12.03 07:18:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:18:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 07:18:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 07:18:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:18:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:18:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 07:20:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:20:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:20:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:20:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 29ms[0m
2023.12.03 07:21:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 30ms[0m
2023.12.03 07:21:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 29ms[0m
2023.12.03 07:21:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 33ms[0m
2023.12.03 07:21:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:21:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 29ms[0m
2023.12.03 07:21:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:21:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 07:21:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:21:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 44ms[0m
2023.12.03 07:21:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 29ms[0m
2023.12.03 07:21:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 29ms[0m
2023.12.03 07:21:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:21:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:21:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:21:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 07:21:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.12.03 07:21:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:21:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 89ms[0m
2023.12.03 07:26:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:26:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 97ms[0m
2023.12.03 07:26:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:26:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 89ms[0m
2023.12.03 07:26:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:26:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.12.03 07:26:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:26:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.03 07:27:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:27:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 52ms[0m
2023.12.03 07:27:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:27:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.12.03 07:27:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:27:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.03 07:27:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:27:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 82ms[0m
2023.12.03 07:27:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:27:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.03 07:27:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:27:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 84ms[0m
2023.12.03 07:27:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:27:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.12.03 07:27:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:27:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.03 07:27:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:27:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 90ms[0m
2023.12.03 07:27:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:27:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.67s[0m
2023.12.03 07:29:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:29:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.1s[0m
2023.12.03 07:29:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:29:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.38s[0m
2023.12.03 07:29:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:29:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 89ms[0m
2023.12.03 07:29:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:29:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.03 07:29:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:29:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 82ms[0m
2023.12.03 07:29:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:29:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.03 07:29:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:29:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 49ms[0m
2023.12.03 07:29:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:29:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 88ms[0m
2023.12.03 07:29:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:29:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.75s[0m
2023.12.03 07:34:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:34:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 90ms[0m
2023.12.03 07:34:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:34:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.03 07:34:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:34:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 81ms[0m
2023.12.03 07:34:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:34:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.03 07:34:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:34:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 97ms[0m
2023.12.03 07:34:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:34:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.03 07:34:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:34:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 86ms[0m
2023.12.03 07:34:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:34:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.65s[0m
2023.12.03 07:35:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:35:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 94ms[0m
2023.12.03 07:35:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:35:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.12.03 07:35:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:35:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 89ms[0m
2023.12.03 07:35:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:35:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.12.03 07:35:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:35:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 07:36:01 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.03 07:36:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.27s[0m
2023.12.03 07:36:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:36:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 90ms[0m
2023.12.03 07:36:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:36:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 24ms[0m
2023.12.03 07:36:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:36:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
23/12/03 07:36:12 WARN RemoteEndpoint: Unmatched cancel notification for request id 12545
2023.12.03 07:36:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:36:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.03 07:36:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:36:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 56ms[0m
2023.12.03 07:36:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:36:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 56ms[0m
23/12/03 07:38:07 ERROR RemoteEndpoint: Internal error: java.lang.UnsupportedOperationException: tail of empty list
java.util.concurrent.CompletionException: java.lang.UnsupportedOperationException: tail of empty list
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.UnsupportedOperationException: tail of empty list
	at scala.collection.immutable.Nil$.tail(List.scala:664)
	at scala.collection.immutable.Nil$.tail(List.scala:661)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.$anonfun$endPosOfTree$1(CreateCompanionObjectCodeAction.scala:77)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.endPosOfTree(CreateCompanionObjectCodeAction.scala:75)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.$anonfun$contribute$5(CreateCompanionObjectCodeAction.scala:61)
	at scala.Option.map(Option.scala:242)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.$anonfun$contribute$4(CreateCompanionObjectCodeAction.scala:58)
	at scala.Option$WithFilter.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.$anonfun$contribute$2(CreateCompanionObjectCodeAction.scala:56)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.CreateCompanionObjectCodeAction.$anonfun$contribute$1(CreateCompanionObjectCodeAction.scala:55)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	... 3 more
2023.12.03 07:38:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:38:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 55ms[0m
2023.12.03 07:38:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:38:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.12.03 07:38:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 07:38:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.03 07:39:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:39:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 89ms[0m
2023.12.03 07:39:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:39:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 88ms[0m
2023.12.03 07:39:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:39:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 94ms[0m
2023.12.03 07:39:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:39:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 90ms[0m
2023.12.03 07:39:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:39:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 92ms[0m
2023.12.03 07:39:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:39:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.12.03 07:39:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:39:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.12.03 07:39:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:39:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 91ms[0m
2023.12.03 07:39:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:39:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.03 07:39:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:39:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 88ms[0m
2023.12.03 07:40:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:40:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 18ms[0m
2023.12.03 07:40:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:40:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 23ms[0m
2023.12.03 07:40:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:40:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 17ms[0m
2023.12.03 07:42:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:42:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.03 07:42:20 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:42:32 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:42:34 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:42:34 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:42:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:42:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.03 07:42:35 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:42:47 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:42:48 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:42:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:42:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.03 07:42:49 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:43:21 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:43:21 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:43:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:43:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.03 07:43:23 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:43:58 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:43:58 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:44:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:44:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.03 07:44:00 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/web/WebServer.scala[0m
2023.12.03 07:44:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:44:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 07:44:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:44:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.03 07:44:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:44:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.03 07:44:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:44:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.03 07:44:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:44:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.03 07:44:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:44:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:45:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:45:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.03 07:45:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:45:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.03 07:45:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:45:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.03 07:45:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:45:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.03 07:45:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:45:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.03 07:45:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:45:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:45:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:45:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:47:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 07:47:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.24s[0m
2023.12.03 07:49:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:49:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.03 07:49:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:49:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.03 07:49:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:49:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
23/12/03 07:49:23 WARN RemoteEndpoint: Unmatched cancel notification for request id 13444
2023.12.03 07:49:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:49:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 07:49:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:49:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 07:49:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:49:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:49:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:49:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.03 07:49:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:49:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.03 07:49:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:49:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.03 07:49:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:49:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.03 07:50:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:50:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.03 07:50:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:50:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.03 07:50:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:50:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.03 07:50:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:50:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.03 07:50:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:50:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.03 07:51:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:51:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.03 07:51:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:51:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.03 07:52:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:52:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.03 07:52:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:52:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:53:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:53:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.03 07:53:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:53:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.12.03 07:53:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:53:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 07:55:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:55:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:55:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:55:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:55:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:55:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:56:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:56:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:58:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:58:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.03 07:58:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:58:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 07:58:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:58:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 07:58:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:58:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:58:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:58:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:59:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:59:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:59:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:59:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.03 07:59:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:59:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 07:59:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:59:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:59:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:59:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 07:59:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 07:59:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 08:00:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:00:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 08:01:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:01:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.03 08:01:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:01:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.03 08:01:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:01:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 08:01:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:01:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 08:01:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:01:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 08:01:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:01:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 08:01:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:01:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 08:01:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:01:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 08:01:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:01:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.03 08:01:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:01:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.03 08:01:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:01:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.03 08:02:48 WARN  Using indexes to guess the definition of MyApp[0m
2023.12.03 08:02:49 WARN  Using indexes to guess the definition of MyApp[0m
2023.12.03 08:03:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:03:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.03 08:04:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:04:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.03 08:04:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:04:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.03 08:16:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:16:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.03 08:16:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:16:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.03 08:16:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 08:16:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.03 08:16:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.03 08:16:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.03 08:16:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 08:16:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.03 08:17:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (3 scala sources)[0m
2023.12.03 08:17:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.63s[0m
2023.12.03 08:19:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 88ms[0m
2023.12.03 08:19:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 29ms[0m
2023.12.03 08:19:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 29ms[0m
2023.12.03 08:19:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 08:19:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 08:19:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 08:19:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 31ms[0m
2023.12.03 08:19:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 31ms[0m
2023.12.03 08:19:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 08:19:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 08:19:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 08:19:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:19:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 08:20:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:20:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 08:20:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:20:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 30ms[0m
2023.12.03 08:20:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:20:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 08:20:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:20:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 29ms[0m
2023.12.03 08:20:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:20:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 08:20:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:20:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 08:20:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:20:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 31ms[0m
2023.12.03 08:20:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:20:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.03 08:20:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:20:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.03 08:21:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:21:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
23/12/03 08:21:36 WARN RemoteEndpoint: Unmatched cancel notification for request id 15111
2023.12.03 08:21:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:21:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 89ms[0m
2023.12.03 08:22:05 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (2 scala sources)[0m
2023.12.03 08:22:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.24s[0m
2023.12.03 08:22:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:22:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.03 08:22:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:22:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 90ms[0m
2023.12.03 08:24:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:24:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 08:24:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:24:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.03 08:24:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 08:24:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 89ms[0m
2023.12.03 22:01:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:01:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.03 22:01:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:01:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.12.03 22:01:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:01:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 22:01:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:01:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 22:01:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:01:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.03 22:01:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:01:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.03 22:01:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:01:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.03 22:01:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:01:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 22:02:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:02:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.12.03 22:02:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:02:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.12.03 22:02:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:02:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.12.03 22:03:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:03:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.03 22:03:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:03:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.03 22:03:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:03:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.03 22:03:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:03:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.03 22:03:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:03:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.03 22:03:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:03:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
23/12/03 22:03:54 ERROR CompilerAccess: A severe compiler error occurred, full details of the error can be found in the error report /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.reports/metals-full/2023-12-03/r_compiler-error_(project-effective-scala-c1-s14-3039-4085)_22-03-54-764.md
2023.12.03 22:07:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.03 22:07:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.03 22:09:38 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:35: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.03 22:09:39 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.03 22:09:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 42ms[0m
2023.12.03 22:09:38 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/app/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:35: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.12.03 22:09:45 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.03 22:09:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.21s[0m
2023.12.03 22:10:03 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.03 22:10:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.14s[0m
2023.12.03 22:10:08 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.03 22:10:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.15s[0m
2023.12.03 22:10:48 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.03 22:10:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.14s[0m
2023.12.03 22:10:53 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.03 22:10:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.13s[0m
2023.12.03 22:11:02 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.03 22:11:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.15s[0m
2023.12.03 22:11:04 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.03 22:11:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.14s[0m
2023.12.03 22:11:06 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.03 22:11:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.13s[0m
2023.12.03 22:11:57 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.03 22:11:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.15s[0m
2023.12.04 09:38:32 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:38:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.13s[0m
2023.12.04 09:39:09 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:39:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.13s[0m
2023.12.04 09:39:11 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:39:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.15s[0m
2023.12.04 09:39:14 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:39:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.14s[0m
2023.12.04 09:39:17 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:39:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.14s[0m
2023.12.04 09:39:29 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:39:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.26s[0m
2023.12.04 09:39:30 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:39:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.15s[0m
2023.12.04 09:39:32 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:39:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.14s[0m
2023.12.04 09:39:34 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:39:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.14s[0m
2023.12.04 09:39:40 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:39:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.14s[0m
2023.12.04 09:39:42 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:39:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.14s[0m
2023.12.04 09:40:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:40:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 20ms[0m
2023.12.04 09:40:56 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:40:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.17s[0m
2023.12.04 09:41:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:41:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 19ms[0m
2023.12.04 09:41:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:41:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 19ms[0m
2023.12.04 09:41:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:41:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 19ms[0m
2023.12.04 09:41:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:41:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 20ms[0m
2023.12.04 09:41:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:41:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 19ms[0m
2023.12.04 09:42:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:42:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 19ms[0m
2023.12.04 09:42:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:42:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 20ms[0m
2023.12.04 09:42:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:42:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 19ms[0m
2023.12.04 09:42:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:42:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 19ms[0m
2023.12.04 09:42:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:42:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 16ms[0m
2023.12.04 09:42:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:42:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 19ms[0m
2023.12.04 09:42:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:42:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 18ms[0m
2023.12.04 09:42:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:42:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 32ms[0m
2023.12.04 09:42:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:42:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 22ms[0m
2023.12.04 09:42:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:42:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 19ms[0m
2023.12.04 09:42:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:42:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.04 09:43:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:43:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.04 09:43:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:43:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 24ms[0m
2023.12.04 09:43:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:43:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 09:44:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:44:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.04 09:44:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:44:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 09:44:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:44:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 09:44:33 WARN  Using indexes to guess the definition of SparkJob[0m
2023.12.04 09:44:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:44:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 74ms[0m
2023.12.04 09:44:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:44:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 09:44:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:44:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 09:44:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:44:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 09:44:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:44:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 09:44:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:44:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 09:45:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:45:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 09:45:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:45:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 09:45:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:45:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 75ms[0m
2023.12.04 09:45:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:45:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 09:45:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:45:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 09:45:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:45:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.04 09:46:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:46:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 09:46:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 09:46:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.04 09:46:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:46:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 67ms[0m
2023.12.04 09:46:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:46:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 39ms[0m
2023.12.04 09:46:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:46:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 38ms[0m
2023.12.04 09:46:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:46:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 34ms[0m
2023.12.04 09:46:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:46:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 38ms[0m
2023.12.04 09:46:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:46:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 34ms[0m
2023.12.04 09:46:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:46:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 34ms[0m
2023.12.04 09:46:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:46:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 80ms[0m
2023.12.04 09:46:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:46:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 70ms[0m
2023.12.04 09:47:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:47:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 33ms[0m
2023.12.04 09:47:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:47:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 68ms[0m
2023.12.04 09:47:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:47:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 72ms[0m
2023.12.04 09:47:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:47:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 69ms[0m
2023.12.04 09:47:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:47:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 68ms[0m
2023.12.04 09:48:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:48:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 73ms[0m
2023.12.04 09:48:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:48:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 72ms[0m
2023.12.04 09:48:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:48:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 09:48:42 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/sparkjobs/SparkJob.scala[0m
2023.12.04 09:48:45 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/sparkjobs/SparkJob.scala[0m
2023.12.04 09:48:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:48:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 09:48:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:48:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.04 09:48:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:48:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.04 09:49:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:49:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.63s[0m
2023.12.04 09:49:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:49:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 66ms[0m
2023.12.04 09:49:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:49:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 55ms[0m
2023.12.04 09:49:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:49:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:50:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:50:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 22ms[0m
2023.12.04 09:50:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:50:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 71ms[0m
2023.12.04 09:50:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:50:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.04 09:50:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:50:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:50:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:50:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:51:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:51:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 09:51:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:51:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.04 09:51:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:51:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:51:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:51:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
23/12/04 09:51:30 WARN RemoteEndpoint: Unmatched cancel notification for request id 17436
23/12/04 09:51:32 WARN RemoteEndpoint: Unmatched cancel notification for request id 17441
2023.12.04 09:51:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:51:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:51:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:51:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:51:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:51:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 09:52:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:52:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.04 09:52:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:52:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:52:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:52:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 09:52:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:52:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:52:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:52:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:52:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:52:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.04 09:52:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:52:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:52:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:52:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:52:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:52:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:52:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:52:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.04 09:53:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:53:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.04 09:53:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:53:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:53:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:53:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:53:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:53:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:53:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:53:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:53:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:53:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:53:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:53:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 09:53:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:53:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 09:53:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:53:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.12.04 09:54:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:54:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 25ms[0m
2023.12.04 09:54:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:54:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 70ms[0m
2023.12.04 09:54:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:54:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 23ms[0m
2023.12.04 09:54:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:54:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 09:55:10 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:55:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.16s[0m
2023.12.04 09:55:17 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.12.04 09:55:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.13s[0m
23/12/04 09:55:41 WARN RemoteEndpoint: Unmatched cancel notification for request id 18017
2023.12.04 09:57:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:57:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 70ms[0m
2023.12.04 09:57:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:57:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 73ms[0m
2023.12.04 09:57:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:57:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 83ms[0m
2023.12.04 09:57:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 09:57:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.41s[0m
2023.12.04 10:01:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:01:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 67ms[0m
2023.12.04 10:01:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:01:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 25ms[0m
2023.12.04 10:02:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.04 10:02:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 80ms[0m
2023.12.04 10:02:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.04 10:02:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.04 10:02:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.04 10:02:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.04 10:02:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.04 10:02:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 25ms[0m
2023.12.04 10:02:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 27ms[0m
2023.12.04 10:02:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 30ms[0m
2023.12.04 10:02:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 25ms[0m
2023.12.04 10:02:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 24ms[0m
2023.12.04 10:02:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:02:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.04 10:03:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:03:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 30ms[0m
2023.12.04 10:03:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:03:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 72ms[0m
2023.12.04 10:03:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:03:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 75ms[0m
2023.12.04 10:03:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:03:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 73ms[0m
2023.12.04 10:03:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:03:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 72ms[0m
2023.12.04 10:03:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:03:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.04 10:03:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:03:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.04 10:03:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:03:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 78ms[0m
2023.12.04 10:03:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:03:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 26ms[0m
2023.12.04 10:05:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:05:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 32ms[0m
2023.12.04 10:05:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:05:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 28ms[0m
2023.12.04 10:07:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:07:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 76ms[0m
2023.12.04 10:07:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:07:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 78ms[0m
2023.12.04 10:07:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:07:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 73ms[0m
2023.12.04 10:07:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:07:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.04 10:07:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:07:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.12.04 10:07:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:07:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.04 10:08:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:08:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.04 10:10:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:10:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.04 10:10:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:10:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.04 10:10:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:10:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.04 10:10:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:10:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.04 10:10:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:10:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.04 10:10:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:10:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.04 10:10:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:10:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.12.04 10:11:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:11:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.04 10:11:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:11:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 84ms[0m
2023.12.04 10:12:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:12:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 73ms[0m
2023.12.04 10:12:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:12:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 73ms[0m
2023.12.04 10:12:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:12:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.04 10:12:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:12:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 69ms[0m
2023.12.04 10:12:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:12:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 77ms[0m
23/12/04 10:12:45 WARN RemoteEndpoint: Unmatched cancel notification for request id 19290
2023.12.04 10:12:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:12:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 79ms[0m
2023.12.04 10:12:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:12:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 10:12:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:12:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:12:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:12:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.04 10:13:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:13:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:13:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:13:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 10:14:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:14:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 10:14:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:14:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:14:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:14:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 10:14:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:14:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:14:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:14:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 57ms[0m
2023.12.04 10:14:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:14:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 10:14:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:14:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 10:15:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:15:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.04 10:15:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:15:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 10:15:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:15:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:15:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:15:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 10:15:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:15:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.25s[0m
2023.12.04 10:15:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:15:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.48s[0m
2023.12.04 10:16:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:16:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.48s[0m
2023.12.04 10:17:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:17:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:17:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:17:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:17:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:17:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 55ms[0m
2023.12.04 10:17:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:17:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 56ms[0m
2023.12.04 10:17:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:17:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 73ms[0m
2023.12.04 10:18:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:18:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.04 10:18:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:18:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.04 10:18:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:18:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:18:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:18:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:18:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:18:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 66ms[0m
2023.12.04 10:18:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:18:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 10:18:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:18:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 70ms[0m
2023.12.04 10:18:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:18:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.04 10:18:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:18:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 10:18:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:18:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 68ms[0m
2023.12.04 10:18:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:18:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 10:19:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:19:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.04 10:19:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:19:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 72ms[0m
2023.12.04 10:19:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:19:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:19:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:19:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:19:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:19:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:19:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:19:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:19:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:19:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 10:19:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:19:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 73ms[0m
2023.12.04 10:19:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:19:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 68ms[0m
2023.12.04 10:19:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:19:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 68ms[0m
2023.12.04 10:19:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:19:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.04 10:20:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:20:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 10:20:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:20:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.04 10:20:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:20:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.04 10:20:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:20:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 10:20:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:20:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 66ms[0m
2023.12.04 10:20:24 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:20:24 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:20:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:20:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 76ms[0m
2023.12.04 10:20:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:20:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.04 10:20:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:20:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:20:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:20:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:20:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:20:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:21:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:21:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.04 10:21:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:21:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 71ms[0m
2023.12.04 10:21:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:21:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:21:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:21:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 69ms[0m
2023.12.04 10:21:35 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:21:35 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.04 10:21:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:21:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 10:21:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:21:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:21:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:21:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:22:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:22:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 10:22:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:22:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.04 10:22:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:22:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:22:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:22:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:22:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
23/12/04 10:22:10 WARN RemoteEndpoint: Unmatched cancel notification for request id 20675
2023.12.04 10:22:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:22:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:22:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:29:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:29:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.12.04 10:29:58 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:29:58 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.12.04 10:30:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:30:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:30:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:30:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.04 10:30:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:30:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.04 10:30:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:30:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 68ms[0m
2023.12.04 10:31:51 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:31:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.04 10:32:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:32:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:32:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:32:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:32:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:32:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:32:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:32:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.04 10:32:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:32:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 66ms[0m
2023.12.04 10:32:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:32:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 72ms[0m
2023.12.04 10:32:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:32:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 10:33:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:33:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 74ms[0m
2023.12.04 10:33:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:33:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:33:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:33:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 71ms[0m
2023.12.04 10:33:50 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:33:50 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.04 10:35:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:35:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:35:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:35:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 67ms[0m
23/12/04 10:35:22 WARN RemoteEndpoint: Unmatched cancel notification for request id 21146
2023.12.04 10:35:28 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:35:28 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.04 10:35:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:35:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:36:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:36:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 10:36:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:36:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 72ms[0m
2023.12.04 10:36:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:36:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.51s[0m
2023.12.04 10:36:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:36:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:36:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:36:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.04 10:36:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:36:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 57ms[0m
2023.12.04 10:36:57 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:36:57 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 58ms[0m
2023.12.04 10:36:59 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:36:59 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:37:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:37:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 68ms[0m
2023.12.04 10:37:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:37:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 77ms[0m
2023.12.04 10:37:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:37:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.12.04 10:37:36 WARN  Using indexes to guess the definition of DataFramesExemples[0m
2023.12.04 10:37:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:37:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 56ms[0m
2023.12.04 10:37:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:37:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 57ms[0m
2023.12.04 10:38:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:38:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:38:20 WARN  Using indexes to guess the definition of runMakeExpression0[0m
2023.12.04 10:38:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:38:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:38:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:38:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 62ms[0m
2023.12.04 10:38:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:38:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 72ms[0m
2023.12.04 10:38:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:38:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 59ms[0m
2023.12.04 10:38:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:38:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.04 10:38:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:38:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:38:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:38:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
23/12/04 10:38:45 WARN RemoteEndpoint: Unmatched cancel notification for request id 21575
2023.12.04 10:38:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:38:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.04 10:39:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:39:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:39:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:39:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:39:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:39:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:39:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:39:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.26s[0m
2023.12.04 10:39:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:39:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:39:25 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:39:25 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:40:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:40:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 74ms[0m
2023.12.04 10:40:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:40:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.04 10:40:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:40:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 70ms[0m
2023.12.04 10:40:44 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:40:44 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 77ms[0m
2023.12.04 10:40:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:40:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:40:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:40:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:41:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.04 10:41:17 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:17 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 63ms[0m
2023.12.04 10:41:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 60ms[0m
2023.12.04 10:41:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:41:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.04 10:41:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:41:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.04 10:41:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:41:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.04 10:41:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:41:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.04 10:41:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:41:42 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:42 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.04 10:41:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:41:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.04 10:41:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:41:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
23/12/04 10:41:46 WARN RemoteEndpoint: Unmatched cancel notification for request id 21910
23/12/04 10:41:46 WARN RemoteEndpoint: Unmatched cancel notification for request id 21911
2023.12.04 10:41:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:41:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.04 10:41:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:41:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:41:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:41:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:41:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:41:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:41:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:41:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:41:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:41:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.04 10:42:02 WARN  Attempt to organize your imports failed. It looks like you have compilation issues causing your semanticdb to be stale. Ensure everything is compiling and try again.[0m
2023.12.04 10:42:02 WARN  Attempt to organize your imports failed. It looks like you have compilation issues causing your semanticdb to be stale. Ensure everything is compiling and try again.[0m
2023.12.04 10:42:03 WARN  Attempt to organize your imports failed. It looks like you have compilation issues causing your semanticdb to be stale. Ensure everything is compiling and try again.[0m
2023.12.04 10:42:04 WARN  Attempt to organize your imports failed. It looks like you have compilation issues causing your semanticdb to be stale. Ensure everything is compiling and try again.[0m
2023.12.04 10:42:05 ERROR /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:159)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
23/12/04 10:42:05 ERROR RemoteEndpoint: Internal error: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
java.util.concurrent.CompletionException: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:159)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
2023.12.04 10:42:05 ERROR /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:159)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
23/12/04 10:42:05 ERROR RemoteEndpoint: Internal error: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
java.util.concurrent.CompletionException: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: scala.meta.internal.metals.ScalafixProvider$ScalafixRunException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/.tmp/src/main/scala/sparkjobs/DataframesAndExpressions.scala:6: error: identifier expected but , found
import org.apache.spark.sql.{, Dataset, Row, DataFrame}
                             ^
	at scala.meta.internal.metals.ScalafixProvider.$anonfun$runScalafixRules$1(ScalafixProvider.scala:159)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:470)
	... 3 more
2023.12.04 10:42:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:42:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 67ms[0m
2023.12.04 10:42:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:42:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 66ms[0m
2023.12.04 10:42:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:42:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 70ms[0m
2023.12.04 10:42:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:42:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 61ms[0m
2023.12.04 10:42:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:42:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:42:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:42:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.12.04 10:42:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:42:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:42:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:42:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.04 10:43:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:43:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.04 10:43:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:43:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.04 10:43:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:43:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:43:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:43:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.04 10:43:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:43:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:43:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:43:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.04 10:43:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:43:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:43:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:43:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.04 10:43:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:43:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:43:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:43:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.04 10:43:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:43:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:43:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:43:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:43:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:43:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:43:53 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:43:53 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.12.04 10:43:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:43:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:43:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:43:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.04 10:44:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:44:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:44:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:44:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.04 10:44:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:44:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:44:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:44:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.04 10:44:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:44:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:44:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:44:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.04 10:44:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:44:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:44:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:44:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.04 10:44:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:44:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:44:55 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:44:55 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:45:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:45:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:45:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:45:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.04 10:45:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:45:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:45:29 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:45:29 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:45:36 WARN  Using indexes to guess the definition of DataFramesExemples[0m
2023.12.04 10:45:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:45:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:45:37 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:45:37 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.04 10:45:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:45:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.04 10:45:43 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:45:43 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:45:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:45:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.12.04 10:45:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:45:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:45:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:45:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:45:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:45:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:45:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:45:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:45:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:45:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.04 10:45:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:45:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.04 10:46:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:46:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 86ms[0m
2023.12.04 10:46:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:46:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 78ms[0m
2023.12.04 10:46:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:46:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:46:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:46:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.12.04 10:46:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:46:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:46:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:46:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.04 10:46:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:46:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.12.04 10:46:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:46:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.12.04 10:46:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:46:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
2023.12.04 10:46:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:46:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
2023.12.04 10:47:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:47:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:47:26 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:47:26 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.04 10:47:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:47:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:47:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:47:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.12.04 10:47:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.12.04 10:47:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.12.04 10:47:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.12.04 10:47:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.12.04 10:48:46 INFO  Disconnecting from Bloop session...[0m
2023.12.04 10:48:46 INFO  Shut down connection with build server.[0m
2023.12.04 10:48:46 INFO  Shut down connection with build server.[0m
2023.12.04 10:48:46 INFO  Deleted directories inside .bloop[0m
2023.12.04 10:48:46 INFO  Attempting to connect to the build server...[0m
2023.12.04 10:48:46 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.04 10:48:47 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.04 10:48:47 INFO  Attempting to connect to the build server...[0m
2023.12.04 10:48:47 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.12.04 10:48:47 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.12.04 10:48:47 INFO  time: Connected to build server in 1.12s[0m
2023.12.04 10:48:47 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.12.04 10:48:48 INFO  time: indexed workspace in 1.19s[0m
2023.12.04 10:48:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.12.04 10:48:51 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 2.79s[0m
2023.12.04 10:50:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (7 scala sources)[0m
2023.12.04 10:50:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 4.24s[0m
