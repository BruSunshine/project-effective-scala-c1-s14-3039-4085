2023.11.27 14:29:55 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.27 14:29:56 INFO  Attempting to connect to the build server...[0m
2023.11.27 14:29:56 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.27 14:29:56 INFO  skipping build import with status 'Installed'[0m
2023.11.27 14:29:56 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.27 14:29:56 INFO  Attempting to connect to the build server...[0m
2023.11.27 14:29:56 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.27 14:29:56 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.27 14:29:56 INFO  time: Connected to build server in 0.39s[0m
2023.11.27 14:29:56 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.27 14:29:58 INFO  no build target found for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala. Using presentation compiler with project's scala-library version: 3.3.1[0m
2023.11.27 14:30:00 INFO  time: indexed workspace in 1.88s[0m
2023.11.27 14:30:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:30:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 1.18s[0m
2023.11.27 14:30:01 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:30:01 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:30:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:30:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.11.27 14:30:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:30:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.24s[0m
2023.11.27 14:30:02 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:30:08 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:30:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:30:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.27 14:30:12 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:30:15 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:30:15 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.11.27 14:30:15 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
23/11/27 14:30:15 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/11/27 14:30:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/11/27 14:30:15 INFO SparkContext: Running Spark version 3.5.0
23/11/27 14:30:15 INFO SparkContext: OS info Linux, 6.2.0-36-generic, amd64
23/11/27 14:30:15 INFO SparkContext: Java version 11.0.20
23/11/27 14:30:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/11/27 14:30:16 INFO ResourceUtils: ==============================================================
23/11/27 14:30:16 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/27 14:30:16 INFO ResourceUtils: ==============================================================
23/11/27 14:30:16 INFO SparkContext: Submitted application: Spark Parquet Example
23/11/27 14:30:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/27 14:30:16 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
23/11/27 14:30:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/27 14:30:16 INFO SecurityManager: Changing view acls to: bsoleille
23/11/27 14:30:16 INFO SecurityManager: Changing modify acls to: bsoleille
23/11/27 14:30:16 INFO SecurityManager: Changing view acls groups to: 
23/11/27 14:30:16 INFO SecurityManager: Changing modify acls groups to: 
23/11/27 14:30:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/11/27 14:30:16 INFO Utils: Successfully started service 'sparkDriver' on port 41949.
23/11/27 14:30:16 INFO SparkEnv: Registering MapOutputTracker
23/11/27 14:30:16 INFO SparkEnv: Registering BlockManagerMaster
23/11/27 14:30:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/27 14:30:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/27 14:30:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/27 14:30:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9ec55810-1f66-4dd1-8e1e-c25671fd7cbf
23/11/27 14:30:16 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/27 14:30:16 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/27 14:30:16 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/11/27 14:30:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/11/27 14:30:16 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/11/27 14:30:16 INFO Executor: OS info Linux, 6.2.0-36-generic, amd64
23/11/27 14:30:16 INFO Executor: Java version 11.0.20
23/11/27 14:30:16 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/11/27 14:30:16 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@80df82b for default.
23/11/27 14:30:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44455.
23/11/27 14:30:16 INFO NettyBlockTransferService: Server created on 10.25.86.80:44455
23/11/27 14:30:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/27 14:30:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 44455, None)
23/11/27 14:30:16 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:44455 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 44455, None)
23/11/27 14:30:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 44455, None)
23/11/27 14:30:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 44455, None)
23/11/27 14:30:17 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/11/27 14:30:17 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/11/27 14:30:18 INFO CodeGenerator: Code generated in 108.873334 ms
23/11/27 14:30:18 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 14:30:18 INFO DAGScheduler: Got job 0 (show at SparkTest.worksheet.sc:68) with 1 output partitions
23/11/27 14:30:18 INFO DAGScheduler: Final stage: ResultStage 0 (show at SparkTest.worksheet.sc:68)
23/11/27 14:30:18 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:18 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:18 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 14:30:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
23/11/27 14:30:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/11/27 14:30:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:44455 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 14:30:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(0))
23/11/27 14:30:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/11/27 14:30:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/11/27 14:30:18 INFO CodeGenerator: Code generated in 8.991488 ms
23/11/27 14:30:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1584 bytes result sent to driver
23/11/27 14:30:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 109 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 14:30:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/11/27 14:30:18 INFO DAGScheduler: ResultStage 0 (show at SparkTest.worksheet.sc:68) finished in 0.233 s
23/11/27 14:30:18 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/11/27 14:30:18 INFO DAGScheduler: Job 0 finished: show at SparkTest.worksheet.sc:68, took 0.256022 s
23/11/27 14:30:18 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 14:30:18 INFO DAGScheduler: Got job 1 (show at SparkTest.worksheet.sc:68) with 4 output partitions
23/11/27 14:30:18 INFO DAGScheduler: Final stage: ResultStage 1 (show at SparkTest.worksheet.sc:68)
23/11/27 14:30:18 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:18 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:18 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 14:30:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
23/11/27 14:30:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/11/27 14:30:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.25.86.80:44455 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 14:30:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:18 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 14:30:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0
23/11/27 14:30:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:18 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7948 bytes) 
23/11/27 14:30:18 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/11/27 14:30:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
23/11/27 14:30:18 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
23/11/27 14:30:18 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
23/11/27 14:30:18 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1498 bytes result sent to driver
23/11/27 14:30:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1498 bytes result sent to driver
23/11/27 14:30:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1498 bytes result sent to driver
23/11/27 14:30:18 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 10 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 14:30:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 12 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 14:30:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 13 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 14:30:19 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.25.86.80:44455 in memory (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 14:30:19 INFO CodeGenerator: Code generated in 24.977339 ms
23/11/27 14:30:19 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1591 bytes result sent to driver
23/11/27 14:30:19 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 554 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 14:30:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/11/27 14:30:19 INFO DAGScheduler: ResultStage 1 (show at SparkTest.worksheet.sc:68) finished in 0.562 s
23/11/27 14:30:19 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/11/27 14:30:19 INFO DAGScheduler: Job 1 finished: show at SparkTest.worksheet.sc:68, took 0.563839 s
23/11/27 14:30:19 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 14:30:19 INFO DAGScheduler: Got job 2 (show at SparkTest.worksheet.sc:68) with 11 output partitions
23/11/27 14:30:19 INFO DAGScheduler: Final stage: ResultStage 2 (show at SparkTest.worksheet.sc:68)
23/11/27 14:30:19 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:19 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 14:30:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
23/11/27 14:30:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/11/27 14:30:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.25.86.80:44455 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 14:30:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:19 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15))
23/11/27 14:30:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 11 tasks resource profile 0
23/11/27 14:30:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7948 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 9) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 10) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 11) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 12) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 13) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 14) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 15) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
23/11/27 14:30:19 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)
23/11/27 14:30:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
23/11/27 14:30:19 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
23/11/27 14:30:19 INFO Executor: Running task 4.0 in stage 2.0 (TID 9)
23/11/27 14:30:19 INFO Executor: Running task 5.0 in stage 2.0 (TID 10)
23/11/27 14:30:19 INFO Executor: Running task 6.0 in stage 2.0 (TID 11)
23/11/27 14:30:19 INFO Executor: Running task 7.0 in stage 2.0 (TID 12)
23/11/27 14:30:19 INFO Executor: Running task 10.0 in stage 2.0 (TID 15)
23/11/27 14:30:19 INFO Executor: Running task 8.0 in stage 2.0 (TID 13)
23/11/27 14:30:19 INFO Executor: Running task 9.0 in stage 2.0 (TID 14)
23/11/27 14:30:19 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1584 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 5.0 in stage 2.0 (TID 10). 1541 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1584 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 6.0 in stage 2.0 (TID 11). 1541 bytes result sent to driver
23/11/27 14:30:19 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 20 ms on 10.25.86.80 (executor driver) (1/11)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 10) in 20 ms on 10.25.86.80 (executor driver) (2/11)
23/11/27 14:30:19 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.25.86.80:44455 in memory (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 14:30:19 INFO Executor: Finished task 8.0 in stage 2.0 (TID 13). 1584 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 3.0 in stage 2.0 (TID 8). 1584 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 9.0 in stage 2.0 (TID 14). 1584 bytes result sent to driver
23/11/27 14:30:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 22 ms on 10.25.86.80 (executor driver) (3/11)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 22 ms on 10.25.86.80 (executor driver) (4/11)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 11) in 21 ms on 10.25.86.80 (executor driver) (5/11)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 14) in 21 ms on 10.25.86.80 (executor driver) (6/11)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 13) in 22 ms on 10.25.86.80 (executor driver) (7/11)
23/11/27 14:30:19 INFO Executor: Finished task 4.0 in stage 2.0 (TID 9). 1591 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 7.0 in stage 2.0 (TID 12). 1591 bytes result sent to driver
23/11/27 14:30:19 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 9) in 26 ms on 10.25.86.80 (executor driver) (8/11)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 12) in 26 ms on 10.25.86.80 (executor driver) (9/11)
23/11/27 14:30:19 INFO Executor: Finished task 10.0 in stage 2.0 (TID 15). 1591 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1591 bytes result sent to driver
23/11/27 14:30:19 INFO TaskSetManager: Finished task 10.0 in stage 2.0 (TID 15) in 25 ms on 10.25.86.80 (executor driver) (10/11)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 28 ms on 10.25.86.80 (executor driver) (11/11)
23/11/27 14:30:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/11/27 14:30:19 INFO DAGScheduler: ResultStage 2 (show at SparkTest.worksheet.sc:68) finished in 0.034 s
23/11/27 14:30:19 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/11/27 14:30:19 INFO DAGScheduler: Job 2 finished: show at SparkTest.worksheet.sc:68, took 0.036500 s
23/11/27 14:30:19 INFO CodeGenerator: Code generated in 8.496507 ms
23/11/27 14:30:19 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO CodeGenerator: Code generated in 6.128519 ms
23/11/27 14:30:19 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:78
23/11/27 14:30:19 INFO DAGScheduler: Got job 3 (parquet at SparkTest.worksheet.sc:78) with 16 output partitions
23/11/27 14:30:19 INFO DAGScheduler: Final stage: ResultStage 3 (parquet at SparkTest.worksheet.sc:78)
23/11/27 14:30:19 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:19 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:19 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:78), which has no missing parents
23/11/27 14:30:19 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 214.5 KiB, free 434.2 MiB)
23/11/27 14:30:19 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 76.8 KiB, free 434.1 MiB)
23/11/27 14:30:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.25.86.80:44455 (size: 76.8 KiB, free: 434.3 MiB)
23/11/27 14:30:19 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:19 INFO DAGScheduler: Submitting 16 missing tasks from ResultStage 3 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
23/11/27 14:30:19 INFO TaskSchedulerImpl: Adding task set 3.0 with 16 tasks resource profile 0
23/11/27 14:30:19 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 16) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 17) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 18) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 19) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 20) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 21) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 22) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 23) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 24) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 25) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7948 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 26) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 27) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 28) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 29) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 30) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:19 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 31) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:19 INFO Executor: Running task 0.0 in stage 3.0 (TID 16)
23/11/27 14:30:19 INFO Executor: Running task 4.0 in stage 3.0 (TID 20)
23/11/27 14:30:19 INFO Executor: Running task 9.0 in stage 3.0 (TID 25)
23/11/27 14:30:19 INFO Executor: Running task 10.0 in stage 3.0 (TID 26)
23/11/27 14:30:19 INFO Executor: Running task 6.0 in stage 3.0 (TID 22)
23/11/27 14:30:19 INFO Executor: Running task 3.0 in stage 3.0 (TID 19)
23/11/27 14:30:19 INFO Executor: Running task 5.0 in stage 3.0 (TID 21)
23/11/27 14:30:19 INFO Executor: Running task 1.0 in stage 3.0 (TID 17)
23/11/27 14:30:19 INFO Executor: Running task 7.0 in stage 3.0 (TID 23)
23/11/27 14:30:19 INFO Executor: Running task 2.0 in stage 3.0 (TID 18)
23/11/27 14:30:19 INFO Executor: Running task 8.0 in stage 3.0 (TID 24)
23/11/27 14:30:19 INFO Executor: Running task 12.0 in stage 3.0 (TID 28)
23/11/27 14:30:19 INFO Executor: Running task 11.0 in stage 3.0 (TID 27)
23/11/27 14:30:19 INFO Executor: Running task 13.0 in stage 3.0 (TID 29)
23/11/27 14:30:19 INFO Executor: Running task 14.0 in stage 3.0 (TID 30)
23/11/27 14:30:19 INFO Executor: Running task 15.0 in stage 3.0 (TID 31)
23/11/27 14:30:19 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.25.86.80:44455 in memory (size: 6.2 KiB, free: 434.3 MiB)
23/11/27 14:30:19 INFO CodeGenerator: Code generated in 10.005531 ms
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 14:30:19 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 14:30:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271430194171268368723483094_0003_m_000002_18
23/11/27 14:30:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271430194171268368723483094_0003_m_000010_26
23/11/27 14:30:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271430194171268368723483094_0003_m_000007_23
23/11/27 14:30:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271430194171268368723483094_0003_m_000008_24
23/11/27 14:30:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271430194171268368723483094_0003_m_000013_29
23/11/27 14:30:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271430194171268368723483094_0003_m_000005_21
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271430194171268368723483094_0003_m_000011_27
23/11/27 14:30:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271430194171268368723483094_0003_m_000014_30
23/11/27 14:30:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271430194171268368723483094_0003_m_000004_20
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271430194171268368723483094_0003_m_000001_17
23/11/27 14:30:19 INFO Executor: Finished task 8.0 in stage 3.0 (TID 24). 2699 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 4.0 in stage 3.0 (TID 20). 2699 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 14.0 in stage 3.0 (TID 30). 2699 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 7.0 in stage 3.0 (TID 23). 2699 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 5.0 in stage 3.0 (TID 21). 2699 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 13.0 in stage 3.0 (TID 29). 2699 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 2.0 in stage 3.0 (TID 18). 2699 bytes result sent to driver
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO Executor: Finished task 11.0 in stage 3.0 (TID 27). 2699 bytes result sent to driver
23/11/27 14:30:19 INFO Executor: Finished task 1.0 in stage 3.0 (TID 17). 2699 bytes result sent to driver
23/11/27 14:30:19 INFO CodecConfig: Compression: SNAPPY
23/11/27 14:30:19 INFO Executor: Finished task 10.0 in stage 3.0 (TID 26). 2699 bytes result sent to driver
23/11/27 14:30:19 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 24) in 127 ms on 10.25.86.80 (executor driver) (1/16)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 23) in 127 ms on 10.25.86.80 (executor driver) (2/16)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 30) in 126 ms on 10.25.86.80 (executor driver) (3/16)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 21) in 129 ms on 10.25.86.80 (executor driver) (4/16)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 20) in 129 ms on 10.25.86.80 (executor driver) (5/16)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 18) in 129 ms on 10.25.86.80 (executor driver) (6/16)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 27) in 128 ms on 10.25.86.80 (executor driver) (7/16)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 29) in 127 ms on 10.25.86.80 (executor driver) (8/16)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 17) in 131 ms on 10.25.86.80 (executor driver) (9/16)
23/11/27 14:30:19 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 26) in 129 ms on 10.25.86.80 (executor driver) (10/16)
23/11/27 14:30:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 14:30:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 14:30:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 14:30:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 14:30:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 14:30:19 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 14:30:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 14:30:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 14:30:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 14:30:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 14:30:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 14:30:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 14:30:20 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 14:30:20 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 14:30:20 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 14:30:20 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 14:30:20 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 14:30:20 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 14:30:20 INFO FileOutputCommitter: Saved output of task 'attempt_202311271430194171268368723483094_0003_m_000000_16' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271430194171268368723483094_0003_m_000000
23/11/27 14:30:20 INFO FileOutputCommitter: Saved output of task 'attempt_202311271430194171268368723483094_0003_m_000003_19' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271430194171268368723483094_0003_m_000003
23/11/27 14:30:20 INFO FileOutputCommitter: Saved output of task 'attempt_202311271430194171268368723483094_0003_m_000012_28' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271430194171268368723483094_0003_m_000012
23/11/27 14:30:20 INFO FileOutputCommitter: Saved output of task 'attempt_202311271430194171268368723483094_0003_m_000009_25' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271430194171268368723483094_0003_m_000009
23/11/27 14:30:20 INFO FileOutputCommitter: Saved output of task 'attempt_202311271430194171268368723483094_0003_m_000006_22' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271430194171268368723483094_0003_m_000006
23/11/27 14:30:20 INFO SparkHadoopMapRedUtil: attempt_202311271430194171268368723483094_0003_m_000006_22: Committed. Elapsed time: 0 ms.
23/11/27 14:30:20 INFO SparkHadoopMapRedUtil: attempt_202311271430194171268368723483094_0003_m_000003_19: Committed. Elapsed time: 0 ms.
23/11/27 14:30:20 INFO SparkHadoopMapRedUtil: attempt_202311271430194171268368723483094_0003_m_000009_25: Committed. Elapsed time: 0 ms.
23/11/27 14:30:20 INFO SparkHadoopMapRedUtil: attempt_202311271430194171268368723483094_0003_m_000000_16: Committed. Elapsed time: 0 ms.
23/11/27 14:30:20 INFO SparkHadoopMapRedUtil: attempt_202311271430194171268368723483094_0003_m_000012_28: Committed. Elapsed time: 0 ms.
23/11/27 14:30:20 INFO FileOutputCommitter: Saved output of task 'attempt_202311271430194171268368723483094_0003_m_000015_31' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271430194171268368723483094_0003_m_000015
23/11/27 14:30:20 INFO SparkHadoopMapRedUtil: attempt_202311271430194171268368723483094_0003_m_000015_31: Committed. Elapsed time: 0 ms.
23/11/27 14:30:20 INFO Executor: Finished task 9.0 in stage 3.0 (TID 25). 2742 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 12.0 in stage 3.0 (TID 28). 2742 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 15.0 in stage 3.0 (TID 31). 2742 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 6.0 in stage 3.0 (TID 22). 2742 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 3.0 in stage 3.0 (TID 19). 2742 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 0.0 in stage 3.0 (TID 16). 2699 bytes result sent to driver
23/11/27 14:30:20 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 25) in 533 ms on 10.25.86.80 (executor driver) (11/16)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 22) in 533 ms on 10.25.86.80 (executor driver) (12/16)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 31) in 532 ms on 10.25.86.80 (executor driver) (13/16)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 28) in 532 ms on 10.25.86.80 (executor driver) (14/16)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 16) in 535 ms on 10.25.86.80 (executor driver) (15/16)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 19) in 535 ms on 10.25.86.80 (executor driver) (16/16)
23/11/27 14:30:20 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/11/27 14:30:20 INFO DAGScheduler: ResultStage 3 (parquet at SparkTest.worksheet.sc:78) finished in 0.578 s
23/11/27 14:30:20 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
23/11/27 14:30:20 INFO DAGScheduler: Job 3 finished: parquet at SparkTest.worksheet.sc:78, took 0.581347 s
23/11/27 14:30:20 INFO FileFormatWriter: Start to commit write Job 901551dc-1094-4069-895f-7e985cd18bb7.
23/11/27 14:30:20 INFO FileFormatWriter: Write Job 901551dc-1094-4069-895f-7e985cd18bb7 committed. Elapsed time: 12 ms.
23/11/27 14:30:20 INFO FileFormatWriter: Finished processing stats for write job 901551dc-1094-4069-895f-7e985cd18bb7.
23/11/27 14:30:20 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
23/11/27 14:30:20 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:82
23/11/27 14:30:20 INFO DAGScheduler: Got job 4 (parquet at SparkTest.worksheet.sc:82) with 1 output partitions
23/11/27 14:30:20 INFO DAGScheduler: Final stage: ResultStage 4 (parquet at SparkTest.worksheet.sc:82)
23/11/27 14:30:20 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:20 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:20 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:82), which has no missing parents
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/11/27 14:30:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.25.86.80:44455 (size: 36.9 KiB, free: 434.3 MiB)
23/11/27 14:30:20 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:82) (first 15 tasks are for partitions Vector(0))
23/11/27 14:30:20 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
23/11/27 14:30:20 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 32) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/11/27 14:30:20 INFO Executor: Running task 0.0 in stage 4.0 (TID 32)
23/11/27 14:30:20 INFO Executor: Finished task 0.0 in stage 4.0 (TID 32). 2006 bytes result sent to driver
23/11/27 14:30:20 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 32) in 36 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 14:30:20 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/11/27 14:30:20 INFO DAGScheduler: ResultStage 4 (parquet at SparkTest.worksheet.sc:82) finished in 0.053 s
23/11/27 14:30:20 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
23/11/27 14:30:20 INFO DAGScheduler: Job 4 finished: parquet at SparkTest.worksheet.sc:82, took 0.082416 s
23/11/27 14:30:20 INFO FileSourceStrategy: Pushed Filters: 
23/11/27 14:30:20 INFO FileSourceStrategy: Post-Scan Filters: 
23/11/27 14:30:20 INFO CodeGenerator: Code generated in 18.870655 ms
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 200.7 KiB, free 433.8 MiB)
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
23/11/27 14:30:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.25.86.80:44455 (size: 34.9 KiB, free: 434.3 MiB)
23/11/27 14:30:20 INFO SparkContext: Created broadcast 5 from show at SparkTest.worksheet.sc:87
23/11/27 14:30:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/11/27 14:30:20 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 14:30:20 INFO DAGScheduler: Got job 5 (show at SparkTest.worksheet.sc:87) with 1 output partitions
23/11/27 14:30:20 INFO DAGScheduler: Final stage: ResultStage 5 (show at SparkTest.worksheet.sc:87)
23/11/27 14:30:20 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:20 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:20 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 15.9 KiB, free 433.7 MiB)
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.7 MiB)
23/11/27 14:30:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.25.86.80:44455 (size: 6.7 KiB, free: 434.2 MiB)
23/11/27 14:30:20 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(0))
23/11/27 14:30:20 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
23/11/27 14:30:20 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 33) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/11/27 14:30:20 INFO Executor: Running task 0.0 in stage 5.0 (TID 33)
23/11/27 14:30:20 INFO CodeGenerator: Code generated in 9.116827 ms
23/11/27 14:30:20 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00003-402d6f92-4956-4d09-84a2-1d60d044ad5d-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 14:30:20 INFO CodecPool: Got brand-new decompressor [.snappy]
23/11/27 14:30:20 INFO Executor: Finished task 0.0 in stage 5.0 (TID 33). 1842 bytes result sent to driver
23/11/27 14:30:20 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 33) in 76 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 14:30:20 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
23/11/27 14:30:20 INFO DAGScheduler: ResultStage 5 (show at SparkTest.worksheet.sc:87) finished in 0.093 s
23/11/27 14:30:20 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
23/11/27 14:30:20 INFO DAGScheduler: Job 5 finished: show at SparkTest.worksheet.sc:87, took 0.097406 s
23/11/27 14:30:20 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 14:30:20 INFO DAGScheduler: Got job 6 (show at SparkTest.worksheet.sc:87) with 4 output partitions
23/11/27 14:30:20 INFO DAGScheduler: Final stage: ResultStage 6 (show at SparkTest.worksheet.sc:87)
23/11/27 14:30:20 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:20 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:20 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 15.9 KiB, free 433.7 MiB)
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.7 MiB)
23/11/27 14:30:20 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.25.86.80:44455 (size: 6.7 KiB, free: 434.2 MiB)
23/11/27 14:30:20 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 14:30:20 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks resource profile 0
23/11/27 14:30:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 34) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 8419 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 35) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 8419 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 36) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 8419 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 37) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 8419 bytes) 
23/11/27 14:30:20 INFO Executor: Running task 0.0 in stage 6.0 (TID 34)
23/11/27 14:30:20 INFO Executor: Running task 2.0 in stage 6.0 (TID 36)
23/11/27 14:30:20 INFO Executor: Running task 3.0 in stage 6.0 (TID 37)
23/11/27 14:30:20 INFO Executor: Running task 1.0 in stage 6.0 (TID 35)
23/11/27 14:30:20 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00015-402d6f92-4956-4d09-84a2-1d60d044ad5d-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 14:30:20 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00009-402d6f92-4956-4d09-84a2-1d60d044ad5d-c000.snappy.parquet, range: 0-957, partition values: [empty row]
23/11/27 14:30:20 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00012-402d6f92-4956-4d09-84a2-1d60d044ad5d-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 14:30:20 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00006-402d6f92-4956-4d09-84a2-1d60d044ad5d-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 14:30:20 INFO CodecPool: Got brand-new decompressor [.snappy]
23/11/27 14:30:20 INFO CodecPool: Got brand-new decompressor [.snappy]
23/11/27 14:30:20 INFO CodecPool: Got brand-new decompressor [.snappy]
23/11/27 14:30:20 INFO Executor: Finished task 3.0 in stage 6.0 (TID 37). 1842 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 1.0 in stage 6.0 (TID 35). 1842 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 0.0 in stage 6.0 (TID 34). 1842 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 2.0 in stage 6.0 (TID 36). 1842 bytes result sent to driver
23/11/27 14:30:20 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 37) in 10 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 35) in 11 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 36) in 10 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 34) in 11 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 14:30:20 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
23/11/27 14:30:20 INFO DAGScheduler: ResultStage 6 (show at SparkTest.worksheet.sc:87) finished in 0.016 s
23/11/27 14:30:20 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
23/11/27 14:30:20 INFO DAGScheduler: Job 6 finished: show at SparkTest.worksheet.sc:87, took 0.017862 s
23/11/27 14:30:20 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 14:30:20 INFO DAGScheduler: Got job 7 (show at SparkTest.worksheet.sc:87) with 1 output partitions
23/11/27 14:30:20 INFO DAGScheduler: Final stage: ResultStage 7 (show at SparkTest.worksheet.sc:87)
23/11/27 14:30:20 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:20 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:20 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.9 KiB, free 433.7 MiB)
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.7 MiB)
23/11/27 14:30:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.25.86.80:44455 (size: 6.7 KiB, free: 434.2 MiB)
23/11/27 14:30:20 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(5))
23/11/27 14:30:20 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/11/27 14:30:20 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 38) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 8419 bytes) 
23/11/27 14:30:20 INFO Executor: Running task 0.0 in stage 7.0 (TID 38)
23/11/27 14:30:20 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-402d6f92-4956-4d09-84a2-1d60d044ad5d-c000.snappy.parquet, range: 0-501, partition values: [empty row]
23/11/27 14:30:20 INFO Executor: Finished task 0.0 in stage 7.0 (TID 38). 1749 bytes result sent to driver
23/11/27 14:30:20 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 38) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 14:30:20 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/11/27 14:30:20 INFO DAGScheduler: ResultStage 7 (show at SparkTest.worksheet.sc:87) finished in 0.015 s
23/11/27 14:30:20 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
23/11/27 14:30:20 INFO DAGScheduler: Job 7 finished: show at SparkTest.worksheet.sc:87, took 0.017136 s
23/11/27 14:30:20 INFO CodeGenerator: Code generated in 7.962014 ms
23/11/27 14:30:20 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 14:30:20 INFO DAGScheduler: Got job 8 (show at SparkTest.worksheet.sc:100) with 1 output partitions
23/11/27 14:30:20 INFO DAGScheduler: Final stage: ResultStage 8 (show at SparkTest.worksheet.sc:100)
23/11/27 14:30:20 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:20 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:20 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 15.2 KiB, free 433.7 MiB)
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 433.7 MiB)
23/11/27 14:30:20 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.25.86.80:44455 (size: 6.5 KiB, free: 434.2 MiB)
23/11/27 14:30:20 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(0))
23/11/27 14:30:20 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
23/11/27 14:30:20 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 39) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:20 INFO Executor: Running task 0.0 in stage 8.0 (TID 39)
23/11/27 14:30:20 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.25.86.80:44455 in memory (size: 34.9 KiB, free: 434.3 MiB)
23/11/27 14:30:20 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.25.86.80:44455 in memory (size: 36.9 KiB, free: 434.3 MiB)
23/11/27 14:30:20 INFO CodeGenerator: Code generated in 14.881104 ms
23/11/27 14:30:20 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.25.86.80:44455 in memory (size: 6.7 KiB, free: 434.3 MiB)
23/11/27 14:30:20 INFO Executor: Finished task 0.0 in stage 8.0 (TID 39). 1541 bytes result sent to driver
23/11/27 14:30:20 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.25.86.80:44455 in memory (size: 6.7 KiB, free: 434.3 MiB)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 39) in 22 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 14:30:20 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/11/27 14:30:20 INFO DAGScheduler: ResultStage 8 (show at SparkTest.worksheet.sc:100) finished in 0.029 s
23/11/27 14:30:20 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
23/11/27 14:30:20 INFO DAGScheduler: Job 8 finished: show at SparkTest.worksheet.sc:100, took 0.030787 s
23/11/27 14:30:20 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.25.86.80:44455 in memory (size: 6.7 KiB, free: 434.3 MiB)
23/11/27 14:30:20 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 14:30:20 INFO DAGScheduler: Got job 9 (show at SparkTest.worksheet.sc:100) with 4 output partitions
23/11/27 14:30:20 INFO DAGScheduler: Final stage: ResultStage 9 (show at SparkTest.worksheet.sc:100)
23/11/27 14:30:20 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:20 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:20 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 15.2 KiB, free 434.1 MiB)
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/11/27 14:30:20 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.25.86.80:44455 (size: 6.5 KiB, free: 434.3 MiB)
23/11/27 14:30:20 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:20 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 14:30:20 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks resource profile 0
23/11/27 14:30:20 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 40) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 41) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 42) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 43) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:20 INFO Executor: Running task 0.0 in stage 9.0 (TID 40)
23/11/27 14:30:20 INFO Executor: Running task 2.0 in stage 9.0 (TID 42)
23/11/27 14:30:20 INFO Executor: Running task 3.0 in stage 9.0 (TID 43)
23/11/27 14:30:20 INFO Executor: Running task 1.0 in stage 9.0 (TID 41)
23/11/27 14:30:20 INFO Executor: Finished task 3.0 in stage 9.0 (TID 43). 1498 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 1.0 in stage 9.0 (TID 41). 1498 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 0.0 in stage 9.0 (TID 40). 1498 bytes result sent to driver
23/11/27 14:30:20 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 43) in 6 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 40) in 7 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 41) in 6 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 14:30:20 INFO Executor: Finished task 2.0 in stage 9.0 (TID 42). 1554 bytes result sent to driver
23/11/27 14:30:20 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 42) in 9 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 14:30:20 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/11/27 14:30:20 INFO DAGScheduler: ResultStage 9 (show at SparkTest.worksheet.sc:100) finished in 0.015 s
23/11/27 14:30:20 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/11/27 14:30:20 INFO DAGScheduler: Job 9 finished: show at SparkTest.worksheet.sc:100, took 0.015985 s
23/11/27 14:30:20 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 14:30:20 INFO DAGScheduler: Got job 10 (show at SparkTest.worksheet.sc:100) with 11 output partitions
23/11/27 14:30:20 INFO DAGScheduler: Final stage: ResultStage 10 (show at SparkTest.worksheet.sc:100)
23/11/27 14:30:20 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:20 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:20 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 15.2 KiB, free 434.1 MiB)
23/11/27 14:30:20 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/11/27 14:30:20 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.25.86.80:44455 (size: 6.5 KiB, free: 434.3 MiB)
23/11/27 14:30:20 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:20 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 10 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15))
23/11/27 14:30:20 INFO TaskSchedulerImpl: Adding task set 10.0 with 11 tasks resource profile 0
23/11/27 14:30:20 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 44) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 45) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 46) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 47) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 48) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 49) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 50) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 51) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 52) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 53) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 14:30:20 INFO TaskSetManager: Starting task 10.0 in stage 10.0 (TID 54) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 14:30:20 INFO Executor: Running task 2.0 in stage 10.0 (TID 46)
23/11/27 14:30:20 INFO Executor: Running task 7.0 in stage 10.0 (TID 51)
23/11/27 14:30:20 INFO Executor: Running task 0.0 in stage 10.0 (TID 44)
23/11/27 14:30:20 INFO Executor: Running task 4.0 in stage 10.0 (TID 48)
23/11/27 14:30:20 INFO Executor: Running task 10.0 in stage 10.0 (TID 54)
23/11/27 14:30:20 INFO Executor: Running task 8.0 in stage 10.0 (TID 52)
23/11/27 14:30:20 INFO Executor: Running task 3.0 in stage 10.0 (TID 47)
23/11/27 14:30:20 INFO Executor: Running task 5.0 in stage 10.0 (TID 49)
23/11/27 14:30:20 INFO Executor: Running task 6.0 in stage 10.0 (TID 50)
23/11/27 14:30:20 INFO Executor: Running task 9.0 in stage 10.0 (TID 53)
23/11/27 14:30:20 INFO Executor: Running task 1.0 in stage 10.0 (TID 45)
23/11/27 14:30:20 INFO Executor: Finished task 0.0 in stage 10.0 (TID 44). 1541 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 5.0 in stage 10.0 (TID 49). 1541 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 9.0 in stage 10.0 (TID 53). 1541 bytes result sent to driver
23/11/27 14:30:20 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 49) in 13 ms on 10.25.86.80 (executor driver) (1/11)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 44) in 14 ms on 10.25.86.80 (executor driver) (2/11)
23/11/27 14:30:20 INFO Executor: Finished task 2.0 in stage 10.0 (TID 46). 1541 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 3.0 in stage 10.0 (TID 47). 1498 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 6.0 in stage 10.0 (TID 50). 1541 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 8.0 in stage 10.0 (TID 52). 1498 bytes result sent to driver
23/11/27 14:30:20 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 53) in 13 ms on 10.25.86.80 (executor driver) (3/11)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 52) in 13 ms on 10.25.86.80 (executor driver) (4/11)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 46) in 14 ms on 10.25.86.80 (executor driver) (5/11)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 50) in 14 ms on 10.25.86.80 (executor driver) (6/11)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 47) in 14 ms on 10.25.86.80 (executor driver) (7/11)
23/11/27 14:30:20 INFO Executor: Finished task 10.0 in stage 10.0 (TID 54). 1590 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 1.0 in stage 10.0 (TID 45). 1597 bytes result sent to driver
23/11/27 14:30:20 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.25.86.80:44455 in memory (size: 6.5 KiB, free: 434.3 MiB)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 10.0 in stage 10.0 (TID 54) in 16 ms on 10.25.86.80 (executor driver) (8/11)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 45) in 18 ms on 10.25.86.80 (executor driver) (9/11)
23/11/27 14:30:20 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.25.86.80:44455 in memory (size: 6.5 KiB, free: 434.3 MiB)
23/11/27 14:30:20 INFO Executor: Finished task 4.0 in stage 10.0 (TID 48). 1597 bytes result sent to driver
23/11/27 14:30:20 INFO Executor: Finished task 7.0 in stage 10.0 (TID 51). 1590 bytes result sent to driver
23/11/27 14:30:20 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 48) in 20 ms on 10.25.86.80 (executor driver) (10/11)
23/11/27 14:30:20 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 51) in 20 ms on 10.25.86.80 (executor driver) (11/11)
23/11/27 14:30:20 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/11/27 14:30:20 INFO DAGScheduler: ResultStage 10 (show at SparkTest.worksheet.sc:100) finished in 0.024 s
23/11/27 14:30:20 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
23/11/27 14:30:20 INFO DAGScheduler: Job 10 finished: show at SparkTest.worksheet.sc:100, took 0.026658 s
23/11/27 14:30:21 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.25.86.80:44455 in memory (size: 76.8 KiB, free: 434.4 MiB)
23/11/27 14:30:21 INFO DAGScheduler: Registering RDD 15 (show at SparkTest.worksheet.sc:116) as input to shuffle 0
23/11/27 14:30:21 INFO DAGScheduler: Got map stage job 11 (show at SparkTest.worksheet.sc:116) with 16 output partitions
23/11/27 14:30:21 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (show at SparkTest.worksheet.sc:116)
23/11/27 14:30:21 INFO DAGScheduler: Parents of final stage: List()
23/11/27 14:30:21 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:21 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[15] at show at SparkTest.worksheet.sc:116), which has no missing parents
23/11/27 14:30:21 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 17.1 KiB, free 434.4 MiB)
23/11/27 14:30:21 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.4 MiB)
23/11/27 14:30:21 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.25.86.80:44455 (size: 7.6 KiB, free: 434.4 MiB)
23/11/27 14:30:21 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:21 INFO DAGScheduler: Submitting 16 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[15] at show at SparkTest.worksheet.sc:116) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
23/11/27 14:30:21 INFO TaskSchedulerImpl: Adding task set 11.0 with 16 tasks resource profile 0
23/11/27 14:30:21 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 55) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7752 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 56) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7752 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 57) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7752 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 58) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7942 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 4.0 in stage 11.0 (TID 59) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7752 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 5.0 in stage 11.0 (TID 60) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7752 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 6.0 in stage 11.0 (TID 61) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7942 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 7.0 in stage 11.0 (TID 62) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7752 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 8.0 in stage 11.0 (TID 63) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7752 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 9.0 in stage 11.0 (TID 64) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7942 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 10.0 in stage 11.0 (TID 65) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7752 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 11.0 in stage 11.0 (TID 66) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7752 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 12.0 in stage 11.0 (TID 67) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7942 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 13.0 in stage 11.0 (TID 68) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7752 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 14.0 in stage 11.0 (TID 69) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7752 bytes) 
23/11/27 14:30:21 INFO TaskSetManager: Starting task 15.0 in stage 11.0 (TID 70) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7942 bytes) 
23/11/27 14:30:21 INFO Executor: Running task 1.0 in stage 11.0 (TID 56)
23/11/27 14:30:21 INFO Executor: Running task 3.0 in stage 11.0 (TID 58)
23/11/27 14:30:21 INFO Executor: Running task 4.0 in stage 11.0 (TID 59)
23/11/27 14:30:21 INFO Executor: Running task 9.0 in stage 11.0 (TID 64)
23/11/27 14:30:21 INFO Executor: Running task 8.0 in stage 11.0 (TID 63)
23/11/27 14:30:21 INFO Executor: Running task 13.0 in stage 11.0 (TID 68)
23/11/27 14:30:21 INFO Executor: Running task 14.0 in stage 11.0 (TID 69)
23/11/27 14:30:21 INFO Executor: Running task 0.0 in stage 11.0 (TID 55)
23/11/27 14:30:21 INFO Executor: Running task 5.0 in stage 11.0 (TID 60)
23/11/27 14:30:21 INFO Executor: Running task 7.0 in stage 11.0 (TID 62)
23/11/27 14:30:21 INFO Executor: Running task 6.0 in stage 11.0 (TID 61)
23/11/27 14:30:21 INFO Executor: Running task 12.0 in stage 11.0 (TID 67)
23/11/27 14:30:21 INFO Executor: Running task 10.0 in stage 11.0 (TID 65)
23/11/27 14:30:21 INFO Executor: Running task 15.0 in stage 11.0 (TID 70)
23/11/27 14:30:21 INFO Executor: Running task 11.0 in stage 11.0 (TID 66)
23/11/27 14:30:21 INFO Executor: Running task 2.0 in stage 11.0 (TID 57)
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 10.757587 ms
23/11/27 14:30:21 INFO Executor: Finished task 0.0 in stage 11.0 (TID 55). 1905 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 2.0 in stage 11.0 (TID 57). 1905 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 7.0 in stage 11.0 (TID 62). 1905 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 11.0 in stage 11.0 (TID 66). 1905 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 10.0 in stage 11.0 (TID 65). 1905 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 4.0 in stage 11.0 (TID 59). 1862 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 1.0 in stage 11.0 (TID 56). 1905 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 13.0 in stage 11.0 (TID 68). 1862 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 8.0 in stage 11.0 (TID 63). 1905 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 14.0 in stage 11.0 (TID 69). 1905 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 5.0 in stage 11.0 (TID 60). 1905 bytes result sent to driver
23/11/27 14:30:21 INFO TaskSetManager: Finished task 13.0 in stage 11.0 (TID 68) in 52 ms on 10.25.86.80 (executor driver) (1/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 4.0 in stage 11.0 (TID 59) in 55 ms on 10.25.86.80 (executor driver) (2/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 7.0 in stage 11.0 (TID 62) in 54 ms on 10.25.86.80 (executor driver) (3/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 57) in 55 ms on 10.25.86.80 (executor driver) (4/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 56) in 55 ms on 10.25.86.80 (executor driver) (5/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 11.0 in stage 11.0 (TID 66) in 54 ms on 10.25.86.80 (executor driver) (6/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 10.0 in stage 11.0 (TID 65) in 54 ms on 10.25.86.80 (executor driver) (7/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 55) in 56 ms on 10.25.86.80 (executor driver) (8/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 8.0 in stage 11.0 (TID 63) in 54 ms on 10.25.86.80 (executor driver) (9/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 5.0 in stage 11.0 (TID 60) in 56 ms on 10.25.86.80 (executor driver) (10/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 14.0 in stage 11.0 (TID 69) in 54 ms on 10.25.86.80 (executor driver) (11/16)
23/11/27 14:30:21 INFO Executor: Finished task 12.0 in stage 11.0 (TID 67). 1991 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 15.0 in stage 11.0 (TID 70). 1991 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 9.0 in stage 11.0 (TID 64). 1991 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 6.0 in stage 11.0 (TID 61). 1991 bytes result sent to driver
23/11/27 14:30:21 INFO Executor: Finished task 3.0 in stage 11.0 (TID 58). 1991 bytes result sent to driver
23/11/27 14:30:21 INFO TaskSetManager: Finished task 12.0 in stage 11.0 (TID 67) in 71 ms on 10.25.86.80 (executor driver) (12/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 6.0 in stage 11.0 (TID 61) in 72 ms on 10.25.86.80 (executor driver) (13/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 15.0 in stage 11.0 (TID 70) in 71 ms on 10.25.86.80 (executor driver) (14/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 9.0 in stage 11.0 (TID 64) in 72 ms on 10.25.86.80 (executor driver) (15/16)
23/11/27 14:30:21 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 58) in 74 ms on 10.25.86.80 (executor driver) (16/16)
23/11/27 14:30:21 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
23/11/27 14:30:21 INFO DAGScheduler: ShuffleMapStage 11 (show at SparkTest.worksheet.sc:116) finished in 0.089 s
23/11/27 14:30:21 INFO DAGScheduler: looking for newly runnable stages
23/11/27 14:30:21 INFO DAGScheduler: running: HashSet()
23/11/27 14:30:21 INFO DAGScheduler: waiting: HashSet()
23/11/27 14:30:21 INFO DAGScheduler: failed: HashSet()
23/11/27 14:30:21 INFO ShufflePartitionsUtil: For shuffle(0, 0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/27 14:30:21 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.25.86.80:44455 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/27 14:30:21 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.25.86.80:44455 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 34.436204 ms
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 8.825779 ms
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 7.706551 ms
23/11/27 14:30:21 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/27 14:30:21 INFO DAGScheduler: Got job 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/27 14:30:21 INFO DAGScheduler: Final stage: ResultStage 13 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/27 14:30:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
23/11/27 14:30:21 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:21 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[22] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/27 14:30:21 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 39.1 KiB, free 434.4 MiB)
23/11/27 14:30:21 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 434.3 MiB)
23/11/27 14:30:21 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.25.86.80:44455 (size: 16.4 KiB, free: 434.4 MiB)
23/11/27 14:30:21 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[22] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/27 14:30:21 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
23/11/27 14:30:21 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 71) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/27 14:30:21 INFO Executor: Running task 0.0 in stage 13.0 (TID 71)
23/11/27 14:30:21 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 14:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 6.607151 ms
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 14.121544 ms
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 6.059889 ms
23/11/27 14:30:21 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 14:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 6.515057 ms
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 14.595323 ms
23/11/27 14:30:21 INFO Executor: Finished task 0.0 in stage 13.0 (TID 71). 4879 bytes result sent to driver
23/11/27 14:30:21 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 71) in 121 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 14:30:21 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/11/27 14:30:21 INFO DAGScheduler: ResultStage 13 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.128 s
23/11/27 14:30:21 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
23/11/27 14:30:21 INFO DAGScheduler: Job 12 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.136731 s
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 5.418621 ms
23/11/27 14:30:21 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 1025.0 KiB, free 433.3 MiB)
23/11/27 14:30:21 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 279.0 B, free 433.3 MiB)
23/11/27 14:30:21 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.25.86.80:44455 (size: 279.0 B, free: 434.4 MiB)
23/11/27 14:30:21 INFO SparkContext: Created broadcast 14 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/27 14:30:21 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 7.992109 ms
23/11/27 14:30:21 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:116
23/11/27 14:30:21 INFO DAGScheduler: Got job 13 (show at SparkTest.worksheet.sc:116) with 1 output partitions
23/11/27 14:30:21 INFO DAGScheduler: Final stage: ResultStage 15 (show at SparkTest.worksheet.sc:116)
23/11/27 14:30:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
23/11/27 14:30:21 INFO DAGScheduler: Missing parents: List()
23/11/27 14:30:21 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[25] at show at SparkTest.worksheet.sc:116), which has no missing parents
23/11/27 14:30:21 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 15.3 KiB, free 433.3 MiB)
23/11/27 14:30:21 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 433.3 MiB)
23/11/27 14:30:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.25.86.80:44455 (size: 7.0 KiB, free: 434.4 MiB)
23/11/27 14:30:21 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580
23/11/27 14:30:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[25] at show at SparkTest.worksheet.sc:116) (first 15 tasks are for partitions Vector(0))
23/11/27 14:30:21 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
23/11/27 14:30:21 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 72) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7711 bytes) 
23/11/27 14:30:21 INFO Executor: Running task 0.0 in stage 15.0 (TID 72)
23/11/27 14:30:21 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 14:30:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/27 14:30:21 INFO CodeGenerator: Code generated in 7.39379 ms
23/11/27 14:30:21 INFO Executor: Finished task 0.0 in stage 15.0 (TID 72). 3989 bytes result sent to driver
23/11/27 14:30:21 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 72) in 13 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 14:30:21 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
23/11/27 14:30:21 INFO DAGScheduler: ResultStage 15 (show at SparkTest.worksheet.sc:116) finished in 0.017 s
23/11/27 14:30:21 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 14:30:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
23/11/27 14:30:21 INFO DAGScheduler: Job 13 finished: show at SparkTest.worksheet.sc:116, took 0.020055 s
2023.11.27 14:30:21 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 9.55s[0m
23/11/27 14:30:21 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.25.86.80:44455 in memory (size: 16.4 KiB, free: 434.4 MiB)
23/11/27 14:30:21 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.25.86.80:44455 in memory (size: 7.0 KiB, free: 434.4 MiB)
[31merror[39m: worksheets/SparkTest.worksheet.sc:76:22: 
Not found: ArgAst
val argAstInstance = ArgAst(myAstInstance)
                     ^^^^^^
[31merror[39m: worksheets/SparkTest.worksheet.sc:77:60: 
Ambiguous given instances: both method JsTrueW in trait JsReadWriters and method JsFalseW in trait JsReadWriters match type upickle.default.Writer[Any] of an implicit parameter of method write in trait Api
val jsonArgAstString = upickle.default.write(argAstInstance)
                                                           ^
2023.11.27 14:30:22 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.65s[0m
23/11/27 14:30:27 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.25.86.80:44455 in memory (size: 279.0 B, free: 434.4 MiB)
2023.11.27 14:30:38 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:30:38 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:30:56 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:30:56 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.27 14:30:57 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:30:57 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:76:22: 
Not found: ArgAst
val argAstInstance = ArgAst(myAstInstance)
                     ^^^^^^
[31merror[39m: worksheets/SparkTest.worksheet.sc:77:60: 
Ambiguous given instances: both method JsTrueW in trait JsReadWriters and method JsFalseW in trait JsReadWriters match type upickle.default.Writer[Any] of an implicit parameter of method write in trait Api
val jsonArgAstString = upickle.default.write(argAstInstance)
                                                           ^
2023.11.27 14:30:57 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.58s[0m
2023.11.27 14:31:01 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:31:01 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.27 14:31:02 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:31:02 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:77:24: 
missing argument for parameter evidence$4 of method write in trait Api: (implicit evidence$4:
  upickle.default.Writer[
    startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]]]
): String
val jsonArgAstString = upickle.default.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2023.11.27 14:31:02 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.43s[0m
2023.11.27 14:31:09 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:31:30 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:31:30 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.16s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:77:24: 
missing argument for parameter evidence$4 of method write in trait Api: (implicit evidence$4:
  upickle.default.Writer[
    startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]]]
): String
val jsonArgAstString = upickle.default.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2023.11.27 14:31:31 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:31:31 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:31:31 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.41s[0m
2023.11.27 14:31:34 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:31:34 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:24: 
missing argument for parameter evidence$4 of method write in trait Api: (implicit evidence$4:
  upickle.default.Writer[
    startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]]]
): String
val jsonArgAstString = upickle.default.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2023.11.27 14:31:35 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:31:35 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:31:35 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.44s[0m
2023.11.27 14:31:38 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:31:38 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:76:1: . expected but \n\n found

^
2023.11.27 14:31:38 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.21s[0m
2023.11.27 14:31:38 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:31:38 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:31:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:31:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:77:1: identifier expected but val found
val myAstInstance: Expression[Dataset[Row]] = myexpr
^^^
2023.11.27 14:31:40 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.15s[0m
2023.11.27 14:31:41 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:31:41 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:31:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:31:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:24: 
missing argument for parameter evidence$4 of method write in trait Api: (implicit evidence$4:
  upickle.default.Writer[
    startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]]]
): String
val jsonArgAstString = upickle.default.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2023.11.27 14:31:50 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.38s[0m
2023.11.27 14:31:50 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:31:50 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:32:02 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:04 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:04 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:32:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:24: 
missing argument for parameter evidence$4 of method write in trait Api: (implicit evidence$4:
  upickle.default.Writer[
    startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]]]
): String
val jsonArgAstString = upickle.default.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2023.11.27 14:32:06 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:06 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:32:06 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.41s[0m
2023.11.27 14:32:08 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:32:08 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
2023.11.27 14:32:09 INFO  time: code lens generation in 1.19s[0m
2023.11.27 14:32:09 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:09 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:75:16: 
value dfwriter is not a member of startup
import startup.dfwriter
               ^^^^^^^^
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:24: 
missing argument for parameter evidence$4 of method write in trait Api: (implicit evidence$4:
  upickle.default.Writer[
    startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]]]
): String
val jsonArgAstString = upickle.default.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2023.11.27 14:32:09 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.5s[0m
2023.11.27 14:32:27 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:31 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:32 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:32 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:32 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:33 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:32:33 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.27 14:32:34 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:34 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:32:38 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:32:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.27 14:32:39 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:39 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:32:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:32:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:75:16: 
value dfwriter is not a member of startup
import startup.dfwriter
               ^^^^^^^^
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:24: 
missing argument for parameter evidence$4 of method write in trait Api: (implicit evidence$4:
  upickle.default.Writer[
    startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]]]
): String
val jsonArgAstString = upickle.default.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2023.11.27 14:32:46 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.32s[0m
2023.11.27 14:32:46 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:46 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:32:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:32:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:77:1: identifier expected but val found
val myAstInstance: Expression[Dataset[Row]] = myexpr
^^^
2023.11.27 14:32:49 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.17s[0m
2023.11.27 14:32:49 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:32:49 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:33:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:33:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:24: 
missing argument for parameter evidence$4 of method write in trait Api: (implicit evidence$4:
  upickle.default.Writer[
    startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]]]
): String
val jsonArgAstString = upickle.default.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2023.11.27 14:33:04 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.27s[0m
2023.11.27 14:33:04 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:33:04 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:33:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:33:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:51: 
Found:    (MdocApp.this.argAstInstance :
  startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]])
Required: upickle.core.Visitor[?, Any]
val jsonArgAstString = given_Writer_Dataset.write(argAstInstance)
                                                  ^^^^^^^^^^^^^^
2023.11.27 14:33:18 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.32s[0m
2023.11.27 14:33:18 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:33:18 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:33:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:33:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:77:1: identifier expected but val found
val myAstInstance: Expression[Dataset[Row]] = myexpr
^^^
2023.11.27 14:33:27 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.16s[0m
2023.11.27 14:33:28 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:33:28 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:33:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:33:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:51: 
Found:    (MdocApp.this.argAstInstance :
  startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]])
Required: upickle.core.Visitor[?, Any]
val jsonArgAstString = given_Writer_Dataset.write(argAstInstance)
                                                  ^^^^^^^^^^^^^^
2023.11.27 14:33:41 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.36s[0m
2023.11.27 14:33:42 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:33:41 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:33:59 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:34:03 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:34:03 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:34:03 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.27 14:34:04 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:34:04 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:34:05 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:34:06 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:34:06 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.11.27 14:34:06 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala[0m
2023.11.27 14:34:06 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:34:17 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:34:57 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:34:58 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:34:59 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/StartUp.scala[0m
2023.11.27 14:35:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:35:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.36s[0m
2023.11.27 14:36:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:36:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.11.27 14:36:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (6 scala sources)[0m
2023.11.27 14:36:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.48s[0m
2023.11.27 14:37:49 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:37:49 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.3s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:51: 
Found:    (MdocApp.this.argAstInstance :
  startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]])
Required: upickle.core.Visitor[?, Any]
val jsonArgAstString = given_Writer_Dataset.write(argAstInstance)
                                                  ^^^^^^^^^^^^^^
2023.11.27 14:38:03 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.43s[0m
2023.11.27 14:41:52 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:41:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 65ms[0m
2023.11.27 14:42:00 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:42:00 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.2s[0m
2023.11.27 14:42:09 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:42:09 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 67ms[0m
2023.11.27 14:42:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:42:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.27 14:42:16 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:42:16 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
2023.11.27 14:43:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:43:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.15s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:75:16: 
value given_Writer_Dataset is not a member of startup
import startup.given_Writer_Dataset
               ^^^^^^^^^^^^^^^^^^^^
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:24: 
Not found: given_Writer_Dataset
val jsonArgAstString = given_Writer_Dataset.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^
2023.11.27 14:43:06 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.34s[0m
2023.11.27 14:43:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:43:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:24: 
Not found: given_Writer_Dataset
val jsonArgAstString = given_Writer_Dataset.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^
2023.11.27 14:43:13 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.24s[0m
2023.11.27 14:43:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:43:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.14s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:24: 
Not found: write
val jsonArgAstString = write(argAstInstance)
                       ^^^^^
2023.11.27 14:43:24 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.22s[0m
2023.11.27 14:43:48 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:43:48 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.18s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:24: 
Not found: write
val jsonArgAstString = write(argAstInstance)
                       ^^^^^
2023.11.27 14:43:48 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.23s[0m
2023.11.27 14:56:40 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:56:40 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.27 14:56:41 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:56:41 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.19s[0m
2023.11.27 14:56:45 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 14:56:45 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.11s[0m
2023.11.27 14:59:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:59:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.27 14:59:39 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:59:39 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.11.27 14:59:46 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:59:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.12s[0m
2023.11.27 14:59:47 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 14:59:47 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.11.27 15:00:05 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:00:05 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.57s[0m
2023.11.27 15:00:12 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:00:12 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.11.27 15:02:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:02:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.11.27 15:02:13 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:02:13 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.31s[0m
2023.11.27 15:02:18 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:02:18 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.11.27 15:02:19 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:02:19 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.34s[0m
2023.11.27 15:02:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:02:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.27 15:02:27 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:02:27 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.11.27 15:02:31 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:02:31 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.27 15:02:36 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:02:36 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.11.27 15:03:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:03:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.33s[0m
2023.11.27 15:03:07 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:03:07 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.27 15:03:23 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:03:23 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.32s[0m
2023.11.27 15:03:32 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:03:32 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.27s[0m
2023.11.27 15:03:54 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:03:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.29s[0m
2023.11.27 15:04:02 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:04:02 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.28s[0m
2023.11.27 15:04:04 INFO  compiling project-effective-scala-c1-s14-3039-4085 (2 scala sources)[0m
2023.11.27 15:04:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.43s[0m
2023.11.27 15:04:04 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.27 15:04:04 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.2s[0m
2023.11.27 15:04:05 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala[0m
2023.11.27 15:04:22 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 15:04:22 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.21s[0m
2023.11.27 15:04:22 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala[0m
2023.11.27 15:04:25 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala[0m
2023.11.27 15:04:46 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.27 15:04:46 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.16s[0m
2023.11.27 15:04:46 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala[0m
2023.11.27 15:04:51 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala[0m
2023.11.27 15:04:51 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:106: error: unclosed comment
/*  
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.27 15:04:52 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.27 15:04:52 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.11s[0m
2023.11.27 15:04:52 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala
scala.meta.tokenizers.TokenizeException: <input>:106: error: unclosed comment
/*  
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.27 15:04:52 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala[0m
2023.11.27 15:04:54 WARN  Could not load snapshot text for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/test/scala/startup/integration_testing/IntegrationSuite.scala[0m
2023.11.27 15:04:54 INFO  compiling project-effective-scala-c1-s14-3039-4085-test (1 scala source)[0m
2023.11.27 15:04:54 INFO  time: compiled project-effective-scala-c1-s14-3039-4085-test in 0.18s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:79:24: 
Not found: write
val jsonArgAstString = write(argAstInstance)
                       ^^^^^
2023.11.27 15:05:32 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.28s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:80:24: 
Not found: write
val jsonArgAstString = write(argAstInstance)
                       ^^^^^
2023.11.27 15:05:34 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.22s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:80:24: 
Not found: write
val jsonArgAstString = write(argAstInstance)
                       ^^^^^
2023.11.27 15:05:45 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.24s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:80:24: 
missing argument for parameter evidence$4 of method write in trait Api: (implicit evidence$4:
  upickle.default.Writer[
    startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]]]
): String
val jsonArgAstString = upickle.default.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2023.11.27 15:05:47 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.29s[0m
[31merror[39m: worksheets/SparkTest.worksheet.sc:80:24: 
missing argument for parameter evidence$4 of method write in trait Api: (implicit evidence$4:
  upickle.default.Writer[
    startup.ArgAst[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]]]
): String
val jsonArgAstString = upickle.default.write(argAstInstance)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2023.11.27 15:06:06 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 0.22s[0m
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
23/11/27 15:06:10 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/11/27 15:06:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/11/27 15:06:10 INFO SparkContext: Running Spark version 3.5.0
23/11/27 15:06:10 INFO SparkContext: OS info Linux, 6.2.0-36-generic, amd64
23/11/27 15:06:10 INFO SparkContext: Java version 11.0.20
23/11/27 15:06:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/11/27 15:06:10 INFO ResourceUtils: ==============================================================
23/11/27 15:06:10 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/27 15:06:10 INFO ResourceUtils: ==============================================================
23/11/27 15:06:10 INFO SparkContext: Submitted application: Spark Parquet Example
23/11/27 15:06:10 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/27 15:06:10 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
23/11/27 15:06:10 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/27 15:06:10 INFO SecurityManager: Changing view acls to: bsoleille
23/11/27 15:06:10 INFO SecurityManager: Changing modify acls to: bsoleille
23/11/27 15:06:10 INFO SecurityManager: Changing view acls groups to: 
23/11/27 15:06:10 INFO SecurityManager: Changing modify acls groups to: 
23/11/27 15:06:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/11/27 15:06:11 INFO Utils: Successfully started service 'sparkDriver' on port 45939.
23/11/27 15:06:11 INFO SparkEnv: Registering MapOutputTracker
23/11/27 15:06:11 INFO SparkEnv: Registering BlockManagerMaster
23/11/27 15:06:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/27 15:06:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/27 15:06:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/27 15:06:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e458fd09-83b0-4e11-97ec-16ad17db4392
23/11/27 15:06:11 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/27 15:06:11 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/27 15:06:11 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/11/27 15:06:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
23/11/27 15:06:11 INFO Utils: Successfully started service 'SparkUI' on port 4041.
23/11/27 15:06:11 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/11/27 15:06:11 INFO Executor: OS info Linux, 6.2.0-36-generic, amd64
23/11/27 15:06:11 INFO Executor: Java version 11.0.20
23/11/27 15:06:11 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/11/27 15:06:11 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1e6b53b6 for default.
23/11/27 15:06:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45571.
23/11/27 15:06:11 INFO NettyBlockTransferService: Server created on 10.25.86.80:45571
23/11/27 15:06:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/27 15:06:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 45571, None)
23/11/27 15:06:11 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:45571 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 45571, None)
23/11/27 15:06:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 45571, None)
23/11/27 15:06:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 45571, None)
23/11/27 15:06:11 WARN SharedState: URL.setURLStreamHandlerFactory failed to set FsUrlStreamHandlerFactory
23/11/27 15:06:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/11/27 15:06:11 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/11/27 15:06:13 INFO CodeGenerator: Code generated in 106.293523 ms
23/11/27 15:06:13 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 15:06:13 INFO DAGScheduler: Got job 0 (show at SparkTest.worksheet.sc:68) with 1 output partitions
23/11/27 15:06:13 INFO DAGScheduler: Final stage: ResultStage 0 (show at SparkTest.worksheet.sc:68)
23/11/27 15:06:13 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:13 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:13 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 15:06:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
23/11/27 15:06:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/11/27 15:06:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:45571 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:06:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(0))
23/11/27 15:06:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/11/27 15:06:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/11/27 15:06:13 INFO CodeGenerator: Code generated in 8.307526 ms
23/11/27 15:06:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1541 bytes result sent to driver
23/11/27 15:06:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 82 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:06:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/11/27 15:06:13 INFO DAGScheduler: ResultStage 0 (show at SparkTest.worksheet.sc:68) finished in 0.177 s
23/11/27 15:06:13 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/11/27 15:06:13 INFO DAGScheduler: Job 0 finished: show at SparkTest.worksheet.sc:68, took 0.197177 s
23/11/27 15:06:13 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 15:06:13 INFO DAGScheduler: Got job 1 (show at SparkTest.worksheet.sc:68) with 4 output partitions
23/11/27 15:06:13 INFO DAGScheduler: Final stage: ResultStage 1 (show at SparkTest.worksheet.sc:68)
23/11/27 15:06:13 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:13 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:13 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 15:06:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
23/11/27 15:06:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/11/27 15:06:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.25.86.80:45571 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:06:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 15:06:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0
23/11/27 15:06:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7948 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/11/27 15:06:13 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
23/11/27 15:06:13 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
23/11/27 15:06:13 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
23/11/27 15:06:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1498 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1498 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1498 bytes result sent to driver
23/11/27 15:06:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 8 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 7 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 9 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 15:06:13 INFO CodeGenerator: Code generated in 26.321423 ms
23/11/27 15:06:13 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1548 bytes result sent to driver
23/11/27 15:06:13 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 57 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 15:06:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/11/27 15:06:13 INFO DAGScheduler: ResultStage 1 (show at SparkTest.worksheet.sc:68) finished in 0.061 s
23/11/27 15:06:13 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/11/27 15:06:13 INFO DAGScheduler: Job 1 finished: show at SparkTest.worksheet.sc:68, took 0.063795 s
23/11/27 15:06:13 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 15:06:13 INFO DAGScheduler: Got job 2 (show at SparkTest.worksheet.sc:68) with 11 output partitions
23/11/27 15:06:13 INFO DAGScheduler: Final stage: ResultStage 2 (show at SparkTest.worksheet.sc:68)
23/11/27 15:06:13 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:13 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:13 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 15:06:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.4 KiB, free 434.3 MiB)
23/11/27 15:06:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.3 MiB)
23/11/27 15:06:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.25.86.80:45571 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:06:13 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:13 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15))
23/11/27 15:06:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 11 tasks resource profile 0
23/11/27 15:06:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7948 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 9) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 10) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 11) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 12) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 13) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 14) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 15) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:13 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
23/11/27 15:06:13 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)
23/11/27 15:06:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
23/11/27 15:06:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
23/11/27 15:06:13 INFO Executor: Running task 4.0 in stage 2.0 (TID 9)
23/11/27 15:06:13 INFO Executor: Running task 5.0 in stage 2.0 (TID 10)
23/11/27 15:06:13 INFO Executor: Running task 6.0 in stage 2.0 (TID 11)
23/11/27 15:06:13 INFO Executor: Running task 7.0 in stage 2.0 (TID 12)
23/11/27 15:06:13 INFO Executor: Running task 8.0 in stage 2.0 (TID 13)
23/11/27 15:06:13 INFO Executor: Running task 10.0 in stage 2.0 (TID 15)
23/11/27 15:06:13 INFO Executor: Running task 9.0 in stage 2.0 (TID 14)
23/11/27 15:06:13 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1498 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 5.0 in stage 2.0 (TID 10). 1498 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 8.0 in stage 2.0 (TID 13). 1455 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 3.0 in stage 2.0 (TID 8). 1498 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 6.0 in stage 2.0 (TID 11). 1498 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1498 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 9.0 in stage 2.0 (TID 14). 1498 bytes result sent to driver
23/11/27 15:06:13 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 8 ms on 10.25.86.80 (executor driver) (1/11)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 13) in 7 ms on 10.25.86.80 (executor driver) (2/11)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 11) in 9 ms on 10.25.86.80 (executor driver) (3/11)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 14) in 8 ms on 10.25.86.80 (executor driver) (4/11)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 9 ms on 10.25.86.80 (executor driver) (5/11)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 10) in 9 ms on 10.25.86.80 (executor driver) (6/11)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 10 ms on 10.25.86.80 (executor driver) (7/11)
23/11/27 15:06:13 INFO Executor: Finished task 7.0 in stage 2.0 (TID 12). 1548 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1548 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 10.0 in stage 2.0 (TID 15). 1548 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 4.0 in stage 2.0 (TID 9). 1548 bytes result sent to driver
23/11/27 15:06:13 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 12 ms on 10.25.86.80 (executor driver) (8/11)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 9) in 12 ms on 10.25.86.80 (executor driver) (9/11)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 12) in 11 ms on 10.25.86.80 (executor driver) (10/11)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 10.0 in stage 2.0 (TID 15) in 17 ms on 10.25.86.80 (executor driver) (11/11)
23/11/27 15:06:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/11/27 15:06:13 INFO DAGScheduler: ResultStage 2 (show at SparkTest.worksheet.sc:68) finished in 0.023 s
23/11/27 15:06:13 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/11/27 15:06:13 INFO DAGScheduler: Job 2 finished: show at SparkTest.worksheet.sc:68, took 0.025577 s
23/11/27 15:06:13 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.25.86.80:45571 in memory (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:06:13 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.25.86.80:45571 in memory (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:06:13 INFO CodeGenerator: Code generated in 7.63552 ms
23/11/27 15:06:13 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO CodeGenerator: Code generated in 5.89245 ms
23/11/27 15:06:13 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:78
23/11/27 15:06:13 INFO DAGScheduler: Got job 3 (parquet at SparkTest.worksheet.sc:78) with 16 output partitions
23/11/27 15:06:13 INFO DAGScheduler: Final stage: ResultStage 3 (parquet at SparkTest.worksheet.sc:78)
23/11/27 15:06:13 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:13 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:13 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:78), which has no missing parents
23/11/27 15:06:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 214.5 KiB, free 434.2 MiB)
23/11/27 15:06:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 76.8 KiB, free 434.1 MiB)
23/11/27 15:06:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.25.86.80:45571 (size: 76.8 KiB, free: 434.3 MiB)
23/11/27 15:06:13 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:13 INFO DAGScheduler: Submitting 16 missing tasks from ResultStage 3 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
23/11/27 15:06:13 INFO TaskSchedulerImpl: Adding task set 3.0 with 16 tasks resource profile 0
23/11/27 15:06:13 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 16) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 17) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 18) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 19) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 20) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 21) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 22) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 23) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 24) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 25) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7948 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 26) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 27) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 28) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 29) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 30) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:13 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 31) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:13 INFO Executor: Running task 2.0 in stage 3.0 (TID 18)
23/11/27 15:06:13 INFO Executor: Running task 7.0 in stage 3.0 (TID 23)
23/11/27 15:06:13 INFO Executor: Running task 6.0 in stage 3.0 (TID 22)
23/11/27 15:06:13 INFO Executor: Running task 1.0 in stage 3.0 (TID 17)
23/11/27 15:06:13 INFO Executor: Running task 0.0 in stage 3.0 (TID 16)
23/11/27 15:06:13 INFO Executor: Running task 3.0 in stage 3.0 (TID 19)
23/11/27 15:06:13 INFO Executor: Running task 4.0 in stage 3.0 (TID 20)
23/11/27 15:06:13 INFO Executor: Running task 5.0 in stage 3.0 (TID 21)
23/11/27 15:06:13 INFO Executor: Running task 10.0 in stage 3.0 (TID 26)
23/11/27 15:06:13 INFO Executor: Running task 11.0 in stage 3.0 (TID 27)
23/11/27 15:06:13 INFO Executor: Running task 8.0 in stage 3.0 (TID 24)
23/11/27 15:06:13 INFO Executor: Running task 9.0 in stage 3.0 (TID 25)
23/11/27 15:06:13 INFO Executor: Running task 12.0 in stage 3.0 (TID 28)
23/11/27 15:06:13 INFO Executor: Running task 14.0 in stage 3.0 (TID 30)
23/11/27 15:06:13 INFO Executor: Running task 13.0 in stage 3.0 (TID 29)
23/11/27 15:06:13 INFO Executor: Running task 15.0 in stage 3.0 (TID 31)
23/11/27 15:06:13 INFO CodeGenerator: Code generated in 8.800089 ms
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:06:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_2023112715061389537887538100788_0003_m_000013_29
23/11/27 15:06:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_2023112715061389537887538100788_0003_m_000004_20
23/11/27 15:06:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_2023112715061389537887538100788_0003_m_000007_23
23/11/27 15:06:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_2023112715061389537887538100788_0003_m_000010_26
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_2023112715061389537887538100788_0003_m_000008_24
23/11/27 15:06:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_2023112715061389537887538100788_0003_m_000001_17
23/11/27 15:06:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_2023112715061389537887538100788_0003_m_000002_18
23/11/27 15:06:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_2023112715061389537887538100788_0003_m_000005_21
23/11/27 15:06:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_2023112715061389537887538100788_0003_m_000011_27
23/11/27 15:06:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:06:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:06:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_2023112715061389537887538100788_0003_m_000014_30
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO Executor: Finished task 13.0 in stage 3.0 (TID 29). 2656 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 2.0 in stage 3.0 (TID 18). 2656 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 11.0 in stage 3.0 (TID 27). 2656 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 14.0 in stage 3.0 (TID 30). 2656 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 5.0 in stage 3.0 (TID 21). 2656 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 10.0 in stage 3.0 (TID 26). 2656 bytes result sent to driver
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO Executor: Finished task 1.0 in stage 3.0 (TID 17). 2656 bytes result sent to driver
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO Executor: Finished task 8.0 in stage 3.0 (TID 24). 2656 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 7.0 in stage 3.0 (TID 23). 2656 bytes result sent to driver
23/11/27 15:06:13 INFO Executor: Finished task 4.0 in stage 3.0 (TID 20). 2656 bytes result sent to driver
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:06:13 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 18) in 71 ms on 10.25.86.80 (executor driver) (1/16)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 29) in 69 ms on 10.25.86.80 (executor driver) (2/16)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 26) in 69 ms on 10.25.86.80 (executor driver) (3/16)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 30) in 69 ms on 10.25.86.80 (executor driver) (4/16)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 27) in 69 ms on 10.25.86.80 (executor driver) (5/16)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 17) in 71 ms on 10.25.86.80 (executor driver) (6/16)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 24) in 71 ms on 10.25.86.80 (executor driver) (7/16)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 21) in 71 ms on 10.25.86.80 (executor driver) (8/16)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 23) in 72 ms on 10.25.86.80 (executor driver) (9/16)
23/11/27 15:06:13 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 20) in 73 ms on 10.25.86.80 (executor driver) (10/16)
23/11/27 15:06:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:06:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:06:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:06:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:06:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:06:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:06:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:06:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:06:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:06:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:06:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:06:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:06:13 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.25.86.80:45571 in memory (size: 6.2 KiB, free: 434.3 MiB)
23/11/27 15:06:13 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:06:13 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:06:13 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:06:13 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:06:13 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:06:13 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:06:14 INFO FileOutputCommitter: Saved output of task 'attempt_2023112715061389537887538100788_0003_m_000000_16' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_2023112715061389537887538100788_0003_m_000000
23/11/27 15:06:14 INFO SparkHadoopMapRedUtil: attempt_2023112715061389537887538100788_0003_m_000000_16: Committed. Elapsed time: 0 ms.
23/11/27 15:06:14 INFO Executor: Finished task 0.0 in stage 3.0 (TID 16). 2742 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 16) in 393 ms on 10.25.86.80 (executor driver) (11/16)
23/11/27 15:06:14 INFO FileOutputCommitter: Saved output of task 'attempt_2023112715061389537887538100788_0003_m_000012_28' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_2023112715061389537887538100788_0003_m_000012
23/11/27 15:06:14 INFO FileOutputCommitter: Saved output of task 'attempt_2023112715061389537887538100788_0003_m_000003_19' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_2023112715061389537887538100788_0003_m_000003
23/11/27 15:06:14 INFO FileOutputCommitter: Saved output of task 'attempt_2023112715061389537887538100788_0003_m_000015_31' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_2023112715061389537887538100788_0003_m_000015
23/11/27 15:06:14 INFO SparkHadoopMapRedUtil: attempt_2023112715061389537887538100788_0003_m_000012_28: Committed. Elapsed time: 0 ms.
23/11/27 15:06:14 INFO FileOutputCommitter: Saved output of task 'attempt_2023112715061389537887538100788_0003_m_000009_25' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_2023112715061389537887538100788_0003_m_000009
23/11/27 15:06:14 INFO FileOutputCommitter: Saved output of task 'attempt_2023112715061389537887538100788_0003_m_000006_22' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_2023112715061389537887538100788_0003_m_000006
23/11/27 15:06:14 INFO SparkHadoopMapRedUtil: attempt_2023112715061389537887538100788_0003_m_000015_31: Committed. Elapsed time: 0 ms.
23/11/27 15:06:14 INFO SparkHadoopMapRedUtil: attempt_2023112715061389537887538100788_0003_m_000003_19: Committed. Elapsed time: 0 ms.
23/11/27 15:06:14 INFO SparkHadoopMapRedUtil: attempt_2023112715061389537887538100788_0003_m_000009_25: Committed. Elapsed time: 0 ms.
23/11/27 15:06:14 INFO SparkHadoopMapRedUtil: attempt_2023112715061389537887538100788_0003_m_000006_22: Committed. Elapsed time: 0 ms.
23/11/27 15:06:14 INFO Executor: Finished task 3.0 in stage 3.0 (TID 19). 2742 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 12.0 in stage 3.0 (TID 28). 2742 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 9.0 in stage 3.0 (TID 25). 2742 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 15.0 in stage 3.0 (TID 31). 2742 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 6.0 in stage 3.0 (TID 22). 2742 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 19) in 401 ms on 10.25.86.80 (executor driver) (12/16)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 22) in 401 ms on 10.25.86.80 (executor driver) (13/16)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 28) in 400 ms on 10.25.86.80 (executor driver) (14/16)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 25) in 401 ms on 10.25.86.80 (executor driver) (15/16)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 31) in 400 ms on 10.25.86.80 (executor driver) (16/16)
23/11/27 15:06:14 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/11/27 15:06:14 INFO DAGScheduler: ResultStage 3 (parquet at SparkTest.worksheet.sc:78) finished in 0.449 s
23/11/27 15:06:14 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
23/11/27 15:06:14 INFO DAGScheduler: Job 3 finished: parquet at SparkTest.worksheet.sc:78, took 0.451076 s
23/11/27 15:06:14 INFO FileFormatWriter: Start to commit write Job 9bbd6034-1059-4359-bdd1-6b351e99b254.
23/11/27 15:06:14 INFO FileFormatWriter: Write Job 9bbd6034-1059-4359-bdd1-6b351e99b254 committed. Elapsed time: 10 ms.
23/11/27 15:06:14 INFO FileFormatWriter: Finished processing stats for write job 9bbd6034-1059-4359-bdd1-6b351e99b254.
23/11/27 15:06:14 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
23/11/27 15:06:14 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:82
23/11/27 15:06:14 INFO DAGScheduler: Got job 4 (parquet at SparkTest.worksheet.sc:82) with 1 output partitions
23/11/27 15:06:14 INFO DAGScheduler: Final stage: ResultStage 4 (parquet at SparkTest.worksheet.sc:82)
23/11/27 15:06:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:14 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:82), which has no missing parents
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.25.86.80:45571 (size: 36.9 KiB, free: 434.3 MiB)
23/11/27 15:06:14 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:82) (first 15 tasks are for partitions Vector(0))
23/11/27 15:06:14 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
23/11/27 15:06:14 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 32) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/11/27 15:06:14 INFO Executor: Running task 0.0 in stage 4.0 (TID 32)
23/11/27 15:06:14 INFO Executor: Finished task 0.0 in stage 4.0 (TID 32). 2006 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 32) in 46 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:06:14 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/11/27 15:06:14 INFO DAGScheduler: ResultStage 4 (parquet at SparkTest.worksheet.sc:82) finished in 0.057 s
23/11/27 15:06:14 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
23/11/27 15:06:14 INFO DAGScheduler: Job 4 finished: parquet at SparkTest.worksheet.sc:82, took 0.058769 s
23/11/27 15:06:14 INFO FileSourceStrategy: Pushed Filters: 
23/11/27 15:06:14 INFO FileSourceStrategy: Post-Scan Filters: 
23/11/27 15:06:14 INFO CodeGenerator: Code generated in 16.780566 ms
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 200.7 KiB, free 433.8 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.25.86.80:45571 in memory (size: 36.9 KiB, free: 434.3 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.25.86.80:45571 in memory (size: 76.8 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 434.2 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.25.86.80:45571 (size: 34.9 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO SparkContext: Created broadcast 5 from show at SparkTest.worksheet.sc:87
23/11/27 15:06:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/11/27 15:06:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 15:06:14 INFO DAGScheduler: Got job 5 (show at SparkTest.worksheet.sc:87) with 1 output partitions
23/11/27 15:06:14 INFO DAGScheduler: Final stage: ResultStage 5 (show at SparkTest.worksheet.sc:87)
23/11/27 15:06:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:14 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 15.9 KiB, free 434.2 MiB)
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.1 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.25.86.80:45571 (size: 6.7 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(0))
23/11/27 15:06:14 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
23/11/27 15:06:14 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 33) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:06:14 INFO Executor: Running task 0.0 in stage 5.0 (TID 33)
23/11/27 15:06:14 INFO CodeGenerator: Code generated in 15.093307 ms
23/11/27 15:06:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00015-6345ca8e-16bf-4cc0-9692-de105db5571e-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:06:14 INFO CodecPool: Got brand-new decompressor [.snappy]
23/11/27 15:06:14 INFO Executor: Finished task 0.0 in stage 5.0 (TID 33). 1842 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 33) in 97 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:06:14 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
23/11/27 15:06:14 INFO DAGScheduler: ResultStage 5 (show at SparkTest.worksheet.sc:87) finished in 0.123 s
23/11/27 15:06:14 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
23/11/27 15:06:14 INFO DAGScheduler: Job 5 finished: show at SparkTest.worksheet.sc:87, took 0.126421 s
23/11/27 15:06:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 15:06:14 INFO DAGScheduler: Got job 6 (show at SparkTest.worksheet.sc:87) with 4 output partitions
23/11/27 15:06:14 INFO DAGScheduler: Final stage: ResultStage 6 (show at SparkTest.worksheet.sc:87)
23/11/27 15:06:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:14 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 15.9 KiB, free 434.1 MiB)
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.1 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.25.86.80:45571 (size: 6.7 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 15:06:14 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks resource profile 0
23/11/27 15:06:14 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 34) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 35) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 36) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 37) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:06:14 INFO Executor: Running task 0.0 in stage 6.0 (TID 34)
23/11/27 15:06:14 INFO Executor: Running task 3.0 in stage 6.0 (TID 37)
23/11/27 15:06:14 INFO Executor: Running task 2.0 in stage 6.0 (TID 36)
23/11/27 15:06:14 INFO Executor: Running task 1.0 in stage 6.0 (TID 35)
23/11/27 15:06:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00012-6345ca8e-16bf-4cc0-9692-de105db5571e-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:06:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00003-6345ca8e-16bf-4cc0-9692-de105db5571e-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:06:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00009-6345ca8e-16bf-4cc0-9692-de105db5571e-c000.snappy.parquet, range: 0-957, partition values: [empty row]
23/11/27 15:06:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00006-6345ca8e-16bf-4cc0-9692-de105db5571e-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:06:14 INFO Executor: Finished task 0.0 in stage 6.0 (TID 34). 1842 bytes result sent to driver
23/11/27 15:06:14 INFO CodecPool: Got brand-new decompressor [.snappy]
23/11/27 15:06:14 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 34) in 9 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 15:06:14 INFO Executor: Finished task 2.0 in stage 6.0 (TID 36). 1842 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 1.0 in stage 6.0 (TID 35). 1842 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 36) in 9 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 15:06:14 INFO Executor: Finished task 3.0 in stage 6.0 (TID 37). 1842 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 35) in 10 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 37) in 10 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 15:06:14 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
23/11/27 15:06:14 INFO DAGScheduler: ResultStage 6 (show at SparkTest.worksheet.sc:87) finished in 0.014 s
23/11/27 15:06:14 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
23/11/27 15:06:14 INFO DAGScheduler: Job 6 finished: show at SparkTest.worksheet.sc:87, took 0.016488 s
23/11/27 15:06:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 15:06:14 INFO DAGScheduler: Got job 7 (show at SparkTest.worksheet.sc:87) with 1 output partitions
23/11/27 15:06:14 INFO DAGScheduler: Final stage: ResultStage 7 (show at SparkTest.worksheet.sc:87)
23/11/27 15:06:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:14 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.9 KiB, free 434.1 MiB)
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 434.1 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.25.86.80:45571 (size: 6.7 KiB, free: 434.3 MiB)
23/11/27 15:06:14 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(5))
23/11/27 15:06:14 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/11/27 15:06:14 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 38) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:06:14 INFO Executor: Running task 0.0 in stage 7.0 (TID 38)
23/11/27 15:06:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-6345ca8e-16bf-4cc0-9692-de105db5571e-c000.snappy.parquet, range: 0-501, partition values: [empty row]
23/11/27 15:06:14 INFO Executor: Finished task 0.0 in stage 7.0 (TID 38). 1749 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 38) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:06:14 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/11/27 15:06:14 INFO DAGScheduler: ResultStage 7 (show at SparkTest.worksheet.sc:87) finished in 0.012 s
23/11/27 15:06:14 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
23/11/27 15:06:14 INFO DAGScheduler: Job 7 finished: show at SparkTest.worksheet.sc:87, took 0.013889 s
23/11/27 15:06:14 INFO CodeGenerator: Code generated in 10.354995 ms
23/11/27 15:06:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 15:06:14 INFO DAGScheduler: Got job 8 (show at SparkTest.worksheet.sc:100) with 1 output partitions
23/11/27 15:06:14 INFO DAGScheduler: Final stage: ResultStage 8 (show at SparkTest.worksheet.sc:100)
23/11/27 15:06:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:14 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 15.2 KiB, free 434.1 MiB)
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.25.86.80:45571 (size: 6.5 KiB, free: 434.3 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.25.86.80:45571 in memory (size: 34.9 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(0))
23/11/27 15:06:14 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
23/11/27 15:06:14 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.25.86.80:45571 in memory (size: 6.7 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 39) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:14 INFO Executor: Running task 0.0 in stage 8.0 (TID 39)
23/11/27 15:06:14 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.25.86.80:45571 in memory (size: 6.7 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.25.86.80:45571 in memory (size: 6.7 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO CodeGenerator: Code generated in 11.803384 ms
23/11/27 15:06:14 INFO Executor: Finished task 0.0 in stage 8.0 (TID 39). 1498 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 39) in 19 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:06:14 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/11/27 15:06:14 INFO DAGScheduler: ResultStage 8 (show at SparkTest.worksheet.sc:100) finished in 0.034 s
23/11/27 15:06:14 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
23/11/27 15:06:14 INFO DAGScheduler: Job 8 finished: show at SparkTest.worksheet.sc:100, took 0.036575 s
23/11/27 15:06:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 15:06:14 INFO DAGScheduler: Got job 9 (show at SparkTest.worksheet.sc:100) with 4 output partitions
23/11/27 15:06:14 INFO DAGScheduler: Final stage: ResultStage 9 (show at SparkTest.worksheet.sc:100)
23/11/27 15:06:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:14 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 15.2 KiB, free 434.4 MiB)
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.4 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.25.86.80:45571 (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 15:06:14 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks resource profile 0
23/11/27 15:06:14 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 40) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 41) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 42) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 43) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:14 INFO Executor: Running task 1.0 in stage 9.0 (TID 41)
23/11/27 15:06:14 INFO Executor: Running task 3.0 in stage 9.0 (TID 43)
23/11/27 15:06:14 INFO Executor: Running task 0.0 in stage 9.0 (TID 40)
23/11/27 15:06:14 INFO Executor: Running task 2.0 in stage 9.0 (TID 42)
23/11/27 15:06:14 INFO Executor: Finished task 1.0 in stage 9.0 (TID 41). 1498 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 0.0 in stage 9.0 (TID 40). 1498 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 3.0 in stage 9.0 (TID 43). 1455 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 41) in 4 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 43) in 4 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 40) in 5 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 15:06:14 INFO Executor: Finished task 2.0 in stage 9.0 (TID 42). 1554 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 42) in 7 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 15:06:14 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/11/27 15:06:14 INFO DAGScheduler: ResultStage 9 (show at SparkTest.worksheet.sc:100) finished in 0.011 s
23/11/27 15:06:14 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/11/27 15:06:14 INFO DAGScheduler: Job 9 finished: show at SparkTest.worksheet.sc:100, took 0.013251 s
23/11/27 15:06:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 15:06:14 INFO DAGScheduler: Got job 10 (show at SparkTest.worksheet.sc:100) with 11 output partitions
23/11/27 15:06:14 INFO DAGScheduler: Final stage: ResultStage 10 (show at SparkTest.worksheet.sc:100)
23/11/27 15:06:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:14 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 15.2 KiB, free 434.3 MiB)
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.3 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.25.86.80:45571 (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:14 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 10 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15))
23/11/27 15:06:14 INFO TaskSchedulerImpl: Adding task set 10.0 with 11 tasks resource profile 0
23/11/27 15:06:14 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 44) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 45) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 46) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 47) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 48) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 49) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 50) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 51) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 52) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 53) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 10.0 in stage 10.0 (TID 54) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:06:14 INFO Executor: Running task 2.0 in stage 10.0 (TID 46)
23/11/27 15:06:14 INFO Executor: Running task 6.0 in stage 10.0 (TID 50)
23/11/27 15:06:14 INFO Executor: Running task 3.0 in stage 10.0 (TID 47)
23/11/27 15:06:14 INFO Executor: Running task 0.0 in stage 10.0 (TID 44)
23/11/27 15:06:14 INFO Executor: Running task 7.0 in stage 10.0 (TID 51)
23/11/27 15:06:14 INFO Executor: Running task 8.0 in stage 10.0 (TID 52)
23/11/27 15:06:14 INFO Executor: Running task 1.0 in stage 10.0 (TID 45)
23/11/27 15:06:14 INFO Executor: Running task 9.0 in stage 10.0 (TID 53)
23/11/27 15:06:14 INFO Executor: Running task 5.0 in stage 10.0 (TID 49)
23/11/27 15:06:14 INFO Executor: Running task 4.0 in stage 10.0 (TID 48)
23/11/27 15:06:14 INFO Executor: Running task 10.0 in stage 10.0 (TID 54)
23/11/27 15:06:14 INFO Executor: Finished task 3.0 in stage 10.0 (TID 47). 1455 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 9.0 in stage 10.0 (TID 53). 1455 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 5.0 in stage 10.0 (TID 49). 1455 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 6.0 in stage 10.0 (TID 50). 1455 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 0.0 in stage 10.0 (TID 44). 1455 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 2.0 in stage 10.0 (TID 46). 1455 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 8.0 in stage 10.0 (TID 52). 1455 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 50) in 4 ms on 10.25.86.80 (executor driver) (1/11)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 47) in 4 ms on 10.25.86.80 (executor driver) (2/11)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 44) in 6 ms on 10.25.86.80 (executor driver) (3/11)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 49) in 5 ms on 10.25.86.80 (executor driver) (4/11)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 52) in 5 ms on 10.25.86.80 (executor driver) (5/11)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 46) in 6 ms on 10.25.86.80 (executor driver) (6/11)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 53) in 4 ms on 10.25.86.80 (executor driver) (7/11)
23/11/27 15:06:14 INFO Executor: Finished task 7.0 in stage 10.0 (TID 51). 1547 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 4.0 in stage 10.0 (TID 48). 1554 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 10.0 in stage 10.0 (TID 54). 1547 bytes result sent to driver
23/11/27 15:06:14 INFO Executor: Finished task 1.0 in stage 10.0 (TID 45). 1554 bytes result sent to driver
23/11/27 15:06:14 INFO TaskSetManager: Finished task 10.0 in stage 10.0 (TID 54) in 7 ms on 10.25.86.80 (executor driver) (8/11)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 45) in 9 ms on 10.25.86.80 (executor driver) (9/11)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 51) in 8 ms on 10.25.86.80 (executor driver) (10/11)
23/11/27 15:06:14 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 48) in 8 ms on 10.25.86.80 (executor driver) (11/11)
23/11/27 15:06:14 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/11/27 15:06:14 INFO DAGScheduler: ResultStage 10 (show at SparkTest.worksheet.sc:100) finished in 0.013 s
23/11/27 15:06:14 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
23/11/27 15:06:14 INFO DAGScheduler: Job 10 finished: show at SparkTest.worksheet.sc:100, took 0.014953 s
23/11/27 15:06:14 INFO DAGScheduler: Registering RDD 15 (show at SparkTest.worksheet.sc:116) as input to shuffle 0
23/11/27 15:06:14 INFO DAGScheduler: Got map stage job 11 (show at SparkTest.worksheet.sc:116) with 16 output partitions
23/11/27 15:06:14 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (show at SparkTest.worksheet.sc:116)
23/11/27 15:06:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:06:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:14 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[15] at show at SparkTest.worksheet.sc:116), which has no missing parents
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 17.1 KiB, free 434.3 MiB)
23/11/27 15:06:14 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.3 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.25.86.80:45571 (size: 7.6 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.25.86.80:45571 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:14 INFO DAGScheduler: Submitting 16 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[15] at show at SparkTest.worksheet.sc:116) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
23/11/27 15:06:14 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.25.86.80:45571 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO TaskSchedulerImpl: Adding task set 11.0 with 16 tasks resource profile 0
23/11/27 15:06:14 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.25.86.80:45571 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:06:14 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 55) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 56) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 57) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 58) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 4.0 in stage 11.0 (TID 59) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 5.0 in stage 11.0 (TID 60) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 6.0 in stage 11.0 (TID 61) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 7.0 in stage 11.0 (TID 62) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 8.0 in stage 11.0 (TID 63) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 9.0 in stage 11.0 (TID 64) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 10.0 in stage 11.0 (TID 65) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 11.0 in stage 11.0 (TID 66) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 12.0 in stage 11.0 (TID 67) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 13.0 in stage 11.0 (TID 68) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 14.0 in stage 11.0 (TID 69) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:06:14 INFO TaskSetManager: Starting task 15.0 in stage 11.0 (TID 70) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:06:14 INFO Executor: Running task 2.0 in stage 11.0 (TID 57)
23/11/27 15:06:14 INFO Executor: Running task 4.0 in stage 11.0 (TID 59)
23/11/27 15:06:14 INFO Executor: Running task 5.0 in stage 11.0 (TID 60)
23/11/27 15:06:14 INFO Executor: Running task 8.0 in stage 11.0 (TID 63)
23/11/27 15:06:14 INFO Executor: Running task 7.0 in stage 11.0 (TID 62)
23/11/27 15:06:14 INFO Executor: Running task 0.0 in stage 11.0 (TID 55)
23/11/27 15:06:14 INFO Executor: Running task 12.0 in stage 11.0 (TID 67)
23/11/27 15:06:14 INFO Executor: Running task 13.0 in stage 11.0 (TID 68)
23/11/27 15:06:14 INFO Executor: Running task 14.0 in stage 11.0 (TID 69)
23/11/27 15:06:14 INFO Executor: Running task 15.0 in stage 11.0 (TID 70)
23/11/27 15:06:14 INFO Executor: Running task 3.0 in stage 11.0 (TID 58)
23/11/27 15:06:14 INFO Executor: Running task 1.0 in stage 11.0 (TID 56)
23/11/27 15:06:14 INFO Executor: Running task 11.0 in stage 11.0 (TID 66)
23/11/27 15:06:14 INFO Executor: Running task 9.0 in stage 11.0 (TID 64)
23/11/27 15:06:14 INFO Executor: Running task 10.0 in stage 11.0 (TID 65)
23/11/27 15:06:14 INFO Executor: Running task 6.0 in stage 11.0 (TID 61)
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 9.435364 ms
23/11/27 15:06:15 INFO Executor: Finished task 7.0 in stage 11.0 (TID 62). 1905 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 10.0 in stage 11.0 (TID 65). 1905 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 5.0 in stage 11.0 (TID 60). 1905 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 8.0 in stage 11.0 (TID 63). 1905 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 1.0 in stage 11.0 (TID 56). 1905 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 14.0 in stage 11.0 (TID 69). 1862 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 11.0 in stage 11.0 (TID 66). 1905 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 0.0 in stage 11.0 (TID 55). 1905 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 4.0 in stage 11.0 (TID 59). 1905 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 13.0 in stage 11.0 (TID 68). 1905 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 2.0 in stage 11.0 (TID 57). 1905 bytes result sent to driver
23/11/27 15:06:15 INFO TaskSetManager: Finished task 7.0 in stage 11.0 (TID 62) in 40 ms on 10.25.86.80 (executor driver) (1/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 11.0 in stage 11.0 (TID 66) in 40 ms on 10.25.86.80 (executor driver) (2/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 10.0 in stage 11.0 (TID 65) in 41 ms on 10.25.86.80 (executor driver) (3/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 8.0 in stage 11.0 (TID 63) in 41 ms on 10.25.86.80 (executor driver) (4/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 14.0 in stage 11.0 (TID 69) in 40 ms on 10.25.86.80 (executor driver) (5/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 56) in 42 ms on 10.25.86.80 (executor driver) (6/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 4.0 in stage 11.0 (TID 59) in 42 ms on 10.25.86.80 (executor driver) (7/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 55) in 43 ms on 10.25.86.80 (executor driver) (8/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 5.0 in stage 11.0 (TID 60) in 41 ms on 10.25.86.80 (executor driver) (9/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 13.0 in stage 11.0 (TID 68) in 40 ms on 10.25.86.80 (executor driver) (10/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 57) in 42 ms on 10.25.86.80 (executor driver) (11/16)
23/11/27 15:06:15 INFO Executor: Finished task 3.0 in stage 11.0 (TID 58). 1991 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 9.0 in stage 11.0 (TID 64). 1991 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 15.0 in stage 11.0 (TID 70). 1991 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 12.0 in stage 11.0 (TID 67). 1991 bytes result sent to driver
23/11/27 15:06:15 INFO Executor: Finished task 6.0 in stage 11.0 (TID 61). 1991 bytes result sent to driver
23/11/27 15:06:15 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 58) in 57 ms on 10.25.86.80 (executor driver) (12/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 9.0 in stage 11.0 (TID 64) in 56 ms on 10.25.86.80 (executor driver) (13/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 15.0 in stage 11.0 (TID 70) in 55 ms on 10.25.86.80 (executor driver) (14/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 12.0 in stage 11.0 (TID 67) in 56 ms on 10.25.86.80 (executor driver) (15/16)
23/11/27 15:06:15 INFO TaskSetManager: Finished task 6.0 in stage 11.0 (TID 61) in 56 ms on 10.25.86.80 (executor driver) (16/16)
23/11/27 15:06:15 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
23/11/27 15:06:15 INFO DAGScheduler: ShuffleMapStage 11 (show at SparkTest.worksheet.sc:116) finished in 0.082 s
23/11/27 15:06:15 INFO DAGScheduler: looking for newly runnable stages
23/11/27 15:06:15 INFO DAGScheduler: running: HashSet()
23/11/27 15:06:15 INFO DAGScheduler: waiting: HashSet()
23/11/27 15:06:15 INFO DAGScheduler: failed: HashSet()
23/11/27 15:06:15 INFO ShufflePartitionsUtil: For shuffle(0, 0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 34.130024 ms
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 5.920627 ms
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 5.512479 ms
23/11/27 15:06:15 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/27 15:06:15 INFO DAGScheduler: Got job 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/27 15:06:15 INFO DAGScheduler: Final stage: ResultStage 13 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/27 15:06:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
23/11/27 15:06:15 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:15 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[22] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/27 15:06:15 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 39.1 KiB, free 434.3 MiB)
23/11/27 15:06:15 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 434.3 MiB)
23/11/27 15:06:15 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.25.86.80:45571 (size: 16.4 KiB, free: 434.4 MiB)
23/11/27 15:06:15 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[22] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/27 15:06:15 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
23/11/27 15:06:15 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 71) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/27 15:06:15 INFO Executor: Running task 0.0 in stage 13.0 (TID 71)
23/11/27 15:06:15 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 15:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 6.051454 ms
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 6.513554 ms
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 5.052535 ms
23/11/27 15:06:15 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 15:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 5.076661 ms
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 12.200575 ms
23/11/27 15:06:15 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.25.86.80:45571 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/27 15:06:15 INFO Executor: Finished task 0.0 in stage 13.0 (TID 71). 4922 bytes result sent to driver
23/11/27 15:06:15 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 71) in 101 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:06:15 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/11/27 15:06:15 INFO DAGScheduler: ResultStage 13 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.108 s
23/11/27 15:06:15 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
23/11/27 15:06:15 INFO DAGScheduler: Job 12 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.113406 s
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 6.792153 ms
23/11/27 15:06:15 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 1025.0 KiB, free 433.3 MiB)
23/11/27 15:06:15 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 279.0 B, free 433.3 MiB)
23/11/27 15:06:15 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.25.86.80:45571 (size: 279.0 B, free: 434.4 MiB)
23/11/27 15:06:15 INFO SparkContext: Created broadcast 14 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/27 15:06:15 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 11.93688 ms
23/11/27 15:06:15 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:116
23/11/27 15:06:15 INFO DAGScheduler: Got job 13 (show at SparkTest.worksheet.sc:116) with 1 output partitions
23/11/27 15:06:15 INFO DAGScheduler: Final stage: ResultStage 15 (show at SparkTest.worksheet.sc:116)
23/11/27 15:06:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
23/11/27 15:06:15 INFO DAGScheduler: Missing parents: List()
23/11/27 15:06:15 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[25] at show at SparkTest.worksheet.sc:116), which has no missing parents
23/11/27 15:06:15 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 15.3 KiB, free 433.3 MiB)
23/11/27 15:06:15 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 433.3 MiB)
23/11/27 15:06:15 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.25.86.80:45571 (size: 7.0 KiB, free: 434.4 MiB)
23/11/27 15:06:15 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580
23/11/27 15:06:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[25] at show at SparkTest.worksheet.sc:116) (first 15 tasks are for partitions Vector(0))
23/11/27 15:06:15 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
23/11/27 15:06:15 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 72) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7711 bytes) 
23/11/27 15:06:15 INFO Executor: Running task 0.0 in stage 15.0 (TID 72)
23/11/27 15:06:15 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 15:06:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/27 15:06:15 INFO CodeGenerator: Code generated in 12.907874 ms
23/11/27 15:06:15 INFO Executor: Finished task 0.0 in stage 15.0 (TID 72). 3989 bytes result sent to driver
23/11/27 15:06:15 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 72) in 20 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:06:15 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
23/11/27 15:06:15 INFO DAGScheduler: ResultStage 15 (show at SparkTest.worksheet.sc:116) finished in 0.026 s
23/11/27 15:06:15 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:06:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
23/11/27 15:06:15 INFO DAGScheduler: Job 13 finished: show at SparkTest.worksheet.sc:116, took 0.029575 s
2023.11.27 15:06:15 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 5.58s[0m
23/11/27 15:06:15 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.25.86.80:45571 in memory (size: 7.0 KiB, free: 434.4 MiB)
23/11/27 15:06:15 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.25.86.80:45571 in memory (size: 16.4 KiB, free: 434.4 MiB)
23/11/27 15:06:19 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.25.86.80:45571 in memory (size: 279.0 B, free: 434.4 MiB)
2023.11.27 15:06:36 INFO  Shutting down server[0m
2023.11.27 15:06:36 INFO  shutting down Metals[0m
2023.11.27 15:06:36 INFO  Shut down connection with build server.[0m
2023.11.27 15:06:36 INFO  Shut down connection with build server.[0m
2023.11.27 15:06:36 INFO  Exiting server[0m
23/11/27 15:06:36 INFO SparkContext: Invoking stop() from shutdown hook
23/11/27 15:06:36 INFO SparkContext: Invoking stop() from shutdown hook
23/11/27 15:06:36 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/11/27 15:06:36 INFO SparkContext: SparkContext is stopping with exitCode 0.
23/11/27 15:06:36 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4041
23/11/27 15:06:36 INFO SparkUI: Stopped Spark web UI at http://10.25.86.80:4040
23/11/27 15:06:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/11/27 15:06:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
23/11/27 15:06:36 INFO MemoryStore: MemoryStore cleared
23/11/27 15:06:36 INFO MemoryStore: MemoryStore cleared
23/11/27 15:06:36 INFO BlockManager: BlockManager stopped
23/11/27 15:06:36 INFO BlockManager: BlockManager stopped
23/11/27 15:06:36 INFO BlockManagerMaster: BlockManagerMaster stopped
23/11/27 15:06:36 INFO BlockManagerMaster: BlockManagerMaster stopped
23/11/27 15:06:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/11/27 15:06:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
23/11/27 15:06:36 INFO SparkContext: Successfully stopped SparkContext
23/11/27 15:06:36 INFO SparkContext: Successfully stopped SparkContext
23/11/27 15:06:36 INFO ShutdownHookManager: Shutdown hook called
23/11/27 15:06:36 INFO ShutdownHookManager: Shutdown hook called
23/11/27 15:06:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-9f9008ff-db97-43b4-abdd-e392ce74333b
23/11/27 15:06:36 INFO ShutdownHookManager: Deleting directory /tmp/spark-5f7fd88f-9a40-42f7-adee-89c3eeb8da30
2023.11.27 15:06:52 INFO  Started: Metals version 1.1.0 in folders '/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085' for client Visual Studio Code 1.84.2.[0m
2023.11.27 15:06:52 INFO  Attempting to connect to the build server...[0m
2023.11.27 15:06:52 INFO  skipping build import with status 'Installed'[0m
2023.11.27 15:06:52 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.27 15:06:52 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.27 15:06:52 INFO  Attempting to connect to the build server...[0m
2023.11.27 15:06:52 INFO  Bloop uses /home/bsoleille/.cache/coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.20%252B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.20_8.tar.gz/jdk-11.0.20+8 defined at /home/bsoleille/.bloop/bloop.json[0m
2023.11.27 15:06:53 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/project/.metals/bsp.trace.json or /home/bsoleille/.cache/metals/bsp.trace.json[0m
2023.11.27 15:06:53 INFO  time: Connected to build server in 0.46s[0m
2023.11.27 15:06:53 INFO  Connected to Build server: Bloop v1.5.11[0m
2023.11.27 15:06:56 INFO  time: indexed workspace in 3.18s[0m
Nov 27, 2023 3:06:56 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleNotification
WARNING: Notification threw an exception: {
  "jsonrpc": "2.0",
  "method": "build/publishDiagnostics",
  "params": {
    "textDocument": {
      "uri": "file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/sparkdata/dataframeApi.scala"
    },
    "buildTarget": {
      "uri": "file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/?id\u003dproject-effective-scala-c1-s14-3039-4085"
    },
    "diagnostics": [
      {
        "range": {
          "start": {
            "line": 0,
            "character": 0
          },
          "end": {
            "line": 0,
            "character": 17
          }
        },
        "severity": 2,
        "source": "bloop",
        "message": "No class, trait or object is defined in the compilation unit.\nThe incremental compiler cannot record the dependency information in such case.\nSome errors like unused import referring to a non-existent class might not be reported.\n",
        "data": {
          "actions": []
        }
      }
    ],
    "reset": true
  }
}
java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$null$0(GenericEndpoint.java:67)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.notify(GenericEndpoint.java:152)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleNotification(RemoteEndpoint.java:220)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:187)
	at scala.meta.internal.metals.RequestMonitorImpl$$anon$1.consume(ServerLivenessMonitor.scala:41)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:113)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.reflect.InvocationTargetException
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$null$0(GenericEndpoint.java:65)
	... 12 more
Caused by: java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/sparkdata/dataframeApi.scala
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:371)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:422)
	at java.base/java.nio.file.Files.readAllBytes(Files.java:3206)
	at scala.meta.internal.io.PlatformFileIO$.slurp(PlatformFileIO.scala:45)
	at scala.meta.internal.io.FileIO$.slurp(FileIO.scala:24)
	at scala.meta.internal.mtags.ScalametaCommonEnrichments$XtensionAbsolutePath.toInput(ScalametaCommonEnrichments.scala:383)
	at scala.meta.internal.metals.Diagnostics.onPublishDiagnostics(Diagnostics.scala:167)
	at scala.meta.internal.metals.Diagnostics.onBuildPublishDiagnostics(Diagnostics.scala:147)
	at scala.meta.internal.metals.clients.language.ForwardingMetalsBuildClient.onBuildPublishDiagnostics(ForwardingMetalsBuildClient.scala:112)
	... 17 more

Nov 27, 2023 3:06:56 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleNotification
WARNING: Notification threw an exception: {
  "jsonrpc": "2.0",
  "method": "build/publishDiagnostics",
  "params": {
    "textDocument": {
      "uri": "file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/spark/dataframeApi.scala"
    },
    "buildTarget": {
      "uri": "file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/?id\u003dproject-effective-scala-c1-s14-3039-4085"
    },
    "diagnostics": [
      {
        "range": {
          "start": {
            "line": 0,
            "character": 0
          },
          "end": {
            "line": 0,
            "character": 13
          }
        },
        "severity": 2,
        "source": "bloop",
        "message": "No class, trait or object is defined in the compilation unit.\nThe incremental compiler cannot record the dependency information in such case.\nSome errors like unused import referring to a non-existent class might not be reported.\n",
        "data": {
          "actions": []
        }
      }
    ],
    "reset": true
  }
}
java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$null$0(GenericEndpoint.java:67)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.notify(GenericEndpoint.java:152)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleNotification(RemoteEndpoint.java:220)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:187)
	at scala.meta.internal.metals.RequestMonitorImpl$$anon$1.consume(ServerLivenessMonitor.scala:41)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:113)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.reflect.InvocationTargetException
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$null$0(GenericEndpoint.java:65)
	... 12 more
Caused by: java.nio.file.NoSuchFileException: /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/spark/dataframeApi.scala
	at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:92)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111)
	at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116)
	at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:371)
	at java.base/java.nio.file.Files.newByteChannel(Files.java:422)
	at java.base/java.nio.file.Files.readAllBytes(Files.java:3206)
	at scala.meta.internal.io.PlatformFileIO$.slurp(PlatformFileIO.scala:45)
	at scala.meta.internal.io.FileIO$.slurp(FileIO.scala:24)
	at scala.meta.internal.mtags.ScalametaCommonEnrichments$XtensionAbsolutePath.toInput(ScalametaCommonEnrichments.scala:383)
	at scala.meta.internal.metals.Diagnostics.onPublishDiagnostics(Diagnostics.scala:167)
	at scala.meta.internal.metals.Diagnostics.onBuildPublishDiagnostics(Diagnostics.scala:147)
	at scala.meta.internal.metals.clients.language.ForwardingMetalsBuildClient.onBuildPublishDiagnostics(ForwardingMetalsBuildClient.scala:112)
	... 17 more

Nov 27, 2023 3:06:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 40
Nov 27, 2023 3:06:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 41
Nov 27, 2023 3:06:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 42
Nov 27, 2023 3:06:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 43
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
23/11/27 15:07:06 WARN Utils: Your hostname, CN3126CH011005 resolves to a loopback address: 127.0.1.1; using 10.25.86.80 instead (on interface enp0s31f6)
23/11/27 15:07:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/11/27 15:07:06 INFO SparkContext: Running Spark version 3.5.0
23/11/27 15:07:06 INFO SparkContext: OS info Linux, 6.2.0-36-generic, amd64
23/11/27 15:07:06 INFO SparkContext: Java version 11.0.20
23/11/27 15:07:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/11/27 15:07:06 INFO ResourceUtils: ==============================================================
23/11/27 15:07:06 INFO ResourceUtils: No custom resources configured for spark.driver.
23/11/27 15:07:06 INFO ResourceUtils: ==============================================================
23/11/27 15:07:06 INFO SparkContext: Submitted application: Spark Parquet Example
23/11/27 15:07:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/11/27 15:07:06 INFO ResourceProfile: Limiting resource is cpus at 2 tasks per executor
23/11/27 15:07:06 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/11/27 15:07:07 INFO SecurityManager: Changing view acls to: bsoleille
23/11/27 15:07:07 INFO SecurityManager: Changing modify acls to: bsoleille
23/11/27 15:07:07 INFO SecurityManager: Changing view acls groups to: 
23/11/27 15:07:07 INFO SecurityManager: Changing modify acls groups to: 
23/11/27 15:07:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: bsoleille; groups with view permissions: EMPTY; users with modify permissions: bsoleille; groups with modify permissions: EMPTY
23/11/27 15:07:07 INFO Utils: Successfully started service 'sparkDriver' on port 34157.
23/11/27 15:07:07 INFO SparkEnv: Registering MapOutputTracker
23/11/27 15:07:07 INFO SparkEnv: Registering BlockManagerMaster
23/11/27 15:07:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/11/27 15:07:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/11/27 15:07:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/11/27 15:07:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8d83450f-653b-4380-b506-c04e9fbbab83
23/11/27 15:07:07 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/11/27 15:07:07 INFO SparkEnv: Registering OutputCommitCoordinator
23/11/27 15:07:07 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
23/11/27 15:07:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/11/27 15:07:07 INFO Executor: Starting executor ID driver on host 10.25.86.80
23/11/27 15:07:07 INFO Executor: OS info Linux, 6.2.0-36-generic, amd64
23/11/27 15:07:07 INFO Executor: Java version 11.0.20
23/11/27 15:07:07 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/11/27 15:07:07 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@2e554dd3 for default.
23/11/27 15:07:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39667.
23/11/27 15:07:07 INFO NettyBlockTransferService: Server created on 10.25.86.80:39667
23/11/27 15:07:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/11/27 15:07:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.25.86.80, 39667, None)
23/11/27 15:07:07 INFO BlockManagerMasterEndpoint: Registering block manager 10.25.86.80:39667 with 434.4 MiB RAM, BlockManagerId(driver, 10.25.86.80, 39667, None)
23/11/27 15:07:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.25.86.80, 39667, None)
23/11/27 15:07:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.25.86.80, 39667, None)
23/11/27 15:07:07 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
23/11/27 15:07:07 INFO SharedState: Warehouse path is 'file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/spark-warehouse'.
23/11/27 15:07:09 INFO CodeGenerator: Code generated in 110.085233 ms
23/11/27 15:07:09 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 15:07:09 INFO DAGScheduler: Got job 0 (show at SparkTest.worksheet.sc:68) with 1 output partitions
23/11/27 15:07:09 INFO DAGScheduler: Final stage: ResultStage 0 (show at SparkTest.worksheet.sc:68)
23/11/27 15:07:09 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:09 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:09 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 15:07:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
23/11/27 15:07:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/11/27 15:07:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.25.86.80:39667 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:07:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
23/11/27 15:07:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/11/27 15:07:09 INFO CodeGenerator: Code generated in 8.510311 ms
23/11/27 15:07:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1541 bytes result sent to driver
23/11/27 15:07:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 134 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
23/11/27 15:07:09 INFO DAGScheduler: ResultStage 0 (show at SparkTest.worksheet.sc:68) finished in 0.295 s
23/11/27 15:07:09 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
23/11/27 15:07:09 INFO DAGScheduler: Job 0 finished: show at SparkTest.worksheet.sc:68, took 0.318256 s
23/11/27 15:07:09 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 15:07:09 INFO DAGScheduler: Got job 1 (show at SparkTest.worksheet.sc:68) with 4 output partitions
23/11/27 15:07:09 INFO DAGScheduler: Final stage: ResultStage 1 (show at SparkTest.worksheet.sc:68)
23/11/27 15:07:09 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:09 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:09 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 15:07:09 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
23/11/27 15:07:09 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/11/27 15:07:09 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.25.86.80:39667 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:07:09 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:09 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 15:07:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0
23/11/27 15:07:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:09 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:09 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7948 bytes) 
23/11/27 15:07:09 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/11/27 15:07:09 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
23/11/27 15:07:09 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
23/11/27 15:07:09 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
23/11/27 15:07:09 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1498 bytes result sent to driver
23/11/27 15:07:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1498 bytes result sent to driver
23/11/27 15:07:09 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1498 bytes result sent to driver
23/11/27 15:07:09 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 10 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 15:07:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 12 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 15:07:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 13 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 15:07:10 INFO CodeGenerator: Code generated in 25.298833 ms
23/11/27 15:07:10 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1548 bytes result sent to driver
23/11/27 15:07:10 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 549 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 15:07:10 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
23/11/27 15:07:10 INFO DAGScheduler: ResultStage 1 (show at SparkTest.worksheet.sc:68) finished in 0.557 s
23/11/27 15:07:10 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
23/11/27 15:07:10 INFO DAGScheduler: Job 1 finished: show at SparkTest.worksheet.sc:68, took 0.559210 s
23/11/27 15:07:10 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 15:07:10 INFO DAGScheduler: Got job 2 (show at SparkTest.worksheet.sc:68) with 11 output partitions
23/11/27 15:07:10 INFO DAGScheduler: Final stage: ResultStage 2 (show at SparkTest.worksheet.sc:68)
23/11/27 15:07:10 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:10 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:10 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 15:07:10 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.4 KiB, free 434.3 MiB)
23/11/27 15:07:10 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.3 MiB)
23/11/27 15:07:10 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.25.86.80:39667 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:07:10 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:10 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 2 (MapPartitionsRDD[3] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15))
23/11/27 15:07:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 11 tasks resource profile 0
23/11/27 15:07:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7948 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 9) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 10) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 11) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 12) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 13) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 14) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 15) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
23/11/27 15:07:10 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
23/11/27 15:07:10 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)
23/11/27 15:07:10 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
23/11/27 15:07:10 INFO Executor: Running task 4.0 in stage 2.0 (TID 9)
23/11/27 15:07:10 INFO Executor: Running task 5.0 in stage 2.0 (TID 10)
23/11/27 15:07:10 INFO Executor: Running task 6.0 in stage 2.0 (TID 11)
23/11/27 15:07:10 INFO Executor: Running task 7.0 in stage 2.0 (TID 12)
23/11/27 15:07:10 INFO Executor: Running task 8.0 in stage 2.0 (TID 13)
23/11/27 15:07:10 INFO Executor: Running task 9.0 in stage 2.0 (TID 14)
23/11/27 15:07:10 INFO Executor: Running task 10.0 in stage 2.0 (TID 15)
23/11/27 15:07:10 INFO Executor: Finished task 6.0 in stage 2.0 (TID 11). 1541 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 9.0 in stage 2.0 (TID 14). 1541 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1541 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 3.0 in stage 2.0 (TID 8). 1541 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 5.0 in stage 2.0 (TID 10). 1541 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 8.0 in stage 2.0 (TID 13). 1584 bytes result sent to driver
23/11/27 15:07:10 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 18 ms on 10.25.86.80 (executor driver) (1/11)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 18 ms on 10.25.86.80 (executor driver) (2/11)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 11) in 17 ms on 10.25.86.80 (executor driver) (3/11)
23/11/27 15:07:10 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1584 bytes result sent to driver
23/11/27 15:07:10 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 13) in 17 ms on 10.25.86.80 (executor driver) (4/11)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 14) in 17 ms on 10.25.86.80 (executor driver) (5/11)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 10) in 18 ms on 10.25.86.80 (executor driver) (6/11)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 20 ms on 10.25.86.80 (executor driver) (7/11)
23/11/27 15:07:10 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1591 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 10.0 in stage 2.0 (TID 15). 1591 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 4.0 in stage 2.0 (TID 9). 1591 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 7.0 in stage 2.0 (TID 12). 1591 bytes result sent to driver
23/11/27 15:07:10 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 9) in 22 ms on 10.25.86.80 (executor driver) (8/11)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 23 ms on 10.25.86.80 (executor driver) (9/11)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 10.0 in stage 2.0 (TID 15) in 21 ms on 10.25.86.80 (executor driver) (10/11)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 12) in 23 ms on 10.25.86.80 (executor driver) (11/11)
23/11/27 15:07:10 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
23/11/27 15:07:10 INFO DAGScheduler: ResultStage 2 (show at SparkTest.worksheet.sc:68) finished in 0.029 s
23/11/27 15:07:10 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
23/11/27 15:07:10 INFO DAGScheduler: Job 2 finished: show at SparkTest.worksheet.sc:68, took 0.030944 s
23/11/27 15:07:10 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.25.86.80:39667 in memory (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:07:10 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.25.86.80:39667 in memory (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:07:10 INFO CodeGenerator: Code generated in 8.151868 ms
23/11/27 15:07:10 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO CodeGenerator: Code generated in 5.346574 ms
23/11/27 15:07:10 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:78
23/11/27 15:07:10 INFO DAGScheduler: Got job 3 (parquet at SparkTest.worksheet.sc:78) with 16 output partitions
23/11/27 15:07:10 INFO DAGScheduler: Final stage: ResultStage 3 (parquet at SparkTest.worksheet.sc:78)
23/11/27 15:07:10 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:10 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:10 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:78), which has no missing parents
23/11/27 15:07:10 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 214.5 KiB, free 434.2 MiB)
23/11/27 15:07:10 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 76.9 KiB, free 434.1 MiB)
23/11/27 15:07:10 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.25.86.80:39667 (size: 76.9 KiB, free: 434.3 MiB)
23/11/27 15:07:10 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:10 INFO DAGScheduler: Submitting 16 missing tasks from ResultStage 3 (MapPartitionsRDD[5] at parquet at SparkTest.worksheet.sc:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
23/11/27 15:07:10 INFO TaskSchedulerImpl: Adding task set 3.0 with 16 tasks resource profile 0
23/11/27 15:07:10 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 16) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 17) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 18) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 19) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 20) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 21) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 22) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 23) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 24) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 25) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7948 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 26) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 27) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 12.0 in stage 3.0 (TID 28) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 13.0 in stage 3.0 (TID 29) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 14.0 in stage 3.0 (TID 30) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:10 INFO TaskSetManager: Starting task 15.0 in stage 3.0 (TID 31) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:10 INFO Executor: Running task 0.0 in stage 3.0 (TID 16)
23/11/27 15:07:10 INFO Executor: Running task 9.0 in stage 3.0 (TID 25)
23/11/27 15:07:10 INFO Executor: Running task 2.0 in stage 3.0 (TID 18)
23/11/27 15:07:10 INFO Executor: Running task 10.0 in stage 3.0 (TID 26)
23/11/27 15:07:10 INFO Executor: Running task 8.0 in stage 3.0 (TID 24)
23/11/27 15:07:10 INFO Executor: Running task 6.0 in stage 3.0 (TID 22)
23/11/27 15:07:10 INFO Executor: Running task 7.0 in stage 3.0 (TID 23)
23/11/27 15:07:10 INFO Executor: Running task 4.0 in stage 3.0 (TID 20)
23/11/27 15:07:10 INFO Executor: Running task 1.0 in stage 3.0 (TID 17)
23/11/27 15:07:10 INFO Executor: Running task 5.0 in stage 3.0 (TID 21)
23/11/27 15:07:10 INFO Executor: Running task 3.0 in stage 3.0 (TID 19)
23/11/27 15:07:10 INFO Executor: Running task 11.0 in stage 3.0 (TID 27)
23/11/27 15:07:10 INFO Executor: Running task 13.0 in stage 3.0 (TID 29)
23/11/27 15:07:10 INFO Executor: Running task 15.0 in stage 3.0 (TID 31)
23/11/27 15:07:10 INFO Executor: Running task 12.0 in stage 3.0 (TID 28)
23/11/27 15:07:10 INFO Executor: Running task 14.0 in stage 3.0 (TID 30)
23/11/27 15:07:10 INFO CodeGenerator: Code generated in 10.892171 ms
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507101056681515016315931_0003_m_000007_23
23/11/27 15:07:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507101056681515016315931_0003_m_000002_18
23/11/27 15:07:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507101056681515016315931_0003_m_000011_27
23/11/27 15:07:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507101056681515016315931_0003_m_000005_21
23/11/27 15:07:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507101056681515016315931_0003_m_000004_20
23/11/27 15:07:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507101056681515016315931_0003_m_000001_17
23/11/27 15:07:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507101056681515016315931_0003_m_000014_30
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507101056681515016315931_0003_m_000010_26
23/11/27 15:07:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507101056681515016315931_0003_m_000008_24
23/11/27 15:07:10 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507101056681515016315931_0003_m_000013_29
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO Executor: Finished task 8.0 in stage 3.0 (TID 24). 2699 bytes result sent to driver
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO Executor: Finished task 13.0 in stage 3.0 (TID 29). 2699 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 14.0 in stage 3.0 (TID 30). 2699 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 5.0 in stage 3.0 (TID 21). 2699 bytes result sent to driver
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO Executor: Finished task 4.0 in stage 3.0 (TID 20). 2656 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 11.0 in stage 3.0 (TID 27). 2699 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 1.0 in stage 3.0 (TID 17). 2699 bytes result sent to driver
23/11/27 15:07:10 INFO TaskSetManager: Finished task 13.0 in stage 3.0 (TID 29) in 122 ms on 10.25.86.80 (executor driver) (1/16)
23/11/27 15:07:10 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:10 INFO Executor: Finished task 10.0 in stage 3.0 (TID 26). 2699 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 7.0 in stage 3.0 (TID 23). 2699 bytes result sent to driver
23/11/27 15:07:10 INFO Executor: Finished task 2.0 in stage 3.0 (TID 18). 2699 bytes result sent to driver
23/11/27 15:07:10 INFO TaskSetManager: Finished task 14.0 in stage 3.0 (TID 30) in 123 ms on 10.25.86.80 (executor driver) (2/16)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 24) in 124 ms on 10.25.86.80 (executor driver) (3/16)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 27) in 124 ms on 10.25.86.80 (executor driver) (4/16)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 20) in 125 ms on 10.25.86.80 (executor driver) (5/16)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 21) in 125 ms on 10.25.86.80 (executor driver) (6/16)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 26) in 125 ms on 10.25.86.80 (executor driver) (7/16)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 17) in 127 ms on 10.25.86.80 (executor driver) (8/16)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 18) in 128 ms on 10.25.86.80 (executor driver) (9/16)
23/11/27 15:07:10 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 23) in 127 ms on 10.25.86.80 (executor driver) (10/16)
23/11/27 15:07:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:10 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:10 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:10 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.25.86.80:39667 in memory (size: 6.2 KiB, free: 434.3 MiB)
23/11/27 15:07:10 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:07:10 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:07:10 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:07:10 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:07:10 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:07:10 INFO CodecPool: Got brand-new compressor [.snappy]
23/11/27 15:07:11 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507101056681515016315931_0003_m_000009_25' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507101056681515016315931_0003_m_000009
23/11/27 15:07:11 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507101056681515016315931_0003_m_000000_16' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507101056681515016315931_0003_m_000000
23/11/27 15:07:11 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507101056681515016315931_0003_m_000006_22' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507101056681515016315931_0003_m_000006
23/11/27 15:07:11 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507101056681515016315931_0003_m_000012_28' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507101056681515016315931_0003_m_000012
23/11/27 15:07:11 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507101056681515016315931_0003_m_000003_19' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507101056681515016315931_0003_m_000003
23/11/27 15:07:11 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507101056681515016315931_0003_m_000015_31' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507101056681515016315931_0003_m_000015
23/11/27 15:07:11 INFO SparkHadoopMapRedUtil: attempt_202311271507101056681515016315931_0003_m_000006_22: Committed. Elapsed time: 1 ms.
23/11/27 15:07:11 INFO SparkHadoopMapRedUtil: attempt_202311271507101056681515016315931_0003_m_000012_28: Committed. Elapsed time: 1 ms.
23/11/27 15:07:11 INFO SparkHadoopMapRedUtil: attempt_202311271507101056681515016315931_0003_m_000003_19: Committed. Elapsed time: 1 ms.
23/11/27 15:07:11 INFO SparkHadoopMapRedUtil: attempt_202311271507101056681515016315931_0003_m_000009_25: Committed. Elapsed time: 1 ms.
23/11/27 15:07:11 INFO SparkHadoopMapRedUtil: attempt_202311271507101056681515016315931_0003_m_000015_31: Committed. Elapsed time: 1 ms.
23/11/27 15:07:11 INFO SparkHadoopMapRedUtil: attempt_202311271507101056681515016315931_0003_m_000000_16: Committed. Elapsed time: 1 ms.
23/11/27 15:07:11 INFO Executor: Finished task 3.0 in stage 3.0 (TID 19). 2742 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 15.0 in stage 3.0 (TID 31). 2742 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 12.0 in stage 3.0 (TID 28). 2742 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 6.0 in stage 3.0 (TID 22). 2742 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 9.0 in stage 3.0 (TID 25). 2742 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 0.0 in stage 3.0 (TID 16). 2699 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 19) in 562 ms on 10.25.86.80 (executor driver) (11/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 15.0 in stage 3.0 (TID 31) in 560 ms on 10.25.86.80 (executor driver) (12/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 22) in 561 ms on 10.25.86.80 (executor driver) (13/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 25) in 561 ms on 10.25.86.80 (executor driver) (14/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 16) in 563 ms on 10.25.86.80 (executor driver) (15/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 12.0 in stage 3.0 (TID 28) in 561 ms on 10.25.86.80 (executor driver) (16/16)
23/11/27 15:07:11 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
23/11/27 15:07:11 INFO DAGScheduler: ResultStage 3 (parquet at SparkTest.worksheet.sc:78) finished in 0.596 s
23/11/27 15:07:11 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
23/11/27 15:07:11 INFO DAGScheduler: Job 3 finished: parquet at SparkTest.worksheet.sc:78, took 0.598368 s
23/11/27 15:07:11 INFO FileFormatWriter: Start to commit write Job 5bc995be-2dbd-4929-83e4-cfb0c6f067ff.
23/11/27 15:07:11 INFO FileFormatWriter: Write Job 5bc995be-2dbd-4929-83e4-cfb0c6f067ff committed. Elapsed time: 11 ms.
23/11/27 15:07:11 INFO FileFormatWriter: Finished processing stats for write job 5bc995be-2dbd-4929-83e4-cfb0c6f067ff.
23/11/27 15:07:11 INFO InMemoryFileIndex: It took 9 ms to list leaf files for 1 paths.
23/11/27 15:07:11 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:82
23/11/27 15:07:11 INFO DAGScheduler: Got job 4 (parquet at SparkTest.worksheet.sc:82) with 1 output partitions
23/11/27 15:07:11 INFO DAGScheduler: Final stage: ResultStage 4 (parquet at SparkTest.worksheet.sc:82)
23/11/27 15:07:11 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:11 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:11 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:82), which has no missing parents
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.25.86.80:39667 (size: 36.9 KiB, free: 434.3 MiB)
23/11/27 15:07:11 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[7] at parquet at SparkTest.worksheet.sc:82) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:11 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
23/11/27 15:07:11 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 32) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/11/27 15:07:11 INFO Executor: Running task 0.0 in stage 4.0 (TID 32)
23/11/27 15:07:11 INFO Executor: Finished task 0.0 in stage 4.0 (TID 32). 2006 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 32) in 33 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:11 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
23/11/27 15:07:11 INFO DAGScheduler: ResultStage 4 (parquet at SparkTest.worksheet.sc:82) finished in 0.045 s
23/11/27 15:07:11 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
23/11/27 15:07:11 INFO DAGScheduler: Job 4 finished: parquet at SparkTest.worksheet.sc:82, took 0.048023 s
23/11/27 15:07:11 INFO FileSourceStrategy: Pushed Filters: 
23/11/27 15:07:11 INFO FileSourceStrategy: Post-Scan Filters: 
23/11/27 15:07:11 INFO CodeGenerator: Code generated in 14.313048 ms
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 200.7 KiB, free 433.8 MiB)
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.25.86.80:39667 (size: 34.9 KiB, free: 434.3 MiB)
23/11/27 15:07:11 INFO SparkContext: Created broadcast 5 from show at SparkTest.worksheet.sc:87
23/11/27 15:07:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/11/27 15:07:11 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 15:07:11 INFO DAGScheduler: Got job 5 (show at SparkTest.worksheet.sc:87) with 1 output partitions
23/11/27 15:07:11 INFO DAGScheduler: Final stage: ResultStage 5 (show at SparkTest.worksheet.sc:87)
23/11/27 15:07:11 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:11 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:11 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 15.9 KiB, free 433.7 MiB)
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.7 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.25.86.80:39667 (size: 6.7 KiB, free: 434.2 MiB)
23/11/27 15:07:11 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:11 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
23/11/27 15:07:11 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 33) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:11 INFO Executor: Running task 0.0 in stage 5.0 (TID 33)
23/11/27 15:07:11 INFO CodeGenerator: Code generated in 11.023133 ms
23/11/27 15:07:11 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00006-83dccce3-dea6-4444-98db-80806d64c508-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:07:11 INFO CodecPool: Got brand-new decompressor [.snappy]
23/11/27 15:07:11 INFO Executor: Finished task 0.0 in stage 5.0 (TID 33). 1842 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 33) in 82 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:11 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
23/11/27 15:07:11 INFO DAGScheduler: ResultStage 5 (show at SparkTest.worksheet.sc:87) finished in 0.099 s
23/11/27 15:07:11 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
23/11/27 15:07:11 INFO DAGScheduler: Job 5 finished: show at SparkTest.worksheet.sc:87, took 0.102993 s
23/11/27 15:07:11 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 15:07:11 INFO DAGScheduler: Got job 6 (show at SparkTest.worksheet.sc:87) with 4 output partitions
23/11/27 15:07:11 INFO DAGScheduler: Final stage: ResultStage 6 (show at SparkTest.worksheet.sc:87)
23/11/27 15:07:11 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:11 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:11 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 15.9 KiB, free 433.7 MiB)
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.7 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.25.86.80:39667 (size: 6.7 KiB, free: 434.2 MiB)
23/11/27 15:07:11 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:11 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 15:07:11 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks resource profile 0
23/11/27 15:07:11 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 34) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 35) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 36) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 37) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:11 INFO Executor: Running task 2.0 in stage 6.0 (TID 36)
23/11/27 15:07:11 INFO Executor: Running task 1.0 in stage 6.0 (TID 35)
23/11/27 15:07:11 INFO Executor: Running task 0.0 in stage 6.0 (TID 34)
23/11/27 15:07:11 INFO Executor: Running task 3.0 in stage 6.0 (TID 37)
23/11/27 15:07:11 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00015-83dccce3-dea6-4444-98db-80806d64c508-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:07:11 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00009-83dccce3-dea6-4444-98db-80806d64c508-c000.snappy.parquet, range: 0-957, partition values: [empty row]
23/11/27 15:07:11 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00003-83dccce3-dea6-4444-98db-80806d64c508-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:07:11 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00012-83dccce3-dea6-4444-98db-80806d64c508-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:07:11 INFO CodecPool: Got brand-new decompressor [.snappy]
23/11/27 15:07:11 INFO CodecPool: Got brand-new decompressor [.snappy]
23/11/27 15:07:11 INFO CodecPool: Got brand-new decompressor [.snappy]
23/11/27 15:07:11 INFO Executor: Finished task 0.0 in stage 6.0 (TID 34). 1842 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 2.0 in stage 6.0 (TID 36). 1842 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 3.0 in stage 6.0 (TID 37). 1842 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 1.0 in stage 6.0 (TID 35). 1842 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 34) in 11 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 36) in 10 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 37) in 10 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 35) in 12 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 15:07:11 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
23/11/27 15:07:11 INFO DAGScheduler: ResultStage 6 (show at SparkTest.worksheet.sc:87) finished in 0.016 s
23/11/27 15:07:11 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
23/11/27 15:07:11 INFO DAGScheduler: Job 6 finished: show at SparkTest.worksheet.sc:87, took 0.017338 s
23/11/27 15:07:11 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 15:07:11 INFO DAGScheduler: Got job 7 (show at SparkTest.worksheet.sc:87) with 1 output partitions
23/11/27 15:07:11 INFO DAGScheduler: Final stage: ResultStage 7 (show at SparkTest.worksheet.sc:87)
23/11/27 15:07:11 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:11 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:11 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 15.9 KiB, free 433.7 MiB)
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.7 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.25.86.80:39667 (size: 6.7 KiB, free: 434.2 MiB)
23/11/27 15:07:11 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[11] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(5))
23/11/27 15:07:11 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
23/11/27 15:07:11 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 38) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:11 INFO Executor: Running task 0.0 in stage 7.0 (TID 38)
23/11/27 15:07:11 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-83dccce3-dea6-4444-98db-80806d64c508-c000.snappy.parquet, range: 0-501, partition values: [empty row]
23/11/27 15:07:11 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.25.86.80:39667 in memory (size: 36.9 KiB, free: 434.3 MiB)
23/11/27 15:07:11 INFO Executor: Finished task 0.0 in stage 7.0 (TID 38). 1792 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 38) in 15 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:11 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
23/11/27 15:07:11 INFO DAGScheduler: ResultStage 7 (show at SparkTest.worksheet.sc:87) finished in 0.020 s
23/11/27 15:07:11 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
23/11/27 15:07:11 INFO DAGScheduler: Job 7 finished: show at SparkTest.worksheet.sc:87, took 0.022745 s
23/11/27 15:07:11 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.25.86.80:39667 in memory (size: 6.7 KiB, free: 434.3 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.25.86.80:39667 in memory (size: 6.7 KiB, free: 434.3 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.25.86.80:39667 in memory (size: 76.9 KiB, free: 434.4 MiB)
23/11/27 15:07:11 INFO CodeGenerator: Code generated in 9.803949 ms
23/11/27 15:07:11 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 15:07:11 INFO DAGScheduler: Got job 8 (show at SparkTest.worksheet.sc:100) with 1 output partitions
23/11/27 15:07:11 INFO DAGScheduler: Final stage: ResultStage 8 (show at SparkTest.worksheet.sc:100)
23/11/27 15:07:11 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:11 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:11 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 15.2 KiB, free 434.1 MiB)
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.25.86.80:39667 (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:07:11 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:11 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
23/11/27 15:07:11 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 39) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:11 INFO Executor: Running task 0.0 in stage 8.0 (TID 39)
23/11/27 15:07:11 INFO CodeGenerator: Code generated in 7.726243 ms
23/11/27 15:07:11 INFO Executor: Finished task 0.0 in stage 8.0 (TID 39). 1498 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 39) in 14 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:11 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
23/11/27 15:07:11 INFO DAGScheduler: ResultStage 8 (show at SparkTest.worksheet.sc:100) finished in 0.022 s
23/11/27 15:07:11 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
23/11/27 15:07:11 INFO DAGScheduler: Job 8 finished: show at SparkTest.worksheet.sc:100, took 0.025654 s
23/11/27 15:07:11 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 15:07:11 INFO DAGScheduler: Got job 9 (show at SparkTest.worksheet.sc:100) with 4 output partitions
23/11/27 15:07:11 INFO DAGScheduler: Final stage: ResultStage 9 (show at SparkTest.worksheet.sc:100)
23/11/27 15:07:11 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:11 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:11 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 15.2 KiB, free 434.1 MiB)
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.25.86.80:39667 (size: 6.5 KiB, free: 434.3 MiB)
23/11/27 15:07:11 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:11 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 9 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 15:07:11 INFO TaskSchedulerImpl: Adding task set 9.0 with 4 tasks resource profile 0
23/11/27 15:07:11 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 40) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 41) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 42) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 43) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:11 INFO Executor: Running task 1.0 in stage 9.0 (TID 41)
23/11/27 15:07:11 INFO Executor: Running task 3.0 in stage 9.0 (TID 43)
23/11/27 15:07:11 INFO Executor: Running task 2.0 in stage 9.0 (TID 42)
23/11/27 15:07:11 INFO Executor: Running task 0.0 in stage 9.0 (TID 40)
23/11/27 15:07:11 INFO Executor: Finished task 1.0 in stage 9.0 (TID 41). 1455 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 0.0 in stage 9.0 (TID 40). 1455 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 3.0 in stage 9.0 (TID 43). 1455 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 40) in 6 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 41) in 6 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 43) in 6 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 15:07:11 INFO Executor: Finished task 2.0 in stage 9.0 (TID 42). 1554 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 42) in 9 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 15:07:11 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
23/11/27 15:07:11 INFO DAGScheduler: ResultStage 9 (show at SparkTest.worksheet.sc:100) finished in 0.014 s
23/11/27 15:07:11 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
23/11/27 15:07:11 INFO DAGScheduler: Job 9 finished: show at SparkTest.worksheet.sc:100, took 0.016069 s
23/11/27 15:07:11 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 15:07:11 INFO DAGScheduler: Got job 10 (show at SparkTest.worksheet.sc:100) with 11 output partitions
23/11/27 15:07:11 INFO DAGScheduler: Final stage: ResultStage 10 (show at SparkTest.worksheet.sc:100)
23/11/27 15:07:11 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:11 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:11 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 15.2 KiB, free 434.1 MiB)
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.25.86.80:39667 (size: 6.5 KiB, free: 434.3 MiB)
23/11/27 15:07:11 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:11 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 10 (MapPartitionsRDD[13] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15))
23/11/27 15:07:11 INFO TaskSchedulerImpl: Adding task set 10.0 with 11 tasks resource profile 0
23/11/27 15:07:11 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 44) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 45) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 46) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 47) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 48) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 49) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 50) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 51) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 8.0 in stage 10.0 (TID 52) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 9.0 in stage 10.0 (TID 53) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 10.0 in stage 10.0 (TID 54) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:11 INFO Executor: Running task 4.0 in stage 10.0 (TID 48)
23/11/27 15:07:11 INFO Executor: Running task 1.0 in stage 10.0 (TID 45)
23/11/27 15:07:11 INFO Executor: Running task 3.0 in stage 10.0 (TID 47)
23/11/27 15:07:11 INFO Executor: Running task 2.0 in stage 10.0 (TID 46)
23/11/27 15:07:11 INFO Executor: Running task 6.0 in stage 10.0 (TID 50)
23/11/27 15:07:11 INFO Executor: Running task 0.0 in stage 10.0 (TID 44)
23/11/27 15:07:11 INFO Executor: Running task 8.0 in stage 10.0 (TID 52)
23/11/27 15:07:11 INFO Executor: Running task 10.0 in stage 10.0 (TID 54)
23/11/27 15:07:11 INFO Executor: Running task 5.0 in stage 10.0 (TID 49)
23/11/27 15:07:11 INFO Executor: Running task 9.0 in stage 10.0 (TID 53)
23/11/27 15:07:11 INFO Executor: Running task 7.0 in stage 10.0 (TID 51)
23/11/27 15:07:11 INFO Executor: Finished task 0.0 in stage 10.0 (TID 44). 1455 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 6.0 in stage 10.0 (TID 50). 1455 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 44) in 7 ms on 10.25.86.80 (executor driver) (1/11)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 50) in 6 ms on 10.25.86.80 (executor driver) (2/11)
23/11/27 15:07:11 INFO Executor: Finished task 9.0 in stage 10.0 (TID 53). 1498 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 9.0 in stage 10.0 (TID 53) in 5 ms on 10.25.86.80 (executor driver) (3/11)
23/11/27 15:07:11 INFO Executor: Finished task 5.0 in stage 10.0 (TID 49). 1498 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 8.0 in stage 10.0 (TID 52). 1498 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 49) in 7 ms on 10.25.86.80 (executor driver) (4/11)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 8.0 in stage 10.0 (TID 52) in 6 ms on 10.25.86.80 (executor driver) (5/11)
23/11/27 15:07:11 INFO Executor: Finished task 3.0 in stage 10.0 (TID 47). 1498 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 47) in 7 ms on 10.25.86.80 (executor driver) (6/11)
23/11/27 15:07:11 INFO Executor: Finished task 2.0 in stage 10.0 (TID 46). 1498 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 46) in 9 ms on 10.25.86.80 (executor driver) (7/11)
23/11/27 15:07:11 INFO Executor: Finished task 4.0 in stage 10.0 (TID 48). 1554 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 48) in 9 ms on 10.25.86.80 (executor driver) (8/11)
23/11/27 15:07:11 INFO Executor: Finished task 1.0 in stage 10.0 (TID 45). 1554 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 10.0 in stage 10.0 (TID 54). 1547 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 7.0 in stage 10.0 (TID 51). 1547 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 45) in 11 ms on 10.25.86.80 (executor driver) (9/11)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 10.0 in stage 10.0 (TID 54) in 9 ms on 10.25.86.80 (executor driver) (10/11)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 51) in 9 ms on 10.25.86.80 (executor driver) (11/11)
23/11/27 15:07:11 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
23/11/27 15:07:11 INFO DAGScheduler: ResultStage 10 (show at SparkTest.worksheet.sc:100) finished in 0.016 s
23/11/27 15:07:11 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
23/11/27 15:07:11 INFO DAGScheduler: Job 10 finished: show at SparkTest.worksheet.sc:100, took 0.017835 s
23/11/27 15:07:11 INFO DAGScheduler: Registering RDD 15 (show at SparkTest.worksheet.sc:116) as input to shuffle 0
23/11/27 15:07:11 INFO DAGScheduler: Got map stage job 11 (show at SparkTest.worksheet.sc:116) with 16 output partitions
23/11/27 15:07:11 INFO DAGScheduler: Final stage: ShuffleMapStage 11 (show at SparkTest.worksheet.sc:116)
23/11/27 15:07:11 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:11 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:11 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[15] at show at SparkTest.worksheet.sc:116), which has no missing parents
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 17.1 KiB, free 434.1 MiB)
23/11/27 15:07:11 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.1 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.25.86.80:39667 (size: 7.6 KiB, free: 434.3 MiB)
23/11/27 15:07:11 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:11 INFO DAGScheduler: Submitting 16 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[15] at show at SparkTest.worksheet.sc:116) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
23/11/27 15:07:11 INFO TaskSchedulerImpl: Adding task set 11.0 with 16 tasks resource profile 0
23/11/27 15:07:11 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 55) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 56) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 57) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 58) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 4.0 in stage 11.0 (TID 59) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 5.0 in stage 11.0 (TID 60) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 6.0 in stage 11.0 (TID 61) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 7.0 in stage 11.0 (TID 62) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 8.0 in stage 11.0 (TID 63) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 9.0 in stage 11.0 (TID 64) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 10.0 in stage 11.0 (TID 65) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 11.0 in stage 11.0 (TID 66) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 12.0 in stage 11.0 (TID 67) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 13.0 in stage 11.0 (TID 68) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 14.0 in stage 11.0 (TID 69) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:11 INFO TaskSetManager: Starting task 15.0 in stage 11.0 (TID 70) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:07:11 INFO Executor: Running task 0.0 in stage 11.0 (TID 55)
23/11/27 15:07:11 INFO Executor: Running task 8.0 in stage 11.0 (TID 63)
23/11/27 15:07:11 INFO Executor: Running task 7.0 in stage 11.0 (TID 62)
23/11/27 15:07:11 INFO Executor: Running task 6.0 in stage 11.0 (TID 61)
23/11/27 15:07:11 INFO Executor: Running task 9.0 in stage 11.0 (TID 64)
23/11/27 15:07:11 INFO Executor: Running task 5.0 in stage 11.0 (TID 60)
23/11/27 15:07:11 INFO Executor: Running task 2.0 in stage 11.0 (TID 57)
23/11/27 15:07:11 INFO Executor: Running task 14.0 in stage 11.0 (TID 69)
23/11/27 15:07:11 INFO Executor: Running task 13.0 in stage 11.0 (TID 68)
23/11/27 15:07:11 INFO Executor: Running task 12.0 in stage 11.0 (TID 67)
23/11/27 15:07:11 INFO Executor: Running task 11.0 in stage 11.0 (TID 66)
23/11/27 15:07:11 INFO Executor: Running task 1.0 in stage 11.0 (TID 56)
23/11/27 15:07:11 INFO Executor: Running task 4.0 in stage 11.0 (TID 59)
23/11/27 15:07:11 INFO Executor: Running task 15.0 in stage 11.0 (TID 70)
23/11/27 15:07:11 INFO Executor: Running task 10.0 in stage 11.0 (TID 65)
23/11/27 15:07:11 INFO Executor: Running task 3.0 in stage 11.0 (TID 58)
23/11/27 15:07:11 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.25.86.80:39667 in memory (size: 34.9 KiB, free: 434.4 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.25.86.80:39667 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.25.86.80:39667 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.25.86.80:39667 in memory (size: 6.7 KiB, free: 434.4 MiB)
23/11/27 15:07:11 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.25.86.80:39667 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:07:11 INFO CodeGenerator: Code generated in 10.599719 ms
23/11/27 15:07:11 INFO Executor: Finished task 7.0 in stage 11.0 (TID 62). 1905 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 1.0 in stage 11.0 (TID 56). 1948 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 13.0 in stage 11.0 (TID 68). 1948 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 5.0 in stage 11.0 (TID 60). 1948 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 10.0 in stage 11.0 (TID 65). 1948 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 8.0 in stage 11.0 (TID 63). 1948 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 4.0 in stage 11.0 (TID 59). 1948 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 11.0 in stage 11.0 (TID 66). 1948 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 0.0 in stage 11.0 (TID 55). 1905 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 2.0 in stage 11.0 (TID 57). 1948 bytes result sent to driver
23/11/27 15:07:11 INFO Executor: Finished task 14.0 in stage 11.0 (TID 69). 1948 bytes result sent to driver
23/11/27 15:07:11 INFO TaskSetManager: Finished task 13.0 in stage 11.0 (TID 68) in 57 ms on 10.25.86.80 (executor driver) (1/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 10.0 in stage 11.0 (TID 65) in 57 ms on 10.25.86.80 (executor driver) (2/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 5.0 in stage 11.0 (TID 60) in 58 ms on 10.25.86.80 (executor driver) (3/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 4.0 in stage 11.0 (TID 59) in 59 ms on 10.25.86.80 (executor driver) (4/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 7.0 in stage 11.0 (TID 62) in 59 ms on 10.25.86.80 (executor driver) (5/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 56) in 60 ms on 10.25.86.80 (executor driver) (6/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 8.0 in stage 11.0 (TID 63) in 59 ms on 10.25.86.80 (executor driver) (7/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 55) in 60 ms on 10.25.86.80 (executor driver) (8/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 57) in 60 ms on 10.25.86.80 (executor driver) (9/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 11.0 in stage 11.0 (TID 66) in 58 ms on 10.25.86.80 (executor driver) (10/16)
23/11/27 15:07:11 INFO TaskSetManager: Finished task 14.0 in stage 11.0 (TID 69) in 57 ms on 10.25.86.80 (executor driver) (11/16)
23/11/27 15:07:12 INFO Executor: Finished task 9.0 in stage 11.0 (TID 64). 2034 bytes result sent to driver
23/11/27 15:07:12 INFO Executor: Finished task 3.0 in stage 11.0 (TID 58). 2034 bytes result sent to driver
23/11/27 15:07:12 INFO Executor: Finished task 15.0 in stage 11.0 (TID 70). 2034 bytes result sent to driver
23/11/27 15:07:12 INFO Executor: Finished task 12.0 in stage 11.0 (TID 67). 2034 bytes result sent to driver
23/11/27 15:07:12 INFO Executor: Finished task 6.0 in stage 11.0 (TID 61). 2034 bytes result sent to driver
23/11/27 15:07:12 INFO TaskSetManager: Finished task 9.0 in stage 11.0 (TID 64) in 81 ms on 10.25.86.80 (executor driver) (12/16)
23/11/27 15:07:12 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 58) in 82 ms on 10.25.86.80 (executor driver) (13/16)
23/11/27 15:07:12 INFO TaskSetManager: Finished task 15.0 in stage 11.0 (TID 70) in 80 ms on 10.25.86.80 (executor driver) (14/16)
23/11/27 15:07:12 INFO TaskSetManager: Finished task 12.0 in stage 11.0 (TID 67) in 81 ms on 10.25.86.80 (executor driver) (15/16)
23/11/27 15:07:12 INFO TaskSetManager: Finished task 6.0 in stage 11.0 (TID 61) in 83 ms on 10.25.86.80 (executor driver) (16/16)
23/11/27 15:07:12 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
23/11/27 15:07:12 INFO DAGScheduler: ShuffleMapStage 11 (show at SparkTest.worksheet.sc:116) finished in 0.098 s
23/11/27 15:07:12 INFO DAGScheduler: looking for newly runnable stages
23/11/27 15:07:12 INFO DAGScheduler: running: HashSet()
23/11/27 15:07:12 INFO DAGScheduler: waiting: HashSet()
23/11/27 15:07:12 INFO DAGScheduler: failed: HashSet()
23/11/27 15:07:12 INFO ShufflePartitionsUtil: For shuffle(0, 0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/27 15:07:12 INFO CodeGenerator: Code generated in 21.936153 ms
23/11/27 15:07:12 INFO CodeGenerator: Code generated in 6.640333 ms
23/11/27 15:07:12 INFO CodeGenerator: Code generated in 5.509012 ms
23/11/27 15:07:12 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/27 15:07:12 INFO DAGScheduler: Got job 12 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/27 15:07:12 INFO DAGScheduler: Final stage: ResultStage 13 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/27 15:07:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
23/11/27 15:07:12 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:12 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[22] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/27 15:07:12 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 39.1 KiB, free 434.3 MiB)
23/11/27 15:07:12 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 434.3 MiB)
23/11/27 15:07:12 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.25.86.80:39667 (size: 16.4 KiB, free: 434.4 MiB)
23/11/27 15:07:12 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[22] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:12 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
23/11/27 15:07:12 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 71) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/27 15:07:12 INFO Executor: Running task 0.0 in stage 13.0 (TID 71)
23/11/27 15:07:12 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 15:07:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
23/11/27 15:07:12 INFO CodeGenerator: Code generated in 5.79583 ms
23/11/27 15:07:12 INFO CodeGenerator: Code generated in 15.11894 ms
23/11/27 15:07:12 INFO CodeGenerator: Code generated in 5.642314 ms
23/11/27 15:07:12 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 15:07:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/27 15:07:12 INFO CodeGenerator: Code generated in 5.550274 ms
23/11/27 15:07:12 INFO CodeGenerator: Code generated in 15.054296 ms
23/11/27 15:07:12 INFO Executor: Finished task 0.0 in stage 13.0 (TID 71). 4879 bytes result sent to driver
23/11/27 15:07:12 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 71) in 118 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:12 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
23/11/27 15:07:12 INFO DAGScheduler: ResultStage 13 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.126 s
23/11/27 15:07:12 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
23/11/27 15:07:12 INFO DAGScheduler: Job 12 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.134254 s
23/11/27 15:07:12 INFO CodeGenerator: Code generated in 6.083953 ms
23/11/27 15:07:12 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 1025.0 KiB, free 433.3 MiB)
23/11/27 15:07:12 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 279.0 B, free 433.3 MiB)
23/11/27 15:07:12 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.25.86.80:39667 (size: 279.0 B, free: 434.4 MiB)
23/11/27 15:07:12 INFO SparkContext: Created broadcast 14 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/27 15:07:12 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/27 15:07:12 INFO CodeGenerator: Code generated in 11.448125 ms
23/11/27 15:07:12 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:116
23/11/27 15:07:12 INFO DAGScheduler: Got job 13 (show at SparkTest.worksheet.sc:116) with 1 output partitions
23/11/27 15:07:12 INFO DAGScheduler: Final stage: ResultStage 15 (show at SparkTest.worksheet.sc:116)
23/11/27 15:07:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
23/11/27 15:07:12 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:12 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[25] at show at SparkTest.worksheet.sc:116), which has no missing parents
23/11/27 15:07:12 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 15.3 KiB, free 433.3 MiB)
23/11/27 15:07:12 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 433.3 MiB)
23/11/27 15:07:12 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.25.86.80:39667 (size: 7.0 KiB, free: 434.4 MiB)
23/11/27 15:07:12 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[25] at show at SparkTest.worksheet.sc:116) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:12 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
23/11/27 15:07:12 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 72) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7711 bytes) 
23/11/27 15:07:12 INFO Executor: Running task 0.0 in stage 15.0 (TID 72)
23/11/27 15:07:12 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 15:07:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/27 15:07:12 INFO CodeGenerator: Code generated in 7.271298 ms
23/11/27 15:07:12 INFO Executor: Finished task 0.0 in stage 15.0 (TID 72). 3989 bytes result sent to driver
23/11/27 15:07:12 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 72) in 14 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:12 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
23/11/27 15:07:12 INFO DAGScheduler: ResultStage 15 (show at SparkTest.worksheet.sc:116) finished in 0.019 s
23/11/27 15:07:12 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
23/11/27 15:07:12 INFO DAGScheduler: Job 13 finished: show at SparkTest.worksheet.sc:116, took 0.021908 s
2023.11.27 15:07:12 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 9.09s[0m
23/11/27 15:07:12 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.25.86.80:39667 in memory (size: 16.4 KiB, free: 434.4 MiB)
23/11/27 15:07:12 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.25.86.80:39667 in memory (size: 7.0 KiB, free: 434.4 MiB)
23/11/27 15:07:12 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.25.86.80:39667 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/27 15:07:13 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.25.86.80:39667 in memory (size: 279.0 B, free: 434.4 MiB)
23/11/27 15:07:13 INFO CodeGenerator: Code generated in 6.074232 ms
23/11/27 15:07:13 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 15:07:13 INFO DAGScheduler: Got job 14 (show at SparkTest.worksheet.sc:68) with 1 output partitions
23/11/27 15:07:13 INFO DAGScheduler: Final stage: ResultStage 16 (show at SparkTest.worksheet.sc:68)
23/11/27 15:07:13 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:13 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:13 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[29] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/11/27 15:07:13 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.25.86.80:39667 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:07:13 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[29] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:13 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
23/11/27 15:07:13 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 73) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO Executor: Running task 0.0 in stage 16.0 (TID 73)
23/11/27 15:07:13 INFO Executor: Finished task 0.0 in stage 16.0 (TID 73). 1455 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 73) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:13 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
23/11/27 15:07:13 INFO DAGScheduler: ResultStage 16 (show at SparkTest.worksheet.sc:68) finished in 0.010 s
23/11/27 15:07:13 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
23/11/27 15:07:13 INFO DAGScheduler: Job 14 finished: show at SparkTest.worksheet.sc:68, took 0.012093 s
23/11/27 15:07:13 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 15:07:13 INFO DAGScheduler: Got job 15 (show at SparkTest.worksheet.sc:68) with 4 output partitions
23/11/27 15:07:13 INFO DAGScheduler: Final stage: ResultStage 17 (show at SparkTest.worksheet.sc:68)
23/11/27 15:07:13 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:13 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:13 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[29] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/11/27 15:07:13 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.25.86.80:39667 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:07:13 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 10.25.86.80:39667 in memory (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:07:13 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:13 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 17 (MapPartitionsRDD[29] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 15:07:13 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks resource profile 0
23/11/27 15:07:13 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 74) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 75) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 76) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 77) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO Executor: Running task 0.0 in stage 17.0 (TID 74)
23/11/27 15:07:13 INFO Executor: Running task 2.0 in stage 17.0 (TID 76)
23/11/27 15:07:13 INFO Executor: Running task 1.0 in stage 17.0 (TID 75)
23/11/27 15:07:13 INFO Executor: Running task 3.0 in stage 17.0 (TID 77)
23/11/27 15:07:13 INFO Executor: Finished task 0.0 in stage 17.0 (TID 74). 1455 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 1.0 in stage 17.0 (TID 75). 1455 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 3.0 in stage 17.0 (TID 77). 1455 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 74) in 4 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 75) in 5 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 77) in 5 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 15:07:13 INFO Executor: Finished task 2.0 in stage 17.0 (TID 76). 1548 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 76) in 7 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 15:07:13 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
23/11/27 15:07:13 INFO DAGScheduler: ResultStage 17 (show at SparkTest.worksheet.sc:68) finished in 0.019 s
23/11/27 15:07:13 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
23/11/27 15:07:13 INFO DAGScheduler: Job 15 finished: show at SparkTest.worksheet.sc:68, took 0.020979 s
23/11/27 15:07:13 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:68
23/11/27 15:07:13 INFO DAGScheduler: Got job 16 (show at SparkTest.worksheet.sc:68) with 11 output partitions
23/11/27 15:07:13 INFO DAGScheduler: Final stage: ResultStage 18 (show at SparkTest.worksheet.sc:68)
23/11/27 15:07:13 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:13 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:13 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[29] at show at SparkTest.worksheet.sc:68), which has no missing parents
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 14.4 KiB, free 434.4 MiB)
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
23/11/27 15:07:13 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.25.86.80:39667 (size: 6.2 KiB, free: 434.4 MiB)
23/11/27 15:07:13 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:13 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 18 (MapPartitionsRDD[29] at show at SparkTest.worksheet.sc:68) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15))
23/11/27 15:07:13 INFO TaskSchedulerImpl: Adding task set 18.0 with 11 tasks resource profile 0
23/11/27 15:07:13 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 78) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 79) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 80) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 81) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 4.0 in stage 18.0 (TID 82) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 5.0 in stage 18.0 (TID 83) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 6.0 in stage 18.0 (TID 84) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 7.0 in stage 18.0 (TID 85) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 8.0 in stage 18.0 (TID 86) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 9.0 in stage 18.0 (TID 87) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 10.0 in stage 18.0 (TID 88) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:13 INFO Executor: Running task 3.0 in stage 18.0 (TID 81)
23/11/27 15:07:13 INFO Executor: Running task 7.0 in stage 18.0 (TID 85)
23/11/27 15:07:13 INFO Executor: Running task 6.0 in stage 18.0 (TID 84)
23/11/27 15:07:13 INFO Executor: Running task 10.0 in stage 18.0 (TID 88)
23/11/27 15:07:13 INFO Executor: Running task 9.0 in stage 18.0 (TID 87)
23/11/27 15:07:13 INFO Executor: Running task 5.0 in stage 18.0 (TID 83)
23/11/27 15:07:13 INFO Executor: Running task 1.0 in stage 18.0 (TID 79)
23/11/27 15:07:13 INFO Executor: Running task 2.0 in stage 18.0 (TID 80)
23/11/27 15:07:13 INFO Executor: Running task 4.0 in stage 18.0 (TID 82)
23/11/27 15:07:13 INFO Executor: Running task 8.0 in stage 18.0 (TID 86)
23/11/27 15:07:13 INFO Executor: Running task 0.0 in stage 18.0 (TID 78)
23/11/27 15:07:13 INFO Executor: Finished task 6.0 in stage 18.0 (TID 84). 1498 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 5.0 in stage 18.0 (TID 83). 1455 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 8.0 in stage 18.0 (TID 86). 1498 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 9.0 in stage 18.0 (TID 87). 1498 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 3.0 in stage 18.0 (TID 81). 1498 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 0.0 in stage 18.0 (TID 78). 1498 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 9.0 in stage 18.0 (TID 87) in 6 ms on 10.25.86.80 (executor driver) (1/11)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 8.0 in stage 18.0 (TID 86) in 6 ms on 10.25.86.80 (executor driver) (2/11)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 5.0 in stage 18.0 (TID 83) in 6 ms on 10.25.86.80 (executor driver) (3/11)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 6.0 in stage 18.0 (TID 84) in 6 ms on 10.25.86.80 (executor driver) (4/11)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 81) in 7 ms on 10.25.86.80 (executor driver) (5/11)
23/11/27 15:07:13 INFO Executor: Finished task 2.0 in stage 18.0 (TID 80). 1455 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 78) in 8 ms on 10.25.86.80 (executor driver) (6/11)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 80) in 7 ms on 10.25.86.80 (executor driver) (7/11)
23/11/27 15:07:13 INFO Executor: Finished task 7.0 in stage 18.0 (TID 85). 1548 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 7.0 in stage 18.0 (TID 85) in 8 ms on 10.25.86.80 (executor driver) (8/11)
23/11/27 15:07:13 INFO Executor: Finished task 4.0 in stage 18.0 (TID 82). 1548 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 10.0 in stage 18.0 (TID 88). 1548 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 1.0 in stage 18.0 (TID 79). 1548 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 4.0 in stage 18.0 (TID 82) in 9 ms on 10.25.86.80 (executor driver) (9/11)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 10.0 in stage 18.0 (TID 88) in 8 ms on 10.25.86.80 (executor driver) (10/11)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 79) in 9 ms on 10.25.86.80 (executor driver) (11/11)
23/11/27 15:07:13 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
23/11/27 15:07:13 INFO DAGScheduler: ResultStage 18 (show at SparkTest.worksheet.sc:68) finished in 0.015 s
23/11/27 15:07:13 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
23/11/27 15:07:13 INFO DAGScheduler: Job 16 finished: show at SparkTest.worksheet.sc:68, took 0.017174 s
23/11/27 15:07:13 INFO CodeGenerator: Code generated in 6.638098 ms
23/11/27 15:07:13 INFO ParquetUtils: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO CodeGenerator: Code generated in 5.173214 ms
23/11/27 15:07:13 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:78
23/11/27 15:07:13 INFO DAGScheduler: Got job 17 (parquet at SparkTest.worksheet.sc:78) with 16 output partitions
23/11/27 15:07:13 INFO DAGScheduler: Final stage: ResultStage 19 (parquet at SparkTest.worksheet.sc:78)
23/11/27 15:07:13 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:13 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:13 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[31] at parquet at SparkTest.worksheet.sc:78), which has no missing parents
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 214.5 KiB, free 434.2 MiB)
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 76.8 KiB, free 434.1 MiB)
23/11/27 15:07:13 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.25.86.80:39667 (size: 76.8 KiB, free: 434.3 MiB)
23/11/27 15:07:13 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:13 INFO DAGScheduler: Submitting 16 missing tasks from ResultStage 19 (MapPartitionsRDD[31] at parquet at SparkTest.worksheet.sc:78) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
23/11/27 15:07:13 INFO TaskSchedulerImpl: Adding task set 19.0 with 16 tasks resource profile 0
23/11/27 15:07:13 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 89) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 90) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 91) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 3.0 in stage 19.0 (TID 92) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 4.0 in stage 19.0 (TID 93) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 5.0 in stage 19.0 (TID 94) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 6.0 in stage 19.0 (TID 95) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 7.0 in stage 19.0 (TID 96) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 8.0 in stage 19.0 (TID 97) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 9.0 in stage 19.0 (TID 98) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 10.0 in stage 19.0 (TID 99) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 11.0 in stage 19.0 (TID 100) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 12.0 in stage 19.0 (TID 101) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 13.0 in stage 19.0 (TID 102) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 14.0 in stage 19.0 (TID 103) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:13 INFO TaskSetManager: Starting task 15.0 in stage 19.0 (TID 104) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:13 INFO Executor: Running task 6.0 in stage 19.0 (TID 95)
23/11/27 15:07:13 INFO Executor: Running task 4.0 in stage 19.0 (TID 93)
23/11/27 15:07:13 INFO Executor: Running task 8.0 in stage 19.0 (TID 97)
23/11/27 15:07:13 INFO Executor: Running task 9.0 in stage 19.0 (TID 98)
23/11/27 15:07:13 INFO Executor: Running task 12.0 in stage 19.0 (TID 101)
23/11/27 15:07:13 INFO Executor: Running task 10.0 in stage 19.0 (TID 99)
23/11/27 15:07:13 INFO Executor: Running task 14.0 in stage 19.0 (TID 103)
23/11/27 15:07:13 INFO Executor: Running task 13.0 in stage 19.0 (TID 102)
23/11/27 15:07:13 INFO Executor: Running task 15.0 in stage 19.0 (TID 104)
23/11/27 15:07:13 INFO Executor: Running task 2.0 in stage 19.0 (TID 91)
23/11/27 15:07:13 INFO Executor: Running task 0.0 in stage 19.0 (TID 89)
23/11/27 15:07:13 INFO Executor: Running task 3.0 in stage 19.0 (TID 92)
23/11/27 15:07:13 INFO Executor: Running task 7.0 in stage 19.0 (TID 96)
23/11/27 15:07:13 INFO Executor: Running task 5.0 in stage 19.0 (TID 94)
23/11/27 15:07:13 INFO Executor: Running task 11.0 in stage 19.0 (TID 100)
23/11/27 15:07:13 INFO Executor: Running task 1.0 in stage 19.0 (TID 90)
23/11/27 15:07:13 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 10.25.86.80:39667 in memory (size: 6.2 KiB, free: 434.3 MiB)
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507138556782872330340475_0019_m_000005_94
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507138556782872330340475_0019_m_000008_97
23/11/27 15:07:13 INFO Executor: Finished task 5.0 in stage 19.0 (TID 94). 2656 bytes result sent to driver
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO TaskSetManager: Finished task 5.0 in stage 19.0 (TID 94) in 67 ms on 10.25.86.80 (executor driver) (1/16)
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 10.25.86.80:39667 in memory (size: 6.2 KiB, free: 434.3 MiB)
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO Executor: Finished task 8.0 in stage 19.0 (TID 97). 2699 bytes result sent to driver
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507138556782872330340475_0019_m_000001_90
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507138556782872330340475_0019_m_000011_100
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO TaskSetManager: Finished task 8.0 in stage 19.0 (TID 97) in 79 ms on 10.25.86.80 (executor driver) (2/16)
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507138556782872330340475_0019_m_000002_91
23/11/27 15:07:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:13 INFO Executor: Finished task 11.0 in stage 19.0 (TID 100). 2656 bytes result sent to driver
23/11/27 15:07:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:13 INFO Executor: Finished task 2.0 in stage 19.0 (TID 91). 2656 bytes result sent to driver
23/11/27 15:07:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:13 INFO TaskSetManager: Finished task 11.0 in stage 19.0 (TID 100) in 80 ms on 10.25.86.80 (executor driver) (3/16)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 91) in 81 ms on 10.25.86.80 (executor driver) (4/16)
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507138556782872330340475_0019_m_000004_93
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507138556782872330340475_0019_m_000014_103
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507138556782872330340475_0019_m_000010_99
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO Executor: Finished task 14.0 in stage 19.0 (TID 103). 2656 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 10.0 in stage 19.0 (TID 99). 2656 bytes result sent to driver
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507138556782872330340475_0019_m_000007_96
23/11/27 15:07:13 INFO Executor: Finished task 1.0 in stage 19.0 (TID 90). 2656 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 4.0 in stage 19.0 (TID 93). 2656 bytes result sent to driver
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
23/11/27 15:07:13 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
23/11/27 15:07:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:13 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
23/11/27 15:07:13 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 90) in 84 ms on 10.25.86.80 (executor driver) (5/16)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 14.0 in stage 19.0 (TID 103) in 83 ms on 10.25.86.80 (executor driver) (6/16)
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: No need to commit output of task because needsTaskCommit=false: attempt_202311271507138556782872330340475_0019_m_000013_102
23/11/27 15:07:13 INFO Executor: Finished task 7.0 in stage 19.0 (TID 96). 2656 bytes result sent to driver
23/11/27 15:07:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:13 INFO Executor: Finished task 13.0 in stage 19.0 (TID 102). 2656 bytes result sent to driver
23/11/27 15:07:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO TaskSetManager: Finished task 4.0 in stage 19.0 (TID 93) in 87 ms on 10.25.86.80 (executor driver) (7/16)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 10.0 in stage 19.0 (TID 99) in 87 ms on 10.25.86.80 (executor driver) (8/16)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 7.0 in stage 19.0 (TID 96) in 87 ms on 10.25.86.80 (executor driver) (9/16)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 13.0 in stage 19.0 (TID 102) in 87 ms on 10.25.86.80 (executor driver) (10/16)
23/11/27 15:07:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO CodecConfig: Compression: SNAPPY
23/11/27 15:07:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:13 INFO ParquetOutputFormat: ParquetRecordWriter [block size: 134217728b, row group padding size: 8388608b, validating: false]
23/11/27 15:07:13 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "doubleField",
    "type" : "double",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "stringField",
    "type" : "string",
    "nullable" : false,
    "metadata" : { }
  }, {
    "name" : "intField",
    "type" : "integer",
    "nullable" : false,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  required double doubleField;
  required binary stringField (STRING);
  required int32 intField;
}

       
23/11/27 15:07:13 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507138556782872330340475_0019_m_000000_89' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507138556782872330340475_0019_m_000000
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: attempt_202311271507138556782872330340475_0019_m_000000_89: Committed. Elapsed time: 0 ms.
23/11/27 15:07:13 INFO Executor: Finished task 0.0 in stage 19.0 (TID 89). 2699 bytes result sent to driver
23/11/27 15:07:13 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507138556782872330340475_0019_m_000003_92' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507138556782872330340475_0019_m_000003
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: attempt_202311271507138556782872330340475_0019_m_000003_92: Committed. Elapsed time: 0 ms.
23/11/27 15:07:13 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507138556782872330340475_0019_m_000009_98' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507138556782872330340475_0019_m_000009
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: attempt_202311271507138556782872330340475_0019_m_000009_98: Committed. Elapsed time: 0 ms.
23/11/27 15:07:13 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 89) in 111 ms on 10.25.86.80 (executor driver) (11/16)
23/11/27 15:07:13 INFO Executor: Finished task 9.0 in stage 19.0 (TID 98). 2742 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 9.0 in stage 19.0 (TID 98) in 111 ms on 10.25.86.80 (executor driver) (12/16)
23/11/27 15:07:13 INFO Executor: Finished task 3.0 in stage 19.0 (TID 92). 2742 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 3.0 in stage 19.0 (TID 92) in 112 ms on 10.25.86.80 (executor driver) (13/16)
23/11/27 15:07:13 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507138556782872330340475_0019_m_000006_95' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507138556782872330340475_0019_m_000006
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: attempt_202311271507138556782872330340475_0019_m_000006_95: Committed. Elapsed time: 0 ms.
23/11/27 15:07:13 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507138556782872330340475_0019_m_000015_104' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507138556782872330340475_0019_m_000015
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: attempt_202311271507138556782872330340475_0019_m_000015_104: Committed. Elapsed time: 0 ms.
23/11/27 15:07:13 INFO Executor: Finished task 6.0 in stage 19.0 (TID 95). 2742 bytes result sent to driver
23/11/27 15:07:13 INFO Executor: Finished task 15.0 in stage 19.0 (TID 104). 2742 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 6.0 in stage 19.0 (TID 95) in 115 ms on 10.25.86.80 (executor driver) (14/16)
23/11/27 15:07:13 INFO TaskSetManager: Finished task 15.0 in stage 19.0 (TID 104) in 114 ms on 10.25.86.80 (executor driver) (15/16)
23/11/27 15:07:13 INFO FileOutputCommitter: Saved output of task 'attempt_202311271507138556782872330340475_0019_m_000012_101' to file:/home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/_temporary/0/task_202311271507138556782872330340475_0019_m_000012
23/11/27 15:07:13 INFO SparkHadoopMapRedUtil: attempt_202311271507138556782872330340475_0019_m_000012_101: Committed. Elapsed time: 0 ms.
23/11/27 15:07:13 INFO Executor: Finished task 12.0 in stage 19.0 (TID 101). 2742 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 12.0 in stage 19.0 (TID 101) in 117 ms on 10.25.86.80 (executor driver) (16/16)
23/11/27 15:07:13 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
23/11/27 15:07:13 INFO DAGScheduler: ResultStage 19 (parquet at SparkTest.worksheet.sc:78) finished in 0.139 s
23/11/27 15:07:13 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
23/11/27 15:07:13 INFO DAGScheduler: Job 17 finished: parquet at SparkTest.worksheet.sc:78, took 0.140805 s
23/11/27 15:07:13 INFO FileFormatWriter: Start to commit write Job a860df42-3c7e-4afc-9ab0-7f4bb88f6971.
23/11/27 15:07:13 INFO FileFormatWriter: Write Job a860df42-3c7e-4afc-9ab0-7f4bb88f6971 committed. Elapsed time: 8 ms.
23/11/27 15:07:13 INFO FileFormatWriter: Finished processing stats for write job a860df42-3c7e-4afc-9ab0-7f4bb88f6971.
23/11/27 15:07:13 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
23/11/27 15:07:13 INFO SparkContext: Starting job: parquet at SparkTest.worksheet.sc:82
23/11/27 15:07:13 INFO DAGScheduler: Got job 18 (parquet at SparkTest.worksheet.sc:82) with 1 output partitions
23/11/27 15:07:13 INFO DAGScheduler: Final stage: ResultStage 20 (parquet at SparkTest.worksheet.sc:82)
23/11/27 15:07:13 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:13 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:13 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[33] at parquet at SparkTest.worksheet.sc:82), which has no missing parents
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 102.9 KiB, free 434.0 MiB)
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 36.9 KiB, free 434.0 MiB)
23/11/27 15:07:13 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.25.86.80:39667 (size: 36.9 KiB, free: 434.3 MiB)
23/11/27 15:07:13 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[33] at parquet at SparkTest.worksheet.sc:82) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:13 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
23/11/27 15:07:13 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 105) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8013 bytes) 
23/11/27 15:07:13 INFO Executor: Running task 0.0 in stage 20.0 (TID 105)
23/11/27 15:07:13 INFO Executor: Finished task 0.0 in stage 20.0 (TID 105). 2006 bytes result sent to driver
23/11/27 15:07:13 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 105) in 7 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:13 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
23/11/27 15:07:13 INFO DAGScheduler: ResultStage 20 (parquet at SparkTest.worksheet.sc:82) finished in 0.030 s
23/11/27 15:07:13 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
23/11/27 15:07:13 INFO DAGScheduler: Job 18 finished: parquet at SparkTest.worksheet.sc:82, took 0.031521 s
23/11/27 15:07:13 INFO FileSourceStrategy: Pushed Filters: 
23/11/27 15:07:13 INFO FileSourceStrategy: Post-Scan Filters: 
23/11/27 15:07:13 INFO CodeGenerator: Code generated in 8.42886 ms
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 200.7 KiB, free 433.8 MiB)
23/11/27 15:07:13 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.7 MiB)
23/11/27 15:07:13 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.25.86.80:39667 (size: 34.9 KiB, free: 434.3 MiB)
23/11/27 15:07:13 INFO SparkContext: Created broadcast 21 from show at SparkTest.worksheet.sc:87
23/11/27 15:07:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
23/11/27 15:07:13 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 15:07:13 INFO DAGScheduler: Got job 19 (show at SparkTest.worksheet.sc:87) with 1 output partitions
23/11/27 15:07:13 INFO DAGScheduler: Final stage: ResultStage 21 (show at SparkTest.worksheet.sc:87)
23/11/27 15:07:13 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:13 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:13 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[37] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 15.9 KiB, free 433.7 MiB)
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.7 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.25.86.80:39667 (size: 6.7 KiB, free: 434.2 MiB)
23/11/27 15:07:14 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[37] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:14 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
23/11/27 15:07:14 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 106) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:14 INFO Executor: Running task 0.0 in stage 21.0 (TID 106)
23/11/27 15:07:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00006-8a6f02ba-ca0b-435d-bad4-6293d17222ca-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:07:14 INFO Executor: Finished task 0.0 in stage 21.0 (TID 106). 1842 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 106) in 8 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:14 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
23/11/27 15:07:14 INFO DAGScheduler: ResultStage 21 (show at SparkTest.worksheet.sc:87) finished in 0.015 s
23/11/27 15:07:14 INFO DAGScheduler: Job 19 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
23/11/27 15:07:14 INFO DAGScheduler: Job 19 finished: show at SparkTest.worksheet.sc:87, took 0.016672 s
23/11/27 15:07:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 15:07:14 INFO DAGScheduler: Got job 20 (show at SparkTest.worksheet.sc:87) with 4 output partitions
23/11/27 15:07:14 INFO DAGScheduler: Final stage: ResultStage 22 (show at SparkTest.worksheet.sc:87)
23/11/27 15:07:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:14 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[37] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 15.9 KiB, free 433.7 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 10.25.86.80:39667 in memory (size: 6.7 KiB, free: 434.3 MiB)
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.7 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.25.86.80:39667 (size: 6.7 KiB, free: 434.2 MiB)
23/11/27 15:07:14 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 10.25.86.80:39667 in memory (size: 36.9 KiB, free: 434.3 MiB)
23/11/27 15:07:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 22 (MapPartitionsRDD[37] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 15:07:14 INFO TaskSchedulerImpl: Adding task set 22.0 with 4 tasks resource profile 0
23/11/27 15:07:14 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 107) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 108) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 109) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 3.0 in stage 22.0 (TID 110) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:14 INFO Executor: Running task 2.0 in stage 22.0 (TID 109)
23/11/27 15:07:14 INFO Executor: Running task 0.0 in stage 22.0 (TID 107)
23/11/27 15:07:14 INFO Executor: Running task 1.0 in stage 22.0 (TID 108)
23/11/27 15:07:14 INFO Executor: Running task 3.0 in stage 22.0 (TID 110)
23/11/27 15:07:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00012-8a6f02ba-ca0b-435d-bad4-6293d17222ca-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:07:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00015-8a6f02ba-ca0b-435d-bad4-6293d17222ca-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:07:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00003-8a6f02ba-ca0b-435d-bad4-6293d17222ca-c000.snappy.parquet, range: 0-959, partition values: [empty row]
23/11/27 15:07:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00009-8a6f02ba-ca0b-435d-bad4-6293d17222ca-c000.snappy.parquet, range: 0-957, partition values: [empty row]
23/11/27 15:07:14 INFO Executor: Finished task 3.0 in stage 22.0 (TID 110). 1842 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 1.0 in stage 22.0 (TID 108). 1842 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 0.0 in stage 22.0 (TID 107). 1842 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 2.0 in stage 22.0 (TID 109). 1842 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 3.0 in stage 22.0 (TID 110) in 8 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 108) in 8 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 109) in 8 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 107) in 9 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 15:07:14 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
23/11/27 15:07:14 INFO DAGScheduler: ResultStage 22 (show at SparkTest.worksheet.sc:87) finished in 0.016 s
23/11/27 15:07:14 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 22: Stage finished
23/11/27 15:07:14 INFO DAGScheduler: Job 20 finished: show at SparkTest.worksheet.sc:87, took 0.017096 s
23/11/27 15:07:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:87
23/11/27 15:07:14 INFO DAGScheduler: Got job 21 (show at SparkTest.worksheet.sc:87) with 1 output partitions
23/11/27 15:07:14 INFO DAGScheduler: Final stage: ResultStage 23 (show at SparkTest.worksheet.sc:87)
23/11/27 15:07:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:14 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[37] at show at SparkTest.worksheet.sc:87), which has no missing parents
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 15.9 KiB, free 433.8 MiB)
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 6.7 KiB, free 433.8 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.25.86.80:39667 (size: 6.7 KiB, free: 434.3 MiB)
23/11/27 15:07:14 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[37] at show at SparkTest.worksheet.sc:87) (first 15 tasks are for partitions Vector(5))
23/11/27 15:07:14 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks resource profile 0
23/11/27 15:07:14 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 111) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 8419 bytes) 
23/11/27 15:07:14 INFO Executor: Running task 0.0 in stage 23.0 (TID 111)
23/11/27 15:07:14 INFO FileScanRDD: Reading File path: file:///home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/dataframes/file.parquet/part-00000-8a6f02ba-ca0b-435d-bad4-6293d17222ca-c000.snappy.parquet, range: 0-501, partition values: [empty row]
23/11/27 15:07:14 INFO Executor: Finished task 0.0 in stage 23.0 (TID 111). 1749 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 111) in 5 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:14 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
23/11/27 15:07:14 INFO DAGScheduler: ResultStage 23 (show at SparkTest.worksheet.sc:87) finished in 0.008 s
23/11/27 15:07:14 INFO DAGScheduler: Job 21 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 23: Stage finished
23/11/27 15:07:14 INFO DAGScheduler: Job 21 finished: show at SparkTest.worksheet.sc:87, took 0.009493 s
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 10.25.86.80:39667 in memory (size: 76.8 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO CodeGenerator: Code generated in 16.049413 ms
23/11/27 15:07:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 15:07:14 INFO DAGScheduler: Got job 22 (show at SparkTest.worksheet.sc:100) with 1 output partitions
23/11/27 15:07:14 INFO DAGScheduler: Final stage: ResultStage 24 (show at SparkTest.worksheet.sc:100)
23/11/27 15:07:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:14 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[39] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 15.2 KiB, free 434.1 MiB)
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.25.86.80:39667 (size: 6.5 KiB, free: 434.3 MiB)
23/11/27 15:07:14 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[39] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:14 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
23/11/27 15:07:14 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 112) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:14 INFO Executor: Running task 0.0 in stage 24.0 (TID 112)
23/11/27 15:07:14 INFO Executor: Finished task 0.0 in stage 24.0 (TID 112). 1455 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 112) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:14 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
23/11/27 15:07:14 INFO DAGScheduler: ResultStage 24 (show at SparkTest.worksheet.sc:100) finished in 0.006 s
23/11/27 15:07:14 INFO DAGScheduler: Job 22 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
23/11/27 15:07:14 INFO DAGScheduler: Job 22 finished: show at SparkTest.worksheet.sc:100, took 0.007073 s
23/11/27 15:07:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 15:07:14 INFO DAGScheduler: Got job 23 (show at SparkTest.worksheet.sc:100) with 4 output partitions
23/11/27 15:07:14 INFO DAGScheduler: Final stage: ResultStage 25 (show at SparkTest.worksheet.sc:100)
23/11/27 15:07:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:14 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[39] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 15.2 KiB, free 434.1 MiB)
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.1 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.25.86.80:39667 (size: 6.5 KiB, free: 434.3 MiB)
23/11/27 15:07:14 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:14 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 25 (MapPartitionsRDD[39] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(1, 2, 3, 4))
23/11/27 15:07:14 INFO TaskSchedulerImpl: Adding task set 25.0 with 4 tasks resource profile 0
23/11/27 15:07:14 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 113) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 114) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 115) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 116) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:14 INFO Executor: Running task 0.0 in stage 25.0 (TID 113)
23/11/27 15:07:14 INFO Executor: Running task 1.0 in stage 25.0 (TID 114)
23/11/27 15:07:14 INFO Executor: Running task 3.0 in stage 25.0 (TID 116)
23/11/27 15:07:14 INFO Executor: Running task 2.0 in stage 25.0 (TID 115)
23/11/27 15:07:14 INFO Executor: Finished task 1.0 in stage 25.0 (TID 114). 1412 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 3.0 in stage 25.0 (TID 116). 1412 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 0.0 in stage 25.0 (TID 113). 1412 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 114) in 2 ms on 10.25.86.80 (executor driver) (1/4)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 116) in 2 ms on 10.25.86.80 (executor driver) (2/4)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 113) in 4 ms on 10.25.86.80 (executor driver) (3/4)
23/11/27 15:07:14 INFO Executor: Finished task 2.0 in stage 25.0 (TID 115). 1511 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 115) in 7 ms on 10.25.86.80 (executor driver) (4/4)
23/11/27 15:07:14 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
23/11/27 15:07:14 INFO DAGScheduler: ResultStage 25 (show at SparkTest.worksheet.sc:100) finished in 0.010 s
23/11/27 15:07:14 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
23/11/27 15:07:14 INFO DAGScheduler: Job 23 finished: show at SparkTest.worksheet.sc:100, took 0.011001 s
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 10.25.86.80:39667 in memory (size: 34.9 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 10.25.86.80:39667 in memory (size: 6.7 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:100
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 10.25.86.80:39667 in memory (size: 6.7 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO DAGScheduler: Got job 24 (show at SparkTest.worksheet.sc:100) with 11 output partitions
23/11/27 15:07:14 INFO DAGScheduler: Final stage: ResultStage 26 (show at SparkTest.worksheet.sc:100)
23/11/27 15:07:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:14 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[39] at show at SparkTest.worksheet.sc:100), which has no missing parents
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 10.25.86.80:39667 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 15.2 KiB, free 434.4 MiB)
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 434.4 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.25.86.80:39667 (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:14 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 26 (MapPartitionsRDD[39] at show at SparkTest.worksheet.sc:100) (first 15 tasks are for partitions Vector(5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15))
23/11/27 15:07:14 INFO TaskSchedulerImpl: Adding task set 26.0 with 11 tasks resource profile 0
23/11/27 15:07:14 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 117) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 118) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 119) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 120) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 4.0 in stage 26.0 (TID 121) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 5.0 in stage 26.0 (TID 122) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 6.0 in stage 26.0 (TID 123) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 7.0 in stage 26.0 (TID 124) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 8.0 in stage 26.0 (TID 125) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 9.0 in stage 26.0 (TID 126) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7763 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 10.0 in stage 26.0 (TID 127) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7953 bytes) 
23/11/27 15:07:14 INFO Executor: Running task 0.0 in stage 26.0 (TID 117)
23/11/27 15:07:14 INFO Executor: Running task 3.0 in stage 26.0 (TID 120)
23/11/27 15:07:14 INFO Executor: Running task 1.0 in stage 26.0 (TID 118)
23/11/27 15:07:14 INFO Executor: Running task 7.0 in stage 26.0 (TID 124)
23/11/27 15:07:14 INFO Executor: Running task 8.0 in stage 26.0 (TID 125)
23/11/27 15:07:14 INFO Executor: Running task 6.0 in stage 26.0 (TID 123)
23/11/27 15:07:14 INFO Executor: Running task 9.0 in stage 26.0 (TID 126)
23/11/27 15:07:14 INFO Executor: Running task 2.0 in stage 26.0 (TID 119)
23/11/27 15:07:14 INFO Executor: Running task 10.0 in stage 26.0 (TID 127)
23/11/27 15:07:14 INFO Executor: Running task 5.0 in stage 26.0 (TID 122)
23/11/27 15:07:14 INFO Executor: Running task 4.0 in stage 26.0 (TID 121)
23/11/27 15:07:14 INFO Executor: Finished task 0.0 in stage 26.0 (TID 117). 1455 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 5.0 in stage 26.0 (TID 122). 1455 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 8.0 in stage 26.0 (TID 125). 1455 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 9.0 in stage 26.0 (TID 126). 1455 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 2.0 in stage 26.0 (TID 119). 1455 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 6.0 in stage 26.0 (TID 123). 1455 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 3.0 in stage 26.0 (TID 120). 1455 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 117) in 6 ms on 10.25.86.80 (executor driver) (1/11)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 5.0 in stage 26.0 (TID 122) in 5 ms on 10.25.86.80 (executor driver) (2/11)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 8.0 in stage 26.0 (TID 125) in 5 ms on 10.25.86.80 (executor driver) (3/11)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 119) in 6 ms on 10.25.86.80 (executor driver) (4/11)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 9.0 in stage 26.0 (TID 126) in 5 ms on 10.25.86.80 (executor driver) (5/11)
23/11/27 15:07:14 INFO Executor: Finished task 4.0 in stage 26.0 (TID 121). 1554 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 10.0 in stage 26.0 (TID 127). 1547 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 1.0 in stage 26.0 (TID 118). 1554 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 120) in 7 ms on 10.25.86.80 (executor driver) (6/11)
23/11/27 15:07:14 INFO Executor: Finished task 7.0 in stage 26.0 (TID 124). 1547 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 6.0 in stage 26.0 (TID 123) in 6 ms on 10.25.86.80 (executor driver) (7/11)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 4.0 in stage 26.0 (TID 121) in 7 ms on 10.25.86.80 (executor driver) (8/11)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 10.0 in stage 26.0 (TID 127) in 6 ms on 10.25.86.80 (executor driver) (9/11)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 118) in 7 ms on 10.25.86.80 (executor driver) (10/11)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 7.0 in stage 26.0 (TID 124) in 6 ms on 10.25.86.80 (executor driver) (11/11)
23/11/27 15:07:14 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
23/11/27 15:07:14 INFO DAGScheduler: ResultStage 26 (show at SparkTest.worksheet.sc:100) finished in 0.011 s
23/11/27 15:07:14 INFO DAGScheduler: Job 24 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 26: Stage finished
23/11/27 15:07:14 INFO DAGScheduler: Job 24 finished: show at SparkTest.worksheet.sc:100, took 0.011882 s
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 10.25.86.80:39667 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 10.25.86.80:39667 in memory (size: 6.5 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO DAGScheduler: Registering RDD 41 (show at SparkTest.worksheet.sc:116) as input to shuffle 1
23/11/27 15:07:14 INFO DAGScheduler: Got map stage job 25 (show at SparkTest.worksheet.sc:116) with 16 output partitions
23/11/27 15:07:14 INFO DAGScheduler: Final stage: ShuffleMapStage 27 (show at SparkTest.worksheet.sc:116)
23/11/27 15:07:14 INFO DAGScheduler: Parents of final stage: List()
23/11/27 15:07:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:14 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[41] at show at SparkTest.worksheet.sc:116), which has no missing parents
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 17.1 KiB, free 434.4 MiB)
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 434.4 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.25.86.80:39667 (size: 7.6 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:14 INFO DAGScheduler: Submitting 16 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[41] at show at SparkTest.worksheet.sc:116) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
23/11/27 15:07:14 INFO TaskSchedulerImpl: Adding task set 27.0 with 16 tasks resource profile 0
23/11/27 15:07:14 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 128) (10.25.86.80, executor driver, partition 0, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 129) (10.25.86.80, executor driver, partition 1, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 130) (10.25.86.80, executor driver, partition 2, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 3.0 in stage 27.0 (TID 131) (10.25.86.80, executor driver, partition 3, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 4.0 in stage 27.0 (TID 132) (10.25.86.80, executor driver, partition 4, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 5.0 in stage 27.0 (TID 133) (10.25.86.80, executor driver, partition 5, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 6.0 in stage 27.0 (TID 134) (10.25.86.80, executor driver, partition 6, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 7.0 in stage 27.0 (TID 135) (10.25.86.80, executor driver, partition 7, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 8.0 in stage 27.0 (TID 136) (10.25.86.80, executor driver, partition 8, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 9.0 in stage 27.0 (TID 137) (10.25.86.80, executor driver, partition 9, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 10.0 in stage 27.0 (TID 138) (10.25.86.80, executor driver, partition 10, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 11.0 in stage 27.0 (TID 139) (10.25.86.80, executor driver, partition 11, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 12.0 in stage 27.0 (TID 140) (10.25.86.80, executor driver, partition 12, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 13.0 in stage 27.0 (TID 141) (10.25.86.80, executor driver, partition 13, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 14.0 in stage 27.0 (TID 142) (10.25.86.80, executor driver, partition 14, PROCESS_LOCAL, 7752 bytes) 
23/11/27 15:07:14 INFO TaskSetManager: Starting task 15.0 in stage 27.0 (TID 143) (10.25.86.80, executor driver, partition 15, PROCESS_LOCAL, 7942 bytes) 
23/11/27 15:07:14 INFO Executor: Running task 0.0 in stage 27.0 (TID 128)
23/11/27 15:07:14 INFO Executor: Running task 4.0 in stage 27.0 (TID 132)
23/11/27 15:07:14 INFO Executor: Running task 6.0 in stage 27.0 (TID 134)
23/11/27 15:07:14 INFO Executor: Running task 7.0 in stage 27.0 (TID 135)
23/11/27 15:07:14 INFO Executor: Running task 8.0 in stage 27.0 (TID 136)
23/11/27 15:07:14 INFO Executor: Running task 10.0 in stage 27.0 (TID 138)
23/11/27 15:07:14 INFO Executor: Running task 12.0 in stage 27.0 (TID 140)
23/11/27 15:07:14 INFO Executor: Running task 14.0 in stage 27.0 (TID 142)
23/11/27 15:07:14 INFO Executor: Running task 1.0 in stage 27.0 (TID 129)
23/11/27 15:07:14 INFO Executor: Running task 3.0 in stage 27.0 (TID 131)
23/11/27 15:07:14 INFO Executor: Running task 2.0 in stage 27.0 (TID 130)
23/11/27 15:07:14 INFO Executor: Running task 15.0 in stage 27.0 (TID 143)
23/11/27 15:07:14 INFO Executor: Running task 13.0 in stage 27.0 (TID 141)
23/11/27 15:07:14 INFO Executor: Running task 11.0 in stage 27.0 (TID 139)
23/11/27 15:07:14 INFO Executor: Running task 9.0 in stage 27.0 (TID 137)
23/11/27 15:07:14 INFO Executor: Running task 5.0 in stage 27.0 (TID 133)
23/11/27 15:07:14 INFO Executor: Finished task 7.0 in stage 27.0 (TID 135). 1905 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 0.0 in stage 27.0 (TID 128). 1905 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 10.0 in stage 27.0 (TID 138). 1905 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 14.0 in stage 27.0 (TID 142). 1905 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 4.0 in stage 27.0 (TID 132). 1905 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 13.0 in stage 27.0 (TID 141). 1905 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 128) in 15 ms on 10.25.86.80 (executor driver) (1/16)
23/11/27 15:07:14 INFO Executor: Finished task 5.0 in stage 27.0 (TID 133). 1905 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 8.0 in stage 27.0 (TID 136). 1905 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 4.0 in stage 27.0 (TID 132) in 15 ms on 10.25.86.80 (executor driver) (2/16)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 5.0 in stage 27.0 (TID 133) in 14 ms on 10.25.86.80 (executor driver) (3/16)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 13.0 in stage 27.0 (TID 141) in 14 ms on 10.25.86.80 (executor driver) (4/16)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 8.0 in stage 27.0 (TID 136) in 14 ms on 10.25.86.80 (executor driver) (5/16)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 7.0 in stage 27.0 (TID 135) in 14 ms on 10.25.86.80 (executor driver) (6/16)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 14.0 in stage 27.0 (TID 142) in 14 ms on 10.25.86.80 (executor driver) (7/16)
23/11/27 15:07:14 INFO Executor: Finished task 11.0 in stage 27.0 (TID 139). 1905 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 10.0 in stage 27.0 (TID 138) in 15 ms on 10.25.86.80 (executor driver) (8/16)
23/11/27 15:07:14 INFO Executor: Finished task 2.0 in stage 27.0 (TID 130). 1905 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 11.0 in stage 27.0 (TID 139) in 15 ms on 10.25.86.80 (executor driver) (9/16)
23/11/27 15:07:14 INFO Executor: Finished task 1.0 in stage 27.0 (TID 129). 1905 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 130) in 16 ms on 10.25.86.80 (executor driver) (10/16)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 129) in 16 ms on 10.25.86.80 (executor driver) (11/16)
23/11/27 15:07:14 INFO Executor: Finished task 9.0 in stage 27.0 (TID 137). 2034 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 3.0 in stage 27.0 (TID 131). 2034 bytes result sent to driver
23/11/27 15:07:14 INFO Executor: Finished task 6.0 in stage 27.0 (TID 134). 2034 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 9.0 in stage 27.0 (TID 137) in 19 ms on 10.25.86.80 (executor driver) (12/16)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 3.0 in stage 27.0 (TID 131) in 20 ms on 10.25.86.80 (executor driver) (13/16)
23/11/27 15:07:14 INFO Executor: Finished task 12.0 in stage 27.0 (TID 140). 2034 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 6.0 in stage 27.0 (TID 134) in 19 ms on 10.25.86.80 (executor driver) (14/16)
23/11/27 15:07:14 INFO Executor: Finished task 15.0 in stage 27.0 (TID 143). 1991 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 12.0 in stage 27.0 (TID 140) in 20 ms on 10.25.86.80 (executor driver) (15/16)
23/11/27 15:07:14 INFO TaskSetManager: Finished task 15.0 in stage 27.0 (TID 143) in 19 ms on 10.25.86.80 (executor driver) (16/16)
23/11/27 15:07:14 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
23/11/27 15:07:14 INFO DAGScheduler: ShuffleMapStage 27 (show at SparkTest.worksheet.sc:116) finished in 0.026 s
23/11/27 15:07:14 INFO DAGScheduler: looking for newly runnable stages
23/11/27 15:07:14 INFO DAGScheduler: running: HashSet()
23/11/27 15:07:14 INFO DAGScheduler: waiting: HashSet()
23/11/27 15:07:14 INFO DAGScheduler: failed: HashSet()
23/11/27 15:07:14 INFO ShufflePartitionsUtil: For shuffle(1, 1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/27 15:07:14 INFO CodeGenerator: Code generated in 11.791236 ms
23/11/27 15:07:14 INFO CodeGenerator: Code generated in 4.583154 ms
23/11/27 15:07:14 INFO CodeGenerator: Code generated in 4.579871 ms
23/11/27 15:07:14 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/27 15:07:14 INFO DAGScheduler: Got job 26 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
23/11/27 15:07:14 INFO DAGScheduler: Final stage: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
23/11/27 15:07:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
23/11/27 15:07:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:14 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[48] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 39.1 KiB, free 434.3 MiB)
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 434.3 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.25.86.80:39667 (size: 16.4 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[48] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:14 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks resource profile 0
23/11/27 15:07:14 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 144) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 8193 bytes) 
23/11/27 15:07:14 INFO Executor: Running task 0.0 in stage 29.0 (TID 144)
23/11/27 15:07:14 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 15:07:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/27 15:07:14 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 15:07:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/27 15:07:14 INFO Executor: Finished task 0.0 in stage 29.0 (TID 144). 4879 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 144) in 9 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:14 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
23/11/27 15:07:14 INFO DAGScheduler: ResultStage 29 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.013 s
23/11/27 15:07:14 INFO DAGScheduler: Job 26 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 29: Stage finished
23/11/27 15:07:14 INFO DAGScheduler: Job 26 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.015344 s
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 10.25.86.80:39667 in memory (size: 16.4 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 10.25.86.80:39667 in memory (size: 7.6 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO CodeGenerator: Code generated in 7.032388 ms
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 1025.0 KiB, free 433.4 MiB)
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 279.0 B, free 433.4 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.25.86.80:39667 (size: 279.0 B, free: 434.4 MiB)
23/11/27 15:07:14 INFO SparkContext: Created broadcast 30 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
23/11/27 15:07:14 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
23/11/27 15:07:14 INFO CodeGenerator: Code generated in 6.149046 ms
23/11/27 15:07:14 INFO SparkContext: Starting job: show at SparkTest.worksheet.sc:116
23/11/27 15:07:14 INFO DAGScheduler: Got job 27 (show at SparkTest.worksheet.sc:116) with 1 output partitions
23/11/27 15:07:14 INFO DAGScheduler: Final stage: ResultStage 31 (show at SparkTest.worksheet.sc:116)
23/11/27 15:07:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 30)
23/11/27 15:07:14 INFO DAGScheduler: Missing parents: List()
23/11/27 15:07:14 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[51] at show at SparkTest.worksheet.sc:116), which has no missing parents
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 15.3 KiB, free 433.4 MiB)
23/11/27 15:07:14 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 433.4 MiB)
23/11/27 15:07:14 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.25.86.80:39667 (size: 7.0 KiB, free: 434.4 MiB)
23/11/27 15:07:14 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1580
23/11/27 15:07:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[51] at show at SparkTest.worksheet.sc:116) (first 15 tasks are for partitions Vector(0))
23/11/27 15:07:14 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
23/11/27 15:07:14 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 145) (10.25.86.80, executor driver, partition 0, NODE_LOCAL, 7711 bytes) 
23/11/27 15:07:14 INFO Executor: Running task 0.0 in stage 31.0 (TID 145)
23/11/27 15:07:14 INFO ShuffleBlockFetcherIterator: Getting 5 (392.0 B) non-empty blocks including 5 (392.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
23/11/27 15:07:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
23/11/27 15:07:14 INFO Executor: Finished task 0.0 in stage 31.0 (TID 145). 3946 bytes result sent to driver
23/11/27 15:07:14 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 145) in 3 ms on 10.25.86.80 (executor driver) (1/1)
23/11/27 15:07:14 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
23/11/27 15:07:14 INFO DAGScheduler: ResultStage 31 (show at SparkTest.worksheet.sc:116) finished in 0.006 s
23/11/27 15:07:14 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
23/11/27 15:07:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 31: Stage finished
23/11/27 15:07:14 INFO DAGScheduler: Job 27 finished: show at SparkTest.worksheet.sc:116, took 0.007231 s
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 10.25.86.80:39667 in memory (size: 7.0 KiB, free: 434.4 MiB)
2023.11.27 15:07:14 INFO  time: evaluated worksheet 'SparkTest.worksheet.sc' in 1.91s[0m
23/11/27 15:07:14 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 10.25.86.80:39667 in memory (size: 279.0 B, free: 434.4 MiB)
2023.11.27 15:08:10 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 15:08:10 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
2023.11.27 15:08:11 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 15:08:11 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.13s[0m
2023.11.27 15:08:13 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala
scala.meta.tokenizers.TokenizeException: <input>:68: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.27 15:08:14 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 15:08:14 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 64ms[0m
2023.11.27 15:08:14 ERROR Failed to tokenize input for semantic tokens for /home/bsoleille/gitea/project-effective-scala-c1-s14-3039-4085/src/main/scala/startup/Dataframe.scala
scala.meta.tokenizers.TokenizeException: <input>:68: error: unclosed comment
/*
^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.skipNestedComments(LegacyScanner.scala:52)
	at scala.meta.internal.tokenizers.LegacyScanner.skipToCommentEnd(LegacyScanner.scala:71)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:313)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:829)
[0m
2023.11.27 15:08:20 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 15:08:20 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.22s[0m
2023.11.27 15:08:21 INFO  compiling project-effective-scala-c1-s14-3039-4085 (1 scala source)[0m
2023.11.27 15:08:21 INFO  time: compiled project-effective-scala-c1-s14-3039-4085 in 0.23s[0m
